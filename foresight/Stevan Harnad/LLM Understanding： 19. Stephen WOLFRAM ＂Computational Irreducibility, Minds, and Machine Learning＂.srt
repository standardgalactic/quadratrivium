1
00:00:00,000 --> 00:00:03,840
Even Wolfram is a mathematician, computer scientist,

2
00:00:03,840 --> 00:00:09,200
physicist, and businessman. Have I lied so far, Steve?

3
00:00:09,200 --> 00:00:13,680
I don't know. So some people would not put mathematician first, but that's okay.

4
00:00:13,680 --> 00:00:17,680
He's known for his work in computer science, mathematics, and theoretical

5
00:00:17,680 --> 00:00:19,920
physics. The fellow of the American Mathematical

6
00:00:19,920 --> 00:00:23,920
Society, founder and CEO of the software company

7
00:00:23,920 --> 00:00:27,840
Wolfram Research, where he works as chief designer of Mathematica,

8
00:00:27,840 --> 00:00:34,560
at the Wolfram Alpha NSERP engine. Now I'm going to move that away,

9
00:00:34,560 --> 00:00:39,920
and I'm going to give it, you have also, besides the people in the

10
00:00:39,920 --> 00:00:45,600
the attendees, there's also one, two, three, four, five

11
00:00:45,600 --> 00:00:48,320
panelists that are here so far, and there might be some more.

12
00:00:48,320 --> 00:00:54,080
Carl Friston, Ronnie Katzier, Sammy Benjiro. I can see the names, yeah.

13
00:00:54,080 --> 00:00:57,840
Hi, Carl. The rest of you, I don't know, so nice to meet you.

14
00:00:57,840 --> 00:01:02,080
Sammy, it's the other Benjiro. We'll find out more about that. He's the

15
00:01:02,080 --> 00:01:07,920
brother of Yoshua, who is the co-sponsor of this event.

16
00:01:07,920 --> 00:01:14,320
Okay, it's all yours. Wing it. Okay, so, well, let's see.

17
00:01:14,320 --> 00:01:18,960
So I think you guys want to talk about language,

18
00:01:18,960 --> 00:01:23,120
and computation, and AI, and all those good kinds of things, and I was

19
00:01:23,120 --> 00:01:27,600
thinking I could talk about things about LLMs and so on.

20
00:01:27,600 --> 00:01:31,920
You know, I wrote this little book last February about

21
00:01:31,920 --> 00:01:35,920
ChatGBT. You can find a version of it online. I can put it in the

22
00:01:35,920 --> 00:01:39,200
chat. It's, let me not talk about that, but if

23
00:01:39,200 --> 00:01:42,000
people want to ask about it, I'm happy to chat about it.

24
00:01:42,000 --> 00:01:45,440
I thought what I would try to do in 45 minutes give you

25
00:01:45,440 --> 00:01:50,560
kind of the, a very rough tour of my last four and a half decades of

26
00:01:50,560 --> 00:01:54,800
development of a worldview, and see how that relates to

27
00:01:54,800 --> 00:01:58,800
things about AI, and language, and so on.

28
00:01:58,800 --> 00:02:08,000
So to begin, you know, I think a thing that,

29
00:02:08,000 --> 00:02:11,920
sort of the, there's kind of this progression of paradigms

30
00:02:11,920 --> 00:02:16,000
to do with how we formalize the world. So there's sort of this

31
00:02:16,080 --> 00:02:21,920
question of what, what can we do? We start, when we, when we see the

32
00:02:21,920 --> 00:02:26,080
world, we're interested in finding ways to have sort of formal

33
00:02:26,080 --> 00:02:29,840
descriptions of it that we can build on. So historically, kind of the

34
00:02:29,840 --> 00:02:33,280
first of those, the big one for our species, was the invention of

35
00:02:33,280 --> 00:02:36,720
human language, and the idea that you didn't have to just point at

36
00:02:36,720 --> 00:02:39,840
each individual rock, but you could have this kind of symbolic

37
00:02:39,840 --> 00:02:45,040
name, rock, wasn't rock originally, obviously, for that concept, and

38
00:02:45,120 --> 00:02:50,000
you could communicate abstractly about that thing using human language.

39
00:02:50,000 --> 00:02:53,040
Now then, we've had sort of a stack of other ideas,

40
00:02:53,040 --> 00:02:58,000
another big idea is logic, being able to, as a way of sort of

41
00:02:58,000 --> 00:03:02,400
abstracting things about the world, formalizing things about the world.

42
00:03:02,400 --> 00:03:06,640
Another big direction is mathematics, being able to,

43
00:03:06,640 --> 00:03:09,760
something that sort of became big in the late 1600s,

44
00:03:09,840 --> 00:03:14,480
of being able to describe our world by mathematical concepts and constructs.

45
00:03:15,520 --> 00:03:20,640
In this century, and the end of the last one, the big new thing has been

46
00:03:20,640 --> 00:03:24,240
using computation as a way to formalize and describe the world.

47
00:03:24,880 --> 00:03:30,320
Being able to specify kind of if you, the way I think about computation,

48
00:03:30,320 --> 00:03:36,480
it's a way of setting up rules, and then saying, let these rules run.

49
00:03:36,480 --> 00:03:41,040
And the question is, can we set up rules that describe the way the world is,

50
00:03:41,040 --> 00:03:44,160
is, or the aspects of the world at least that we care about?

51
00:03:44,800 --> 00:03:49,760
And my kind of day job for the last four decades has been building our

52
00:03:49,760 --> 00:03:52,560
computational language, Wolfram Language, Mathematica, and so on,

53
00:03:53,120 --> 00:03:57,360
as a way to kind of take the things that we humans care about,

54
00:03:57,360 --> 00:04:02,480
whether they're molecules or cities or algorithms or whatever,

55
00:04:02,480 --> 00:04:09,040
and create a systematic computational language to let one describe those things,

56
00:04:09,040 --> 00:04:12,720
and not only describe them in a way that humans can read,

57
00:04:13,440 --> 00:04:19,520
but also something where computers can help humans to execute those things.

58
00:04:20,080 --> 00:04:23,040
So that's been kind of the way I see sort of that effort,

59
00:04:23,040 --> 00:04:28,080
is take the things that we humans care about, and find a way to formalize them

60
00:04:28,160 --> 00:04:32,960
computationally, so that we can provide sort of the raw material that we need

61
00:04:32,960 --> 00:04:36,080
to work with the world computationally. It's kind of the effort,

62
00:04:36,080 --> 00:04:39,120
is a bit like the effort that happened maybe 500 years ago,

63
00:04:39,120 --> 00:04:43,920
with the development of mathematical notation, where people went from kind of talking about

64
00:04:43,920 --> 00:04:48,320
math in terms of words, to having sort of a streamlined notation with plus signs and equal

65
00:04:48,320 --> 00:04:53,680
signs and things like that. And that idea of notation, that sort of streamlined notation

66
00:04:53,680 --> 00:04:58,320
for mathematics, is what ended up launching algebra and then calculus, and basically the

67
00:04:58,320 --> 00:05:05,120
modern mathematical sciences. Kind of my day job mission has been to create a computational

68
00:05:05,120 --> 00:05:14,080
language that lets one kind of launch computational x for all fields x. So okay, that's, so kind of

69
00:05:14,080 --> 00:05:20,320
this idea is computational language as a way to sort of formalize things that happen in the world,

70
00:05:20,320 --> 00:05:26,080
things that we care about in the world. Now the next question is what is the intrinsic description

71
00:05:26,080 --> 00:05:33,280
of the world, so to speak? How should we describe the world in general? And the thing that sort of

72
00:05:33,280 --> 00:05:38,320
had been the tradition of exact science for about 300 years, was use mathematical equations,

73
00:05:38,320 --> 00:05:43,600
write down an equation that describes this or that aspect of the world. The thing that I got

74
00:05:43,600 --> 00:05:49,760
interested in in the early 1980s is how does one generalize that idea? How does one, how does one,

75
00:05:49,760 --> 00:05:55,600
what kinds of raw material can you find to talk about the world? And the thing that I started

76
00:05:55,600 --> 00:06:00,640
studying a lot was using computation as kind of the raw material for describing the world.

77
00:06:01,360 --> 00:06:07,280
And so the question, the first question is, well okay, what kinds of, how do you set up kind of

78
00:06:07,280 --> 00:06:12,480
computational systems to do that? And for example, let's see, let's actually do something here.

79
00:06:14,560 --> 00:06:26,640
Okay, let's say we are just kind of, we want to see what do

80
00:06:27,600 --> 00:06:34,160
programs that might be computational descriptions of the world, what, let's just look at some

81
00:06:34,160 --> 00:06:42,960
program that, just say what do the typical programs out there do? So this is a very simple example,

82
00:06:43,040 --> 00:06:48,080
it's just you imagine a line of black and white cells and you have some simple rule that says,

83
00:06:48,080 --> 00:06:52,960
given the colors of cells on one row, these are the, this is the color, this is how you determine

84
00:06:52,960 --> 00:07:02,080
the color of the cells on the next row. So if you run this and just run this starting,

85
00:07:02,080 --> 00:07:08,480
let's say, from one black cell, let's run it for like 40 steps. According to that rule,

86
00:07:09,040 --> 00:07:13,680
you start off from, you end up with something where you have this very simple rule, very

87
00:07:13,680 --> 00:07:18,240
simple computational rule, you run it, you get this very simple pattern. Now the question is,

88
00:07:18,240 --> 00:07:22,560
what happens if we look at other kinds of rules? What happens if we kind of turn our

89
00:07:22,560 --> 00:07:27,200
computational telescope out into the computational universe and just look at what's out there?

90
00:07:27,840 --> 00:07:33,840
So we can do that, let's do this, let's just make a, let's just make a table of

91
00:07:33,920 --> 00:07:45,360
all possible rules, let's say the first 63 of these rules, 64 of these rules.

92
00:07:46,160 --> 00:07:49,920
Okay, so each one of these rules corresponds, each one of these pictures

93
00:07:50,640 --> 00:07:56,320
corresponds to a different rule for how the colors of cells are determined by colors of

94
00:07:56,320 --> 00:08:02,480
cells above them. What we see is many of these patterns are very simple, sometimes we'll get

95
00:08:02,480 --> 00:08:07,120
slightly more complicated patterns, we might get a nested pattern, for example, here,

96
00:08:07,760 --> 00:08:11,680
but the thing that is kind of my all-time favorite science discovery that I made almost

97
00:08:11,680 --> 00:08:17,840
exactly 40 years ago, it was 40 years ago on June 1st, is this thing that I call rule 30.

98
00:08:18,480 --> 00:08:26,160
It's specified by this set of cases here, and if we just run,

99
00:08:26,480 --> 00:08:37,600
just run this, started off from single black cell, let's run it for let's say 200 steps,

100
00:08:39,920 --> 00:08:46,240
this is what we get. And to me, this is something very surprising and kind of intuition breaking.

101
00:08:46,240 --> 00:08:53,200
We have a very simple rule, and yet when we run that rule, we're generating something that looks

102
00:08:53,200 --> 00:08:58,640
at least to us very complicated. And actually, you can go and you can sort of work out what's the

103
00:08:58,640 --> 00:09:03,760
center column of cells here, and for all practical purposes, it seems completely random. But so what

104
00:09:03,760 --> 00:09:09,600
this is telling us is out in the computational universe, even very simple rules can easily give

105
00:09:09,600 --> 00:09:15,040
one very complicated behavior. And there are a lot of consequences of this. One thing that this led

106
00:09:15,040 --> 00:09:20,560
me to is this thing I call the principle of computational equivalence. So the thing that is

107
00:09:20,560 --> 00:09:26,000
sort of a big question is, how do you characterize what's going on in a system like this? Well,

108
00:09:26,000 --> 00:09:32,000
you can think about the system as performing a computation. It starts from its initial conditions

109
00:09:32,000 --> 00:09:38,320
at the top, and then it's going crunch, crunch, crunch, and and executing a computation. The

110
00:09:38,320 --> 00:09:43,200
question then is sort of how sophisticated is that computation? And we might have thought, well,

111
00:09:43,200 --> 00:09:47,600
it's just a simple rule, it's doing what it does. If we think about the kinds of computations that,

112
00:09:47,680 --> 00:09:51,760
for example, we do in our brains, well, those are going to be much more sophisticated than this.

113
00:09:52,560 --> 00:09:57,680
But what the principle of computational equivalence says is that actually that's not true.

114
00:09:57,680 --> 00:10:03,920
Above some very low threshold, essentially, all of these kinds of systems, regardless of how simple

115
00:10:03,920 --> 00:10:09,920
their rules are, are equivalent in the sophistication of the computations that they can do. So that

116
00:10:09,920 --> 00:10:15,120
means that in a sense, this little rule 30 thing is doing a computation that's just as sophisticated

117
00:10:15,200 --> 00:10:20,720
as the computations that go on, for example, in our brains. Well, what consequences does that have?

118
00:10:21,600 --> 00:10:27,120
One consequence that has is this phenomenon I call computational irreducibility. So let's say

119
00:10:27,120 --> 00:10:32,400
you want to know what this, well, how this pattern is going to work out a billion steps

120
00:10:32,400 --> 00:10:37,600
later from now. Well, how do you how do you figure that out? One way you can figure that out is just

121
00:10:37,600 --> 00:10:42,320
to follow those billion steps and see what happens. Another thing you can do is to say, wait a minute,

122
00:10:42,400 --> 00:10:46,080
I'm much smarter than this system. I'm just going to jump ahead and I'm going to say,

123
00:10:46,080 --> 00:10:51,040
I know what the answer is after a billion steps. That's the thing we've become used to

124
00:10:51,040 --> 00:10:57,760
in doing, for example, mathematical science. You imagine an idealized planet orbiting a star.

125
00:10:57,760 --> 00:11:02,160
You say, do you have to work out where it's going to be a million years from now? Do you have to

126
00:11:02,160 --> 00:11:07,600
follow those million orbits? Or can you just use a formula and kind of fill in the number of million

127
00:11:07,600 --> 00:11:12,000
and jump ahead and see what the answer is? That kind of what we can call computational

128
00:11:12,000 --> 00:11:17,120
reducibility is what we've become used to from kind of what happens in mathematical science.

129
00:11:17,840 --> 00:11:22,560
But the principle of computational equivalence tells us that will not generally be what one

130
00:11:22,560 --> 00:11:28,320
can do. In general, the systems that we're studying will be just as computationally sophisticated

131
00:11:28,320 --> 00:11:32,960
as anything that we can muster in studying them. And so that means we won't be able to do that kind

132
00:11:32,960 --> 00:11:37,680
of jumping ahead. We won't be able to do that kind of computational outrunning of the system

133
00:11:37,680 --> 00:11:41,520
and will be reduced to something where to work out what the system does,

134
00:11:41,520 --> 00:11:47,040
we basically have to follow every step and see what the outcome is. So this is something which

135
00:11:47,600 --> 00:11:53,200
or kind of in a sense for science, it's telling when there's a major limitation on science. And

136
00:11:53,200 --> 00:11:58,640
by the way, this idea is something, things like girl's theorem, a sort of a special case of this

137
00:11:58,640 --> 00:12:03,600
idea and lots of other kinds of things that one knows about universal computation and so on

138
00:12:03,600 --> 00:12:10,240
is also related to this. But this is kind of a tighter version of those kinds of ideas

139
00:12:11,200 --> 00:12:16,800
and one which I think sort of shows one kind of the relationship of these things to science.

140
00:12:16,800 --> 00:12:22,320
And sort of the big consequences, there's lots of stuff that you won't be able to

141
00:12:22,320 --> 00:12:27,600
have a theory for, work out, jump ahead, know what's going to happen. You'll have to just follow

142
00:12:27,600 --> 00:12:34,320
every step and see what happens. And so in a sense, that's a limitation on science. From within

143
00:12:34,320 --> 00:12:39,680
science, one is seeing kind of a fundamental limitation of science. It's actually something

144
00:12:39,680 --> 00:12:44,480
which for many purposes might, one might not think of being a such bad thing, because in a sense,

145
00:12:44,480 --> 00:12:50,240
it's the thing that makes, for example, the passage of time meaningful. If it wasn't for

146
00:12:50,240 --> 00:12:58,160
computational irreducibility, then if you live for 50 years, then in a sense, that would not be,

147
00:12:58,160 --> 00:13:02,720
nothing would be achieved by that. One would be able to say, oh, I know what's going to happen in

148
00:13:02,720 --> 00:13:07,200
the end. I can jump ahead and say what the outcome is going to be. But because of computational

149
00:13:07,200 --> 00:13:12,720
irreducibility, there is something sort of really happening in the passage of time. It is a sort of

150
00:13:12,720 --> 00:13:17,200
an irreducible computation that's going on. There are many other consequences of computational

151
00:13:17,280 --> 00:13:23,040
irreducibility. For example, when it comes to things like AI, we can ask the question,

152
00:13:24,160 --> 00:13:29,840
what in so far as AI is doing computation? And we'll talk about the sense maybe later

153
00:13:29,840 --> 00:13:35,440
in which typical modern neural nets are doing only very weak levels of computation.

154
00:13:35,440 --> 00:13:41,040
But let's imagine that we have a system that is doing computation as computation can be done.

155
00:13:41,680 --> 00:13:47,760
Well, we sort of have a choice. Either we can say that system is we're going to make that system

156
00:13:47,760 --> 00:13:52,800
computationally reducible. So we know what the outcome is going to be. And so, for example,

157
00:13:52,800 --> 00:13:58,000
we can say we're absolutely sure this system will never do the wrong thing because we know its outcomes

158
00:13:58,000 --> 00:14:03,360
and we can constrain it to say that, to set it up so we can sort of prove that we'll never do the

159
00:14:03,360 --> 00:14:07,680
wrong thing. It's reducible enough that we can know enough about what it's going to do that we

160
00:14:07,680 --> 00:14:14,080
can know it isn't going to do the wrong thing. So that's plan A. But the problem with plan A

161
00:14:14,080 --> 00:14:19,840
is that means that the system can't do irreducible computations. The system can only do computations

162
00:14:19,840 --> 00:14:24,720
where we can jump ahead and foresee the outcome. So in a sense, that means we're crippling the

163
00:14:24,720 --> 00:14:29,520
system. We're preventing it from doing what it could do as a computational system. We're saying

164
00:14:29,520 --> 00:14:34,640
it's only going to do those things which are kind of reducible. So in a sense, I think it's going

165
00:14:34,720 --> 00:14:41,360
to end up being sort of a big societal choice is, do we want the AIs, computational systems,

166
00:14:41,360 --> 00:14:45,200
to be able to do all the powerful things that computational systems can do,

167
00:14:45,200 --> 00:14:49,280
or do we want to insist that they'll only do things where we can foresee what they'll do?

168
00:14:49,920 --> 00:15:02,000
And in a sense, it's kind of like we have a, you could say, well, I'm going to set up all these

169
00:15:02,000 --> 00:15:08,240
rules for the AIs that make sure they only do the right things. Well, to make that work,

170
00:15:08,240 --> 00:15:13,440
you have to have the AIs be sort of computationally reducible. If they're computationally

171
00:15:13,440 --> 00:15:18,080
irreducible, well, maybe you can constrain it in all sorts of ways, but there'll always be surprises.

172
00:15:18,080 --> 00:15:22,160
There'll always be things where you can't foresee that particular outcome. By the way,

173
00:15:22,160 --> 00:15:27,360
computational irreducibility has many, many consequences. But another consequence it has

174
00:15:27,360 --> 00:15:33,280
is that sort of science will never be finished. There will always be, if we think about kind of,

175
00:15:33,280 --> 00:15:38,000
there'll always be things where we can't foresee the next thing that will happen.

176
00:15:38,000 --> 00:15:42,560
There will always be surprises in mathematics. There will always be new theorems that can be

177
00:15:42,560 --> 00:15:47,600
proved and so on. The thing that is an issue there in terms of things like will science be

178
00:15:47,600 --> 00:15:54,960
finished and so on is, well, okay, there might be things that were surprises, but are they surprises

179
00:15:54,960 --> 00:15:59,440
we care about? If we were exploring all of mathematics, we would prove more and more and more

180
00:15:59,440 --> 00:16:04,240
theorems. But it could be that we get to the point where we know all the theorems we care about,

181
00:16:04,240 --> 00:16:08,000
and anything else is something we're not going to care about. So in a sense, it's a,

182
00:16:08,000 --> 00:16:15,120
there's sort of this, this connection to sort of human issues in what, but the point is that

183
00:16:15,120 --> 00:16:21,120
there is ultimately an infinite and unlimited frontier of what's possible to discover in science

184
00:16:21,200 --> 00:16:25,760
and so on. By the way, that also relates, maybe we can talk about, to things like,

185
00:16:27,440 --> 00:16:33,920
well, okay, let's, let's maybe talk about, so, so kind of this, this idea of computational

186
00:16:33,920 --> 00:16:39,840
irreducibility, that you can't know the outcome of a computational process in general, except by

187
00:16:39,840 --> 00:16:45,040
running it and seeing what happens. Limitation on science, thing that makes the passage of time

188
00:16:45,040 --> 00:17:00,720
meaningful, kind of dichotomy for thinking about AI and so on. It's the, so that, so let's see,

189
00:17:01,680 --> 00:17:08,320
one of the things that's sort of interesting about this is we can just sort of, in this

190
00:17:08,320 --> 00:17:15,040
computational universe, we'll find all sorts of, of things that go on. The question becomes,

191
00:17:15,040 --> 00:17:20,480
sort of, are those things that we find out there, things that we care about or not? In other words,

192
00:17:20,480 --> 00:17:26,320
we can go and we can, oh, I don't know, we can, you know, that's a, an example of just a simple

193
00:17:26,320 --> 00:17:31,120
rule and what it does and we can get the lots of other, lots of other examples we can, we can,

194
00:17:31,840 --> 00:17:41,040
we can go and do this ourselves if we want to, let's see, and just go find very simple rules

195
00:17:41,040 --> 00:17:45,280
that do very complicated things. It's easy to kind of launch out into the computational

196
00:17:45,280 --> 00:17:53,360
universe and find these things. The question ends up being, so how, what do we humans care about

197
00:17:53,360 --> 00:17:59,280
these things? Well, it could be that this particular thing, we will be able to use it for

198
00:17:59,280 --> 00:18:03,840
technology in some way. It could be that we'll think this is something very important for art,

199
00:18:04,400 --> 00:18:08,080
but it's something where out there in the computational universe, there's kind of an

200
00:18:08,080 --> 00:18:15,440
infinite supply of original things. The question is, which ones do we humans choose to care about?

201
00:18:16,240 --> 00:18:23,600
And, and for example, if we imagine kind of the, the, the future of AIs, you can say, okay AI,

202
00:18:23,600 --> 00:18:28,240
go out into the computational universe, you can go and create things that have never been seen

203
00:18:28,240 --> 00:18:33,760
before, all kinds of things. The question is, are those things that are of, of kind of human

204
00:18:33,760 --> 00:18:40,080
relevance to us now? Well, one thing you might do, you can actually do a little experiment here,

205
00:18:40,080 --> 00:18:48,640
let me show you something. Where is it? So for example, we could say we could take some image

206
00:18:48,640 --> 00:18:58,880
generation AI, and this is just a diffusion image generator. And we could say, let's, let's look,

207
00:18:58,880 --> 00:19:05,440
let's ask the thing to make a picture of a cat in a party hat. Okay, but inside the AI,

208
00:19:06,080 --> 00:19:11,920
it's got some, you know, embedding vector, it's got some, some set of numbers that describe

209
00:19:11,920 --> 00:19:17,280
that is its version of what that concept is. But one thing we could do is something very simple

210
00:19:18,080 --> 00:19:23,520
to sort of explore the universe of possibilities. We could say we're going to take this AI that's

211
00:19:23,520 --> 00:19:28,080
very aligned with human interest because it's been trained on billions of human images.

212
00:19:28,080 --> 00:19:33,840
But nevertheless, we could say, let's take this AI and let's sort of move around in this space of

213
00:19:33,840 --> 00:19:39,440
possibilities. And so for some set of numbers, we've got the cat and the party hat. But as we

214
00:19:39,440 --> 00:19:44,240
change those numbers, we're moving out from that. And we have this kind of in the middle,

215
00:19:44,240 --> 00:19:49,920
we have this thing we might sort of describe as kind of cat island, that is things that to us kind

216
00:19:49,920 --> 00:19:56,080
of look like cats. But then we go further away, and we'll get into things which aren't like cats.

217
00:19:56,080 --> 00:20:00,720
If we go far enough, you know, we'll, we'll be able to go, I don't know, as an example, we'd be

218
00:20:00,720 --> 00:20:06,080
able to go from, what is that going to? That's, well, okay, here's one that goes from a cat to

219
00:20:06,080 --> 00:20:13,600
a dog, we're going through through this kind of meaning space from a cat to a dog. But in general,

220
00:20:13,600 --> 00:20:21,280
what we'll find is that we in this sort of space of possibilities, there's this region that corresponds

221
00:20:21,280 --> 00:20:27,360
to this concept that we have of a cat and a party hat. But as we go away from that, eventually,

222
00:20:27,360 --> 00:20:32,000
we move far enough, we'll get to a picture of a, you know, a dog wearing a sweater or something.

223
00:20:32,960 --> 00:20:39,360
But we go through a large volume of inter concept space of things which are images,

224
00:20:39,360 --> 00:20:45,120
which were generated by this AI using, you know, computationally generated out there in the

225
00:20:45,120 --> 00:20:50,880
computational universe, even set up to be quite aligned with kind of the pictures that we humans

226
00:20:50,880 --> 00:20:55,120
have put on the web. But nevertheless, they're not things which are normally described by a

227
00:20:55,120 --> 00:21:00,000
word like a cat or a dog or whatever else. So you might ask the question, you know, in an image

228
00:21:00,000 --> 00:21:06,560
generation AI, what volume of the space of possibilities is covered by concepts that we

229
00:21:06,560 --> 00:21:13,680
have already defined? The answer is maybe one part and 10 to the 600. So in other words, there's

230
00:21:13,680 --> 00:21:21,600
this vast kind of inter concept space of possible images, only tiny corners of which are described

231
00:21:21,600 --> 00:21:28,720
by words that we have in human languages. So in a sense, as we look at this kind of inter concept

232
00:21:28,720 --> 00:21:34,320
space, we could say, you know, we don't necessarily have a word to describe some of these patterns,

233
00:21:34,400 --> 00:21:39,280
but we might say, oh, that's kind of a cool pattern. And maybe we decide at some point that

234
00:21:39,280 --> 00:21:43,600
that's a particular style of art. And eventually we get a word for it. And then we develop this

235
00:21:43,600 --> 00:21:49,120
whole kind of human interest in that particular piece of what was inter concept space. And now

236
00:21:49,120 --> 00:21:58,320
that becomes a concept in our languages and so on. So this idea is sort of this core idea that

237
00:21:58,320 --> 00:22:02,720
there's this huge space, this huge kind of computational universe of possibilities,

238
00:22:02,720 --> 00:22:08,240
even reduced here by ones that are sort of images aligned with images that we put on the web.

239
00:22:08,240 --> 00:22:13,680
Even if you reduce it in that way, the part of that space that we have so far explored,

240
00:22:13,680 --> 00:22:20,240
that we have so far come up with words for and described with concepts, is a tiny part of the

241
00:22:20,240 --> 00:22:26,320
space. And there's vastly more that is kind of be found in the sort of inter concept space.

242
00:22:26,400 --> 00:22:31,920
Now, what, you know, can we describe kind of the way that kind of we, we think about

243
00:22:31,920 --> 00:22:38,960
sort of our progression in kind of the progression of human civilization and so on.

244
00:22:38,960 --> 00:22:44,640
In some sense, you can think about us as progressively colonizing inter concept space.

245
00:22:44,640 --> 00:22:49,280
We're progressively coming up with things coming up with, we're coming up with sort of this

246
00:22:49,280 --> 00:22:55,840
social construct of language that that different ones of us sort of collectively understand,

247
00:22:55,840 --> 00:23:00,720
that corresponds to the, these different points in the space of possibilities.

248
00:23:01,280 --> 00:23:06,160
And sort of the progression of civilization, we can think of as being this progressive kind of

249
00:23:07,120 --> 00:23:12,880
progressive exploration of inter concept space. And, you know, as we invent new paradigms for

250
00:23:12,880 --> 00:23:16,720
things, we get to kind of, or new ways of describing things, we get to kind of move

251
00:23:16,720 --> 00:23:23,440
outwards in the space. Now, for example, in my day job of creating computational language to

252
00:23:23,440 --> 00:23:31,760
describe things, my, my mission in a sense is to find those, those places in the space of

253
00:23:31,760 --> 00:23:37,760
possibilities that we humans care about, and that we can use as kind of building blocks

254
00:23:37,760 --> 00:23:44,880
to construct kind of in a computational way, a description of what we want. But there's kind

255
00:23:44,880 --> 00:23:50,800
of a broader science of what's in principle out there, which is broader than the things that we

256
00:23:50,800 --> 00:23:55,600
humans have so far chosen to, to come up with words for and so on and have languages for.

257
00:23:56,480 --> 00:24:01,760
Well, just to kind of fill out a little bit, kind of the, a little bit more of kind of the,

258
00:24:02,320 --> 00:24:09,520
the world view that develops from all of this, we can ask questions about, okay, what about

259
00:24:09,520 --> 00:24:14,640
our physical world? How is that constructed? What is the, what's kind of the, the underlying

260
00:24:14,640 --> 00:24:18,640
structure there? And one of the things that's been very exciting to me in the last few years,

261
00:24:18,720 --> 00:24:25,920
something I really did not expect sort of to, to, to happen is that it's, it's turned out that we've

262
00:24:25,920 --> 00:24:33,120
been able to work out that how this kind of computational ideas provide sort of an ultimate

263
00:24:34,240 --> 00:24:40,000
infrastructure, an ultimate kind of machine code for the physical universe. And what, what,

264
00:24:40,000 --> 00:24:44,560
let me describe that a little bit because we're going to come back to this question of concepts

265
00:24:44,560 --> 00:24:49,440
and into concept space and so on, but we're going to come at it now from a different direction

266
00:24:49,440 --> 00:24:57,120
from understanding the structure of the physical world. So, sort of big picture, back in antiquity,

267
00:24:57,680 --> 00:25:01,120
people were arguing, you know, is the world discreet or is it continuous? Is it made of

268
00:25:01,120 --> 00:25:07,440
atoms or is it just things that are sort of flowing? And one didn't know. End of the 19th

269
00:25:07,440 --> 00:25:14,240
century, it became clear, yes, there are molecules, matter is discreet. A little bit later, became

270
00:25:14,240 --> 00:25:19,440
clear, there are photons like can be thought of as being discreet. At that time, people mostly

271
00:25:19,440 --> 00:25:24,480
assumed that space would turn out to be discreet as well. But for various reasons, nobody technically

272
00:25:24,480 --> 00:25:29,920
managed to make that work. And so physics kind of went on with the space is continuous, you can

273
00:25:29,920 --> 00:25:35,680
kind of put things anywhere you want in space. Well, if you're thinking about things in kind

274
00:25:35,680 --> 00:25:40,800
of computational terms, you're immediately led to say, wait a minute, you know, perhaps space is

275
00:25:40,800 --> 00:25:45,680
actually fundamentally a computational construct, fundamentally a discreet kind of thing. And the

276
00:25:45,680 --> 00:25:50,960
big surprise of four years ago now was that, yes, we actually managed to figure out how to make that

277
00:25:50,960 --> 00:25:58,080
work and managed to figure out how that connects to the big theories of current 20th century physics.

278
00:25:58,080 --> 00:26:01,840
And actually, the really remarkable thing that maybe I'll have a chance to describe

279
00:26:01,840 --> 00:26:06,480
is that the big theories of 20th century physics, essentially general relativity, the theory of

280
00:26:06,480 --> 00:26:11,600
gravity and spacetime, quantum mechanics, and statistical mechanics for the second law of

281
00:26:11,600 --> 00:26:17,360
thermodynamics, those are sort of three big theories of 20th century physics. It turns out that all

282
00:26:17,360 --> 00:26:23,040
three of those theories are not just things that we can kind of say, oh, that's what's true.

283
00:26:23,040 --> 00:26:28,800
There are actually things that we can in some sense derive from fundamental considerations.

284
00:26:28,800 --> 00:26:34,000
I had not expected any such thing to be the case that we could derive the laws of physics, so to

285
00:26:34,000 --> 00:26:39,440
speak. But we can and I'll explain how that works. And that's kind of loop back to questions about

286
00:26:39,440 --> 00:26:47,360
language and concepts and so on. But okay, so what's the universe made of? Well, in our models,

287
00:26:47,360 --> 00:26:52,560
the universe consists of a bunch of sort of discrete atoms of space, we tend to call them

288
00:26:52,560 --> 00:26:58,320
eames, kind of atoms of existence. They're things where the only thing you can say about them is

289
00:26:58,320 --> 00:27:02,000
they exist, and they have an identity, and they're distinct from each other.

290
00:27:02,960 --> 00:27:08,160
And then there's one more thing, which is you can say how these eames, how these atoms of space

291
00:27:08,160 --> 00:27:12,800
are related to each other. You can say this one is related to these two other ones. It's kind of

292
00:27:12,800 --> 00:27:18,080
like what atom of space is friends with what other atoms of space? And you define this whole

293
00:27:18,080 --> 00:27:22,800
collection of relations between atoms of space, and you can represent that by a graph, a network,

294
00:27:22,800 --> 00:27:29,200
or actually more formally in our models, a hypergraph. But the essentially one's just dealing

295
00:27:29,200 --> 00:27:35,440
with this big network of relations between the atoms of space. And so everything in the universe

296
00:27:35,440 --> 00:27:40,640
in our models is just made of the relations between atoms of space. So for example, if

297
00:27:41,360 --> 00:27:50,160
something like a black hole, for example, is just a structure in the, I might even be able to show

298
00:27:50,160 --> 00:28:07,120
you a picture of one, let me see if I can pull this up. This is actually in kind of the fabric

299
00:28:07,120 --> 00:28:14,000
of space. This is two little tiny black holes. And we'll see in this video kind of space, most of

300
00:28:14,000 --> 00:28:18,080
the activity of the universe actually is knitting together the structure of space. But there are

301
00:28:18,080 --> 00:28:22,400
two black holes there, and you can kind of see they eventually merge. They produce gravitational

302
00:28:22,400 --> 00:28:28,560
radiation. Actually, what we get from this model, where we're looking at kind of the

303
00:28:28,560 --> 00:28:33,600
discrete structure of space, we can successfully reproduce the actual things that are observed

304
00:28:33,600 --> 00:28:40,000
in black hole mergers and so on. But in any case, the basic point is what the universe is made of,

305
00:28:40,000 --> 00:28:45,520
everything in the universe is just a feature of the structure of space. And when it comes to time,

306
00:28:46,160 --> 00:28:52,400
time is the progressive rewriting of the structure of that network that represents space.

307
00:28:52,400 --> 00:28:56,240
So time is actually a very different kind of thing in these models from space.

308
00:28:56,240 --> 00:29:01,920
Things like relativity emerge as a feature of the model. They're not things that are put in

309
00:29:01,920 --> 00:29:07,680
from the underlying structure of the model. Okay, so we've got sort of the notion of space,

310
00:29:07,680 --> 00:29:15,200
notion of time. It turns out quantum mechanics is a thing that inevitably emerges from the fact that

311
00:29:15,280 --> 00:29:19,680
when we are updating this network, there isn't just one possible path of history. There isn't

312
00:29:19,680 --> 00:29:24,800
just one possible way that the network can be updated. There are many possible paths of history

313
00:29:24,800 --> 00:29:30,000
that branch and merge. And essentially, the structure of those things is what leads to

314
00:29:30,000 --> 00:29:35,920
quantum mechanics. Well, one of the issues is when we're looking at the system, and we're

315
00:29:35,920 --> 00:29:41,920
seeing all these rewrites and the structure of space and so on, the question is, how do we experience

316
00:29:41,920 --> 00:29:48,480
that? There are all these things microscopically happening, but we have a certain experience of

317
00:29:48,480 --> 00:29:54,240
that. And it turns out that sort of a critical feature of what's going on is that we are observers

318
00:29:54,240 --> 00:30:02,640
of a certain kind. So let's take the case of, let's look at, for example, let's see,

319
00:30:06,880 --> 00:30:10,640
let's look at something like statistical mechanics. We've got a bunch of molecules

320
00:30:10,640 --> 00:30:15,920
bouncing around in a box. And one of the kind of big principles is the second law of thermodynamics

321
00:30:15,920 --> 00:30:20,960
that says when you start those molecules off in an orderly way, their motion will tend to

322
00:30:20,960 --> 00:30:26,240
eventually look disordered and random. It will look as if it has higher entropy. And the question

323
00:30:26,240 --> 00:30:33,040
is sort of what's really going on there? And it turns out that what's actually happening,

324
00:30:33,040 --> 00:30:38,960
something I finally understood, I've been thinking about this for like 50 years, actually, is that

325
00:30:39,760 --> 00:30:44,160
what's ultimately going on, you can look at different kinds of versions of this, what's

326
00:30:44,160 --> 00:30:50,160
ultimately going on is that these molecules are bouncing around in a certain determined way

327
00:30:50,160 --> 00:30:55,040
according to some rule. And in fact, that rule can be reversed. So you can take this pattern of

328
00:30:55,040 --> 00:30:59,280
molecules you get at the end and you can say, I can figure out, oh, yes, that pattern of molecules

329
00:30:59,280 --> 00:31:05,120
came from the simple initial state. Well, in principle, you can do that, but it's a computationally

330
00:31:05,680 --> 00:31:10,960
irreducible process. And the difficulty is that we human observers of things

331
00:31:11,680 --> 00:31:18,080
computationally bounded, we can't do that, that, that all the computation that's needed to reverse

332
00:31:18,080 --> 00:31:23,600
what happens in the molecules, we're just stuck saying that we can, we can get this

333
00:31:23,600 --> 00:31:28,000
impression of what's going on. And with that impression of what's going on with that computationally

334
00:31:28,000 --> 00:31:33,280
bounded impression of what's going on, all we can say is, oh, it looks random to us. And that's

335
00:31:33,280 --> 00:31:37,680
kind of the ultimate origin of the second law of thermodynamics is something which is to do with

336
00:31:37,680 --> 00:31:43,440
the relationship between underlying computational irreducibility and our computational boundedness

337
00:31:43,440 --> 00:31:50,880
as observers. Well, it turns out that both general relativity and quantum mechanics

338
00:31:50,880 --> 00:31:57,440
come from the exact same thing. They both come from this idea that there is computational

339
00:31:57,440 --> 00:32:02,320
irreducibility underneath. But we are, well, actually, there are two attributes that we have

340
00:32:02,320 --> 00:32:07,680
to have as observers, that we are computationally bounded, and that we believe we are persistent

341
00:32:07,680 --> 00:32:13,280
in time. So in this model, for example, we are at every moment in time, we're made of different

342
00:32:13,280 --> 00:32:20,240
atoms of space, yet we all have the impression that we are experiencing things through that it's

343
00:32:20,240 --> 00:32:26,160
still us a second later, so to speak, and that we experience things we are persistent, we have a

344
00:32:26,160 --> 00:32:32,560
continuous thread of experience through time. Well, okay, so the really ultimately big concept

345
00:32:32,560 --> 00:32:39,200
here is this thing we call the Ruliad. And so here's how this works. When we look at

346
00:32:40,800 --> 00:32:44,960
these, this underlying hypergraph and its rewrite rules and all those kinds of things,

347
00:32:45,760 --> 00:32:53,760
we can, we say, okay, there are these underlying rules. And if we run those enough times,

348
00:32:53,760 --> 00:32:58,560
we'll eventually get something that seems like our universe that satisfies Einstein's equations

349
00:32:58,560 --> 00:33:03,040
of general relativity, that shows the Feynman path integral for quantum mechanics, all those kinds of

350
00:33:03,040 --> 00:33:09,760
good things. But we still might be asking the question, well, why did our universe get one

351
00:33:09,760 --> 00:33:16,480
particular rule and not another? And that had me very confused for quite a while, until I realized

352
00:33:16,480 --> 00:33:23,440
that actually we can think of the universe as running all possible rules. So what we imagine is

353
00:33:23,440 --> 00:33:28,080
that there are these possible computational rules that can be used to update this hypergraph and so

354
00:33:28,080 --> 00:33:33,920
on. But let's just imagine that we use all possible rules. What we get are all these different parts

355
00:33:33,920 --> 00:33:38,800
of history that branched and merge and so on, corresponding to the application of all these

356
00:33:38,800 --> 00:33:45,120
different rules. And this whole object that is the entangled limit of all possible computational

357
00:33:45,120 --> 00:33:52,000
processes, we call the Ruliad. And the Ruliad is a completely unique thing. It is, it is you take

358
00:33:52,000 --> 00:33:57,360
every possible Turing machine, every possible computational system, you run all of them, and

359
00:33:57,360 --> 00:34:02,480
you run them in such a way that they are producing kind of, that they don't just have one possible

360
00:34:02,480 --> 00:34:07,200
outcome, they have all possible outcomes. You might say, what an incredible mess, how could you ever

361
00:34:07,200 --> 00:34:11,920
conclude anything from this Ruliad object? It is the case that this Ruliad object is a unique thing,

362
00:34:11,920 --> 00:34:16,880
there's not, it's not like there's seven different Ruliad's, there's just this thing that is the

363
00:34:16,880 --> 00:34:21,440
entangled limit of all possible computations. And so then the question is, well, how can you conclude

364
00:34:21,440 --> 00:34:26,560
anything about, about this Ruliad object? Well, what you have to realize is the Ruliad object

365
00:34:26,560 --> 00:34:34,160
represents everything that's possible, everything. And so, for example, we, as observers of what's

366
00:34:34,160 --> 00:34:41,120
going on, we must be embedded within this Ruliad. And so what we can think of is that this, this

367
00:34:41,680 --> 00:34:53,680
was I sharing the screen or did I stop sharing? Well, anyway, the, this, so the issue is we are

368
00:34:53,680 --> 00:34:59,680
observers embedded within this Ruliad, observing the Ruliad. And the question is, what do we

369
00:34:59,680 --> 00:35:04,720
conclude about the Ruliad? And the Ruliad is a necessary thing, there's no choice about it.

370
00:35:05,280 --> 00:35:12,000
But the nature of us as observers is contingent, so to speak. And so what turns out to be the case

371
00:35:12,000 --> 00:35:19,680
is that observers like us, observers that have certain attributes necessarily conclude that

372
00:35:19,680 --> 00:35:26,160
necessarily describe the Ruliad in certain ways. So in a sense, by being an observer who is

373
00:35:26,160 --> 00:35:31,680
computationally bounded, who believes they're persistent in time, those two attributes alone

374
00:35:31,760 --> 00:35:36,320
are sufficient to tell us that the slice of the Ruliad, the way that we parse the Ruliad

375
00:35:36,880 --> 00:35:40,080
is exactly the way that corresponds to the laws of physics that we know.

376
00:35:40,800 --> 00:35:45,840
So in other words, what we're saying is you can derive the laws of physics, the laws of physics

377
00:35:45,840 --> 00:35:51,440
are derived by starting with this Ruliad, which is a necessary unique object, and then saying what,

378
00:35:52,240 --> 00:35:56,960
for observers like us, which happen to have the properties that we have of being computationally

379
00:35:56,960 --> 00:36:02,720
bounded and believing we're persistent in time, any observer with those very coarse properties

380
00:36:02,720 --> 00:36:08,000
will necessarily conclude that the universe operates according to Einstein's equations and

381
00:36:08,000 --> 00:36:12,640
the path integral and so on. So that's a rather interesting philosophical conclusion.

382
00:36:13,200 --> 00:36:17,600
Now you can ask, well, what would observers not like us conclude? Well, we don't know.

383
00:36:18,400 --> 00:36:25,680
You can kind of, and that's sort of a question of how do we think about observers not like us?

384
00:36:26,560 --> 00:36:32,400
Well, one thing to realize is we can think of in the Ruliad, we can think of different possible

385
00:36:32,400 --> 00:36:38,080
observers as being sort of at different points in the Ruliad. There are different places in Rulial

386
00:36:38,080 --> 00:36:43,600
space. Just like in physical space, we could be here on this planet, we could be on a galaxy on

387
00:36:43,600 --> 00:36:48,000
the other side of the universe, we can be at different places in physical space, and each

388
00:36:48,000 --> 00:36:52,160
different place in physical space will give us a different point of view about how the universe

389
00:36:52,160 --> 00:36:58,240
works. Well, so it is in Rulial space, each different place in Rulial space will give us

390
00:36:58,240 --> 00:37:05,280
a different point of view about how the universe works, how things work. So here's a way to think

391
00:37:05,280 --> 00:37:11,280
about that. We can think of essentially different minds as being at different places in Rulial

392
00:37:11,280 --> 00:37:20,800
space. It's as if, and these different minds are kind of experiencing possibilities in a

393
00:37:20,800 --> 00:37:26,000
different way. So if we think about that in terms of, you know, the LLMs and so on, it's kind of

394
00:37:26,000 --> 00:37:31,520
like we could imagine just having a differently trained LLM and that differently trained LLM

395
00:37:31,520 --> 00:37:38,800
basically exists at a different place in Rulial space. So for example, minds that are sort of

396
00:37:38,800 --> 00:37:43,600
similar and sort of similarly trained will be fairly close in Rulial space. Minds that are

397
00:37:43,600 --> 00:37:48,000
different, like, you know, let's say cats and dogs, further away in Rulial space.

398
00:37:48,800 --> 00:37:53,520
Minds, I tend to, I think that one of the consequences of the principle of computational

399
00:37:53,520 --> 00:37:58,240
equivalence that I mentioned earlier is that one could sort of attribute mind like things

400
00:37:58,240 --> 00:38:03,040
to lots of systems in the world and lots of abstract systems. And so for example,

401
00:38:03,040 --> 00:38:08,720
when one says the weather has a mind of its own, in the principle of computational equivalence says,

402
00:38:08,720 --> 00:38:13,440
yes, that's a meaningful thing to say. But in a sense, the mind that corresponds to the

403
00:38:13,440 --> 00:38:19,280
weather is pretty far away from us in Rulial space. Also now there's a question, how do you

404
00:38:19,280 --> 00:38:24,320
communicate across Rulial space? How do you, what is it what's involved in doing that? Well,

405
00:38:24,320 --> 00:38:29,520
at some computational level, one point in Rulial space corresponds to sort of computing,

406
00:38:29,520 --> 00:38:33,440
according to let's say one Turing machine, another point in Rulial space computing,

407
00:38:33,440 --> 00:38:37,520
according to another Turing machine, another computer. We know that in principle, we can

408
00:38:37,520 --> 00:38:41,440
make a translation from one place in Rulial space to another place in Rulial space takes

409
00:38:41,440 --> 00:38:45,360
effort. We have to actually create that interpreter that's going to interpret the

410
00:38:45,360 --> 00:38:49,760
instructions of one machine as the instructions of another machine. It takes effort in the same

411
00:38:49,760 --> 00:38:55,280
way as it takes effort to move in physical space. In a sense, when we move in physical space in our

412
00:38:55,280 --> 00:39:00,560
models, we're reconstructing ourselves at a different point in physical space. And by the way,

413
00:39:00,560 --> 00:39:04,720
you can understand things like time dilation and relativity. There's a nice kind of mechanical

414
00:39:04,720 --> 00:39:09,520
explanation of that. If you're always in one place, you're spending your kind of computation

415
00:39:09,520 --> 00:39:15,520
budget figuring out what the next behave what the what the next stage you'll be in is. But if

416
00:39:15,520 --> 00:39:20,720
you're moving, then you're using some of your computation budget to kind of recreate yourself

417
00:39:20,720 --> 00:39:26,560
at a different place in space. And so that's used up having used up some of your computation budget,

418
00:39:26,560 --> 00:39:32,960
you necessarily sort of moves go through time more slowly time time goes more slowly because

419
00:39:32,960 --> 00:39:38,960
you used up some of your computation budget in moving in space. But in any case, you can you

420
00:39:38,960 --> 00:39:45,200
can think of so so by the way, in our models, the possibility of motion is non trivial. It's not

421
00:39:45,200 --> 00:39:50,240
obvious that you can you know pick up a glass and move it somewhere, and it'll still be the same

422
00:39:50,240 --> 00:39:55,200
glass. That's something that we generally assume about the world that pure motion is possible.

423
00:39:55,200 --> 00:39:59,520
But it's something in our models that you have to prove that pure motion is possible. And even

424
00:39:59,520 --> 00:40:05,040
in traditional physics, if you're sufficiently near a space time singularity, for example,

425
00:40:05,040 --> 00:40:11,280
no no material object will maintain its identity as you move it around that that singularity.

426
00:40:11,280 --> 00:40:16,560
But in our models, the the possibility that that thing can just move, and that it's still the same

427
00:40:16,560 --> 00:40:23,200
thing is non trivial. And actually, in a sense, the the particles of motion are exactly the kinds

428
00:40:23,200 --> 00:40:27,600
of particles that we know about like electrons and quarks and so on. What is an electron an

429
00:40:27,600 --> 00:40:33,840
electron in some sense in an abstract level is a lump that is capable of pure motion. It's something

430
00:40:33,840 --> 00:40:39,440
where you can have an electron in one place, and you can move it and it'll still just be that electron.

431
00:40:39,440 --> 00:40:43,440
So it's it's a particles are kind of the carriers of pure motion and physical space.

432
00:40:44,320 --> 00:40:50,400
So here's a here's a thing in rural space, we can ask sort of what is motion in rural space about.

433
00:40:51,120 --> 00:40:56,000
Well, in a sense, what what it means to have motion in rural space is you're effectively

434
00:40:56,000 --> 00:41:01,200
transporting something from one mind to another if different points in rural space

435
00:41:01,280 --> 00:41:05,840
correspond to the positions of different minds, you're asking the question, what does it take

436
00:41:05,840 --> 00:41:11,600
to kind of transport things around rural space. And I think this is one of the very bizarre

437
00:41:11,600 --> 00:41:17,040
kinds of things that one realizes is it seems to be the case that concepts are the analog of

438
00:41:17,040 --> 00:41:22,000
particles. So what in physical space and an electron that doesn't change as you move it from

439
00:41:22,000 --> 00:41:29,200
here to there, in rural space, it's the concept of a cat, for example, that can be moved from one

440
00:41:29,200 --> 00:41:34,560
mind to another without change. I mean, the particular details of the neural firings that

441
00:41:34,560 --> 00:41:40,320
exist in my brain, when I think of the concept of cat, in any of your brains, the particular

442
00:41:40,320 --> 00:41:46,800
neural firings will be different. But yet, we can package up the concept of a cat, and I can say

443
00:41:46,800 --> 00:41:54,000
the word cat, I can transport it to you, and then you can unpack it. And in your place in rural space,

444
00:41:54,080 --> 00:41:59,520
you can end up with the same thing, so to speak. So it's kind of a way of understanding that that's

445
00:41:59,520 --> 00:42:05,920
sort of the fundamental thing that's going on. And we can think of kind of concepts as being

446
00:42:05,920 --> 00:42:12,960
the particles of rural space. Well, there are lots of lots of things I see I'm running out of time

447
00:42:12,960 --> 00:42:20,320
here. But there are lots of things we can talk about about what, well, let me just say a couple

448
00:42:20,320 --> 00:42:29,280
of other things about, I'll talk a little bit about AI. And I mean, the AI has had many different

449
00:42:29,280 --> 00:42:33,680
meanings over the course of time. And many things where people have said, if we can only have that,

450
00:42:33,680 --> 00:42:39,280
then we have AI are things that I've built as kind of pure computational systems. And then

451
00:42:39,280 --> 00:42:43,280
people say, well, it's just a computational system, it's not really AI. And in more than seconds,

452
00:42:43,840 --> 00:42:49,040
just one second, I want to, you do have more time, because for some reason, I can't explain,

453
00:42:50,160 --> 00:42:55,840
Caillou, who has been extremely conscientious in everything, is not here, which may mean that he

454
00:42:55,840 --> 00:43:00,960
had misunderstood being a discussant for being a member of the panel, which means he won't be here

455
00:43:00,960 --> 00:43:08,320
until the panel starts, in which case you have more time, if you wish. I just compressed four

456
00:43:08,400 --> 00:43:12,240
and a half decades into a remarkably short time, I hope people could follow it.

457
00:43:12,800 --> 00:43:16,160
Nothing, you could have taken place at this time.

458
00:43:19,280 --> 00:43:22,720
Well, okay, so let me let me finish what I was saying here, and then maybe we can

459
00:43:22,720 --> 00:43:29,840
turn this over to discussion, which is more fun for me. So talking about kind of modern

460
00:43:29,840 --> 00:43:39,520
AIs, and you know, to many people, modern AI is neural networks. And the, there's sort of a

461
00:43:39,520 --> 00:43:50,240
question of, well, what can, how do neural networks relate to all of the things I've been talking

462
00:43:50,240 --> 00:43:56,080
about? And one of the questions we can ask is, okay, we have, we have our friendly neural net

463
00:43:56,160 --> 00:43:59,120
here, let's see, oops, share the screen and then,

464
00:44:06,240 --> 00:44:10,240
okay, we have some typical trained neural net, let's say we're trying to train it,

465
00:44:10,240 --> 00:44:15,680
let's say we're trying to train it to reproduce the sine wave. So what we're doing is we're going

466
00:44:15,680 --> 00:44:22,400
to feed in the x value at the top there, and we're going to have set up these neural net weights,

467
00:44:22,400 --> 00:44:27,360
and it's going to compute the y value down here. And actually, we'll do a pretty crummy job of that

468
00:44:27,360 --> 00:44:33,040
typically. And you can, you can change the neural net, you'll get different kinds of behavior,

469
00:44:33,040 --> 00:44:37,520
it's usually not particularly good at computing something like this. Well, so one thing you can

470
00:44:37,520 --> 00:44:43,440
ask is, you know, neural nets, let's say if we have a big enough neural net, maybe we can break

471
00:44:43,440 --> 00:44:47,440
computational irreducibility, maybe we can just predict what's going to happen in any kind of system.

472
00:44:48,400 --> 00:44:56,320
That is not going to work. I mean, the way that a neural net of this type works, it's just having

473
00:44:56,320 --> 00:45:01,600
kind of numbers ripple through the sequence of layers. And we're ending up with something where

474
00:45:01,600 --> 00:45:10,320
you can, this is something trained, I used a modern transformer architecture and trained it

475
00:45:10,320 --> 00:45:14,960
to try and recognize what was going to happen in a cellular automaton. And it has certain,

476
00:45:14,960 --> 00:45:18,960
it says, well, there's certain probability of what's going to happen. But when the behavior is

477
00:45:18,960 --> 00:45:24,320
pretty simple, it'll nail it. When the behavior is more complicated, it's like, I'm sorry, I can't,

478
00:45:25,680 --> 00:45:30,080
you know, I can't figure that out. This is, this is different levels of training of one of those

479
00:45:30,080 --> 00:45:36,720
neural nets. So in a sense, it's not surprisingly, the kind of very finite computation of these layers

480
00:45:36,720 --> 00:45:43,360
of a neural net can't do the unboundedly large computation required to kind of solve a computationally

481
00:45:43,440 --> 00:45:49,440
irreducible problem. And you can see that again. See, where do I have an example here? This is,

482
00:45:49,440 --> 00:45:56,960
these are examples of the three body problem in celestial mechanics, Earth, Moon, Sun, all idealized,

483
00:45:56,960 --> 00:46:02,080
all with interacting through gravity. You can ask the question, if you train a neural net,

484
00:46:02,080 --> 00:46:07,200
can it correctly reproduce the behavior? The answer is the neural net is the kind of solid

485
00:46:07,200 --> 00:46:11,760
line here, that's its prediction. When the behavior is fairly simple, yes, it can do it.

486
00:46:11,760 --> 00:46:14,960
When the behavior is kind of computationally irreducible, no, it can't do it.

487
00:46:15,520 --> 00:46:22,160
None of this is really very surprising. But there's kind of the question, for example,

488
00:46:22,160 --> 00:46:26,880
when we look at something like chat GPT, and we say, oh my gosh, it actually worked, it produced

489
00:46:26,880 --> 00:46:32,800
something that is like human language. How did that work? What I think is the main thing going on

490
00:46:32,800 --> 00:46:36,720
is something which tells us a lot more about human language, probably, than it does about

491
00:46:36,720 --> 00:46:45,360
neural nets. Because what it's telling us is, if we think about how does chat GPT work,

492
00:46:45,920 --> 00:46:52,400
it's basically just saying, I'm going to predict the next word by figuring out certain probabilities.

493
00:46:52,400 --> 00:46:57,680
And it's going to do that by, at the very simplest level, it might just do it, let's see if we've got

494
00:46:57,680 --> 00:47:03,040
one here, might just do it by knowing the frequencies of different letters. And then,

495
00:47:03,040 --> 00:47:06,320
if you just use the frequencies of different letters, you get pretty much nonsense.

496
00:47:06,320 --> 00:47:10,080
If you use blocks of letters, you'll start getting more sensible kinds of things.

497
00:47:10,080 --> 00:47:16,880
If you use kind of whole words occurring with the probability that they occur in English,

498
00:47:16,880 --> 00:47:23,360
you'll get things that don't make much sense, but they're kind of things that can construct.

499
00:47:23,360 --> 00:47:29,440
Now, the big thing that's interesting and surprising is that when you kind of train

500
00:47:29,440 --> 00:47:36,800
a neural net from kind of all of the text, you know, a trillion words of text or something,

501
00:47:37,440 --> 00:47:43,760
that the extrapolations it makes about what make meaningful sentences tend to agree with

502
00:47:43,760 --> 00:47:48,720
the extrapolations that we humans would make about that. It's very similar to the fact that if we

503
00:47:48,720 --> 00:47:54,720
train a neural net to recognize cats from dogs and images, that the distinctions it will make

504
00:47:54,720 --> 00:47:59,280
seem to be similar to the distinctions we will make. At a theoretical level, if we say,

505
00:47:59,280 --> 00:48:04,800
where's the dividing line between cat pictures and dog pictures? There isn't a good mathematical

506
00:48:04,800 --> 00:48:10,240
characterization of where that dividing line is. It's really a question of where do we humans say

507
00:48:10,240 --> 00:48:14,720
is a dividing line between cats and dogs? And the thing that's interesting about neural nets

508
00:48:14,720 --> 00:48:19,040
is they tend to make the same kinds of decisions about that that we tend to make.

509
00:48:19,600 --> 00:48:23,600
Probably the reason is that ultimately their architecture is similar to the architecture

510
00:48:23,600 --> 00:48:28,320
of our brains. But the main point is that those kinds of distinctions, there's not a theorem,

511
00:48:28,400 --> 00:48:33,280
there's no theorem that says the neural net will reproduce the distinction between cats and dogs,

512
00:48:33,280 --> 00:48:37,440
because you don't know what the target is. The target is what do humans think is going on there,

513
00:48:37,440 --> 00:48:42,640
and it does a pretty good job at that. So now the question is, in the case of language, what's

514
00:48:42,640 --> 00:48:52,720
going on? And I think what's happened is that the thing that allows an LLM to produce reasonable

515
00:48:52,720 --> 00:48:57,920
language is something that is a regularity of language that we could have recognized a long

516
00:48:57,920 --> 00:49:04,000
time ago, but we didn't. And so we know certain regularities in language. We know that, for example,

517
00:49:04,000 --> 00:49:10,720
in English, you tend to have sentences that go noun verb noun. But there are plenty of sentences

518
00:49:10,720 --> 00:49:16,640
of the form noun verb noun that are total nonsense. So the question is, you have this kind of

519
00:49:16,640 --> 00:49:21,760
syntactic grammar of language that says that you go things like noun verb noun. But now you have

520
00:49:21,760 --> 00:49:27,600
the question of, well, what noun verb nouns actually make sense? And so what I think chat,

521
00:49:27,600 --> 00:49:32,720
you know, chat GBT and LLMs and so on are kind of showing us is that there is also a semantic

522
00:49:32,720 --> 00:49:39,440
grammar of language. There's also a construction kit, not only of what the parts of speech might be,

523
00:49:39,440 --> 00:49:44,640
but also what kinds of words they might be to have them make sense. And that's something that

524
00:49:44,640 --> 00:49:49,760
eventually kind of sort of expands up to write a whole essay and have these puzzle pieces fit

525
00:49:49,760 --> 00:49:55,120
together in a way so that the whole thing makes sense. So, you know, in a sense, what one's

526
00:49:55,120 --> 00:50:02,560
seeing and one can kind of look at, let's see if I have some pictures here. Maybe I have some pictures.

527
00:50:04,960 --> 00:50:09,920
Yeah, these are from, these are very ancient, actually, there's better ones now for GBT-4.

528
00:50:12,240 --> 00:50:18,240
What extent can you kind of imagine semantic laws of motion where you're kind of moving around in

529
00:50:18,240 --> 00:50:24,480
meaning space, and where, just like Newton's laws tell you in physical space, how you move

530
00:50:24,480 --> 00:50:30,240
from one, you know, how motion happens when in the absence of a force you just keep moving in

531
00:50:30,240 --> 00:50:35,120
the same direction and so on. So you can ask questions about rural space, and you can ask

532
00:50:35,120 --> 00:50:42,000
questions about kind of the structure of rural space and how that works. And I think we're kind

533
00:50:42,000 --> 00:50:46,560
of learning some scientific things from the operation of LLMs about how that works.

534
00:50:47,280 --> 00:50:54,800
Now, another question would be, so in other words, I think the reason LLMs work as well as they do

535
00:50:54,800 --> 00:50:58,560
is because there are a bunch of regularities in human language that we kind of didn't know were

536
00:50:58,560 --> 00:51:04,320
there and that we've never really codified. People started codifying these things back in the 1600s,

537
00:51:04,320 --> 00:51:09,280
for example, people tried to invent these so-called philosophical languages that would be kind of

538
00:51:09,920 --> 00:51:13,840
not specific to any particular language, but they would be things that sort of represent the

539
00:51:13,840 --> 00:51:19,600
meaning of things without the specificity of particular languages. Well, actually,

540
00:51:19,600 --> 00:51:25,120
I've had a project for a while now much more energetic to make what I call a symbolic discourse

541
00:51:25,120 --> 00:51:31,120
language, a language where just like in Wolfman language, we have this computational language

542
00:51:31,120 --> 00:51:38,160
that describes many aspects of the world. I mean, we might have all sorts of different

543
00:51:39,120 --> 00:51:48,880
sort of categories of thing that we describe in our language. And the question is, can we kind

544
00:51:48,880 --> 00:52:00,000
of describe all, can we describe sort of things that come up in everyday language? Can we describe

545
00:52:00,000 --> 00:52:05,200
those kinds of things in a sort of precise symbolic way? And I have to say that I can't say I've got

546
00:52:05,200 --> 00:52:09,120
the full answer to that, but it's going really well. And it's become clear, and by the way,

547
00:52:09,120 --> 00:52:16,160
LLMs are quite helpful in this, to having a way to take something not the level of language where

548
00:52:16,160 --> 00:52:20,640
we're actually putting words together, but the representation of the core meaning of what's

549
00:52:20,640 --> 00:52:26,720
going on. Just like in our computational language, we have that representation of sort of the core

550
00:52:26,720 --> 00:52:31,520
meaning of what's going on in a way that can be read by humans, but also executed by a computer.

551
00:52:32,320 --> 00:52:37,600
So in any case, that's sort of one direction about things with LLMs and so on. Another question

552
00:52:37,600 --> 00:52:44,400
that I was curious about is, okay, why does machine learning work at all? Why is it the case that you

553
00:52:44,400 --> 00:52:51,360
can train one of these neural nets to do something like, I don't know, recognize digits or recognize

554
00:52:51,360 --> 00:52:57,680
cats and dogs or generate language or whatever else? Why does that work? When I played around

555
00:52:57,680 --> 00:53:03,440
with neural nets back in 1981, and I couldn't get them to do anything interesting. And I kind of

556
00:53:03,440 --> 00:53:06,960
thought at the time, oh, if I've got a simple enough problem, I'll be able to get a simple neural

557
00:53:06,960 --> 00:53:13,200
net to do things, didn't really work very well, wasn't very interesting. The big thing that got

558
00:53:13,200 --> 00:53:19,600
sort of accidentally discovered basically in 2011 was that if you have a big neural net and you

559
00:53:19,600 --> 00:53:25,200
bash it really hard, you show it enough training examples, it'll learn, well, lots of different

560
00:53:25,280 --> 00:53:30,320
kinds of things, it'll learn almost anything. And the kind of the big meta discovery of modern

561
00:53:30,320 --> 00:53:35,280
machine learning is that if you bash a neural net hard enough, it'll learn almost anything. We don't

562
00:53:35,280 --> 00:53:39,920
know quite what the almost is. We can't really characterize what kind of thing it can learn.

563
00:53:39,920 --> 00:53:45,280
For example, as I said, it can't break out of computational irreducibility. So there's limitations

564
00:53:45,280 --> 00:53:49,680
to what it can learn, what it can do. But nevertheless, there's a broad class of things that seem to

565
00:53:49,680 --> 00:53:54,480
correspond a lot to kinds of things that we humans can do easily that the neural net can

566
00:53:54,480 --> 00:54:03,520
successfully do. And so that's sort of the meta discovery. The question is, why does that work?

567
00:54:04,240 --> 00:54:09,600
Why is it the case that this neural net can be successfully sort of bashed into learning

568
00:54:09,600 --> 00:54:14,880
things? Why doesn't it get stuck? Why doesn't it get to the point where you just can't get there

569
00:54:14,880 --> 00:54:20,080
from here? You can't arrange it. Why is it the case that it's possible to do it and then why is it

570
00:54:20,080 --> 00:54:27,280
the case that you can iteratively do it by sort of adaptively training it? I got interested in

571
00:54:27,280 --> 00:54:32,400
this very recently, actually. And I don't know whether I can show you pictures. Let me see. I can

572
00:54:32,400 --> 00:54:36,560
show you some things that I did recently. And then maybe I'll be able to pull up some pictures

573
00:54:36,560 --> 00:54:46,560
just from the last few days that let me see here. Right. So actually, I decided to look at a simpler

574
00:54:46,560 --> 00:54:52,000
problem, which is the problem of biological evolution, which is sort of another case of adaptation

575
00:54:52,800 --> 00:54:57,920
that is a little simpler than neural nets. But let me explain what I figured out about

576
00:54:57,920 --> 00:55:02,080
biological evolution. For a long time, I wondered what sort of the minimal model of biological

577
00:55:02,080 --> 00:55:06,800
evolution was always very unsatisfied because models, you know, natural selection seems like a

578
00:55:06,800 --> 00:55:11,120
simple principle. But when you actually try and make explicit models for it, you end up with all

579
00:55:11,120 --> 00:55:16,720
kinds of hair about, you know, how many sub, you know, suboptimal organisms do you keep and all

580
00:55:16,720 --> 00:55:20,800
this kind of thing. So I was interested in sort of a minimal version of that. So here's a version

581
00:55:20,800 --> 00:55:25,440
of that. This is actually one of these cellular automata. It's got these rules here, starts off

582
00:55:25,440 --> 00:55:31,040
from one red cell here. And with these particular rules, you get a pattern that lives for this amount

583
00:55:31,040 --> 00:55:39,520
of time and then dies out. Okay, so let's imagine that you're interested in doing something where

584
00:55:39,600 --> 00:55:44,960
you just keep on tweaking the rules, you keep on resetting the rules, you keep on making

585
00:55:44,960 --> 00:55:50,880
single point mutations in the rules to try and get it to live longer and longer. This is what

586
00:55:50,880 --> 00:55:56,560
happens. You start off from something that that is just a blank rule. For example, it dies immediately,

587
00:55:56,560 --> 00:56:00,720
you keep tweaking the rule, you have to go through many different tweaks and so on. But

588
00:56:00,720 --> 00:56:04,160
eventually you'll get to the point where it lives there for 50 something steps.

589
00:56:04,720 --> 00:56:08,960
Well, and you can see that the sequence of mutations that got made there. And if you look at how the

590
00:56:08,960 --> 00:56:14,800
fitness of this organism, the length of time it lived, varies as you go through all these

591
00:56:14,800 --> 00:56:20,720
different sort of steps of adaptive evolution, you'll see there are, you know, it's going along

592
00:56:20,720 --> 00:56:26,400
and there are many things that don't work out. But, you know, it'll kind of cruise along here at a

593
00:56:26,400 --> 00:56:31,600
certain fitness, and then it makes a discovery. And then it can go to higher fitness. And actually,

594
00:56:32,560 --> 00:56:36,480
you can end up with all kinds of discoveries that it makes. These are different sort of

595
00:56:36,480 --> 00:56:41,200
paths of evolution. And you'll see that, for example, here, it's kind of going along and

596
00:56:41,200 --> 00:56:45,920
eventually it manages to discover a lot. It manages to live a long time. You could sort of imagine

597
00:56:45,920 --> 00:56:51,760
in the fossil record, you might find, you know, a critter from the Cambrian period that looks

598
00:56:51,760 --> 00:56:57,280
like this. And then it uses that idea to extend further. And by the time it's in the Silurian

599
00:56:57,360 --> 00:57:02,560
period, it's looking like this. And maybe it makes it to this in the Triassic period or something.

600
00:57:02,560 --> 00:57:07,840
But what's happening here is that there are sort of, it's having progressively more ideas,

601
00:57:07,840 --> 00:57:13,760
in a sense, about how to live longer in this particular case. And actually, you can even

602
00:57:13,760 --> 00:57:18,960
go ahead, this is a simple enough system, that you can actually work out. Let's see, that's an

603
00:57:18,960 --> 00:57:24,960
example of a better example. There we go. This is, this is the path of all possible paths of

604
00:57:24,960 --> 00:57:31,760
evolution for a simple system like this. So every different picture here is a possible organism.

605
00:57:31,760 --> 00:57:36,480
And the arrows show the possible adaptation paths. And what you see is something that's very much

606
00:57:36,480 --> 00:57:41,120
like what happens in biological evolution. There are different branches in the tree of life.

607
00:57:41,120 --> 00:57:46,320
There are, you know, one set of ideas leads to long life over here. In this way, a different

608
00:57:46,320 --> 00:57:51,440
set of ideas leads to kind of long life over here in a different way. Okay, what does this have to

609
00:57:51,520 --> 00:57:58,000
do with machine learning? Well, you can, you can ask the question, let me see if I can pull this up.

610
00:57:58,720 --> 00:58:04,160
I am going to have to pull up something that I just made. So I'm not sure whether I can find it here.

611
00:58:05,040 --> 00:58:10,640
Hold on, you can get hot off the press or not really off the press at all. Where is it?

612
00:58:13,520 --> 00:58:15,520
Let me see. Maybe.

613
00:58:22,400 --> 00:58:26,080
Maybe this will have it. Oh yeah, this is, this might be it.

614
00:58:29,840 --> 00:58:32,560
This is a very minimal model for,

615
00:58:36,240 --> 00:58:44,240
let's see if I can get this bigger. It's a very minimal model for a neural net where

616
00:58:44,240 --> 00:58:50,480
it's actually a cellular automaton as well. But instead of having a fixed rule that it keeps on

617
00:58:50,480 --> 00:58:55,600
applying kind of like a recurrent neural network, it has something more like a feed forward neural

618
00:58:55,600 --> 00:59:01,360
network where you have a discrete choice of one of let's say two different possible rules. And at

619
00:59:01,360 --> 00:59:06,240
every point in space time, so to speak, you're picking a different rule. And so then the learning

620
00:59:06,240 --> 00:59:10,720
consists of, well, what's the pattern of rules you should pick to get a particular outcome. In

621
00:59:10,720 --> 00:59:15,680
this particular case, we're trying to learn to live as long as possible. And what's interesting

622
00:59:15,760 --> 00:59:23,760
here, and again, this is just raw off the literally raw material that from a couple of days ago,

623
00:59:24,960 --> 00:59:31,840
this is kind of showing in a sense how the thing does what it does. So in a standard neural net,

624
00:59:31,840 --> 00:59:36,080
it's just much more complicated to display what's going on. You've got these neurons with

625
00:59:36,080 --> 00:59:41,440
continuous weights and you've got connectivity all over the place and so on. This is a much simpler

626
00:59:41,440 --> 00:59:45,680
case. So you can kind of see more about what's going on. What's non trivial is that training

627
00:59:45,680 --> 00:59:51,120
actually works in this case. And it does, you can find this arrangement of bits that will cause

628
00:59:51,120 --> 00:59:56,160
the thing to do, I don't know whether I have it in this example here, but that will cause it to

629
00:59:56,160 --> 01:00:04,320
learn, see if I have one here. Now those activation levels, well, it doesn't matter, but that will

630
01:00:04,320 --> 01:00:10,880
basically cause it to learn something like, you know, to tell whether the number of bits at the

631
01:00:10,880 --> 01:00:15,040
beginning is even or odd or something like this. And we actually even tried training this on the

632
01:00:15,040 --> 01:00:23,200
MNIST training set, and it doesn't do too badly. So the point here, the thing that's interesting

633
01:00:23,200 --> 01:00:29,840
here, these are all different solutions that this kind of very idealized neural net found

634
01:00:30,400 --> 01:00:37,120
to living for this exact number of steps. What's interesting about these is they're very bizarre.

635
01:00:37,120 --> 01:00:42,080
They're not sort of engineered solutions. They're not solutions where we can say, oh, yeah, let me

636
01:00:42,080 --> 01:00:46,800
look inside and see how this works. Let me show you another example of that. And this is more back

637
01:00:46,800 --> 01:00:53,040
to the biological evolution case. This is kind of all the different ways that a certain class of

638
01:00:53,040 --> 01:00:58,240
systems manages to live a long time. And some of them, it's kind of pretty structured. You can imagine

639
01:00:58,240 --> 01:01:02,640
sort of this was an engineered thing, but some of them, it's like it just seems to sort of happen

640
01:01:02,640 --> 01:01:09,120
to live that long, and then it dies out. So in other words, there's a lot. And by doing this

641
01:01:09,120 --> 01:01:14,880
sort of adaptive evolution, you're ending up finding these things which are very not,

642
01:01:14,880 --> 01:01:20,000
they're not mechanical, they're not engineered kind of ways that things work. They're things

643
01:01:20,000 --> 01:01:28,640
where kind of this is sort of what's happening inside. This is the thing that's going on,

644
01:01:28,640 --> 01:01:33,440
but it's not something where you can say, oh, I've got a mechanism. By the way, if you're interested

645
01:01:33,440 --> 01:01:38,720
in neuroscience, this is something you should pay attention to, because in a sense, if you're

646
01:01:38,720 --> 01:01:43,120
trying to explain what's happening in the brain, and you say, oh, I'm going to figure out how this

647
01:01:43,120 --> 01:01:49,280
works. Well, how this works is an attempt to have kind of a human understandable narrative

648
01:01:49,280 --> 01:01:54,400
for what's going on. But if I were to look at these pictures in the background here,

649
01:01:54,400 --> 01:01:58,320
if this was something going on in a brain, I might be able to say, okay,

650
01:01:58,400 --> 01:02:02,160
I can have some human narrative about what's happening here. If this is what's going on in a

651
01:02:02,160 --> 01:02:06,720
brain, it's just, well, it happens to work that way, and it happens to give this result. It's

652
01:02:06,720 --> 01:02:12,640
kind of a computational irreducible story. It's something where there's no sort of narrative

653
01:02:12,640 --> 01:02:18,080
mechanistic explanation. It's something which just works that way, and it's computationally

654
01:02:18,080 --> 01:02:22,640
irreducible, but it just comes out in that fashion. And I think there's sort of an interesting question

655
01:02:23,200 --> 01:02:30,720
for in machine learning. Why does machine learning work? Okay, so let's look at,

656
01:02:32,800 --> 01:02:40,000
was a nice picture of that. By the way, this is in biological evolution. People often talk

657
01:02:40,000 --> 01:02:44,800
about fitness landscapes. This is an actual fitness landscape correctly drawn, so to speak.

658
01:02:44,800 --> 01:02:49,920
And you can start seeing all kinds of things about things evolving on fitness landscapes.

659
01:02:49,920 --> 01:02:56,880
But the thing I really wanted to show you, here it is. This is kind of the local behavior

660
01:02:56,880 --> 01:03:04,320
at a particular point in rule space at various steps in the adaptive evolution.

661
01:03:04,320 --> 01:03:09,280
So what's happening here is at this step, for example, in the adaptive evolution,

662
01:03:09,280 --> 01:03:14,960
here are different possible directions in rule space that you might go. And the ones inside

663
01:03:14,960 --> 01:03:18,800
the circle are ones that are losers relative to where you've already got. They're ones that would be

664
01:03:18,880 --> 01:03:23,440
live less long than what we have here, but there are some that would make progress.

665
01:03:24,240 --> 01:03:28,320
And in fact, this is the one we happened to choose in this particular random

666
01:03:28,320 --> 01:03:32,800
sequence of adaptive evolution steps. And that was the thing that made progress. So

667
01:03:32,800 --> 01:03:38,160
the thing that is not obvious is in this sort of high dimensional space of possible ways you could

668
01:03:38,160 --> 01:03:42,720
go, the question is, will you always be able to make progress? Will there be a direction that

669
01:03:42,720 --> 01:03:48,160
makes progress? Or will you get stuck? Well, I think that this is again a computational

670
01:03:48,160 --> 01:03:54,320
irreducibility story that basically what would make you get stuck? Well, if the structure of

671
01:03:54,320 --> 01:04:01,200
this rule space was very orderly, very reducible and easy to predict, you might end up in a box

672
01:04:01,200 --> 01:04:07,040
with very precisely defined walls and you just can't escape from that. But the presence of

673
01:04:07,040 --> 01:04:11,920
computational irreducibility kind of implies a certain degree of unpredictability, a certain

674
01:04:11,920 --> 01:04:17,680
degree of intrinsic randomness effectively in the structure of rule space. And that's what

675
01:04:17,680 --> 01:04:22,720
means that in these high dimensional spaces, there's always a kind of a path to success.

676
01:04:22,720 --> 01:04:30,320
So in a sense, I think computational irreducibility, which is a limitation on what one can do with,

677
01:04:30,320 --> 01:04:34,480
for example, a neural net, what kinds of things computations one can expect to do,

678
01:04:34,480 --> 01:04:41,440
is also the reason that training of neural nets, for example, can work. And so I think that's a,

679
01:04:41,520 --> 01:04:49,920
anyway, this is still an in progress kind of investigation. But I sort of think it's

680
01:04:49,920 --> 01:04:53,520
an interesting connection between a lot of different things I've talked about.

681
01:04:53,520 --> 01:05:01,200
All right, I've gone on longer than I intended to. So let me wrap up there and I'm happy to

682
01:05:01,200 --> 01:05:06,960
have a discussion, questions, whatever else. I just fed you an awful lot of material.

683
01:05:07,440 --> 01:05:11,760
Yes, good. Let's first applaud this president.

684
01:05:16,640 --> 01:05:24,160
The problem was that Kaiyou had an emergency during your talk, so he couldn't hear it.

685
01:05:24,160 --> 01:05:28,880
Kaiyou, do you think that you have, from the background material you might have looked at,

686
01:05:28,880 --> 01:05:35,520
you have a basis for saying something? Sorry, I missed most part of the time, so probably.

687
01:05:36,240 --> 01:05:43,120
If you haven't seen, this is a large amount of material. I would be surprised if we could

688
01:05:43,120 --> 01:05:48,960
have a useful conversation without having some anchor to this. Could you please explain to Kaiyou

689
01:05:48,960 --> 01:05:57,280
and to me and to us how computational irreducibility differs from ABC,

690
01:05:57,600 --> 01:06:06,080
the commagor of complexity, the church-touring thesis, and NP completeness.

691
01:06:07,120 --> 01:06:17,200
Okay. All right, let's start off with Chetan Komogorov complexity. So when we look at a picture

692
01:06:17,520 --> 01:06:27,520
like this, the algorithmic complexity of this picture is tiny. That's the program that's needed

693
01:06:27,520 --> 01:06:34,320
to produce it, just a few bits. The thing that is remarkable is that even things with very low

694
01:06:34,320 --> 01:06:40,880
algorithmic complexity are very complicated. In fact, they're complicated enough that to us humans,

695
01:06:40,880 --> 01:06:45,840
we wouldn't even be able to distinguish them from things that have high algorithmic complexity.

696
01:06:45,840 --> 01:06:49,920
One of the things I've had a long-running discussion with my friend Greg Chetan,

697
01:06:49,920 --> 01:06:56,480
where the question is, is the universe like Pi or like Omega? Omega is this thing that Greg

698
01:06:56,480 --> 01:07:02,480
invented 50 years ago, actually, that is the halting probability for a universal Turing machine.

699
01:07:02,480 --> 01:07:09,600
It's a fundamentally non-computable object. It's an object with infinite algorithmic complexity.

700
01:07:09,680 --> 01:07:17,520
It is a thing where there is no small program that you can't specify it by a small program.

701
01:07:17,520 --> 01:07:24,560
Pi, on the other hand, is a thing that is specified by a quite a small program.

702
01:07:26,400 --> 01:07:30,080
Once you generate its digits, it looks for all practical purposes random.

703
01:07:30,080 --> 01:07:35,680
So the question that one can ask is, in our universe, is there anything of high algorithmic

704
01:07:35,680 --> 01:07:42,400
complexity? Or is the whole universe actually a thing that is like Pi generated from something

705
01:07:42,400 --> 01:07:49,440
which is a very simple underlying sort of program? And in our model of physics, the answer is the

706
01:07:49,440 --> 01:07:56,400
universe is like Pi. The universe is something that is generated from a thing of very tiny

707
01:07:56,400 --> 01:08:02,080
algorithmic complexity. So that's kind of the distinction between everything I'm talking about

708
01:08:02,160 --> 01:08:07,120
is things of incredibly low algorithmic complexity. The remarkable fact that is not obvious,

709
01:08:07,120 --> 01:08:11,760
it kind of breaks one's intuition, is that things, very simple programs, things of very

710
01:08:11,760 --> 01:08:17,600
low algorithmic complexity can produce what seems to us like great complexity. And the

711
01:08:17,600 --> 01:08:24,320
seems to us becomes much harder when we start talking about our computational boundedness.

712
01:08:24,320 --> 01:08:29,680
It's not the case that it's just, oh, it seems complicated. It's that for a computationally

713
01:08:29,680 --> 01:08:37,600
bounded observer like us, there is no way to compress it. So in algorithmic complexity,

714
01:08:37,600 --> 01:08:42,560
algorithmic information, when saying this is the program and there is no shorter program,

715
01:08:42,560 --> 01:08:48,000
one can say for a computationally bounded observer, this is the set of bits and there is no way to

716
01:08:48,000 --> 01:08:55,040
make it shorter. So that was algorithmic information theory, algorithmic complexity.

717
01:08:55,040 --> 01:09:04,480
I think the second one you had was, what was it? Church Turing. Okay. So, okay. The thing that,

718
01:09:08,240 --> 01:09:12,960
if you go back to the beginning of the 20th century, and you'd wanted to get an adding

719
01:09:12,960 --> 01:09:17,920
machine, you might go to a store, you buy an adding machine. You want to get a square root

720
01:09:17,920 --> 01:09:22,240
machine. Okay, you go to a different store, perhaps, and you buy a different machine that

721
01:09:22,240 --> 01:09:27,120
is the square root machine. The big discovery that actually originally got made by Moses

722
01:09:27,120 --> 01:09:32,320
Schoenfinkel with combinators in 1920, but nobody understood it then or since, basically,

723
01:09:32,320 --> 01:09:40,640
but then kind of got clarified by Turing in 1936 is that there exist kind of,

724
01:09:42,560 --> 01:09:47,520
there exist systems that are universal in the sense that you can have a single piece of hardware

725
01:09:47,520 --> 01:09:51,440
that by feeding it different initial conditions, by feeding it different inputs,

726
01:09:51,520 --> 01:09:56,640
you can make it compute different kinds of things. So, for example, you can have a Turing machine

727
01:09:56,640 --> 01:10:02,960
that has some, where just by feeding it different initial conditions, it will emulate any other

728
01:10:02,960 --> 01:10:10,400
Turing machine. So, for example, if we go to, in terms of Turing machines, there's some, I'm going

729
01:10:10,480 --> 01:10:22,880
to show you something. There we go. Well, so, the big point is there exist machines that are

730
01:10:22,880 --> 01:10:27,680
universal in the sense that they can at least emulate all other machines of their type. The thing

731
01:10:27,680 --> 01:10:32,880
that then became clear, starting in the 1930s, is that Turing machines, you can have a Turing machine

732
01:10:32,880 --> 01:10:37,280
that emulates every other Turing machine. It also, by the way, can emulate every register machine,

733
01:10:37,280 --> 01:10:44,480
every piece of lambda calculus, every combinator and so on. So, there's this notion that in the

734
01:10:44,480 --> 01:10:50,320
class of computational devices, there's a certain degree of universality. People had not thought

735
01:10:50,320 --> 01:10:57,680
that that extended to physics. That was the thing that basically was my effort in the 1980s was to

736
01:10:57,680 --> 01:11:05,040
kind of imagine that this notion that what is computationally computable would also be what

737
01:11:05,040 --> 01:11:10,160
is what can happen in physics. People had sort of assumed that physics kind of breaks out of

738
01:11:10,160 --> 01:11:14,480
kind of this computational paradigm. It has real numbers, precise real numbers, has other kinds

739
01:11:14,480 --> 01:11:20,000
of things like that. So, the first thing is the realization in the principle of computational

740
01:11:20,000 --> 01:11:25,840
equivalence. The first thing is kind of the claim that, well, first part of it is sort of the

741
01:11:25,840 --> 01:11:31,440
physics part that, yes, actually, in the physical universe, this is all we've got. We can't say,

742
01:11:31,520 --> 01:11:39,200
oh, we're going to make an analog computer that jumps beyond kind of the church Turing level.

743
01:11:39,200 --> 01:11:45,840
Second point is this. People imagined that to make a universal machine was a complicated

744
01:11:45,840 --> 01:11:51,680
matter. It was something that would be kind of, you have to build this whole microprocessor. It

745
01:11:51,680 --> 01:11:56,400
might have a billion gates in it. It has all these instructions. It's got if statements. It's got all

746
01:11:56,400 --> 01:12:01,120
this kind of structure. And the question is, well, what's, you know, is that really necessary?

747
01:12:01,120 --> 01:12:06,240
Or is universal computation actually something much more naturally occurring? Is universal

748
01:12:06,240 --> 01:12:10,320
computation a special thing? Have to go to a lot of trouble to get? Or is it something that's just

749
01:12:10,320 --> 01:12:14,560
sort of lying around the computational universe? One of the big points to the principle of

750
01:12:14,560 --> 01:12:19,120
computational equivalence is, yes, it's just lying around the computational universe. So,

751
01:12:19,120 --> 01:12:25,360
for example, if we look at these different possible rules here, some of them behave in

752
01:12:25,440 --> 01:12:28,480
such simple ways that we can readily see what they're going to do. They're computationally

753
01:12:28,480 --> 01:12:34,080
reducible. There's nothing more to say. But some of them behave in a complicated enough way

754
01:12:34,080 --> 01:12:38,400
that we're kind of not really sure what they do. Let me show you an example of one of those. So,

755
01:12:38,400 --> 01:12:47,600
this is, let me show you rule 110. This thing actually only grows on one side here, but

756
01:12:48,880 --> 01:12:53,280
just show that. I shall make it, just show just the part where it's growing. So that's,

757
01:12:53,760 --> 01:12:59,040
after 200 steps, let's run it for 1,000 steps. Okay, there it is. It's a little bit unclear what

758
01:12:59,040 --> 01:13:03,600
it's going to do. This is kind of computational irreducibility in action or undecidability,

759
01:13:03,600 --> 01:13:07,760
ultimately in action. What's it going to do? Is it going to have all those little things,

760
01:13:07,760 --> 01:13:10,480
structures? Are they going to survive or are they eventually going to die out?

761
01:13:11,120 --> 01:13:17,200
After, I think it's about 4,500 steps, they do eventually all die out and they just get left

762
01:13:17,200 --> 01:13:21,680
with this one single structure here. But this kind of computational irreducibility in action,

763
01:13:21,680 --> 01:13:27,040
you can't tell what's going on. This particular rule turns out, if you just look at it, let's

764
01:13:27,040 --> 01:13:35,600
start it off from random initial conditions. Let's say 600 across. No, let's say 1,000 across.

765
01:13:36,800 --> 01:13:45,280
And let's say 800 down. Okay, oh boy. It's a little bit on the screen here. Let me

766
01:13:46,240 --> 01:13:53,040
make it a bit bigger. Okay, there we go. So what you see there is that's the initial condition.

767
01:13:53,680 --> 01:13:58,640
This is what happens. What you see is a bunch of little structures here. And you might imagine as

768
01:13:58,640 --> 01:14:02,320
you look at these structures, oh, they're kind of interacting and maybe that's like a logic gate

769
01:14:02,320 --> 01:14:06,960
and maybe we can make an OR gate out of this and so on. But it turns out with considerable

770
01:14:06,960 --> 01:14:12,400
effort, you can do that. And you can show that rule 110, which is kind of just the 110th rule

771
01:14:12,400 --> 01:14:17,120
in this very simple enumeration of possible rules. It's universal. The first one that you

772
01:14:17,120 --> 01:14:22,240
might imagine could be universal is actually universal. So in a sense, you know, the church

773
01:14:22,240 --> 01:14:26,640
touring thesis is saying it is possible to have a universal machine, at least universal within the

774
01:14:26,640 --> 01:14:30,400
class of computational devices that we're talking about. The principle of computational

775
01:14:30,400 --> 01:14:35,360
equivalence says not only is it possible, it's also generically the case it is ubiquitous.

776
01:14:35,920 --> 01:14:40,800
And in fact, it goes on to talk more about individual computations rather than

777
01:14:40,800 --> 01:14:45,920
programmability, but that's kind of a bonus. By the way, in terms of touring machines,

778
01:14:45,920 --> 01:14:50,080
I was very curious what is, you know, if you just look out in the space of possible touring

779
01:14:50,080 --> 01:14:55,280
machines, just start enumerating touring machines. The first one whose behavior is not

780
01:14:55,280 --> 01:14:59,920
obviously simple as this one here that I found sometime in the 1990s. And so then I was really

781
01:14:59,920 --> 01:15:07,200
curious, is this in fact a universal machine in 2007? I put up this little prize and a chap called

782
01:15:07,200 --> 01:15:13,920
Alex Smith managed to show that yes, this particular touring machine, the first conceivably

783
01:15:13,920 --> 01:15:18,560
universal touring machine actually is universal, which is a nice piece of evidence for the principle

784
01:15:18,560 --> 01:15:24,160
of computational equivalence. So that's kind of the relationship between church touring and

785
01:15:25,280 --> 01:15:30,400
principle of computational equivalence. And computational irreducibility is something that

786
01:15:31,040 --> 01:15:38,720
is sort of, it's made tougher by the fact that this property of universality

787
01:15:38,720 --> 01:15:44,160
is ubiquitous in the computational universe. Okay, thank you. MP completeness. What's that?

788
01:15:44,720 --> 01:15:51,600
We have a question here already, so. Wait a second. You get me. My software is not empty yet.

789
01:15:52,000 --> 01:15:58,640
So you asked about NP completeness. So let me try and address that. So

790
01:16:00,880 --> 01:16:07,760
normally, in a touring machine, for example, you have this touring machine, it has a rule,

791
01:16:07,760 --> 01:16:14,240
you started off from some initial condition, it just evolves in some specific way. It has a specific

792
01:16:14,240 --> 01:16:18,880
history. But you can also have, let's see if I have a picture of this.

793
01:16:35,440 --> 01:16:38,800
I have a bunch of these multiway systems. Well, here, let me show you

794
01:16:45,200 --> 01:16:47,200
a tag.

795
01:16:58,400 --> 01:17:04,880
Find some multiway touring machines. There we go. Multiway touring machines. Okay. So

796
01:17:07,520 --> 01:17:11,520
that's a typical touring machine. It has a rule, it evolves in a particular way.

797
01:17:12,240 --> 01:17:16,960
But you can also have a multiway touring machine in which there isn't just a single

798
01:17:16,960 --> 01:17:20,640
possible path of evolution, but there are many paths. So you can end up with this

799
01:17:20,640 --> 01:17:24,800
kind of branching structure. This turns out to be closely related to what happens in quantum

800
01:17:24,800 --> 01:17:32,080
mechanics. That's a separate issue. But so this idea of NP completeness, NP problems versus

801
01:17:32,080 --> 01:17:38,000
P problems and so on, it's this question. If we have a touring machine and it computes something

802
01:17:38,080 --> 01:17:42,560
and it takes a certain amount of number of steps to compute it, an ordinary touring machine

803
01:17:42,560 --> 01:17:48,160
might take n squared steps to compute a size n version of some problem. But we can also have

804
01:17:48,160 --> 01:17:53,200
a non-deterministic touring machine. We can have a multiway touring machine that follows many

805
01:17:53,200 --> 01:17:59,040
different possible paths. And we say, if we have a path that gets to the answer, then it's a winner,

806
01:17:59,040 --> 01:18:04,320
so to speak. And that's the story of NP problems, non-deterministic polynomial time problems,

807
01:18:04,480 --> 01:18:10,720
ones where there exists a path in this multiway touring machine, which gets you to that answer.

808
01:18:11,520 --> 01:18:20,480
So in a sense, this question of NP, sort of the big question, is P equal to NP? Is the class of

809
01:18:20,480 --> 01:18:28,640
problems that you can solve with in polynomial time with an ordinary touring machine, the same

810
01:18:28,640 --> 01:18:33,440
class or different class, than the ones that you can solve with a non-deterministic

811
01:18:34,080 --> 01:18:42,240
with a multiway touring machine? And actually, that question, so, well, let's see. I mean,

812
01:18:42,240 --> 01:18:46,080
we can talk about computational irreducibility and its relationship to computational complexity

813
01:18:46,080 --> 01:18:51,520
theory in general. But NP completeness in particular, there's perhaps a more interesting

814
01:18:51,520 --> 01:19:08,160
thing to say, which is, if I can find this one. Okay, so we can look at all possible touring machines.

815
01:19:08,160 --> 01:19:16,800
This is in a sense in rural space. Where is this? Nice picture somewhere here. Do I? Yes, here we go.

816
01:19:17,360 --> 01:19:21,680
Okay, so this is a picture of kind of the behavior of all possible multiway touring

817
01:19:21,680 --> 01:19:28,320
machines. So in a sense, all possible programs. And this is showing sort of all possible

818
01:19:28,320 --> 01:19:35,600
non-deterministic programs. The red part is the part that's showing deterministic programs only.

819
01:19:35,600 --> 01:19:40,240
It's not allowing the possibility of the rules changing, so to speak, as you go through the system.

820
01:19:41,040 --> 01:19:45,280
So the P equals NP problem, one of the things that's pretty interesting that comes out of

821
01:19:45,280 --> 01:19:51,680
our physics project is essentially a geometrization of the P equals NP problem. That is a question

822
01:19:51,680 --> 01:20:00,000
of the structure of these objects in rural space, that P equals NP becomes the question of

823
01:20:00,000 --> 01:20:05,280
whether essentially the red bit here eventually fills out the gray part of this picture. So you

824
01:20:05,280 --> 01:20:10,800
can kind of have a geometrical version of this ball in rural space that corresponds to the

825
01:20:11,760 --> 01:20:17,200
P problems and the NP problems. So that's a little bit of an indication of that. But you can,

826
01:20:17,200 --> 01:20:24,880
I mean, this whole question about non-determinism and so on, it's a, oh gosh, there's much to

827
01:20:24,880 --> 01:20:34,400
say about that. I've studied this a lot because it ends up being sort of a proxy for quantum

828
01:20:34,400 --> 01:20:40,000
mechanics. What happens in quantum mechanics is that you are following many paths of history

829
01:20:40,000 --> 01:20:45,360
and the observer in quantum mechanics is effectively a sort of an interesting situation.

830
01:20:45,360 --> 01:20:50,000
The observer is branching in the same way that these actual paths of history in the universe

831
01:20:50,000 --> 01:20:54,720
are branching. So quantum mechanics becomes this question of how does a branching mind

832
01:20:54,720 --> 01:20:59,920
perceive a branching universe? And so it's interesting to kind of see a bunch of different

833
01:20:59,920 --> 01:21:04,640
examples of multi-way systems as a way to get sort of more intuition about that.

834
01:21:05,440 --> 01:21:07,120
Okay, another question, apparently.

835
01:21:08,560 --> 01:21:15,040
Well, let's bring it back to our universe just for now. I want to, if possible, in a few minutes

836
01:21:15,040 --> 01:21:20,560
left, because I don't want to say anything. I want to make a connection between what you said

837
01:21:20,560 --> 01:21:30,800
and what Kyle, what Kai you said before. His program was related to computer aided proof

838
01:21:31,520 --> 01:21:40,160
and transformation of verbally stated truths and conjectures into

839
01:21:41,200 --> 01:21:48,000
formal form called auto formalization. And my question to you is what does the irreducibility

840
01:21:48,000 --> 01:21:54,320
principle say about all the possible theorems and all the possible paths to their solution?

841
01:21:54,320 --> 01:22:00,960
And Kyle, you can say a couple of words in response, but you have to say it in your own

842
01:22:00,960 --> 01:22:06,400
words first because you missed your talk. Well, let's see, I wrote a book recently about the

843
01:22:06,400 --> 01:22:14,080
physicalization of metamathematics, which I think is pretty relevant to this. And so, you know,

844
01:22:14,080 --> 01:22:20,400
we can imagine some, let's see, where's a good example? This is that might be some axiom in a

845
01:22:20,400 --> 01:22:25,520
mathematical system. And we can ask the question, what are the consequences of that axiom? That

846
01:22:25,520 --> 01:22:32,160
axiom is saying x dot y is equivalent to y dot x dot y. And now we can say, well, what things are

847
01:22:32,160 --> 01:22:38,640
also equivalent based on that axiom, we can start figuring out. So every path here is a theorem,

848
01:22:38,640 --> 01:22:44,240
that that's equivalent to that. We can start just following, we can start making this network

849
01:22:44,320 --> 01:22:54,480
of all possible equivalent things. And actually, and so a proof becomes a path in this whole network.

850
01:22:54,480 --> 01:22:57,600
And actually, it's a little bit trickier than that when you start looking at,

851
01:22:59,280 --> 01:23:07,040
there's a good example here. The way one actually does, let's see where I've got a good example.

852
01:23:07,040 --> 01:23:13,280
Okay, so this is an example of what more is actually what's happening in mathematics. You have

853
01:23:13,280 --> 01:23:19,840
basically, let's say two axioms here, and you are combining them to get a new theorem. And so you

854
01:23:19,840 --> 01:23:25,520
can kind of build up this kind of this structure you get with those two green axioms, you're,

855
01:23:25,520 --> 01:23:31,200
you're deriving all those theorems, you get this big network that represents all possible

856
01:23:31,200 --> 01:23:36,560
theorems derived from a particular set of axioms. So you can go on, you can get pretty complicated

857
01:23:36,560 --> 01:23:42,000
versions of this, you can derive all sorts of theorems that are true based on certain axioms.

858
01:23:42,000 --> 01:23:48,960
And what's happening is in this, in this graph, the every blue dot is a theorem. Okay. So then you

859
01:23:48,960 --> 01:23:58,080
can ask the question, if you look at, do I have an example of this? If you look at actual axiom

860
01:23:58,080 --> 01:24:03,360
systems in present day mathematics, so for example, you can look at, there's the axiom for semi-groups.

861
01:24:04,080 --> 01:24:08,400
You can start proving theorems about semi-groups. Okay, so we've got this whole network of theorems

862
01:24:08,400 --> 01:24:14,800
about semi-groups. And so one big question is, if you do that, well, okay, so here's, here's an

863
01:24:14,800 --> 01:24:20,720
example based on the axioms of Boolean algebra. So this is proving theorems based on axioms in

864
01:24:20,720 --> 01:24:25,920
Boolean algebra. And you can go and you can build up this giant network of theorems of Boolean

865
01:24:25,920 --> 01:24:31,600
algebra. And this is, this is kind of the, the enumeration of all possibilities. Okay. So now

866
01:24:31,600 --> 01:24:36,160
the question is, is we enumerate all those possibilities? Where are the theorems we care

867
01:24:36,160 --> 01:24:41,440
about? We've got gazillions of theorems that we can just build out eventually. And this is kind

868
01:24:41,440 --> 01:24:46,480
of spoiled. If you didn't know, you don't haven't followed this, but this really odd object that

869
01:24:46,480 --> 01:24:52,320
I talked about in the talk I gave, that is the ultimate limit of all possible mathematics is

870
01:24:52,320 --> 01:24:59,760
this really odd object. And the question of what theorems are, so all these theorems here are true.

871
01:24:59,760 --> 01:25:04,160
All these theorems can be constructed from the axioms. But these are the only two theorems that

872
01:25:04,160 --> 01:25:10,720
people give names to in textbooks of logic out of this collection. We can keep going. We can find,

873
01:25:10,720 --> 01:25:15,280
we can go to, to lots of other theorems. If we, if we use a theorem proving system,

874
01:25:15,280 --> 01:25:20,080
we can, in that big giant explosion of possible theorems, we can go and say, this is the theorem

875
01:25:20,080 --> 01:25:25,280
we're searching for, and we can find a path to it using, using theorem proving. And those are the

876
01:25:25,280 --> 01:25:33,920
paths in that, in that structure of, of, of possible theorems. Okay, so one question then is,

877
01:25:34,800 --> 01:25:40,800
well, out of all these possible, this, this complicated network of all possible theorems,

878
01:25:40,800 --> 01:25:46,720
where are the ones that we humans care about? And so I looked a little bit at that. And so,

879
01:25:46,720 --> 01:25:52,400
for example, you can, you can look, well, that's, that's, for example, that's Euclid. So Euclid

880
01:25:52,400 --> 01:25:58,160
has 465 theorems. And you can start off from the axioms at the top. And you can see what are the

881
01:25:58,160 --> 01:26:03,600
connections between those theorems, according to the proofs in Euclid. Perhaps more interestingly,

882
01:26:03,600 --> 01:26:11,040
you can take a proof of existence system. I looked at lean. I looked a little bit simpler

883
01:26:11,040 --> 01:26:17,360
to look at the system called metamath, which is a formalized math system. And you can ask questions

884
01:26:17,360 --> 01:26:23,920
like, well, that's the Pythagorean theorem, proved from the axioms in metamath. And you can see

885
01:26:23,920 --> 01:26:28,080
they're a different, it's a pretty complicated thing. This somewhere, I think at the bottom here

886
01:26:28,080 --> 01:26:32,400
is the Pythagorean theorem. And you start from the axioms there, and you can kind of count up

887
01:26:33,120 --> 01:26:37,840
of the various axioms, you know, how many times did you use the axiom of equality?

888
01:26:37,840 --> 01:26:44,080
Five times 10 to the 31 times. This is a, you know, this, this is kind of a, a, this is what

889
01:26:44,080 --> 01:26:49,200
happens if you start from sort of the axiomatic foundation, and you build up to something like

890
01:26:49,200 --> 01:26:56,000
the Pythagorean theorem. So, okay. So one interesting point here is this is the axiomatic

891
01:26:56,000 --> 01:27:00,640
sort of structure of the Pythagorean theorem. The question is, do mathematicians care about this?

892
01:27:01,360 --> 01:27:05,600
So, you know, a decade ago, I was very interested in formalization of mathematics. I organized

893
01:27:05,600 --> 01:27:10,720
this conference. We invited all these formalization of mathematics people, all these people interested

894
01:27:10,720 --> 01:27:15,600
in mathematics itself. The formalizers all showed up. The mathematicians didn't show up.

895
01:27:17,600 --> 01:27:21,440
And so the question is, what does a working mathematician actually do? You know, working

896
01:27:21,440 --> 01:27:27,680
mathematician who's, who's thinking about the, you know, the Pythagorean theorem, are they

897
01:27:27,680 --> 01:27:32,240
thinking about it in this kind of axiomatic way? Are they drilling down to kind of this, this low

898
01:27:32,240 --> 01:27:36,160
level axiomatic structure? Or are they just saying it's the Pythagorean theorem and I'm going to do

899
01:27:36,160 --> 01:27:39,840
things at that level? The thing that's pretty interesting and relates to a lot of what I was

900
01:27:39,840 --> 01:27:46,000
talking about is at this kind of axiomatic level of mathematics, it's kind of like molecular

901
01:27:46,000 --> 01:27:50,560
dynamics in a, in a fluid. You've got all these molecules bouncing around. They're doing all these

902
01:27:50,560 --> 01:27:55,920
complicated things. But then at the higher level, at the more human level, what we get to see is

903
01:27:55,920 --> 01:28:01,760
fluid dynamics. And we can ask the question, can we make conclusions at the fluid dynamics level?

904
01:28:01,760 --> 01:28:06,640
Or do we get dragged down to the molecular dynamics level and have to address things at that level?

905
01:28:06,640 --> 01:28:10,800
So in the question of, you know, using the Pythagorean theorem, for example, do you need

906
01:28:10,800 --> 01:28:15,520
to go down to the level of these axioms and worry about how you define the real numbers and so on?

907
01:28:15,520 --> 01:28:20,160
Or are you actually operating in practical mathematics at a higher level, at this level,

908
01:28:20,160 --> 01:28:29,760
where you're, you're just operating in terms of, of, of these kind of sort of fluid dynamics

909
01:28:30,000 --> 01:28:36,240
concepts? So I have to say, I was curious in, you know, in the, in sort of the world of LLMs and

910
01:28:36,240 --> 01:28:42,880
so on. So I will say that the mission of taking kind of a piece of informal mathematics and

911
01:28:42,880 --> 01:28:48,480
formalizing it seems like a fairly, fairly promising use case for things like LLMs.

912
01:28:49,600 --> 01:28:54,960
I don't know whether the formalization in terms of, you know, existing proof assistance and so on,

913
01:28:54,960 --> 01:29:00,400
I don't know how useful that will really end up being. I was curious whether you could use

914
01:29:00,400 --> 01:29:15,920
LLMs as a way to, as a way to, to kind of guide theorem proving. So I looked here at, here we go.

915
01:29:16,480 --> 01:29:21,520
May I make another suggestion instead of looking at, let Kai answer, just a second,

916
01:29:21,520 --> 01:29:23,920
because there's so little time now we can continue in the back.

917
01:29:23,920 --> 01:29:28,720
Please. Am I, let me just ask a very practical question. I have another thing in 30 minutes.

918
01:29:28,720 --> 01:29:32,800
Am I, I could push it back, but am I going to make that or not?

919
01:29:32,800 --> 01:29:38,320
Yes. The other thing in 30 minutes is the plan, is the panel where you, where you plan,

920
01:29:38,320 --> 01:29:38,800
Oh really?

921
01:29:38,800 --> 01:29:40,400
The panel, are you going to do something else?

922
01:29:41,760 --> 01:29:44,640
Well, I don't know. It really depends, but go ahead.

923
01:29:44,640 --> 01:29:47,120
Danielle, Danielle said that you were going to do both.

924
01:29:47,680 --> 01:29:48,480
Okay. All right.

925
01:29:48,480 --> 01:29:53,040
I think she, if you got the other thing from Danielle, it is in fact the panel.

926
01:29:53,120 --> 01:29:58,000
No, no, no. It's a completely different thing, but that's okay. We'll, we'll, we'll tell you a panel.

927
01:29:58,000 --> 01:29:58,480
That's great.

928
01:29:59,200 --> 01:29:59,680
Say this.

929
01:30:00,400 --> 01:30:06,240
Yeah. I think the short answer is yes. Yes. People are using informal mathematics and

930
01:30:06,800 --> 01:30:11,280
auto formalization, which means translating informal to formal to guide theorem proving.

931
01:30:11,280 --> 01:30:15,680
For example, given a proof, you can use language model like GPT-4 to,

932
01:30:15,680 --> 01:30:20,000
you just ask it to generate informal proof or even a sketch, some ideas of,

933
01:30:20,960 --> 01:30:23,600
could be high level idea of how this proof might go.

934
01:30:23,600 --> 01:30:26,320
And then conditioned on this informal sketch,

935
01:30:27,040 --> 01:30:30,640
you, there will be a second step to generate the formal proof.

936
01:30:30,640 --> 01:30:36,400
And, but I think a caveat is if you rely on auto formalization to give you the proof,

937
01:30:37,360 --> 01:30:40,640
it only works if human already discovered this proof.

938
01:30:42,320 --> 01:30:47,440
Because then there's no, if not, if it's completely alien to mathematics,

939
01:30:47,440 --> 01:30:49,200
then there's nothing for you to auto formalize.

940
01:30:50,240 --> 01:30:54,720
I think another direction related to what Stephen mentioned is,

941
01:30:55,680 --> 01:31:01,040
how can we even take one step further? Can we use language models to generate conjecture?

942
01:31:01,040 --> 01:31:04,560
Like generate the huge graph Stephen was mentioning.

943
01:31:05,200 --> 01:31:10,880
But of course the graph, I think it might be infinite or it may be simply too big.

944
01:31:10,880 --> 01:31:16,000
So a really interesting question I want to maybe learn from Stephen is

945
01:31:16,720 --> 01:31:23,040
say we want to generate this graph, but how do we tell if a node is worthy?

946
01:31:23,040 --> 01:31:28,880
Like if a math statement is interesting, because I imagine in this infinite graph,

947
01:31:28,880 --> 01:31:33,520
most of the nodes will be just garbage, like two greater than one, three greater than two.

948
01:31:33,520 --> 01:31:36,400
But we really want to focus on this interesting nodes.

949
01:31:37,040 --> 01:31:42,080
Yes, it's an interesting question. So I've looked at this a bit and I can tell you that in the case

950
01:31:42,080 --> 01:31:47,440
of Boolean algebra, there is a criterion. So maybe I can pull up a picture of that.

951
01:31:48,640 --> 01:32:04,640
If you order, here we go. Hold on. Let's see. If you order the theorems of Boolean algebra

952
01:32:05,360 --> 01:32:13,520
in lexicographic order, then you can ask which are the theorems of all possible theorems? Which

953
01:32:13,520 --> 01:32:19,920
ones are given names in logic textbooks? And sort of a surprise to me is the theorems that

954
01:32:19,920 --> 01:32:24,400
are given names in logic textbooks are the theorems that have, in this case, no back links.

955
01:32:24,400 --> 01:32:28,720
So there's a backlink from this result here, which might be one of your boring results.

956
01:32:29,440 --> 01:32:34,240
This result is derivable from something earlier in this lexicographic list.

957
01:32:35,120 --> 01:32:40,160
So in a sense, it gives you no new information. It turns out the ones that get given names

958
01:32:40,160 --> 01:32:44,640
are precisely the ones that do not have back links. They are not derivable

959
01:32:44,640 --> 01:32:50,800
from lexicographically simpler theorems. So in other words, I was surprised that I discovered

960
01:32:50,800 --> 01:32:55,360
this sometime in the 90s. I was surprised by this, that there was actually a criterion

961
01:32:55,440 --> 01:33:00,080
for what would be given a name in a logic textbook. Now, the general case of is this

962
01:33:00,080 --> 01:33:05,280
theorem interesting? Can we learn enough about the humans to know what they'll think is interesting?

963
01:33:05,280 --> 01:33:09,440
It's a good question. I mean, by the way, in this connection between formal and informal,

964
01:33:09,440 --> 01:33:15,200
obviously, Wolfram language gets connected to LLMs. And we've done lots of work in kind of

965
01:33:15,200 --> 01:33:20,800
tool calling from LLMs to Wolfram language. And there's this whole question of, can you take,

966
01:33:20,960 --> 01:33:25,840
to what extent can you get the LLM to crisp things up to the point where you can, I don't know,

967
01:33:25,840 --> 01:33:34,160
I mean, if I say something like draw a pentagon and a hexagon, for example,

968
01:33:35,200 --> 01:33:40,160
let's see what it does. I don't know if it'll figure it out or not. It might be able to,

969
01:33:41,120 --> 01:33:52,080
we could, the question is, can we generate a, can we turn that informal statement into a piece

970
01:33:52,080 --> 01:34:00,000
of formal Wolfram language code? Okay, not bad to manage to do that one. And if we look here,

971
01:34:00,000 --> 01:34:06,640
I'm sure we can get it to, there we go. So that showed us the actual code that did that,

972
01:34:06,640 --> 01:34:11,440
wouldn't have been the way I would have done it, but it's okay. That's a reasonable way to do it.

973
01:34:11,440 --> 01:34:15,760
But so this is a case where we're going from an informal description to this computational

974
01:34:15,760 --> 01:34:19,920
language, which we can then compute from. And that's a very powerful thing to do. And in fact,

975
01:34:19,920 --> 01:34:24,160
we even have a product that's coming out soon that is based precisely on that idea.

976
01:34:25,280 --> 01:34:31,920
But so I think this question of whether you can sort of, can you guide the proof this way?

977
01:34:31,920 --> 01:34:37,840
I suspect you can. Now this question of what is a human proof, what's, okay, this is an example.

978
01:34:37,840 --> 01:34:43,200
So in automated theorem proving, one of the shocking things about automated theorem proving,

979
01:34:43,200 --> 01:34:48,000
I believe you might correct me and tell me, one day somebody is going to tell me I'm wrong about

980
01:34:48,000 --> 01:34:54,560
this. But so far as I know, essentially all the theorems that have been proved by automated

981
01:34:54,560 --> 01:34:59,280
theorem proving were theorems that somebody already believed were true. In other words,

982
01:34:59,280 --> 01:35:05,200
there is no newly discovered thing that came from automated theorem proving with one counter

983
01:35:05,200 --> 01:35:10,400
example. The one counter example is something I found 24 years ago now, which is this is the

984
01:35:10,400 --> 01:35:17,120
simplest axiom system for Boolean algebra. So you can think of that as a NAND operator.

985
01:35:17,120 --> 01:35:23,760
This is of all possible from that one axiom, you can derive all the true statements of Boolean

986
01:35:23,760 --> 01:35:32,400
algebra. The proof of that is this long 100 step automated proof. Let's see if I have a picture

987
01:35:32,400 --> 01:35:36,800
of it. Yeah, I mean, that's sort of some kind of visual representation of that proof. It has

988
01:35:36,800 --> 01:35:42,560
various popular lemmas in it and so on. In the last 24 years, despite quite a bit of effort,

989
01:35:42,560 --> 01:35:47,840
actually, nobody has ever understood this proof. But it is interesting because it is a proof of

990
01:35:47,840 --> 01:35:53,600
something surprising, potentially interesting, depending on whether you care about simplest

991
01:35:53,600 --> 01:36:00,480
axiom systems for things. But it was found by automated theorem proving without already knowing

992
01:36:00,480 --> 01:36:07,280
what you were searching for, so to speak. And that's a case where now you ask the question,

993
01:36:07,280 --> 01:36:14,560
if you're out in the wilds of, I mean, we can look, I have a nice picture of this,

994
01:36:14,560 --> 01:36:25,120
we can look at, oh, here, is that one? Yeah, this is, these are axiom systems down the left.

995
01:36:25,840 --> 01:36:33,120
Those are theorems across the top. And there's a dot, a blue square, whenever that theorem

996
01:36:33,120 --> 01:36:39,280
is true in that axiom system. So we can ask the question, given an axiom system that we decide

997
01:36:39,280 --> 01:36:44,240
is exciting, and how we decide that is an interesting question, it's unright. But given an axiom system,

998
01:36:44,640 --> 01:36:50,240
we can say, here are the theorems that are true. Now, which are the theorems here that we care about?

999
01:36:50,880 --> 01:36:56,240
And that's essentially a model for humans. And I think it's an interesting question. We've done

1000
01:36:56,240 --> 01:37:01,600
some experiments kind of grinding up archive and so on, and trying to figure out, can we deduce

1001
01:37:02,240 --> 01:37:08,160
what, in a space of possible theorems, what theorems are likely to be interesting? I don't

1002
01:37:08,160 --> 01:37:13,040
know if you've looked at that. Is that, I think that's an interesting thing to look at. Have you

1003
01:37:13,040 --> 01:37:25,600
looked at that? Yeah, I think the way I'm looking at it is more, so I kind of am not considering

1004
01:37:25,600 --> 01:37:33,360
its relationship with other theorems. I'm taking the theorem statement itself and try to have some,

1005
01:37:34,080 --> 01:37:38,240
for example, have the language model telling me whether it's interesting. I believe the language

1006
01:37:38,240 --> 01:37:45,760
model can look at some kind of superficial cues, like how long the theorem is and what are the

1007
01:37:45,760 --> 01:37:52,000
variables, how they are arranged, how messy it is, and which can already give us some way of

1008
01:37:53,360 --> 01:37:59,200
judging how interesting it is. But I agree, like maybe ultimately what an interesting theorem is,

1009
01:38:00,480 --> 01:38:06,400
it can help you prove a lot of other theorems. Is that your definition of an interesting theorem?

1010
01:38:06,400 --> 01:38:13,920
I'm not sure that's right. I mean, in other words, that is one possible way, I guess.

1011
01:38:15,280 --> 01:38:19,600
There are many different criteria you can imagine for interestingness. That particular one

1012
01:38:19,600 --> 01:38:25,120
would be saying that if that was the correct criterion, then what you could do,

1013
01:38:26,240 --> 01:38:30,080
like I was just showing that picture, actually, in the Boolean algebra case,

1014
01:38:30,640 --> 01:38:39,840
wherever it is, then I would deduce from your statement that the theorems that are big here are

1015
01:38:39,840 --> 01:38:46,320
the ones that have many, those are the high-out-degree theorems. In other words, those theorems,

1016
01:38:46,320 --> 01:38:51,520
that theorem there should be the one I should care about. I don't understand these theorems,

1017
01:38:51,520 --> 01:38:58,960
honestly. What's that? I mean, in that sense, yes, because they are special in this graph.

1018
01:38:59,680 --> 01:39:07,200
That's right. But the question of whether those are human useful is, I think, a different question.

1019
01:39:07,200 --> 01:39:13,680
I mean, in other words, what is, you know, there's this question. It could be the case that two,

1020
01:39:13,680 --> 01:39:19,280
okay, first question is, if you look at many different possible things you might prove,

1021
01:39:19,280 --> 01:39:25,200
you can ask the question, are there repeated theorems that often, are there repeated lemmas

1022
01:39:25,200 --> 01:39:31,680
that often come up in those proofs? Okay. So I looked at that. And the answer is there are.

1023
01:39:32,320 --> 01:39:39,920
And so, for example, that axiom system of mine for Boolean algebra, if you use it to prove

1024
01:39:39,920 --> 01:39:45,200
theorems in Boolean algebra, you can just look at what intermediate lemmas does a theorem prove

1025
01:39:45,200 --> 01:39:50,080
are typically proved to make progress. And the answer is, for example, it takes it 100 steps

1026
01:39:50,080 --> 01:39:55,040
to prove the commutativity of NAND, and it often does that and then goes on and does other things.

1027
01:39:55,680 --> 01:40:00,240
So in that sense, you know, you can, I mean, it is an interesting experimental question.

1028
01:40:00,240 --> 01:40:04,720
To what extent are there repeated lemmas that show up? And that might be a criterion,

1029
01:40:04,720 --> 01:40:08,800
but that's a criterion that has nothing to do with LLMs and so on. That's a criterion that just

1030
01:40:08,800 --> 01:40:17,280
has to do with the mathematical graph. I think this question of, you know, if we look at images,

1031
01:40:17,280 --> 01:40:22,960
for example, you didn't see what I was showing earlier, but here I'll pull up a,

1032
01:40:24,720 --> 01:40:30,880
I was just showing something like this. This is in, you know, embedding space of a

1033
01:40:30,880 --> 01:40:36,640
generative AI system with in the middle is the cat in the party hat, then there's sort of a cat

1034
01:40:36,640 --> 01:40:41,920
island of cat-like things, and then you're out in sort of inter-concept space that we have not yet

1035
01:40:41,920 --> 01:40:47,600
explored. And so you can imagine the same kind of thing for mathematics. You say, here's a theorem

1036
01:40:47,600 --> 01:40:53,920
that somebody wrote down. Let's sort of change the embedding in some sense and say here are nearby

1037
01:40:53,920 --> 01:41:01,440
theorems that weren't necessarily, you know, where is the island? How far out does the island of

1038
01:41:01,440 --> 01:41:07,600
interestingness go? What happens in this kind of inter-concept space between this theorem

1039
01:41:07,600 --> 01:41:11,360
that we thought was interesting and this other one we thought was interesting? So I mean, I think

1040
01:41:12,160 --> 01:41:20,880
it's a, I mean, let's take an example. Let's say, I don't know, let's take, well here, we've got,

1041
01:41:20,880 --> 01:41:25,760
you know, these are random pictures generated in inter-concept space that maybe are of things

1042
01:41:25,760 --> 01:41:30,160
that we care about. I don't know. I mean, that one on the right, we might kind of think it's,

1043
01:41:30,160 --> 01:41:34,640
I don't know what it is, but you know, it was just generated by a generative AI.

1044
01:41:34,640 --> 01:41:39,200
And similarly, imagine that was a theorem. The question is, is this a theorem that we care about?

1045
01:41:40,160 --> 01:41:42,720
You know, it's just like, is this a picture we somehow

1046
01:41:43,840 --> 01:41:50,640
seems relevant to us? And I think, you know, this question of whether, I mean, if we look,

1047
01:41:51,280 --> 01:41:55,760
one of the things that's sort of interesting that one can do is to kind of look at this whole space

1048
01:41:56,640 --> 01:42:04,240
of, let's see, we can kind of look at metamathematical space and we can kind of ask,

1049
01:42:05,200 --> 01:42:11,120
let's take a look here. I think I had a nice picture and find it. I mean, we can ask all sorts

1050
01:42:11,120 --> 01:42:18,400
of questions about different possible proof structures, which are, that's a meta mathematical

1051
01:42:18,400 --> 01:42:24,720
thing, but let's see if I can find a picture here. Yeah, that's a picture of, I think this is

1052
01:42:24,720 --> 01:42:33,440
from metamath. This is empirical metamathematics. It's asking, in the space of all 200,000 theorems,

1053
01:42:33,520 --> 01:42:40,800
discussed in, you know, presented in the metamath corpus, where do these famous theorems of mathematics

1054
01:42:40,800 --> 01:42:46,480
lie in that space? So it's kind of asking this question that this isn't all possible theorems.

1055
01:42:46,480 --> 01:42:54,160
This one is reduced to just the ones that are in the, I think it's set dot mm corpus for metamath.

1056
01:42:56,560 --> 01:43:00,240
But, you know, this is again related to this question of where are the ones,

1057
01:43:00,240 --> 01:43:04,560
where are the ones one cares about, so to speak. And you can kind of, well, you can kind of see,

1058
01:43:04,560 --> 01:43:08,560
this is kind of how the different theorems and different areas of mathematics kind of

1059
01:43:09,360 --> 01:43:12,560
get related to each other. But I think it's a really interesting question. What,

1060
01:43:13,840 --> 01:43:20,560
you know, and you mentioned that, I mean, I suspect LLM is a really good at picking up on

1061
01:43:20,560 --> 01:43:26,960
cues from humans. And so I'm sure there's ways that people will write their master theorem.

1062
01:43:26,960 --> 01:43:31,200
You know, they'll make, there'll be more trumpets blaring when they present the master theorem in

1063
01:43:31,200 --> 01:43:36,320
their paper than when they present a little lemma. But here's a good question. Here's a question.

1064
01:43:36,320 --> 01:43:43,680
If you try and make this, this is an easy thing to test. Okay. Can an LLM classify,

1065
01:43:43,680 --> 01:43:49,120
given a statement, can it decide whether the, whether the author of the paper will have called

1066
01:43:49,200 --> 01:43:57,520
it a theorem or a lemma? Well, I would guess yes, because there are different subtle cues,

1067
01:43:57,520 --> 01:44:05,680
but I didn't try. What I tried, what I did try is I gave LLM some inequalities, like very simple

1068
01:44:05,680 --> 01:44:10,880
elementary inequalities. Some were written by humans from the problem sets, from MO problem

1069
01:44:10,880 --> 01:44:16,160
sets, for example. And others are just generated randomly by machines, which typically look very

1070
01:44:16,160 --> 01:44:23,120
messy. And LLMs can do a reasonably good job at that task. Although I would say that task may not

1071
01:44:23,120 --> 01:44:27,520
be very difficult. Well, okay, so we've tried to do things like this, because we've been interested

1072
01:44:27,520 --> 01:44:32,320
in automated testing of Mathematica and Moulton language. So we're interested in generating

1073
01:44:32,320 --> 01:44:38,240
tests that are plausible input, so to speak. So we've indeed tried doing things like that.

1074
01:44:39,200 --> 01:44:43,680
Not been particularly successful. I mean, in other words, you can, you can generate an

1075
01:44:43,680 --> 01:44:48,800
expression at random just by some Markov process, for example, and you can generate an expression

1076
01:44:48,800 --> 01:44:55,520
by using some LLM like device. And you can ask the question, you know, given, given that you've seen,

1077
01:44:56,240 --> 01:45:01,920
I don't know, we've got billions of sort of human related Wolfram language expressions.

1078
01:45:01,920 --> 01:45:07,520
And then the question is, can we generate others that are like those? That's one question. Another

1079
01:45:07,520 --> 01:45:13,120
question of great practical interest for us is, can we guess whether something that somebody entered

1080
01:45:13,200 --> 01:45:19,440
is likely to be what they meant? Or is it something, in other words, it's like asking the question,

1081
01:45:19,440 --> 01:45:23,920
is this a, a plausible sentence, or is this a sentence nobody would ever write,

1082
01:45:24,640 --> 01:45:28,320
which is something which LLMs in a sense implicitly are capable of doing?

1083
01:45:29,360 --> 01:45:34,720
I must make an executive decision now. And it's a calculated risk. We may lose

1084
01:45:35,440 --> 01:45:40,880
Steven Wolfram, if it turns out he has something else of higher priority. We may use lose other

1085
01:45:40,880 --> 01:45:47,040
people for the panel, in which case I will have called closure on this needlessly. And there may

1086
01:45:47,040 --> 01:45:51,600
be nothing in the panel, but I have to call closure because we have to stop this session

1087
01:45:51,600 --> 01:45:57,600
and then restart for the next session. I want to thank you very much, Steven, for your, for

1088
01:45:57,600 --> 01:46:03,440
your talk. And I hope we'll be seeing you again in 10 minutes, but we'll see. Okay.

1089
01:46:04,000 --> 01:46:06,720
Are we using the same link for the panel?

1090
01:46:08,720 --> 01:46:11,040
Are we using the same Zoom link for the panel?

1091
01:46:11,040 --> 01:46:15,200
I will redo it on, I'll restart it for the panel and I hope you'll be there.

1092
01:46:16,240 --> 01:46:19,440
Steven's there too, but I have to break it now.

