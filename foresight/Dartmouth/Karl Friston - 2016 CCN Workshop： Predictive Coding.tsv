start	end	text
0	11640	Llywbeth hon am wneud ym mwyn sicrhau hynny ac mae'r ydych混wyl sy'n cynnig mewn gw'r dym такую rhoi riannol?
12760	22460	Mewn gwneud o'c flyny y plwydio yn rhai ddiddio'r cyfnodau, Beth lle mae am gwaeth hyn a chi véliwr ja Prud Follow gwelwch.
22780	28640	Dolwedd yn geist startoeth오еч arall yn i ballrain arall, lle arall yn gweithio'r Llywodraeth.
28640	45620	rhoi
45620	71740	回來 i'w gyddi'w gwybodaeth honom i
71740	75260	... Almighty Mike, tewi ydy gyrygau…
75400	77520	… dyma ar-dysgu!
78060	82000	Fy enw i, i���ch cicitYEalsoch…
82900	85660	… yma amary teuluw...
85800	89600	… i'r ffordd ydych Lady Worker...
89600	94100	… Trunwau ystafelu'n bob gynyddio...
94220	98740	… Mae'n eu clynyddu i'r ddelig, yn ddefnyddioSeePlayer...
98920	101500	… Neil yma am ar-zell, amaeddrannu...
101500	107420	Ac rydw i fyny mis o bwyfia'r amser,
107420	112760	nad maen nhw gwybod gweithre vaccinations,
112760	115100	rydw i'n amser ar gwell feedêctig Sa怎么样au?
115100	122440	Rydw i'n mir enghreithio y cael meddwl ei m следdi habiloghau ar resideộld,
122440	128200	ph番 dod yn gynghreithi a wyloach amoduslu ar draw.
128200	130200	i'w ddweud i'w ddweud i'w ddweud.
158200	187200	So, this is an overview of what we are going to go through. I am going to introduce the notion that you are the free energy principle, but from a, using a slightly heuristic approach in terms of action and the path of least resistance,
187200	196200	highlighting the importance of having internal models or hypotheses that enable us to generate predictions, talking about active inference.
196200	212200	And one key thing that I am going to focus on is translating the theory into a process theory that can be used to understand neuronal message passing in the brain and help us exactly constrain the sorts of experiments that Jim was talking about.
212200	229200	So, that is going to be a big part of what I hope that we will be talking about, taking normative principles and seeing how they unpack in the service of understanding empirical measurements anatomy and physiology and how they can be used to nuance experimental design,
230200	237200	showing the sorts of things that one can simulate and speaking to some empirical predictions of these sorts of schemes.
237200	248200	And I have put, as an epilogue, more recent work, simulations of reading that introduce hierarchies into the particular forms of generative models that I want to survey for you.
248200	254200	We won't have time to go without that, but I just want to show you the slides in case of something that catches your attention.
254200	263200	So, I'm going to start with a question. Let's assume you're hungry, and let's assume you're an owl. So, what are you going to do?
266200	270200	You're going to search for a mouse? And how are you going to do that?
272200	275200	Don't cheat. You have to look at me, not at me.
277200	279200	Absolutely. Perfect answer.
279200	286200	So, in terms of optimal behaviour, the first thing you do is search. You scan.
286200	294200	You confront the epistemics of reducing uncertainty about what you need to do in order to fulfil your goal.
294200	300200	So, it's all about beliefs. So, in that answer is the basis of everything that I'm going to say.
300200	307200	Your behaviour is always driven by beliefs, and that tells us something quite important.
307200	314200	So, here's you scanning and searching, and you've found a little mouse that you might want to eat there.
314200	323200	That's quite important because it speaks to two basic classes of ways of thinking about optimising behaviour.
323200	332200	You can either imagine that there is some value function of the next state that will be brought about by some action,
332200	339200	and optimise that action by selecting the action that maximises the value of the next state.
339200	349200	That's the classical way of doing it, but that just doesn't work if the best next thing to do is to search and resolve uncertainty.
349200	352200	Because uncertainty is an attribute of beliefs.
352200	363200	Therefore, the function of a function that you need to optimise in terms of action you hear is a function of beliefs,
363200	367200	which I'm deleting by Q, beliefs about the states of the world.
367200	377200	That introduces a fundamental distinction between the sorts of schemes that you bring to bear in terms of understanding optimal behaviour.
377200	389200	The other thing about the scanning and searching answer is that action depends upon beliefs about the world, states of the world, and subsequent actions.
389200	396200	So, not only is it a function of beliefs about the world, but it's the order in which you interrogate that world.
396200	402200	So, it makes a difference whether you search, then eat, as opposed to eat, then search.
402200	409200	That means that we are in the game of optimising sequences or policies or actions.
409200	411200	I'm going to call it a sequence of actions policy.
411200	424200	So, what that means from the point of view technically of what sort of thing we have to optimise, it's a functional of a belief integrated over time, or summed over time, a path integral.
424200	429200	If we call that an energy, then the integral, the path integral of an energy is called an action.
429200	443200	So, what we've just said is that we've reduced the problem of good behaviour to Hamilton's principle of least action, where action is the path integral or the trajectory integral or the sum over an energy functional of beliefs.
443200	448200	And that's the basic premise that I'm going to pursue.
449200	462200	Just to highlight the distinction, if you subscribe to this way of thinking about how systems work, then you end up with optimal control theory, Bayesian decision theory, reinforcement learning and all that good stuff.
462200	474200	Conversely, if you believe this is how biological systems work, then you end up essentially with Hamilton's principle of least action, the free energy principle, active inference, active learning and so on.
474200	476200	And that's what we're going to focus on.
476200	489200	And the energy function that I'm going to consider, we've already heard mentioned, is the variational free energy or the free energy, which we've already heard very roughly scores surprise.
489200	495200	It approximates surprise or suprisal and is simplifying assumptions prediction error.
495200	504200	So, what we are saying is that we're just in the game of minimising prediction error and more specifically prediction error over time over sequences of behaviour.
504200	513200	I'm going to quickly go through this because there are lots of interesting connections with existing theories and formulations.
513200	521200	This is a bit technical. These are both iconic and ironic equations. You'll hear more about those later on.
522200	540200	In words, if it's the case that good agents, good people, minimise their free energy, their surprise, their average surprise and their uncertainty, then they must believe that the actions that they emit will minimise expected free energy.
540200	554200	You can write that down very simply in terms of these belief functions here and rearrange them in a way that discloses important links with lots of established formal treatments of behaviour.
554200	565200	I've written the expected free energy associated with any particular policy in terms of its expinsic value here and its epistemic value.
565200	574200	Basically, these things store the surprise about what you predict will happen under a particular behaviour and what you think should happen.
574200	578200	Your preference is like, I'm going to eat a mouse and I'm not going to be hungry.
578200	582200	That's a surprise bit, explicit or expinsic surprise bit.
582200	588200	There's another sort of average surprise or relative entropy which is called epistemic value.
588200	593200	It's a reduction in uncertainty or the information gain, and that's the key bit.
593200	602200	It's the epistemic which is missing from classic theories but is part of this formulation of Hamilton's principle of least action.
602200	609200	That relates very closely to theories of visual salience, of Bayesian surprise.
609200	620200	Technically, Bayesian surprise is the divergence of the difference between a prior belief and a posterior belief or a posterior belief to be informed by observations here.
620200	639200	What we're saying is that we will choose to act in a way that reduces our uncertainty relative to prior beliefs, looking at data which gives us information that maximally reduces that uncertainty that has the greatest epistemic value or Bayesian surprise.
639200	651200	In fact, mathematically, that's exactly the same as the mutual information between the causes, the hidden states of the world S and the consequences, the outcomes that we actually observe.
651200	663200	So another way of saying this is that we are subscribing to the principle of maximum information, mutual information or minimum redundancy or maximum information efficiency of the sort articulated by Horace Barlow.
663200	671200	Always of expressing one particular form of perspective on this underlying functional.
671200	683200	Another way of thinking about this in the case, if there is no ambiguity, if we actually can observe the states directly, then we can discount this uncertainty term here.
683200	693200	And what we're left with is something called KL control, which is the state of the art of what people would use in optimal control theory and dynamical systems control.
693200	703200	In economics, it's called risk sensitive control. It's minimizing risk. So this is a surprise between what I think will happen and what I want to happen.
703200	713200	And if what I think will happen is surprising relation to what I thought was going to happen, then I have a high degree of surprise, a high degree of risk, and I want to minimize that.
713200	728200	And then finally, if there's no ambiguity or there's no risk, then we reduce to classical expected utility theory or all the sorts of theories that reinforcement depends upon this maximizing our preferred outcomes there.
728200	738200	So, clearly, in order to be surprised, we have to have predictions against which we can match outcomes to score that surprise.
738200	755200	And this brings us to generative models. And the departure that I promised you from what people currently understand in terms of predictive coding and what I'm going to talk about for the next few minutes is I'm going to formulate generative models not for continuous state space
755200	767200	of the sorts used in predictive coding of, say, visual angles or content or acoustics, but generative models in which we can label the entire world in terms of a number of discrete states.
767200	776200	So these are generative models for discrete state spaces, and they don't normally have the look and feel of predictive coding, but my story will be, is in fact they do.
776200	789200	They are actually formally very, very similar to the sorts of schemes that we understand in terms of top-down predictions and bottom-up prediction errors in hierarchical message-passing allopredicative coding in the visual cortex.
790200	797200	So in these models, all we have, this is not, ignore the equations, but it's focused on this graphical model here.
797200	811200	What we're saying is that the world unfolds in one of many, many states, and the transitions from one state of the world to the next state of the world are encoded by probability transitions that themselves depend upon how we act.
811200	820200	They depend upon the policies that we choose, and we have a certain confidence in those policies, denoted by their precision or inverse temperature beta here.
820200	837200	So if we knew the probability transitions or the transitions from time to time of the states, we can generate a sequence or trajectory of states, and each state, at each point in time, generates an outcome through this likelihood of matrix A.
837200	847200	And that's it. That's the generative model. The world has states, they unfold, and each state generates an outcome that's observable.
847200	852200	And that's the basis of everything else that I'm going to say.
852200	873200	If I'm now given a generative model, what I can do is I can evaluate the free energy of my beliefs under that generative model, and I can then minimize everything with respect to that proxy for surprise or uncertainty, namely the expected free energy.
873200	885200	And I can write down equations or solutions that tell me how an optimal agent person would behave in a sort of Bayesian sense.
885200	890200	And these are the solutions to the equations expressed in terms of the parameters of that model.
890200	898200	So A was this mapping from states of the world to outcomes, and B was the mapping between subsequent hidden states.
898200	907200	And despite the complicated nature of the equations on the previous slide, the actual updates, the solutions are incredibly simple.
907200	912200	And furthermore, they look very much like the sorts of things that the brain does.
912200	923200	So, for example, expected states of the world are a nonlinear sigmoid function of linear mixtures of expected states of the world and observations.
923200	932200	So we're mixing together evidence from outcomes and our beliefs about the states of the world to update our beliefs about the current state of the world.
932200	949200	Our beliefs about what we're going to do next, our policy pie here, is this a softmax function of the expected free energy weighted by an inverse temperature parameter that you will see we associate with dopamine, a classical softmax response rule.
950200	958200	If you're not familiar with that, that's what people in economics and choice behaviour use for those people who deal more with perception.
958200	974200	We also have a model of incentive salience. The confidence or the precision or the inverse temperature associated with our beliefs about action now becomes, as a Bayes optimal solution, that depends upon the goodness of a policy or the negative goodness, the expected free energy here.
974200	983200	And the form of these equations speaks to a rough anatomy of computations in the brain, a computational anatomy.
983200	992200	And it sort of goes like this, where we have these equations dictate what each update needs to know about the other updates.
992200	1008200	So, basically, it prescribes a connectome for the exchange of information or sufficient statistics that is implied by placing the Hamilton's principle of least action on the simplest sort of generating model that you can imagine.
1008200	1022200	And that's the sort of anatomy we have here. Outcomes, expected states, expected policies, the goodness or the expected free energy of policies, the precision of policies, states in the future, which prescribe action.
1022200	1028200	So, I won't go through that, but I'll just give you a more heuristic version of that one. So, what those equations tell us.
1028200	1035200	So, this is like a very top-down argument. It's not, you know, let's think about how the brain works and come up with some hypotheses.
1035200	1044200	This unfolds or unravels from, impacts from, just applying Hamilton's principle of least action to a very simple generating model.
1044200	1056200	And what it tells us is that sensory input comes in, say, at the back of the brain. It informs and updates expectations about hidden states of the world, sometimes referred to as state estimation.
1056200	1068200	They are associated with a free energy or a surprise that is combined with an evaluation of those states in relation to prior preferences and their potential reduction of uncertainty, their epistemic value.
1068200	1078200	They are combined to give us beliefs about the policy that we are currently pursuing. We have a certain confidence in that policy.
1078200	1088200	And then those policies are used to weight all the different states conditioned upon what we are currently doing to give us the best estimate of what's going to happen next, the next state of the world.
1088200	1102200	And if we know that, then we can choose the action that brings about, that realises our expectations, our predictions about the next state of the world, that action solicits a new observation from the environment and the cycle begins again.
1102200	1109200	So, we have a perception action cycle that falls out of the minimisation scheme that we've just been talking about.
1109200	1120200	So, very briefly, I'm just going to show you how that sort of thing works with a series of examples, and then hopefully I'll turn it over to you to see what you want to talk about.
1120200	1134200	The first example is just a very simple simulation of foraging in a two-arm maze. So, in this example, there's a little rat here, and there are rewards on the right and the left arms of the maze, but the rat doesn't know where the reward is.
1134200	1144200	There's also an informative queue at the bottom of the maze here, and if it went to solicit that queue, it would then know where the reward was, and it could only make two moves.
1144200	1162200	So, it can either take a chance and go to one of the other top arms, or it can be a bit more clever and resolve any uncertainty about the context it's currently operating in, which arm is baited, and go and retrieve the epistemic value of the informative queue and then make an informed decision.
1162200	1176200	So, this is exactly the searching that you were talking about before, scaling your environment, knowing where you are, resolve your epistemic, solve the epistemic problem, and then turn to your prior preferences or your pragmatics.
1176200	1199200	You can write this model down in very simple terms of these A and B matrices here. There's partial reinforcement here, and the C matrix here just denotes the preferences in terms of what sorts of states this rat thinks it should occupy, basically thinks it should be in the baited arm and not in the unbaited arm.
1199200	1225200	That's all it's saying here, with minus threes and plus threes on the upper arms that are baited. And if we do that, and we just integrate those solutions that I told you before, we actually generate very realistic behaviour, summarised here in terms of the expected policy and the policies that this agent or this little animal can entertain.
1225200	1243200	It stays there and then goes to one of the three arms, or it goes to one of the two arms, or it goes to the bottom and then goes to any of the three arms. So there are eight policies here.
1243200	1260200	And what it does in the first instance is because it doesn't know where the reward is. It gets the cue and then obtains its reward. What we've done here is actually baited the left arm all the time.
1260200	1278200	So slowly it accumulates evidence that, in fact, the reward's always on this side here. So as time goes on, it actually switches and learns, and it's probably better to avoid or dispense with the epistemic move and go directly to the reward.
1278200	1297200	And it starts doing that after about 20 or 30 trials here, at which point its reaction times, and this is the actual floating point operations of the scheme, decrease. And because the goodness of a policy is this path integral, it's actually spent more time being rewarded.
1297200	1311200	So if you like, the payoff also increases by going straight there. So this prescribes good policies, and it can be used to simulate nice behaviors of the sort you've seen experimentally.
1311200	1329200	But what I want to do finally is just connect that to neurophysiology and neuroanatomy. But to do that, I have to have a process theory. I have to have a theory which says this particular neuroactivity or this particular connection strength corresponds to this quantity in the model.
1329200	1354200	And I have to have a process in play that is neurarily plausible. And the way that we're going to do that is just take those update equations that we've seen before, and instead of just writing down the solutions mathematically, I'm going to recast the solutions in terms of a gradient descent or a hill climbing, or actually a hill descent here.
1354200	1370200	So this is a standard way of optimizing something. If you've got a quantity you want to minimize, you just go downhill until it stops getting smaller. And if I do that, I can write down exactly the same scheme in terms of differential equations on expected states of the world.
1370200	1390200	It's very similar form, but here that's a rate of change of activity, which is now a nonlinear function of linear mixtures of expectations about states of the world and the observations. And in doing that, I've created a dynamical system that now has as much closer to the look and feel of a neuronal system.
1391200	1409200	And that now enables me to look at the dynamics that underlie the behavior. And these are the dynamics here, and we can basically break these into inference and state estimation in terms of the updates or the fluctuations in the states as new evidence comes along.
1409200	1425200	Policy selection that we've already seen with our softmax response rule, and learning as we accumulate from trial to trial evidence about particular states or contingents of the world in this instance that the left hand arm of the maze was always baited.
1426200	1438200	I illustrated those things here, a couple of interesting things to note. First of all, with every new move and every bit of new sensory information, there are lots of fluctuations in these states that look very much like an ERP.
1438200	1459200	Furthermore, when we become a little bit more automatic or not habitual, but certainly going straight for our reward, there is an attenuation of these responses. The confidence, the precision in those responses also shows these phasic changes and progressive changes as we learn the context.
1459200	1470200	So we actually get something which looks remarkably similar to transfer of dopamine responses as we become more familiar and more confident about the outcomes that we see.
1470200	1485200	Let me just quickly show you a couple of those outcomes. This slide highlights just one trial, and it shows the representations of time over the different hidden states of the world.
1486200	1505200	Just highlights a couple of things. First of all, it shows that as we accumulate evidence for our preferred policies or our preferred outcomes, the probability that we are in a state which we will ultimately choose increases whereas the probability of states that we don't decreases.
1506200	1519200	This is formally identical to evidence accumulation or drift diffusion models, but now a consequence of a gradient descent on variational free energy or a bound for surprise.
1519200	1537200	What we also see is an interesting dynamics in the sense that if information keeps coming in every, say, 250 milliseconds, like the frequency at which we go and sample the world with mechanic eye movements, that means that we have two timescales in play.
1537200	1554200	One is a theta rhythm as we go and get information once, say, four times every second. But within each sampling there's this fast updating that's minimising and optimising our beliefs, and that faster updating has a temporal scale in the gamma range.
1554200	1571200	So what we see is effectively, as we move along, fast updating that repeats itself every theta cycle, but as we accumulate more and more evidence we get more and more efficient and confident about the things that we are inferring.
1572200	1580200	The dynamics mean that they accumulate evidence more quickly, more efficiently, and we get a phase procession of the sort seen in the hippocampus.
1581200	1596200	I've already mentioned that as time goes on, by virtue of increasing our confidence as we assimilate this evidence, then that confidence is expressed in the confidence of our policies and we have a nice way of assimilating dopamine responses.
1597200	1613200	We can look at the behaviour or the activity of these representations of different states of the world at different points in time during our policy, and if we plot their responses as a function of where the rat actually is, we can simulate place cell activity.
1614200	1631200	There has many characteristics of the sort seen empirically. This just illustrates this theta-gamma coupling, which is an almost necessary consequence of this sort of solitary sampling of the world, and then updating bleeds quickly before the next sample comes along.
1631200	1643200	Again, the sort of thing that one sees empirically. We can now do violation responses exactly as Jim was talking about. What I've shown here are the responses to two trials.
1644200	1655200	They're identical in nature, but one is from the beginning of the trial where the rat was not familiar with its environment, and one is at the end of the trial where it becomes very familiar just before it starts going directly for the reward.
1656200	1678200	Interesting, if we look at the representations of key states here, what we see is that they are much more efficient and therefore less exuberant updating of expectations of hidden states that if we subtract the standard familiar one from the odd ball or the unfamiliar one, we reproduce the temporal dynamics of things like the mismatch negativity in ERP research.
1679200	1692200	We also demonstrate this transfer of confidence or simulated dopamine responses from the rewarded cue per se to this instructional condition stimulus here.
1692200	1713200	I'm going from slightly negative to positive here. We can play similar games by introducing deliberate violations and illicit P300 responses. We can look at reinforcement learning by switching contingencies halfway through and look at the effects on dopamine-urgent responses and also electrophysiological responses.
1716200	1717200	How long have I got?
1717200	1741200	Oh, that's very good, isn't it? I've only been talking for 25 minutes. I can be true to my promise to finish in half an hour. This is the epilogue. That's the story so far. Most of that will be in the next few weeks in the published literature.
1742200	1755200	You'll notice at the moment there's nothing really about hierarchies. Most people here, I'm sure, are more interested in the implications of this sort of theory for perceptual hierarchies and evidence of accumulation and purely perceptual domain.
1755200	1784200	The more recent work that I wanted to, this is not published, to introduce you to, is now taking this formalism, which has a lot of constant validity in relation to choice behaviour and your economics, active vision, active sensing, and see what it has to say about the source of themes we're more interested in, which is the hierarchical message passing and the deep generative models that we assume.
1785200	1789200	The brain is using to actually understand perceptual sequences, say.
1791200	1808200	So this is the epilogue. Again, I'll just speed through this in five minutes. What we're going to do now is tell exactly the same story, but now we're going to put one of those discrete state-space models, they're known as Markov decision processes, on top of the first one and another one on top of that and another one on top of that.
1809200	1820200	So in this construction, hidden states, at any one level in the model, don't generate outcomes, they generate the first or the initial hidden state of the level below.
1821200	1833200	And then that cycles over a few iterations and then terminates like the rat-terminated when it entered the baited arms of the cues.
1834200	1843200	And that process repeats hierarchically to any arbitrary depth. So what we have are deep temporal generative models.
1844200	1868200	And they're really interesting because not only do they have a hierarchical structure in their form, but also in their time, because if the state at any high level is generating the initial state that must have subsequent states, then it means that the lower states unfold more quickly than the higher states.
1869200	1884200	So one way of thinking about this is the generative model says that at this hour, at this minute and at this second, I am safe, I was reading, I'm on this page, on this paragraph and on this word.
1885200	1904200	So if you think about the lower levels of us ticking over more quickly, like the second hand of a clock, and every revolution or every trajectory or every path they take, then the high level goes forward one step, and then it goes round again, it goes another step, another gain, sorry, again and then another step.
1905200	1912200	And then that process is repeated. So as the minute hand is going round, once it goes round, then the hour hand goes round.
1912200	1926200	So what we have here is a generative model that basically has in mind, literally, beliefs about the world that are much more protracted in time and are hierarchically nested.
1926200	1937200	So if you could invert this sort of model, you would have a representation of the context and the context of context and the context of context.
1937200	1942200	At each point, as you go deeper into the model, they are more temporally enduring.
1942200	1958200	So you know that working from the top down, you'd know the story of the narrative, if you knew the story of the narrative, you'd be able to generate a particular sentence, if you could generate a particular sentence, if you could generate a particular word, if you could generate a particular word...
1958200	1962200	.. you could generate a particular letter. All faster and faster and more elemental timescales.
1962200	1969020	That's the sort of model now that people are starting to play with.
1969020	1972860	It has exactly the same performance before— coping with policies in play
1972860	1976220	that generate transitions among hidden states that generate outcomes,
1976220	1979140	but now the first hidden state is generated
1979140	1985400	by the same sort of model, formally identical, of a higher level.
1985400	1989300	There are transitions over time here, but they are much slower.
1989300	1992820	that by making these red lines upon red states here,
1993540	1995700	a different colour from these because these, basically,
1995780	1997900	are the same as these but they're re-used
1997980	1999300	at a later point in time.
2000500	2004500	And this sort of model now allows you to think more carefully
2004580	2006700	about the hierarchical message passing
2006940	2008580	and the implications of neuro-anatomy.
2008660	2010700	So if we now turn straight to the process theory,
2011300	2013780	these are the differential equations
2014860	2017780	that fall out of that generatord model in the previous slide.
2017780	2022340	ei wneud o unig lwydaeth pob ddechrau.
2022580	2027260	Derbyn i ch risingdef o dystru i dystru i ddim yn cael ei ddif respir,
2027420	2032660	egOC yn gyfrasch ychydig ar y totu org10-g جون inequality.
2032980	2037580	A dwi'n credu hynny bir maen i ddim yn ddigonol gyda L rug
2037740	2043340	yn misoedd f hybridd stag yn y gwroad тр sír.
2043580	2047700	Til ond mythigr o'r ddim yn y ddigonor,
2047780	2052060	a gan y doddoriaeth yn y tai nhw'r drefnio fan y plainachau.
2052860	2057940	Diolch yn ddechrau am ddechrau coddyntau hynny a detch,
2058420	2067020	ac rydw i addysgu'n chi fod rhywbeth rydyn ni'n ach yn perwhaith gweithio.
2067140	2073860	Mae ydw mitant ar hufwn, felly dyma'n ddechrau ddiwrnod ni'n ddechrau
2074100	2080520	Ond biggestonethol, er di particularly gw Snapod,
2080520	2088760	yn ynghyd yn yr ymddangos lleethau hyn arall hynny,
2088760	2095360	ddweud yma cwm declar o repliedol, ar m 게isirol arall y dyfod,
2095360	2102760	Golw llawer arall llawer mewn amser gan y cwmputatio nanallynol, yкими yuyaeth
2102760	2108560	yw Somehow carried a 84.5 Sauce Ndun, iawn i' fi bwyzaid eu droslawn fφm.
2109160	2112760	I airportio pleid según fill.
2112760	2117640	Er si GLORIA cyhoedd, Assembly Down yw dweud yn gyda hynny yng Nghymru a'i sefydlu'r
2117640	2122960	rhywbeth gyda'r berth dweud, er mwyafMatthewch szeynerrym ynты grandiaf minzysolEl
2122960	2125660	Mae wedi'i converti analw!!!!!!
2125660	2128640	A 되fnodd ar yr adegowadau mewn gindig adegowadau
2128640	2131060	that atbypaenter, a gennych amherei
2131060	2133040	A ddau roi gwodd!.
2133040	2135040	Fmarfin analw Ring
2135040	2137260	ac mewn gwir y cитеch,
2137260	2139160	dw i ddim yn gwneud o wnes cy hunain
2139160	2142360	Dasodd yr adegowadau i gwenallu
2142360	2144420	cais grathio adegowadau
2144420	2146720	Maeлюч ychydig iddo nhw a 선urdwy
2146720	2149260	Rydyn ni gadael
2149260	2151600	sy'n fioedd y gwaith
2151600	2160300	ma wedi ar hyn o gwbl panallu, a hyffordda.
2160380	2172160	Mae'n gwneud ond yn gennaledd, wedi a cofdown o'i gael niferion,
2172160	2177260	llaoi i amιο overseas ychydig wedi ai'r hyn am misgfemi
2177340	2192920	seisin ag llwy
2192960	2199120	na'ch wneud ar hyn o hyd llwyddi, i hwnna, gael dd sel m sorcera
2199120	2202660	iawn i'r Fyged growth Yw'r Oorferd Folaid theoriaeth mewn cyd y fry Jaime
2202660	2207320	Meddor C ar y rueth Cenaiswn ni'n samp lun prosg uppu pho t Momo
2207320	2210960	astad i'n ein bachMyw yma ar gyfnodd Rhaid Fygedr
2210960	2214080	Diolch ar gyfer hwn i'r Ro Virus Fog толwy...
2214080	2218260	...ynghyd gy ved Cynyd rel Fygedr honw i'r fnod i'n tufyniadhe iddopeth yma y gweithiau
2218260	2221620	neu yn nar真 Curioroedd ar gyfer rhowch â boffraedd y pwyntill
2221620	2225880	ddoseud o effaith yi'r Llyfr yma rydym hanfodd d communism
2225880	2234200	dweud yn ddeud democrat. Rydyn ni'n ei chylygu diwethaf y gallwllais liquids mae yw'r eff cheatuppau pleannam ar y liar mewn ilmenau
2234760	2255580	Mae nid yn ein cael cyn deafnaetennu am y chylynadau fossemwjent hynny ac mae'n!]
2255880	2270880	If you subscribe to this scheme anatomically and the theory being a metaphor for neuronal activity in the brain, what you'd end up claiming is that the goodness of a policy, is negative expected for energy, is encoded in the
2270880	2279880	is encoded in the call date for high-level, more abstract representations in the deep-generative model,
2279880	2288880	for more intermediate levels, sorry, the call date for intermediate levels for more abstract ones in the globus pallidum,
2289880	2304880	and in the putamen for motor loops, whereas the policy expectations per se have here been assigned again to the globus pallidus internum.
2304880	2317880	So just a way of getting from the mathematical anatomy to the biological or neuroanatomy in a purely top-down dispassionate mathematically dry way,
2317880	2325880	is taking the equations and seeing what form do they imply for message-passing and what sorts of message-passing do we see in the real brain.
2325880	2334880	Andre Bastos will, I think he may not, but he did a lot of work on this sort of intrinsic connectivity within a macro-column,
2334880	2342880	clinical micro-circuits for predictive coding, exactly the same game can be played here for this discrete state-space model,
2342880	2353880	and that's one key exception which Lars might like, because there's been a lot of debate in Scotland about whether the superficial parameter cells encode predictions
2353880	2366880	or expectations or prediction errors. In this scheme, in this discrete state-space scheme, the superficial parameter cells code expectations, not prediction errors,
2366880	2373880	and you may ask why. Well, the reason is, they do encode prediction errors, but they do it by physically in a very different way,
2373880	2383880	and that follows from the form of this differential equation here, where we're expressing the states as a sigmoid function, a softmax operator,
2383880	2390880	on V, which we associate with depolarisation, where the rate of change of depolarisation or voltage is proportional to the error.
2390880	2399880	So, the error from the point of view of a neural mass model now becomes the conductance. So, the cells are encoding prediction error, but the error is in the conductance.
2399880	2410880	So, when all the postsynaptic drives to the conductance postsynaptically are in balance and there is no further change or drive to the potential,
2410880	2420880	that means prediction errors are zero. So, when the cell or a population has reached electrodynamically steady state, it's found its minimum prediction error,
2420880	2432880	and then it fires, but it is the firing here that is associated with the expected states of the world here.
2432880	2439880	So, that's an interesting thing which I thought might be useful for discussion in terms of reconciling a lot of paradoxes about what's been passed forward,
2439880	2447880	and would you expect it to be expended away or would you expect it to be boosted, sharpened, all sorts of interesting issues here.
2447880	2456880	Closing with an example of reading, a deep hierarchical model where we have beliefs about six sentences, each comprising four words.
2456880	2468880	Each word here has iconic letters that can either be in an uppercase or a lowercase, a palindromic in the sense that it doesn't matter whether the cat has to flee
2468880	2480880	from the cat, it doesn't matter whether we flip them in a horizontal way, it still means the same thing, but it does, this agent is surprised if we use a lowercase.
2480880	2481880	Three words.
2481880	2498880	Let me just skip through this because we want to spend more time in discussion if we can.
2498880	2510880	So, that's just a generative model with two levels, semantics or sentence structure, word structure and outcomes generating particular, if you like, letters, but there are icons in this instance.
2510880	2514880	And then with this scheme, we can simulate things like reading.
2514880	2527880	So, here's a little four page story or sentence and that word is flee, that word is wait because there's nothing next to the bird, that word is feed because there are seeds that the bird can feed on, and that is wait.
2527880	2535880	So, this is a sentence, flee, wait, feed, wait, and that's a happy sentence and it will categorise it as happy.
2535880	2541880	But the problem that we're trying to address here is exactly what we started with.
2541880	2549880	How do you scan? How do you search? Where do you go forage for information to resolve as much uncertainty as you can about which of these six sentences is in play?
2549880	2563880	And when the system does this just by trying to minimise its expected free energy, it shows this very interesting behaviour where it jumps from one word or page to the next
2563880	2569880	without really dwelling and wasting time resolving uncertainty that is already resolved.
2569880	2579880	So, once it sees a cat, it already knows that this has to be a flea word and it doesn't need to see where the other letters in this word are actually doing.
2579880	2584880	It already knows, there's no more epistemic value to be had, there's no more uncertainty to resolve.
2584880	2591880	It'll now jump to the next page and resolves uncertainty after a couple of Sokelechi movements, then jump to the next page.
2591880	2598880	And after this once a card in the final page, it knows exactly what this sentence was doing.
2598880	2610880	And if I can, I'll just show a movie of it doing that.
2610880	2622880	So, the red dots correspond to where it's looking at the present time and the images that are mixtures of the icons represent conditional expectations.
2622880	2628880	And the main point to be taken from this is that it knows there's a bird there, but it never looked there.
2628880	2632880	It has sufficient prior knowledge in its deep, depth temporal model.
2632880	2639880	It doesn't need to actually go and see stuff. It knows stuff is there because it knows what caused that stuff.
2639880	2647880	And with this sort of simulation, one can then do exactly what Jim was talking about, which was if it knows stuff and it has predictions,
2647880	2655880	then it should be possible to disclose or reveal that knowledge, that predictability by introducing violations
2655880	2660880	and elicit the sorts of classical responses that we see empirically.
2660880	2665880	And what we've done here is because we've got a deep model, we can do local and global violations.
2665880	2672880	We can make the final story, the final sentence, a very surprising one without changing any of the stimuli,
2672880	2682880	at the same time with or without making the prior beliefs about the upper lower case, the sort of local featureal expectations.
2682880	2688880	We can switch those around so we replay exactly the same stimuli and the same behaviors,
2688880	2694880	but just by changing the prior beliefs of the agent, we can cause certain things to be surprising,
2694880	2699880	and those things can either be at the local, the first level, or the higher, the second level.
2699880	2708880	And if we do that, we get lots of behaviors that look again a little bit like delay period activity
2708880	2716880	in the prefrontal cortex of a periscadic sort that you see prior to a saccade being selected and enacted.
2716880	2725880	While at the same time the band pass filtered voltages that are being driven by the implicit prediction errors
2725880	2729880	look very much like periscadic ERPs.
2729880	2734880	And when you look at those periscadic ERPs under local versus global violations,
2734880	2740880	what you actually see is something almost identical if it's a local violation to a mismatch negativity,
2740880	2749880	whereas, for the global violation, you get the mismatches or the differences much later on in time,
2749880	2752880	very much like a P300.
2752880	2757880	I can see what I was going to show you. No, I can't. I can't.
2757880	2761880	That was a very pretty slide, but I can't.
2761880	2766880	Very clever. It's a quote from, well, you don't need to know that.
2766880	2771880	And then the final slide, it's got a thank you.
2771880	2776880	A lot of people were on this slide, but you'll never know who now, will you?
2776880	2778880	So thank you very much.
2787880	2795880	So the workshop is structured so that there's a lot of time for discussion after each talk.
2795880	2803880	And so the floor is open now for people to ask questions or make observations.
2803880	2810880	I was just informed about how they do this in philosophy conferences that involves raising your hand or your finger,
2810880	2814880	but I haven't mastered that yet, so I don't understand it.
2814880	2821880	So I think it's too complicated for this group.
2821880	2825880	But not for philosophers.
2825880	2833880	So who would like to start?
2833880	2836880	I'll start.
2836880	2839880	I was just wondering if you could say more.
2839880	2848880	You mentioned that you get something when there's choice involved with the rat experiment simulation.
2848880	2851880	Something that looks like a drift diffusion model.
2851880	2859880	And I've always been puzzled at how you get something that looks really like choice or agency out of a predictive coding model.
2859880	2863880	So maybe you can elaborate a little bit on that.
2863880	2869880	So the question is, where does the choice come into predictive coding?
2869880	2871880	I think that question.
2871880	2874880	Let me just be a little more specific.
2874880	2886880	It's not that I don't see how you get choice behavior in the sense that you can use predictive coding in order to evaluate some options.
2886880	2903880	But the notion of agency seems, if what you're doing is just predicting what you will do, then it seems to kind of undermine the notion of agency.
2903880	2907880	So the answer to that question is very simple. It's tribly simple.
2907880	2914880	You put agency into these schemes through prior preferences that define the sort of agent that I am.
2914880	2921880	So we were talking before about reducing surprise of all sorts, whether it's epistemic uncertainty.
2921880	2929880	But the simplest sort of pragmatic surprise, if I have a cost function that I don't want to be very hungry,
2929880	2933880	or I don't want to end up in an arm that has no rewards in it,
2933880	2941880	then I'd simply have to have the pride belief that at the end of the day I will end up rewarded or sated or happy or complete.
2941880	2944880	So that anything else that happens is surprising.
2944880	2952880	And therefore I can then bring the whole machinery of predictive coding to bear upon the problem of suppressing prediction errors and surprises.
2952880	2955880	So I'm putting it very simply in terms of predictive coding.
2955880	2964880	If I, a priori, believe that I'm always going to be happy and complete and that I am built to always minimise my prediction errors in the future,
2964880	2969880	then I will look as if I have agency, I will look as if I have purpose,
2969880	2977880	because I will always choose my actions in a way that avoids the prediction errors that suggest that I am not happy and complete.
2977880	2990880	So the answer is just to absorb cost functions into inference by making costly states surprising through prior preferences.
2990880	2993880	And that comes out of things like planning as inference.
2997880	3003880	There are lots of ways of articulating that from the point of view of the rhetoric that I was using.
3003880	3005880	The expected free energy has two bits to it.
3005880	3010880	It has this epistemic bit and this pragmatic bit, but very simply it's uncertainty and surprise.
3010880	3013880	The epistemic bit is minimising uncertainty.
3013880	3024880	The value, the purpose, the goal is a pragmatic bit defined through cost functions that are literally the surprise of a costly outcome.
3025880	3033880	So, just to follow up a little bit, so is this sort of like a hyper-prior that's going to be,
3033880	3039880	I mean it sounds like we all have to have this ultimate belief that it's all going to end well at the end of the day.
3039880	3043880	So pessimists, none of us are really pessimists or something like that, right?
3043880	3050880	By definition. You may be perverse in your optimism, but you are quintessentially optimistic.
3051880	3057880	You're getting to some, you know, the deeper backstories behind the free energy principle.
3057880	3066880	The only, if you like, assumption that this instance of Hamilton's principle of release action makes is that you exist.
3066880	3073880	And if you exist, that means you behave as if you have beliefs that you exist.
3073880	3077880	And by existing, that just means that you're not decaying or dying.
3077880	3087880	All your states are within some bounds, be they physiological or homeostatic or pecunary in terms of being rich or in terms of interceptive inference.
3087880	3091880	You're, you know, the hedonics on that happy.
3091880	3099880	But it's all about keeping things in bounds. It's all about minimising entropy, minimising uncertainty.
3099880	3107880	So it always looks as if agents that exist have prior beliefs that they exist.
3107880	3117880	And when you unpack that, that simply means I have preferred states that I will expect myself to occupy.
3117880	3121880	Literally they are attracting states, they are an attractor.
3121880	3130880	So that rhetoric, which actually is a rhetoric from dynamical systems theory, applies identically to this sort of purposeful reinforcement learning,
3130880	3135880	or sort of goal directed style of thinking about things.
3135880	3141880	There are attracting states, they are simply the ones that you frequent,
3141880	3148880	which means that you will appear to behave as if you have prior preferences for being in those states.
3148880	3151880	And you will always choose actions to get to those states.
3151880	3155880	It is those prior preferences that define the sort of agent you are.
3155880	3162880	So in answer to your very first question, the agentfulness comes in by implication,
3162880	3168880	or just through the sorts of priors that characterise that particular sort of agent.
3168880	3173880	So if I was a virus, I would have very different preferences than if I was a person.
3174880	3180880	But there are still both plausible and viable preferences in the sorts of agents.
3180880	3182880	Hi, thanks for your talk, Carl.
3182880	3189880	I was wondering now that the slides are back if we could go to the delay period activity that you had briefly mentioned.
3189880	3195880	And I just wanted to see that a little bit unpacked and related to what you were just talking about,
3195880	3198880	that is agents reducing their free energy.
3198880	3207880	Is that principle then generate the delay period activity that we see in places like prefrontal cortex and in working memory and so forth?
3207880	3208880	Thanks.
3208880	3217880	Right, well, those sorts of phenomena which we all know and have and will try to explain and measure empirically.
3217880	3219880	So let me just try and find it.
3219880	3221880	Do you remember where it was?
3221880	3223880	Right, thank you.
3224880	3226880	There you go.
3226880	3235880	All those sorts of nuts and bolts getting down and dirty in terms of what this scheme would do when you put dynamics on it through the gradient descent,
3235880	3237880	depend upon the gerontid model.
3237880	3245880	So actually very similar to the last, one key component of the gerontid model are the prior beliefs, the preferences, what gives it purpose, what are its goals.
3245880	3248880	Your question, I think, has a very similar answer.
3248880	3254880	Once you've written down the gerontid model, everything else is not up for discussion.
3254880	3258880	The maths tells you exactly what has to happen once you've written down the gerontid model.
3258880	3264880	And the delay period activity you're talking about simply follows from the fact you've got a deep gerontid model or a deep temporal model.
3264880	3277880	So as soon as you write that deep structure into the model, it means that certain beliefs have to outlive or change on a slower temporal scale than other beliefs lower in the hierarchy.
3277880	3285880	Which means that you have to have delay period activity whilst other stuff unfolds at the lower levels of the hierarchy.
3285880	3295880	So in this particular example, what I've done here is show the beliefs about the six sentences over the four moves,
3295880	3299880	giving us six times four moves or five moves.
3299880	3303880	So it should be about 30 beliefs here.
3303880	3311880	On the same time access as beliefs about the particular word that's currently being seen.
3311880	3318880	These resets here indicate the onset of saccades and the acquisition of new information.
3318880	3325880	You can see roughly every 250 milliseconds there's a saccade and new beliefs are updated about the current word.
3325880	3334880	But at the high level, we're only considering beliefs about each letter in my part.
3334880	3337880	We're only considering beliefs about the word.
3337880	3350880	So beliefs about the word corresponding to what's on this page or what's in this word are invariant during the successive saccades as you sample the different letters.
3350880	3354880	So these things change more quickly than these things.
3354880	3358880	When these are completed, then there's a change here and then the cycle begins again.
3358880	3368880	So these tick over faster than this and then this looks a little bit now like the rastles that you see prior to the emission of the saccade here.
3368880	3372880	They're not from the same paper but a related paradigm.
3372880	3379880	If I take the voltage causing this delay period activity and band pass filter it, you get these sorts of fluctuations out here.
3379880	3386880	So when there's an increase in delay period activity, there's usually a positive deflection that looks a little bit like an ERP.
3386880	3394880	And just to follow up, so is the presence of delay period activity, is that associated then with prediction error or with the build up of a prediction?
3394880	3406880	No, I think the prediction error in this scheme and this is the maths that comes from the discrete aspect of the genetic models lies in the rate of change of neural firing.
3406880	3423880	If you associate the bi-physical encoding of expected states of the world in terms of population firing rates, then if you subscribe to that, if you accept that, then the prediction error now becomes the conductances that drive the depolarisation that drive the firing.
3423880	3433880	So these basically reflect the fact that as time goes on you can more and more confident that one particular sentence is in play and you can see that.
3433880	3453880	This is beliefs about which sentence is in play at the first, second, third, fourth and fifth page or word and they are now internally consistent and at every point in time in the past, at the end, I now believe I was reading the first sentence.
3453880	3461880	And that belief endures during the sampling of all the actual letters within each of the words.
3461880	3472880	So these would now represent just basically numbers between nought and one, zero and 100% neural firing that score your expectation that this is the current state of the world.
3472880	3488880	At the beginning, there's lots of ambiguity, not an enormous amount, but there is ambiguity. It's 50-50 because of the six sentences, only two of them begin with the word flee, which means that we resolve our uncertainty about four of them,
3488880	3501880	but we're still ambiguous about having ambiguity about sentences one and four and that can only be resolved at the end because these sentences only differ in the words right at the end.
3501880	3519880	So during this time, there's delay period activity which we've got these two explanations, hypotheses in play that are resolved epistemically, optimally, right at the end when we get to the last word here and it's a wait and that determines which of the letters it was.
3519880	3533880	Thank you for the talk. I wanted to go back to this idea of this contrast between reinforcement learning and the kind of formulation that you're making here.
3533880	3547880	So one of the things that I thought was interesting is this formulation in terms of external value plus you basically decompose your KL divergence to external value and epistemic value.
3547880	3564880	So how do you get exploration in this model? So it seems to me that you're doing an ARMAX over actions to get some balance between immediate value and information gain.
3564880	3567880	Is that the basic idea?
3567880	3581880	Yes. I mean, we can look at the equation or we can look at this. That's absolutely right. So, well, the exploration is good that you brought that in because another perspective on this is the whole foraging ethological perspective on exploration versus exploitation.
3581880	3593880	That rhetoric just maps very simply to the epistemic and the pragmatic. So, and there is no, again, there is no up for discussion or there's no ad hoc waiting between the two.
3593880	3602880	The expected free energy can always be written down in terms of exploration plus exploitation in terms of the epistemic value and the pragmatic value.
3602880	3617880	And what happens is in minimizing that one quantity, you get this scanning searching behaviour until the epistemic bit has been reduced, allowing then you to focus on the pragmatic bit.
3617880	3629880	So for free, you get a base optimal exploration to the extent that it is sufficient to resolve uncertainty given the precision of your beliefs about your prior preferences that then allow you to pursue your goals.
3629880	3643880	So this solves the exploration dilemma in a base optimal sense. It also suggests that the very carving of behaviour into these two complementary drives is actually probably a misdirection.
3644880	3661880	So it's only you and me that have actually teased apart the two components of the expected free energy and called one an epistemic exploratory one or a novelty seeking one and the other bit a pragmatic cost function like rewarding preference goal directed like one.
3662880	3669880	There are lots of different ways of rearranging those. You can also rearrange them in terms of risk and ambiguity, intrinsic and extrinsic value.
3669880	3685880	There are lots of ways of carving them and getting different perspectives. When you see that and when you work with that, you start to realize that it's not necessarily the best thing just to have one particular religious perspective on it
3686880	3700880	because it lends you to the false belief if you subscribe to this formalism that there has to be some other adjudicator. There has to be some other harmonculus that's decided, oh, I need to explore now.
3700880	3710880	I've done my exploration and now I'm going to go and do a bit of pragmat and stop the scanning and then I'm going to go and exploit what I've discovered. It doesn't work like that. You should get that for free.
3710880	3725880	If they're both part of the same cost function, then once you've sufficiently reduced your uncertainty, then just naturally you go into as illustrated here your exploratory behaviour.
3725880	3735880	This is exploratory behaviour or novelty seeking in the sense that you don't know what the queue is going to tell you. It doesn't have any immediate rewarding aspect to it.
3735880	3746880	There are no preferences associated with the condition stimulus, but it's interesting, uncertainty resolving, but after a time it becomes boring because you already know what it's going to tell you.
3746880	3759880	Once it does that, then you get exploratory behaviour. I should have done that. I should have put exploration and exploitation. Have an argument with me because it's meant to be a discussion. Do you not like that?
3760880	3775880	It's very interesting perspective on it. I'm surprised that it comes out that the simple deterministic policy works well and just kind of works out of the box.
3775880	3802880	My inkling is that when you go and implement this stuff, it can be difficult for it to balance the exploration and exploitation. So there's no tuning parameters, there's no off policy estimation, you just throw it in there.
3802880	3821880	It all works out. I know exactly what you're saying because this was a big selling point when we first realised that a couple of years ago and it will remain a bit like one of these five to ten year changing the direction of the ocean liner of the oil tanker.
3822880	3833880	Two years later, all that we're saying is in fact people behave according to Hampton's principle of least action. That's all that we're saying.
3834880	3851880	That implicitly, or it looks like, that behaviour has this dual aspect. It doesn't, if you formulate it as a variational principle of the sort you did at school when doing new turning mechanics and then Einstein did with general relativity.
3852880	3871880	It sort of falls out of the mix in a way that does actually dismiss these separatist perspectives on, I can either do this or that and I've got to now optimise the exploration in relation to the exploitation.
3871880	3886880	The key trick that puts you into this simple world of Hampton's principle of least action is the realisation you can't prescribe good behaviour unless the prescription is an optimisation of a function of beliefs.
3886880	3903880	A really simple example would be an economics game. I've got a really high risk and a low risk option. But there may be a third option, which is if I don't know which is which, I should do nothing until I know more.
3904880	3926880	In using words like I don't know, I am now saying that my behaviour now becomes a function of my knowledge or my uncertainty, so I now induce different options, different behaviours, different policies and actions that rest upon my degree of belief, which means you can't do it with value function optimisation or utility function optimisation or reinforcement learning.
3926880	3939880	It can't be done with queue learning. It cannot be done with a Bellman optimisation scheme because what you've done is you've said that there are better behaviours when I don't know what to do, which I generally don't do anything or wait until more information comes about.
3940880	3952880	And once you write that down, you make your objective function a function of a probability distribution which becomes an energy and then you integrate that over time and then you've got to Hampton's principle of least action.
3952880	3960880	So the simplicity post hoc is evident for me anyway. Does that make any sense?
3961880	3972880	Can I ask you a question about the general approach here, which is I see that you start saying that there is an urge, there is a force to reduce surprise.
3972880	3983880	So this is like I'm making an analogy with physics because that's what you're doing. And there you start saying I can rewrite the whole thing instead of force in terms of a Fourier energy.
3984880	3991880	And then you go on and explain what it implies. My fear is that there is a difference here between what we do in terms of behaviour.
3991880	4006880	First of all, reducing behaviour to just minimizing surprise, there are other forces that we cannot measure. We cannot even measure forces, force in terms of reducing surprise in an individual.
4007880	4017880	So even though you can write these equations and describe something general so you can prescribe what should be the brain doing, do you think you can actually make any prediction?
4017880	4026880	I know you're doing it, but I'm asking how can you think that you can do it because there is no measurement to tell you that's actually the case.
4027880	4040880	So in physics you could come up with any new evidence, you would write a new term into your equation and just keep adding it and then you're always safe because there are some conservation laws that basically will keep the Hamilton principle intact.
4040880	4049880	Well, who said there is such a thing in terms of behaviour and I think the simplest thing to assume there is no such thing.
4050880	4062880	So then by doing that, if you let's say you keep adding terms because you believe that what we are doing is just reducing surprise, this is the ultimate goal of behaviour, then just keep adding terms to your free energy.
4062880	4074880	And then basically the whole thing becomes a tautology because you're assuming that you're adding terms and there is no proof or disprove for that.
4075880	4081880	So that's my main question is that what is, I mean, how do you think it's going to work?
4082880	4088880	Right, that's a very good, I mean I ended quite a bit weakly, but that was a very good question.
4088880	4101880	So lots of really interesting issues there, so the tautology issue, the practical utility of this style of theorising, can it ever be falsified adding things too?
4102880	4107880	So I think we could spend hours talking about any one of those.
4107880	4115880	First of all, the whole point of my style of neuroscience is that we never add anything in.
4116880	4121880	You're always obliged to, for every advance, you have to get rid of something which was a distraction or ad hoc or a heuristic.
4122880	4128880	We've been talking about this magic parameter, the nuances, the balance between exploration and exploitation.
4129880	4134880	So that just goes, there's only one thing that's being minimised here, about everything and that's variation free energy.
4134880	4140880	That's it, there's nothing being added. However, of course, the free energy is a function of the gerontive model.
4141880	4152880	So all the interesting, all the hard work or the heavy lifting understanding this biological system in this experimental context or this social context, that really calls upon you writing down a gerontive model.
4153880	4160880	So that's, it doesn't mean there is no free lunch, there's still a lot of neurobiology and psychology and cognitive neuroscience and computational neuroscience to do.
4160880	4167880	It's just all at the level of the gerontive model, not the normative principles or the variational principles behind it.
4168880	4179880	The tautology, part of that drive for simplification is a drive to get to the ultimate explanation which has to be tautological and for me the free energy principle is tautological.
4180880	4186880	It's as tautological as the natural selection, but beautifully so. Once it's completely tautological, I'll be happy.
4186880	4200880	Part of that tautology comes along in a slightly technical guise called the complete class theorem and I'm bringing that to the discussion because it speaks to, I think, a very interesting point you were essentially making.
4201880	4207880	Is there anything that you can not explain, any behaviour in a real biological system that cannot be explained by this?
4208880	4211880	Because if there isn't, then what's the point?
4212880	4235880	Now, if there is no behaviour that this cannot explain, so it is provably true that for any pair of cost functions and behaviours there are a set of prior beliefs, prior preferences that we're talking about that endow the behaviour with an agent, with agency,
4235880	4240880	that render that behaviour based optimal and by definition therefore conforms to the free energy principle.
4241880	4246880	So what that means is that there is no behaviour that this can't describe if you can find the right prize.
4247880	4252880	So is that a weakness or a strength? Well, in the sense of falsifiability, it's a weakness.
4253880	4263880	In the sense of actually using it practically, it's a real strength because what that means is any system, normal human being or psychiatric cohort,
4263880	4271880	that you bring to me, if I can solve the problem of getting the most appropriate or a sufficiently good generative model that describes their behaviour,
4272880	4276880	it means I can quantify exactly the sort of person they are by their prior beliefs.
4277880	4281880	And we actually can write back down to the first question again, is what makes an agent an agent, it's their prior beliefs.
4282880	4287880	It's that attracting set that describes the sorts of states that that sort of person occupies.
4287880	4294880	So, yeah, there is a deep tautology, there's a fundamental difficulty for falsification,
4295880	4300880	but there's also a glorious insight underneath that which means that everything can now be written down in terms of an agent's prior beliefs
4301880	4304880	and that if you can get the right model, you can actually estimate these things.
4305880	4308880	You can actually quantify them and this is one of the tenets of computational psychiatry.
4308880	4318880	It's to be able to use games, ERPs, mismatch negativities, whatever in the service of say, what sort of person am I looking at,
4319880	4322880	quantified in terms of the prior beliefs about the way they should behave.
4323880	4331880	Carl, but aren't you making the assumption that there is just a unique set of beliefs that will match a data set?
4331880	4336880	Because if you have several beliefs and I would think that when we minimize those type of system,
4337880	4344880	that's equivalent to several solutions and which almost always we've got several solutions because we've got several minimas there.
4345880	4348880	Because it's not convex, the story that we are minimizing there.
4349880	4354880	So, therefore, we have a lot of minimas and I would say that if we're lucky that means that for any behavior that we can measure,
4354880	4360880	we are now with a set and that could be thrilling to know which one, a set of prior beliefs.
4361880	4364880	So, in other words, we cannot inverse that or am I wrong?
4365880	4369880	No, no, no, you're absolutely right but you've taken us into metabasian land now.
4370880	4375880	Okay, so just to, those people who may be getting a bit confused.
4376880	4383880	So, the argument I think, let me just paraphrase it, if we're now saying well how do we practically use this style of thinking
4384880	4392880	and I'm now in the job of quantifying this person with autistic spectrum disorder,
4393880	4399880	given a bead's task, an earned task, in terms of the prior beliefs about the volatility of the environment
4400880	4406880	and the need to please the experimenter by responding within a certain time frame.
4406880	4414880	If that is the problem, then we're now in and observing the observer or using Bayesian inference
4415880	4422880	to make inferences about a Bayesian machine, which is the autistic patient, which is hence the metabasian thing
4423880	4425880	and you're absolutely right, that could be an ill-posed problem.
4426880	4432880	So, there may be, the complete class there does not say that there is only one unique set of prior beliefs
4432880	4436880	that will make, render the behaviour based on what it says that it exists, it doesn't have to be a unique solution.
4437880	4445880	However, what will happen is that if you actually use Bayesian statistics to infer the prior beliefs of the Bayesian or ASD subject,
4446880	4451880	you will then see if you've got the appropriate model that there are a number of equally plausible solutions
4452880	4456880	and you will also see that you haven't got enough data to disambiguate between them.
4456880	4461880	But you will also have an insight into which sorts of experiments you would need to do that disambiguation
4462880	4464880	because you've got a generative model underneath of this.
4465880	4469880	You can do simulations to see the sorts of data that you are, or the ways of looking at the responses
4470880	4477880	that would enable you now to narrow down these competing but equally plausible sets of prior beliefs that characterize that subject.
4478880	4485880	So, it's a very important issue, but I think it's a generic one about how we actually apply Bayesian statistics
4486880	4489880	to understand the ways in which our data are being generated.
4490880	4495880	I think that in that sense it's less profound than the complete class theorem in itself,
4496880	4500880	which speaks to the sort of tautology of the game that we find ourselves in.
4503880	4505880	I think we can have time for one more short question.
4505880	4509880	I have two short ones.
4510880	4516880	The first one is about the semantics and the second one is about the substance.
4517880	4523880	So, regarding the semantics, I'm wondering, it seems as though there are these two aspects to the problem.
4524880	4529880	One is inference, the other is control and there is the epistemic cost in the context of inference
4529880	4536880	and there is the pragmatic costs, ultimately reproduction, the well-being and survival of the organism.
4537880	4546880	It seems as though you are declaring the primacy of surprise, so you want to absorb the pragmatic costs under the epistemic costs.
4547880	4552880	So, that's a bit of a semantic issue perhaps, but doesn't it make more sense to do it the other way around
4552880	4560880	and say, so the ultimate goal is reproduction and epistemic benefits should be a sub-goal of that.
4561880	4563880	So, that's the semantic question.
4564880	4574880	The question on substances, is this something that is already going on in engineering in AI, for example?
4575880	4581880	Can these principles be scaled up to real-world tasks such as visual object recognition?
4582880	4589880	If so, has it already been done or is this an impending revolution for AI?
4590880	4595880	And if not, is it just a reinterpretation of what already exists?
4596880	4598880	I agree because they were very short questions.
4599880	4602880	Very short. You couldn't get them shorter than that, could you?
4603880	4605880	Do you want me to try to answer them shortly?
4606880	4608880	The semantic one.
4608880	4611880	No, I don't think so.
4612880	4619880	I take your point that one could articulate a whole theory and absorb uncertainty into cost functions,
4620880	4627880	but I think that misses the key point that I was trying to make at the beginning of the talk,
4628880	4633880	that the quantity you have to optimise is a function of probability distributions or beliefs.
4634880	4641880	That's the key thing, which means you can never use a Bellman optimality scheme to properly solve that.
4642880	4647880	You do see heroic attempts, and those heroic attempts have been endemic for the past 40 years,
4648880	4652880	they're known as partial observed mark-up decision processes or belief state machines,
4653880	4658880	and all sorts of heroic attempts to try and recover or resolve the problem,
4658880	4665880	or once you write down a discrete state space over continuous beliefs, you can't do it,
4666880	4670880	therefore you have to parameterise those continuous beliefs in those sorts of glorious and clever ways,
4671880	4672880	they don't work, they don't scale.
4673880	4678880	So people have been aware of the problem, and hence the vast literature on partial observed mark-up decision problems.
4679880	4684880	What I'm saying is that's the wrong approach, the right approach is Hampton's principle of least action,
4684880	4689880	where the functional that you need to optimise is a function of the beliefs before you start,
4690880	4693880	and by proof of principle I can demonstrate the veracity of that argument,
4694880	4698880	because I can solve problems which people working with partial observed MDPs cannot solve.
4699880	4706880	So I think it's much more than semantics, I think it's actually, people have got it wrong in the 20th century.
4707880	4711880	I think the Bellman's optimality equations are very beautiful construct, completeness direction.
4711880	4715880	We should have been looking at Hamilton's principle of least action, and that's the 21st century.
4716880	4717880	Are people doing this? Yeah.
4718880	4724880	So Google Deep Mind, for example, they've now, a small group within Google Deep Mind,
4725880	4730880	have now started using variational free energy in their deep energy model, not the temporal models,
4731880	4738880	but certainly sort of 10-led neural networks in the context of the sort of pattern recognition approach.
4738880	4745880	So people have always rears, I think, that the variational approach was the right way to do this,
4746880	4750880	and of course you remember most of deep learning started with Geoffrey Hinton's work,
4751880	4759880	and he came from the variational formulation, so he was the first person to be down to propose the Helmholtz machine,
4760880	4764880	but they've taken a sort of security stream back to those early work in the 1990s.
4764880	4768880	Will it scale? I don't know, because I don't think they're quite on top of that,
4769880	4776880	because what they do is they haven't quite got, well, this is insulting, but I hope, is anybody here from Google?
4777880	4780880	Ah, well I won't say that then.
4781880	4786880	Well anyway, they love amortisation, they love casting things in terms of learning,
4787880	4791880	so what they do is instead of actually trying to optimise their beliefs, their expectations,
4791880	4796880	they try and optimise beautifully constructed deep nets, convolution nets,
4797880	4803880	that have parameters that would map from data to beliefs, or sufficient statistics or beliefs,
4804880	4808880	and then they learn that because they're experts, and they are more than well experts,
4809880	4812880	they are the experts in optimising the parameters.
4813880	4818880	That's a slight problem because it denies any context sensitivity of the sort that we deal with the neuroscientists
4818880	4820880	and I deal with them in my simulations.
4821880	4825880	I think once they get beyond amortising their deep networks, then they'll be in this game,
4826880	4831880	and then we'll find out whether it scales, you know, that you'll need lots of computer scientists, big computers.
4832880	4835880	So I would imagine the next five to ten years this style of approach,
4836880	4843880	and so the very actual free energy formulation will become increasingly dominant in people doing artificial intelligence.
4843880	4850880	And I should quip, I mean, for some people, the new AI is actually active inference.
4851880	4860880	It wasn't a coincidence that we chose that sort of rhetoric to promote it.
4861880	4864880	Yes, so maybe I could just have a comment rather than a question then.
4865880	4866880	Okay, okay.
4867880	4872880	So that's a bit straight-laced approach to free energy reduction.
4873880	4878880	It's based on surprise aversion, but I'm sure you have another talk on surprise-seeking,
4879880	4882880	curiosity, creativity, playful managerial styles,
4883880	4890880	which must have some adaptive purpose beyond our interest in horror movies and jokes.
4890880	4897880	It must help us get out of dead-end problem space to problem spaces we can't even imagine.
4898880	4906880	So the comment is, if you add surprise-seeking to free energy minimisation, I don't believe it remains tractable.
4907880	4908880	So I'll leave it at that.
