1
00:00:00,000 --> 00:00:22,560
Hello everybody and welcome to Open to Debate. I'm Zania Wicked, your guest moderator for

2
00:00:22,560 --> 00:00:26,920
today. Having spent a number of years in the policy domain, including the State Department

3
00:00:26,920 --> 00:00:31,680
and the White House, I now make my living by trying to ask the right questions, either

4
00:00:31,680 --> 00:00:37,400
as a moderator or coach, in order to bring clarity and direction to people and organisations.

5
00:00:37,400 --> 00:00:45,000
And my job today is to do just that on the topic of will the future be abundant. In 2011,

6
00:00:45,000 --> 00:00:49,400
the Pew Research Centre conducted a study that showed, for the first time, that more

7
00:00:49,400 --> 00:00:53,480
Americans thought that their children were going to be worse off themselves than thought

8
00:00:53,480 --> 00:01:00,120
otherwise. That trend has continued. Imprinted in our basic genetic makeup is the commitment

9
00:01:00,120 --> 00:01:05,680
to ensure the propagation of the species, and not just its continuation, but in such a way

10
00:01:05,680 --> 00:01:11,400
that we are healthier and happier. And it's in this context that I can't think of a more

11
00:01:11,400 --> 00:01:16,560
important question to answer than whether the future will be abundant or not. What world

12
00:01:16,560 --> 00:01:22,080
are we leaving for our children, for our species? This is not about whether we are optimists

13
00:01:22,080 --> 00:01:27,280
or pessimists, nor is it about the political oscillations that consume the papers every

14
00:01:27,280 --> 00:01:35,840
day. This is about understanding the underlying trend line. Is the future going to be abundant?

15
00:01:35,840 --> 00:01:40,400
As a former policymaker, it's a vital question to answer, one that drives behaviours, our

16
00:01:40,400 --> 00:01:44,800
own, that of our businesses, our societies and our governments. It is one that should

17
00:01:44,800 --> 00:01:50,280
drive our international relations. So, to talk us through the dynamics, and to answer

18
00:01:50,280 --> 00:01:55,560
the question of will the future be abundant, we have two Peters. Let's get into it and

19
00:01:55,560 --> 00:02:02,760
meet our debaters. Arguing yes, the future will be abundant, Peter Diamandis, founder

20
00:02:02,760 --> 00:02:08,760
and executive chairman of XPRIZE Foundation, and author of Abundance, The Future is Better

21
00:02:08,760 --> 00:02:13,880
Than You Think, and The Future is Faster Than You Think. Welcome, Peter.

22
00:02:13,880 --> 00:02:19,480
A pleasure to be here. Good to be here. And arguing no to the question, will the future

23
00:02:19,480 --> 00:02:24,720
be abundant, is geopolitical strategist and author of The End of the World is Just the

24
00:02:24,720 --> 00:02:31,440
Beginning, Peter Zahan. Welcome, Peter. Great to be here. Now, because we have two Peters

25
00:02:31,440 --> 00:02:36,840
debating with us today, I'm going to be referring to each of you as Peter D and Peter Z, to

26
00:02:36,840 --> 00:02:43,760
try and minimise some confusion. Before we get started, I just want to take a quick sense

27
00:02:43,760 --> 00:02:49,440
of what motivates you both to make this argument. So, I'm going to ask you each to take the

28
00:02:49,440 --> 00:02:54,400
30 seconds and tell us why you're here today. Peter D, what are the stakes for you in this

29
00:02:54,400 --> 00:03:01,520
argument? An individual's mindset is probably the single most important tool they have to

30
00:03:01,520 --> 00:03:07,440
solving problems and creating a better world. And our inherent mindset that we evolved over

31
00:03:07,440 --> 00:03:14,000
100,000 years is one of fear and scarcity. But that doesn't put you in a very good position

32
00:03:14,000 --> 00:03:19,420
to solve problems. Having an abundance mindset, optimistic mindset is probably the most important

33
00:03:19,420 --> 00:03:25,520
thing for delivering a future for our children that is better than our past. And so, my mission

34
00:03:25,520 --> 00:03:32,180
here is to give people a clear understanding of why the future is extraordinarily abundant

35
00:03:32,180 --> 00:03:38,760
and why they're more empowered than ever before to create that future. Phenomenal. It's about

36
00:03:38,760 --> 00:03:44,580
mindset. And Peter Z, the same question for you. Why did you show up? We've been living

37
00:03:44,580 --> 00:03:48,700
through one of the most atypical periods in human history, and a lot of us have drawn

38
00:03:48,780 --> 00:03:54,140
linear forecasts as to where that takes us. That's never been true and it's not true now. We're

39
00:03:54,140 --> 00:03:59,420
entering a period of extreme change, and my goal is to get people to understand the size of the

40
00:03:59,420 --> 00:04:04,700
icebergs ahead of us and where they are so we can navigate around them. The future isn't necessarily

41
00:04:04,700 --> 00:04:10,220
dark, but that doesn't mean there's going to be anything we can predict. Okay, so this goes to

42
00:04:10,220 --> 00:04:15,580
the core, both of you. So let's get to our opening statements. We want each of you to take a few

43
00:04:15,580 --> 00:04:22,540
minutes to explain your position. Peter D, you're first and you're arguing yes to the question,

44
00:04:22,540 --> 00:04:25,100
will the future be abundant? Tell us why.

45
00:04:28,620 --> 00:04:35,100
Exponential technologies, and I define those as computation, sensors, networks, AI, robotics,

46
00:04:35,100 --> 00:04:42,700
3D printing, AR, VR, blockchain, biotech, are technologies that are making those things that

47
00:04:42,700 --> 00:04:51,020
used to be scarce more and more abundant. And so we're living in a world where technology is

48
00:04:51,020 --> 00:04:57,100
transforming scarcity into abundance at an extraordinary rate. Everything that we used to

49
00:04:57,100 --> 00:05:03,900
view as scarce, access to food, water, energy, healthcare, education, is blossoming. Now to

50
00:05:03,900 --> 00:05:10,060
be clear, we are living during a time that is chaotic and unpredictable and sometimes downright

51
00:05:10,060 --> 00:05:16,060
scary. I don't deny that at all. We humans like going to sleep and waking up in the morning,

52
00:05:16,060 --> 00:05:21,180
knowing that the world is the same as it was the night before. And it's not. It's changing at an

53
00:05:21,180 --> 00:05:27,980
accelerating rate. And we're not arguing that there are issues, there will be issues for sure.

54
00:05:28,540 --> 00:05:35,100
But even as it's changing at this accelerating rate, what is happening is those things that used

55
00:05:35,100 --> 00:05:43,260
to be scarce are becoming abundant. And so if we look at this, and I believe in what's called

56
00:05:43,260 --> 00:05:52,220
data-driven optimism, there is a huge amount of data that drives towards this vision that abundance

57
00:05:52,220 --> 00:05:59,660
is in fact the future. So first of all, global life expectancy has more than doubled over the last

58
00:05:59,660 --> 00:06:09,660
70 years, from roughly 40 years old to now hitting 75. Global child mortality has precipitously

59
00:06:09,660 --> 00:06:16,940
dropped from 43% in the 1800s down to under 4% today. Maternal mortality rates, women dying in

60
00:06:16,940 --> 00:06:26,220
pregnancy, over the last 20 years alone has dropped 34%. Cancer deaths have reduced by a third over the

61
00:06:26,220 --> 00:06:34,620
last 20 years. You may not believe this, but even democracy has blossomed over the last century. In

62
00:06:34,620 --> 00:06:45,740
1900, about 1% of countries had universal voting rights. Today, it's 96%. Extreme poverty has plummeted

63
00:06:46,780 --> 00:06:54,140
from 95% extreme poverty in the world down to under 10% today. Literacy rights have skyrocketed,

64
00:06:54,220 --> 00:07:00,620
mobile phone uses, we have some 8 billion mobile phones. The poorest on the planet now have

65
00:07:00,620 --> 00:07:06,940
most advanced technology for communications and access to knowledge. We have 5 billion internet

66
00:07:06,940 --> 00:07:15,260
connected individuals. Access to electricity has exploded. We have swatter safety. We have more

67
00:07:15,260 --> 00:07:22,860
access to food. And so the question is, why is this happening? Why are we seeing this incredible

68
00:07:22,860 --> 00:07:29,020
abundance in access that people have? And it's not that we humans have gotten smarter, we don't

69
00:07:29,020 --> 00:07:36,460
have better forms of government or better politicians. It is the technology. Technology is a

70
00:07:36,460 --> 00:07:43,740
scarcity, is a resource liberating force. It transforms scarcity into abundance over and over

71
00:07:43,740 --> 00:07:49,100
again, right? We used to go kill whales to get whale oil to light our nights. Then we ravaged

72
00:07:49,100 --> 00:07:54,540
mountain sides. Then we drilled kilometers under the ground to get access to oil. And now we have

73
00:07:54,540 --> 00:07:59,660
8,000 times more energy hitting the surface of the earth from the sun than we consume as a

74
00:07:59,660 --> 00:08:07,180
species in a year. Energy will become squanderable abundance, right? And that tips water and that

75
00:08:07,180 --> 00:08:16,540
tips health. And so all of these things are increasing abundance. I have zero question.

76
00:08:16,620 --> 00:08:23,180
Now, and by the way, anybody who wants access to this data, if you go to diamandis.com backslash

77
00:08:23,180 --> 00:08:30,700
data, I have 50 charts showing over the last decades and century this increasing access to

78
00:08:30,700 --> 00:08:36,780
abundance. So it's not about creating a world of luxury for everybody, but it's about creating a

79
00:08:36,780 --> 00:08:49,580
world of possibility for everybody. And you're muted, senior. Peter, absolutely perfect. Thank

80
00:08:49,580 --> 00:08:55,260
you so much. And now let's hear from Peter Z. You're answering no to the question, will the

81
00:08:55,260 --> 00:09:01,020
future be abundant? Tell us why. Peter D is absolutely correct. The world of the last 75,

82
00:09:01,020 --> 00:09:05,500
80 years has gotten better and better and better and better. But it's important to understand

83
00:09:05,500 --> 00:09:10,540
why we've been able to go down this technological path. We've had three things going on.

84
00:09:11,260 --> 00:09:16,460
First of all, we had globalization. At the end of World War II, the Americans found themselves

85
00:09:16,460 --> 00:09:22,940
facing off against Stalin on the plains of Europe. And it was a war we knew we could not win. We knew

86
00:09:22,940 --> 00:09:28,700
we needed tens of millions of people to stand not behind us or with us, but in front of us to serve

87
00:09:28,700 --> 00:09:34,380
as cannon fodder. And that meant bribing them. And our bribe was globalization. We used our

88
00:09:34,380 --> 00:09:39,660
navy to open the seas so that anyone could go anywhere and interface with any partner and access

89
00:09:39,660 --> 00:09:45,660
any commodity in any product and sell into any market. If in exchange, you would join us against

90
00:09:45,660 --> 00:09:51,500
the Soviets and it worked and it generated the greatest prosperity and security the world has

91
00:09:51,500 --> 00:09:58,060
ever seen. But the Cold War ended in 92. And ever since then, the United States in a series of ever

92
00:09:58,060 --> 00:10:03,900
more nationalist political contests has elected the guy who wants to do away with it faster.

93
00:10:04,380 --> 00:10:09,260
And the biggest difference between Trump and Biden when it comes to international economics

94
00:10:09,260 --> 00:10:15,420
is that Biden was able to hire a grammar checker. The road hasn't changed. And this is a very strongly

95
00:10:15,420 --> 00:10:22,220
bipartisan issue. And we're moving away from the generations of security and economic growth that

96
00:10:22,220 --> 00:10:26,860
gave us the ability to go down to this technological path. Then there's demographics.

97
00:10:28,220 --> 00:10:33,660
Pre-Stalin, we all lived on farms where kids were free labor. So you'd have as many of them as you

98
00:10:33,660 --> 00:10:39,260
could put up with plus one because that's how you found out it was too many. But then Stalin

99
00:10:39,260 --> 00:10:43,500
brought us globalization and industrialization and urbanization and all the new industrial

100
00:10:43,500 --> 00:10:49,340
jobs were in town. So we moved in to take them. Well, in town, kids aren't free labor. They're

101
00:10:49,340 --> 00:10:54,700
just a source of migraine. So you just fast forward 30 years to the 70s to the 90s. We entered

102
00:10:54,700 --> 00:10:59,660
this weird period where we had huge numbers of young workers and huge amounts of consumption

103
00:10:59,660 --> 00:11:04,620
because of it, but not a lot of kids that we had to spend money on. It was demographically

104
00:11:04,620 --> 00:11:09,500
speaking a moment in time. You fast forward another 20 years to the 2000s and the 2010s,

105
00:11:09,500 --> 00:11:14,940
and we now have lots of mature workers who are over 40 but not yet retired. People were at the

106
00:11:14,940 --> 00:11:20,060
height of their income, but their expenses were under control. So we saw a huge tax base, huge

107
00:11:20,060 --> 00:11:25,500
infrastructure spending, lots of production, lots of investment, which generated, among other things,

108
00:11:25,500 --> 00:11:31,340
the tech boom that brought us the world we're in now. But this too is only a moment in time.

109
00:11:32,140 --> 00:11:40,780
And in the 2020s, we're now aging out. Whether it's Spain or Italy or Germany or Japan or Korea

110
00:11:40,780 --> 00:11:46,540
or Taiwan or China or Thailand, this is the end of the road because that bulge now hits mass

111
00:11:46,540 --> 00:11:51,100
retirement. And we have to come up with something that works without investment or consumption or

112
00:11:51,100 --> 00:11:57,180
production. And we're not going to get that first right on our first try. And then finally, there's

113
00:11:57,180 --> 00:12:02,380
China. China is a country that exists because of globalization and demographic change. It's

114
00:12:02,380 --> 00:12:08,140
utterly dependent upon globalization for access to raw materials and access to markets. But it's

115
00:12:08,140 --> 00:12:13,900
also the fastest urbanizing country in history, which means it's the fastest aging population

116
00:12:13,900 --> 00:12:19,260
in history. And they've already aged so quickly and so far that consumption led growth or cost

117
00:12:19,260 --> 00:12:24,220
competitive production has already faded into memory. Their birth rate fell by more in the last

118
00:12:24,220 --> 00:12:29,660
six years than it did among European Jews during the Holocaust. So even repopulation is now

119
00:12:29,660 --> 00:12:35,180
statistically impossible. And China will cease to exist as a unified industrialized political

120
00:12:35,180 --> 00:12:41,980
economy within 10 years. Major shifts in economic models take at least a couple of decades, and

121
00:12:41,980 --> 00:12:48,380
they are messy. The shift from imperialism to globalization, for example, took the better

122
00:12:48,380 --> 00:12:54,780
part of five decades and gave us two world wars and the Great Depression. So no, abundance is not

123
00:12:54,780 --> 00:13:02,700
the word that I would use to describe the future. We've passed that already. We just heard opening

124
00:13:02,700 --> 00:13:09,820
statements from ex-prize founder Peter Diamandis and geopolitical strategist Peter Zahan. And I

125
00:13:09,820 --> 00:13:17,660
want to trans summarize those briefly. Peter D, you argued yes to the question of will the future

126
00:13:17,660 --> 00:13:27,180
be abundant. Your principal points were that exponential technology changes are making scarce

127
00:13:27,180 --> 00:13:34,700
things more abundant. Technology is moving scarcity into abundance at an incredible rate.

128
00:13:35,820 --> 00:13:41,260
You acknowledge the fact that we're living in a frightening time and that the world is changing

129
00:13:41,260 --> 00:13:50,780
at an accelerated rate. But you gave us some statistics that emphasize your optimism. You

130
00:13:50,780 --> 00:13:59,340
talked about the doubling of global life expectancy over 40 years, the lowering by a huge factor of

131
00:13:59,340 --> 00:14:06,220
child mortality and maternal mortality, the blossoming of democracy despite what it might feel like,

132
00:14:06,220 --> 00:14:11,980
the tumbling of extreme poverty and more. And you asked the question, why is this happening?

133
00:14:12,940 --> 00:14:20,700
And your answer was technology is a resource liberating force and that energy will be a

134
00:14:20,700 --> 00:14:31,340
squanderable abundance. Arguing no to the question was Peter Z. And Peter Z, you acknowledge the

135
00:14:31,340 --> 00:14:37,900
fact that the world has got better, but you thought it was important to understand why it had gotten

136
00:14:37,900 --> 00:14:43,340
better over the last century or so. And you said there were three reasons for that. The first was

137
00:14:43,340 --> 00:14:51,660
globalization. You described following the Second World War the fact that we had bribed the world

138
00:14:51,660 --> 00:15:00,060
through globalization and generated incredible security through that globalization. The second

139
00:15:00,060 --> 00:15:07,180
reason that you put for why things have gotten better are demographics. You described the pre-Stalin

140
00:15:07,180 --> 00:15:14,220
period when people lived in farms and subsequently moved to the towns. And there were huge numbers of

141
00:15:14,220 --> 00:15:20,140
resources in those people. You fasted forward through a couple of decades and a couple of decades

142
00:15:20,140 --> 00:15:29,180
and moments in time where there was abundance of people as in the last 20 years. But you talked about

143
00:15:29,180 --> 00:15:37,020
as we move into the 2020s, we're now aging out in your words. You've got a population bubble

144
00:15:37,020 --> 00:15:43,660
that is hitting mass retirement. We need to come up with a solution and we're not going to do that

145
00:15:43,660 --> 00:15:51,660
on our first try. And then the third reason you laid out was around China. The fastest urbanizing

146
00:15:51,660 --> 00:15:59,500
country in history that is now aging. You described China as a country that will cease to exist

147
00:15:59,500 --> 00:16:08,300
in it as a unified industrialized economy in the next decade. You talked about those three factors,

148
00:16:08,300 --> 00:16:13,660
globalization, demographics, and China being on a positive trajectory and now hitting a negative

149
00:16:13,660 --> 00:16:22,700
trajectory. And the major shifts in systems that we need to manage this

150
00:16:23,900 --> 00:16:31,180
never go smoothly and we're going to get it wrong. So that is why the future is not going to be abundant.

151
00:16:34,620 --> 00:16:41,820
So let me pick up and ask you both a few questions and pick up where you left off.

152
00:16:41,820 --> 00:16:47,980
The first question, and this is for both of you, abundant for whom? How do imbalances and

153
00:16:47,980 --> 00:16:53,660
inequities factor into your thinking? Does it matter where you sit? What nationality? What country?

154
00:16:53,660 --> 00:16:57,660
What ethnic or socio-economic group? And maybe I'll start with you, Peter D.

155
00:17:01,100 --> 00:17:06,940
It matters in the beginning, but it doesn't at the end. In the beginning, when the first mobile

156
00:17:06,940 --> 00:17:13,020
phones cost a million dollars in New York, Manhattan for the Wall Street, traders and they

157
00:17:13,020 --> 00:17:19,500
worked very poorly. That's the way it was. Towards the end, now there are $40 handsets and

158
00:17:19,500 --> 00:17:23,980
they're available to billions of people and they work incredibly well. And not only do they work

159
00:17:23,980 --> 00:17:32,140
incredibly well, on this handset which every child on the planet has access to comes the world's

160
00:17:32,140 --> 00:17:37,020
information, two-way video conferencing for free libraries of books, entertainment, knowledge,

161
00:17:37,020 --> 00:17:42,700
information that were neither available to the heads of nations 20 years ago are now available

162
00:17:42,700 --> 00:17:49,820
to the poorest. There are eight billion handsets on the planet. So what we see is technology is a

163
00:17:49,820 --> 00:17:57,820
democratizing and demonetizing force. And so, you know, things do begin when they work poorly.

164
00:17:57,820 --> 00:18:03,580
They're available to the richest who take the risk and eventually they rapidly demonetize and

165
00:18:03,580 --> 00:18:10,220
democratize and are accessible to everyone. We're seeing this on communications. We're seeing this

166
00:18:10,220 --> 00:18:15,900
on energy. We're seeing this even in artificial intelligence, right? All the AI systems that

167
00:18:15,900 --> 00:18:20,860
we're seeing coming out of Google and different parts of the world are available for free to

168
00:18:20,860 --> 00:18:30,620
anyone with a handset. Again, amazing. And so, I believe that this is a force and it's a non-stoppable

169
00:18:30,620 --> 00:18:36,060
force and it is what is causing increasing abundance. Whether or not it's used for negative

170
00:18:36,060 --> 00:18:40,540
purposes or positive purposes is a different issue. The question we're asking here is it

171
00:18:40,540 --> 00:18:44,380
will it be abundant? And yes, these things are abundant across the board.

172
00:18:44,380 --> 00:18:53,260
Bundled across the board. A lot of people have described technologies like AI as things that

173
00:18:53,260 --> 00:19:00,700
increase inequality. So I just want to quickly, quick follow up with you, Peter. What's your

174
00:19:00,700 --> 00:19:05,420
argument to people who say that actually these technologies are increasing inequality rather

175
00:19:05,420 --> 00:19:11,980
than decreasing? And then I'll come to you, Peter. Peter Z. Again, my comment is in the beginning

176
00:19:11,980 --> 00:19:18,940
they're accessible to a smaller group, but we've seen over and over again these technologies become

177
00:19:19,500 --> 00:19:25,500
demonetized and democratized. I talk about the six D's of exponential. When you digitize anything,

178
00:19:25,500 --> 00:19:30,940
in the early days of its growth, it's deceptive. 30 doublings later, it's a billion fold bigger

179
00:19:30,940 --> 00:19:35,820
and it's disruptive. And it's dematerializing, demonetizing, and democratizing. We've seen

180
00:19:35,820 --> 00:19:43,660
this over and over again across every technology. AI is going to be ultimately the best educating

181
00:19:43,660 --> 00:19:49,180
system, the best healthcare system will be available to the poorest child and the wealthiest child

182
00:19:49,180 --> 00:19:56,460
delivered by AI platforms. Okay, thank you. Peter Z. The question abundant for whom?

183
00:19:59,180 --> 00:20:04,860
Geographic factors and demographic factors are not the same everywhere. Some countries are aging

184
00:20:04,860 --> 00:20:10,140
faster than others. Others have better borders and better economic geography. And as a rule, gross

185
00:20:10,140 --> 00:20:16,060
oversimplification, the Western Hemisphere looks pretty good. They, in many cases, industrialized

186
00:20:16,060 --> 00:20:21,260
on a slower rate or from a later start. So their birth rates haven't fallen nearly as much. And what

187
00:20:21,260 --> 00:20:26,620
I outlined in my opener is less true for them with the United States being one of the youngest

188
00:20:26,620 --> 00:20:31,580
demographies in the world as well as Mexico. So we have a transition period here that's going to be

189
00:20:31,580 --> 00:20:35,500
a half a century as opposed to what they're going to have to do in Europe, which is going to be in

190
00:20:35,500 --> 00:20:40,140
less than a decade. That buys us a lot of time to figure out the details. It also means that we

191
00:20:40,140 --> 00:20:45,500
have the ability of expanding our supply chains to make up for those that fall. But when it comes to

192
00:20:45,500 --> 00:20:53,580
technology at its core, the demographic structure is everything. Developing new technologies requires

193
00:20:53,580 --> 00:20:58,300
a huge number of people in their 20s and their 30s who are social, who are integrated, who can work

194
00:20:58,300 --> 00:21:04,460
as a team and can imagine the future and then figure out how to operationalize it and then figure

195
00:21:04,460 --> 00:21:09,980
out how to mass manufacture it. The problem with this process is that every step up until mass

196
00:21:09,980 --> 00:21:16,460
manufactured generates no income. And that means you have to have a huge amount of capital to push

197
00:21:16,460 --> 00:21:23,100
this whole process forward. Now in the 2000s and the 2010s, we had exactly that world. We had the

198
00:21:23,100 --> 00:21:28,860
millennials, which were many, and we had the boomers who were nearing retirement but had not yet

199
00:21:28,860 --> 00:21:33,500
retired. So they had their life accumulation of savings, which pushed down capital costs for

200
00:21:33,500 --> 00:21:38,380
everybody. That's one of the reasons why growth these last 25 years has been so robust. Lots of

201
00:21:38,380 --> 00:21:44,620
young smart people, lots of money for them to do things with. Well, that's over. As of December

202
00:21:44,620 --> 00:21:48,700
of last year, half of the world's baby boomers had already retired and they'd liquidated their

203
00:21:48,700 --> 00:21:52,940
savings. And so we've seen capital costs triple. They're going to triple again in the next few

204
00:21:52,940 --> 00:21:58,620
years. And the oldest baby boomer, sorry millennial, I'm sorry, the oldest millennial, sorry millennials,

205
00:21:59,580 --> 00:22:05,580
turns 45 next year. They're no longer the young bucks and the next generation down is small and

206
00:22:05,580 --> 00:22:10,940
to be perfectly blunt kind of antisocial. So the environment that has allowed us to push the

207
00:22:10,940 --> 00:22:16,460
technological envelopes so far, so fast, so consistently, it's already behind us. And we're

208
00:22:16,460 --> 00:22:21,020
already seeing those adjustments throughout the tech space with layoffs, with shutdowns,

209
00:22:21,020 --> 00:22:26,460
with focusing more on manufacturing now, rather than idea generation, because we're realizing

210
00:22:26,460 --> 00:22:34,220
we're losing China at the same time. So the risk here isn't that we're not going to push the envelope

211
00:22:34,220 --> 00:22:38,140
forward. I'd say that's almost impossible. The risk here is we're going to lose too much of where

212
00:22:38,140 --> 00:22:43,100
we have and we backslide a little bit. And we're going to find out the answer to that question

213
00:22:43,100 --> 00:22:48,860
in just the next five years about whether or not we can retool fast enough. North America

214
00:22:48,860 --> 00:22:52,940
basically needs to double the size of the industrial plant. And if we fail that,

215
00:22:53,820 --> 00:23:00,300
then we lose a lot of what we already have. I can see that Peter Dee disagrees. So Peter

216
00:23:00,300 --> 00:23:06,780
Dee, back to you. I vehemently disagree. Yeah, so this is so wrong in my opinion.

217
00:23:07,740 --> 00:23:15,180
What's happening is we have more individuals, more empowered with technology than ever before.

218
00:23:15,180 --> 00:23:20,780
We have created an interconnected globe where people have gigabit bandwidth anywhere on the

219
00:23:20,780 --> 00:23:27,340
planet. They now have the ability to use AI to code at a speed like never before. The cost is

220
00:23:27,340 --> 00:23:33,340
demonetizing of the ability to innovate and create, right? It used to be that it would cost you

221
00:23:33,420 --> 00:23:39,980
$100 million to sequence a genome. It's now down to 200 bucks. Your ability to code used to

222
00:23:39,980 --> 00:23:47,420
require a massive amount of education. Now you can code just by explaining through natural language

223
00:23:47,420 --> 00:23:53,580
what you want. So the speed of innovation is exploding onto the scene. And the number of

224
00:23:53,580 --> 00:23:59,420
individuals who've got access to this technology is greater than any time ever in human history.

225
00:23:59,420 --> 00:24:06,060
And entrepreneurs that used to require 50 or 100 or 200 people to create a company

226
00:24:06,060 --> 00:24:11,260
are now creating a company that's delivering a valuable asset or resource with two or three

227
00:24:11,260 --> 00:24:18,460
people. So I think we're seeing a Cambrian explosion of innovation by no means a decrease,

228
00:24:18,460 --> 00:24:26,140
and it's going to be accelerating. I'm going to move us on. What I took away from this little bit

229
00:24:26,140 --> 00:24:33,820
was Peter Z. You're saying that the world is aging, and so the ratios are changing. And Peter D,

230
00:24:33,820 --> 00:24:38,460
you're saying, yeah, but all of those people who weren't part of the system and weren't productive

231
00:24:38,460 --> 00:24:46,700
are now part of all $8.1 billion, $8.2 billion are enabled productive. Okay, enabled. I like it,

232
00:24:46,700 --> 00:24:50,540
caveat. Let me ask you another question. Again, maybe I'll start with Peter Z this time.

233
00:24:51,340 --> 00:25:00,940
Tell me in 30 seconds what you think the future looks like in, say, 2050, and maybe take an American,

234
00:25:00,940 --> 00:25:06,460
a standard American, what do you think life looks like? And then I'm going to come to you, Peter Z,

235
00:25:06,460 --> 00:25:13,900
for your view as well. I think we're going to make it over the hump. I think we're going to succeed in

236
00:25:13,900 --> 00:25:17,420
doubling the size of the industrial plant. And I think we're going to make it through to when the

237
00:25:17,420 --> 00:25:21,900
millennials' kids enter the market and rebalance our demographics here. I don't think it's going

238
00:25:21,900 --> 00:25:26,860
to take till 2050. I think 2040 will be plenty of time. And we will have a system where we are

239
00:25:26,860 --> 00:25:31,180
largely immune to international shocks, and we have local workers serving local markets using

240
00:25:31,180 --> 00:25:36,220
local resources. And getting there is going to be the fastest economic growth in the history of

241
00:25:36,220 --> 00:25:40,860
Canada, Mexico, and the United States. It's not a good story. It's a great story. It's a story of

242
00:25:40,860 --> 00:25:46,460
growth. But I wouldn't call it abundant. It will be driven by a breakdown of the old system.

243
00:25:48,220 --> 00:25:55,500
Okay. So Peter Z, 2050 looks good. It's much more localized, but it's an ugly way to get there.

244
00:25:55,500 --> 00:26:04,060
Peter D. So I'm going to agree with Peter Z and a lot of that. And I do think 2040,

245
00:26:04,060 --> 00:26:09,100
it's hard to predict beyond 2040, honestly. We're going to be in the next 20 years,

246
00:26:09,100 --> 00:26:13,740
we're going to be adding healthy decades on to the human lifespan. And that's one of areas that

247
00:26:13,740 --> 00:26:20,540
I'm focused on, fingers crossed, and about to launch a massive XPRIZE in that area. But we're

248
00:26:20,540 --> 00:26:26,540
going to add 20 healthy years. The study done out of Harvard London School of Business in Oxford

249
00:26:26,540 --> 00:26:34,140
said that for every healthy year you add to the lifespan of humanity, it's worth $38 trillion

250
00:26:34,140 --> 00:26:41,660
to the global economy. So we have more people living longer, healthier lives. It's positive on

251
00:26:41,660 --> 00:26:47,260
both sides of the equation, more empowered than ever before. We're going to see AI have the most

252
00:26:47,260 --> 00:26:52,460
disruptive and most reinventive impact. There are going to be two kinds of companies at the

253
00:26:52,460 --> 00:26:57,420
end of this decade, those fully utilizing AI and those out of business. It's going to be that black

254
00:26:57,420 --> 00:27:05,100
and white. And so we're going to see AI as the closest analogy for me is Jarvis from Ironman,

255
00:27:05,980 --> 00:27:11,340
where it's your partner, it's your co-pilot, it's your inspiration, it's your collaborator.

256
00:27:11,660 --> 00:27:18,300
Across everything, allowing you to fulfill your dreams, giving you access to not information

257
00:27:18,300 --> 00:27:24,460
but knowledge. I'm going to come back to productivity towards the end of this time,

258
00:27:24,460 --> 00:27:29,340
but I want to move on to climate. And Peter Dee, I want to turn to you first and say,

259
00:27:30,780 --> 00:27:36,860
aren't we using up the Earth's resources? Will there ever be a tipping point at which we can't

260
00:27:36,860 --> 00:27:43,740
multiply them or become sufficiently efficient or productive to deliver more with less? Is science

261
00:27:43,740 --> 00:27:57,420
going to allow this? This idea that we are scarcity-bound, again, is built into our old brain

262
00:27:57,420 --> 00:28:03,420
that evolved for hundreds of thousands of years. We're living, again, in a world where technology

263
00:28:03,420 --> 00:28:09,180
liberates resources. So again, we used to kill whales to get whale oil. Now we're on the verge

264
00:28:09,180 --> 00:28:15,580
of fusion, which will give us near infinite energy. We still have an oil economy and we will for the

265
00:28:15,580 --> 00:28:20,300
next 20 or 30 years. There's no issue about that, but we're going to be increasing the amount of

266
00:28:20,300 --> 00:28:27,500
resources available to us. We're about to launch a very large XPRIZE for large-scale desalination.

267
00:28:28,060 --> 00:28:35,340
We fight over water. 97.5% of the water on the planet is salt, 2% is ice, and we fight over

268
00:28:35,340 --> 00:28:41,100
a half a percent of the water on this planet. But there's an abundance-minded way of thinking about

269
00:28:41,100 --> 00:28:45,340
it. There's plenty of water. We live on a water planet. It's just not a usable form. That's where

270
00:28:45,340 --> 00:28:51,900
technology comes in to capture trillions of tons of water out of the atmosphere. We call it rain

271
00:28:52,620 --> 00:28:59,900
or desalinate water out of the oceans. What other resources do we consider scarce? Because

272
00:28:59,900 --> 00:29:06,300
I can show you the technologies that can make it abundant. I'll just say for climate real quick,

273
00:29:07,100 --> 00:29:14,220
our ability to bring the earth back into balance is something fundamentally critical,

274
00:29:14,220 --> 00:29:20,140
and I think I would rather be fighting that battle today with the tech we have versus 20 or 30 years

275
00:29:20,220 --> 00:29:27,660
ago. Peter Z, do you want to come back on that? By the way, you don't need my permission to push

276
00:29:27,660 --> 00:29:32,940
back on one another, but I have a feeling, Peter Z, there might be something you want to answer to

277
00:29:32,940 --> 00:29:37,500
that one. Well, you know, me and Peter D were both such shrinking violets. Thank you for unleashing.

278
00:29:37,500 --> 00:29:42,940
I noticed that, really. You're very well behaved, both of you. Go ahead, Peter Z.

279
00:29:43,740 --> 00:29:47,900
Sure. Climate change is definitely a big issue. Anyone who thinks they can predict it on a zip

280
00:29:47,900 --> 00:29:52,540
code by zip code basis, I think is a little crazy because our math just isn't that good yet.

281
00:29:52,540 --> 00:29:58,460
My concern isn't, on this topic, isn't so much that we don't have the tools. It's that we don't

282
00:29:58,460 --> 00:30:03,260
have the tools, yeah, to deal with it yet. I think a best example I can give you is what it takes to

283
00:30:03,260 --> 00:30:09,260
put up a solar panel. Aluminum is the most energy intensive of the primary industries that we have,

284
00:30:09,260 --> 00:30:15,820
if you look at steel and fertilizer and the rest. Taking raw silicon and turning it into a finished

285
00:30:15,820 --> 00:30:22,780
silicon panel requires seven times the energy that it takes to make the same volume of aluminum.

286
00:30:23,820 --> 00:30:28,460
We're probably going to lose most of our capacity to produce polysilicon at scale

287
00:30:28,460 --> 00:30:35,820
when the Chinese break down. The issue here is ultimately out of timeframes. How long does it

288
00:30:35,820 --> 00:30:41,020
take to build the industrial plant? How long does it take to apply the technology? The issue that

289
00:30:41,020 --> 00:30:46,540
Peter D and I have always struggled with is whether or not we've already passed the point of no

290
00:30:46,540 --> 00:30:51,100
return on these technologies and we no longer need the old system to push it forward, or whether we

291
00:30:51,100 --> 00:30:56,940
do need time to move it forward. I think the best example I can give you there of where we haven't

292
00:30:56,940 --> 00:31:03,900
crossed the Rubicon yet is AI. AI chips are all three nanometer or smaller. They all come from the

293
00:31:03,900 --> 00:31:09,580
same city in Taiwan, but that makes it sound a lot simpler than it is. There are 9,000 companies

294
00:31:09,580 --> 00:31:14,540
that are involved in the manufacturing system to allow those fabrication plants to work,

295
00:31:14,540 --> 00:31:19,180
and over half of them only produce one product for one customer and they have no competition

296
00:31:19,180 --> 00:31:23,980
anywhere else in the world. So if you peel out any small section of the global system that's

297
00:31:23,980 --> 00:31:29,420
technologically oriented, like say Germany, which is any severe demographic collapse right now,

298
00:31:30,300 --> 00:31:37,100
we lose the ability to make those chips at all, or certainly at scale. Now we can rebuild that

299
00:31:37,100 --> 00:31:43,820
ecosystem, but it takes time. So everything that Peter D said about productivity, I agree. The question

300
00:31:43,820 --> 00:31:51,580
is whether that's this decade, the next decade, or the decade after. Okay, I'm going to go back.

301
00:31:51,580 --> 00:31:57,420
We've got so much to cover in so little time, so I'm going to ask for quite snappy responses if I

302
00:31:57,420 --> 00:32:04,860
can get from you. I want to come back to you, Peter D. I love it. I'm coming back. I want to go back

303
00:32:04,860 --> 00:32:11,820
to you, Peter D. There's a war in Ukraine. We've got a growing conflict in the Middle East.

304
00:32:12,940 --> 00:32:18,620
Peter Z has already bought up China and his view that China is my language, not yours, Peter Z,

305
00:32:18,620 --> 00:32:25,100
but effectively in decline and over the next decade. We have a vulnerable Taiwan. I haven't

306
00:32:25,100 --> 00:32:34,060
even talked about Iran and Russia. Are we on the verge of a great powers war? And does that, how does

307
00:32:34,860 --> 00:32:43,900
this conflict affect your assessment? There's no question that there's lots of reasons to be

308
00:32:43,900 --> 00:32:53,020
scared, concerned, frightful, and so forth. What I draw confidence from is history as well as a

309
00:32:53,020 --> 00:32:59,580
projected future. You know, if you ask anybody, you know, would you rather live in the year 1900

310
00:32:59,580 --> 00:33:05,420
or the year 2023? If you truly understood what life was like in 1900, where you were working

311
00:33:05,420 --> 00:33:11,100
80-hour work weeks, your 12-year-old kids were in the factories, you were dead by 40 from tuberculosis,

312
00:33:11,900 --> 00:33:18,700
you'd have to answer, I'd rather live today. And so the world has gotten extraordinarily better

313
00:33:18,700 --> 00:33:23,980
by almost every measure, not every measure, but by almost every measure over the last 123 years.

314
00:33:24,860 --> 00:33:29,820
And over that 123 years, we've also seen World War I, World War II, the Spanish

315
00:33:29,820 --> 00:33:37,340
Flu, the Vietnam War, 150 million people died needlessly in those conflicts, and yet the world

316
00:33:37,340 --> 00:33:45,820
has gotten extraordinarily better. This is not a straight and linear path. It has got ups and

317
00:33:45,820 --> 00:33:50,940
downs, ups and downs, but what I truly believe is, yes, we're going to have these problems,

318
00:33:50,940 --> 00:33:57,180
and we're going to overcome them. And the number one way to allow people to become more peaceful

319
00:33:58,380 --> 00:34:05,660
is to give them access to prosperity. And technology does that. If you have access to all

320
00:34:05,660 --> 00:34:09,420
of, you know, if your kids have access to the food, water, energy, health, care, education,

321
00:34:11,420 --> 00:34:14,540
they're not going to want to go kill themselves and put on a suicide vest.

322
00:34:15,100 --> 00:34:23,420
You've just silenced me for one moment. Thank you for that image.

323
00:34:24,620 --> 00:34:29,980
Peter Z, I'm going to come back to you for one final quick question before I get back

324
00:34:29,980 --> 00:34:35,100
to this issue of time that we keep coming up with. And I want to talk to you about population,

325
00:34:35,100 --> 00:34:42,220
because that's one of the big issues that you've put on the table. Thomas Malthus back in 1798

326
00:34:42,300 --> 00:34:45,420
predicted the population growth would outstrip food production.

327
00:34:46,700 --> 00:34:50,620
Since then, numerous other scientists and experts have said similarly,

328
00:34:51,580 --> 00:34:57,740
including most notably Paul Ehrlich and his wife in the population bomb in the late 60s.

329
00:34:57,740 --> 00:35:01,900
They've all been wrong. Why is this moment different?

330
00:35:03,260 --> 00:35:07,900
Industrialization. Industrialization plus technology introduced us to this very

331
00:35:07,900 --> 00:35:12,140
simple concept called synthetic fertilizer. And it was applied at scale. And we were able to

332
00:35:12,140 --> 00:35:17,500
put it on geographies that without it could not grow food, things like the Brazilian Serato,

333
00:35:17,500 --> 00:35:23,500
for example. And that effectively increased the amount of land that we could cultivate by a factor

334
00:35:23,500 --> 00:35:30,700
of three. And that's what's kept us all alive. As long as there is no disruption to the synthetic

335
00:35:30,700 --> 00:35:36,460
fertilizer supply chain, we're good. China is where the single largest source of phosphate

336
00:35:36,460 --> 00:35:41,900
comes from Belarus and Russia. The single largest source of potash and nitrogen is a natural gas

337
00:35:41,900 --> 00:35:45,340
derivative. And we're going to lose access to a lot of that from the Russian space in the Middle

338
00:35:45,340 --> 00:35:52,940
East as well. So we're going to have to hack the genome of plants in order to grow more food with

339
00:35:52,940 --> 00:35:59,020
less fertilizer. And it is a race against time, whether we can figure out a way to improve yields

340
00:35:59,020 --> 00:36:05,580
on the genetic side faster than we lose the ability to produce it on the synthetic fertilizer side.

341
00:36:05,660 --> 00:36:10,300
And I do not have enough confidence to tell you how we're going to come down on that race.

342
00:36:12,460 --> 00:36:17,660
So time is a big issue here, not just because our clock is ticking. So I'm going to come back to

343
00:36:17,660 --> 00:36:22,220
you both with one last question that's on time. We've talked a lot about time as a macro sense,

344
00:36:22,220 --> 00:36:29,900
but I want to talk about time in a micro sense. Peter Dee, in your 2012 book, Abundance, you

345
00:36:29,900 --> 00:36:37,420
quote Matt Ridley that, and I love this, save time is the best definition of prosperity.

346
00:36:38,620 --> 00:36:42,780
You give a whole host of examples of how time has been saved. You've done that today as well.

347
00:36:43,580 --> 00:36:48,300
But many would argue today that time is an increasingly rare commodity. Expectations of

348
00:36:48,300 --> 00:36:55,580
what we achieve in any moment has multiplied many times over. So I'd love to get from both of you

349
00:36:55,580 --> 00:37:01,980
what do you say to this argument about time and prosperity? And you both have about 25 seconds

350
00:37:01,980 --> 00:37:12,460
to do it. So maybe Peter Z, start with you. So save time is the best definition of prosperity.

351
00:37:12,460 --> 00:37:18,300
So for you, Peter Z, what do you say to the argument that actually time is shrinking, in fact?

352
00:37:20,060 --> 00:37:24,380
Electrification. Electrification allowed us to push back the night that gave us the

353
00:37:24,380 --> 00:37:28,060
woman's rights movement, because all of a sudden women could have time to do things that were not

354
00:37:28,060 --> 00:37:35,660
related to the household. Holding those advantages is our single biggest challenge. If we lose China,

355
00:37:35,660 --> 00:37:41,500
if we lose the capital that comes from a positive demographic structure, our ability to hold the

356
00:37:41,500 --> 00:37:49,020
line on industrialization itself is at risk. And electrification requires globalization,

357
00:37:49,020 --> 00:37:54,860
and we could see a significant regression in the next 15 years as we lose the ability to do that

358
00:37:54,860 --> 00:38:00,620
at scale on a planet-wide basis. And an asteroid could strike us and we'd all be dead. But the

359
00:38:00,620 --> 00:38:06,300
fact of the matter is, you know, every human on the planet has one thing in common, 24 hours in

360
00:38:06,300 --> 00:38:11,100
a day, seven days in a week, and how you use that time that differentiates wealth and capabilities.

361
00:38:11,100 --> 00:38:16,780
And, you know, Google saved us from going to the libraries. ChatGPT is now giving us increased,

362
00:38:16,780 --> 00:38:22,460
you know, so yes, we are resetting our expected performance per unit time,

363
00:38:23,260 --> 00:38:28,620
and it's exploding onto the world, right? And so our ability to solve problems, to create new

364
00:38:28,620 --> 00:38:36,700
products, to create additional prosperity is increasing at an exponential rate because of

365
00:38:36,700 --> 00:38:41,740
these technologies. And these technologies enable us to solve the problems, you know, whether it's

366
00:38:41,740 --> 00:38:49,180
labor from robots or AI, you know, I would rather bet on today than any time in human history.

367
00:38:49,900 --> 00:38:53,900
We're going to bring some other voices in, some members of the audience.

368
00:38:53,900 --> 00:38:59,500
Up first, we have Alexa Mikhail of Fortune Magazine. Alexa, welcome. What's your question for the

369
00:38:59,500 --> 00:39:07,820
debaters? Thank you so much for having me. Yeah, so, Peter D, I'll start with you. You know,

370
00:39:07,900 --> 00:39:15,180
you mentioned that in advances in technology and research has really expanded, you know,

371
00:39:15,180 --> 00:39:20,700
not just health, not just lifespan, but health span, and we're going to have these 20 extra years.

372
00:39:20,700 --> 00:39:24,620
So I kind of want to talk about what those years are really going to look like and what it's going

373
00:39:24,620 --> 00:39:31,100
to sort of mean to age, to age in this country, given that, you know, this is sort of uncharted

374
00:39:31,100 --> 00:39:36,780
territory, especially that I think people would argue that, you know, people are also, you know,

375
00:39:36,860 --> 00:39:42,540
aging into poverty. People are dealing with caregiving duties. And so what's that going to

376
00:39:42,540 --> 00:39:48,300
look like? Yeah, it's a challenge, Alexa, because people are probably not saving enough money for

377
00:39:48,300 --> 00:39:55,260
those extra years. You know, the reality is people retire because of one of three reasons,

378
00:39:55,260 --> 00:40:04,460
either they're in pain, they're either low on energy or they're forced to retire. But what happens

379
00:40:04,460 --> 00:40:10,140
at 65 or 70, if at the top of your game, we've got all the energy, all the capabilities, everything

380
00:40:10,140 --> 00:40:18,700
you've ever had and more, I think it's going to be a boom for global GDP if we allow people to

381
00:40:18,700 --> 00:40:23,980
continue working. I think we're going to enter a new period of life where you're starting your next

382
00:40:23,980 --> 00:40:29,340
startup, you're getting your next university degree, you're exploring the world even more.

383
00:40:29,340 --> 00:40:37,660
You know, we shut down people's earning capacity at 65. Why? What if they don't have to? I think

384
00:40:37,660 --> 00:40:45,660
it's a huge economic window of opportunity that is coming. We obviously need to change the, oh, sorry.

385
00:40:46,540 --> 00:40:50,540
I was going to say, Alexa, do you have a, go ahead, Peter, but I think Alexa also had a

386
00:40:50,540 --> 00:40:54,220
separate question for you. But Peter, if you want to respond quickly, go ahead.

387
00:40:55,260 --> 00:40:58,060
I was just going to say, we obviously have to change the political incentives right now and

388
00:40:58,060 --> 00:41:02,780
that requires reform of a lot of programs that encourage people to stop even before 65. And

389
00:41:02,780 --> 00:41:07,180
from a medical point of view, the technology to watch is biologics, because if we can figure out

390
00:41:07,180 --> 00:41:13,580
a way to make people productive without the mental degradation, that obviously moves the metrics on

391
00:41:13,580 --> 00:41:21,340
a lot of this. Alex, you had a question for Peter Z, too. Yeah, thank you. I mean, I think you touched

392
00:41:21,340 --> 00:41:25,660
on it a little bit, but given, you know, that you talked about mass retirement and people also

393
00:41:25,660 --> 00:41:30,940
involuntary retirement as well, and just thinking about, in your mind, kind of similar to what I

394
00:41:30,940 --> 00:41:35,660
asked for your D, sort of, what do you hope to envision about this, as we're going to be living

395
00:41:35,660 --> 00:41:40,780
longer? I think of all the technologies that are on the table that are about to be manifested,

396
00:41:40,780 --> 00:41:46,060
you know, which is, I'm stepping into Peter D's world here a little bit. Keeping mental

397
00:41:46,060 --> 00:41:52,540
acuity firm throughout your 60s and 70s is the single most important one, because if you can

398
00:41:52,540 --> 00:41:58,780
do that, we get an extra group of people, roughly 70 million in the United States, who can be part

399
00:41:58,780 --> 00:42:03,260
of whatever the future solution and struggles are, as opposed to being part of the problem.

400
00:42:03,980 --> 00:42:07,340
And that is one of the very few technologies that I'm, like, watching very, very closely,

401
00:42:07,340 --> 00:42:10,780
because it looks like it's right at the cusp, and we might be able to tip that

402
00:42:10,780 --> 00:42:14,700
into usefulness within the next 24 months. And that's very good. Pushing hard. Pushing hard. Yeah.

403
00:42:14,700 --> 00:42:20,780
Please, please, please continue. Thank you. I'm hearing some positivity here. Thanks so much,

404
00:42:21,020 --> 00:42:27,660
Alexa. Next, I want to invite Diane Francis to our stage. Diane is from the National Post.

405
00:42:27,660 --> 00:42:32,940
Diane, what question do you have for the debaters? Well, I think this is a marvelous

406
00:42:32,940 --> 00:42:41,260
said debate. I really enjoyed it. Am I on mute? We can hear you. Go right ahead. Great. Great

407
00:42:41,260 --> 00:42:49,580
debate. Here's my question. Human nature. Malevolent usage, lack of regulation, anti-regulation,

408
00:42:50,540 --> 00:42:55,900
ignorance, and, and algorithms in the form of very dangerous religions and theologies.

409
00:42:56,460 --> 00:43:03,500
What, you know, tech can't solve that, in fact, could be, and is being utilized to a bigger,

410
00:43:03,500 --> 00:43:11,100
worse extent than before. I'd like you to comment on that as well. I'll jump in. And you're absolutely

411
00:43:11,100 --> 00:43:16,300
right. There's no question that we're going to see malevolent use of AI. And it's my biggest

412
00:43:16,300 --> 00:43:21,580
concern over the next one to five years. I think we're going to see the election be patient zero

413
00:43:22,220 --> 00:43:30,620
in this situation. I think on the flip side, what's going on is what I would call loss of privacy

414
00:43:31,180 --> 00:43:37,660
is going to be a countervailing force. It's hard to hide things more than ever before. So our,

415
00:43:37,660 --> 00:43:43,180
you know, it's going to be a white hat, black hat race in terms of AI being used to help determine

416
00:43:43,820 --> 00:43:51,260
malevolent AI's usage. And one question to ask everybody listening is, do you believe that

417
00:43:51,260 --> 00:43:58,380
human nature is ultimately good or bad? I believe it is ultimately good. And I believe that an

418
00:43:58,380 --> 00:44:03,260
entrepreneur, and this is my mission is to inspire and guide entrepreneurs to create a hopeful,

419
00:44:03,260 --> 00:44:07,900
compelling, and abundant future for humanity. That's my massive transformative purpose. I say it

420
00:44:07,900 --> 00:44:13,580
every morning. It drives all of my organizations and my companies. Entrepreneurs are individuals

421
00:44:13,580 --> 00:44:20,060
who find problems and fix problems. And so, you know, the world's largest problems are the world's

422
00:44:20,060 --> 00:44:25,580
biggest business opportunities. So when you see a problem, it's an entrepreneurial opportunity.

423
00:44:25,580 --> 00:44:30,300
And I think we have more positive mind than entrepreneurs trying to find and slay and solve

424
00:44:30,300 --> 00:44:39,820
problems than any time ever in human history. Peter Z, I think that question was also framed

425
00:44:39,820 --> 00:44:44,380
at you, wasn't it, Diane? Absolutely. Sure. Let me give you the bad and then the good. First

426
00:44:44,380 --> 00:44:48,860
the bad. We've got two major powers, the Russians and the Chinese, who are going to vanish from the

427
00:44:48,860 --> 00:44:53,020
world over the course of the next generation or two. The question is whether it happens fast or

428
00:44:53,020 --> 00:44:56,940
slow. And when countries feel they're in a corner and they have nothing to lose, the chances of

429
00:44:56,940 --> 00:45:01,820
them doing something that they normally wouldn't consider, of course, rises very high. But let

430
00:45:01,820 --> 00:45:07,580
me give you two examples of why I don't think that their decline is going to be catastrophic

431
00:45:07,580 --> 00:45:13,900
for the rest of us. In the case of China, they don't command the top technology. They import

432
00:45:13,900 --> 00:45:19,420
all the server time, they import all the chips that are necessary for them to access AI at scale.

433
00:45:19,420 --> 00:45:23,660
And we're already in the early stages of the Biden administration and whoever follows Biden,

434
00:45:23,660 --> 00:45:28,620
probably working to build a wall in that space. That limits the damage that can be done from a

435
00:45:28,620 --> 00:45:36,780
strategic point of view. The Russians, back in 1987, when the KGB realized that the end was

436
00:45:36,780 --> 00:45:41,900
nigh, and remember back in the late 80s, the KGB controlled the Politburo. They basically

437
00:45:41,900 --> 00:45:45,500
had a meeting where they decided whether or not they wanted to spread nuclear weapons around

438
00:45:45,500 --> 00:45:50,300
the world and salt the earth to destroy whatever the West might do next. And they decided the

439
00:45:50,380 --> 00:45:59,580
answer was no. Even in the darkest hour for a lot of these countries, the desire to end the human

440
00:45:59,580 --> 00:46:05,260
condition just doesn't exist. That doesn't mean they die quietly. That doesn't mean there aren't

441
00:46:05,260 --> 00:46:12,540
problems. And we are still cleaning up the mess from the Soviet disintegration. But it does mean

442
00:46:12,540 --> 00:46:20,860
there are limits. I am far more concerned about powerful individuals that maybe don't have restrictions

443
00:46:20,860 --> 00:46:24,860
on their actions than I am about powerful countries that are getting desperate. And that's a different

444
00:46:24,860 --> 00:46:31,740
sort of problem. Peter D, I think you've just come up with a great suggestion of another debate,

445
00:46:31,740 --> 00:46:36,300
which is are people inherently good or bad? And if open to debate haven't done it yet,

446
00:46:37,180 --> 00:46:41,100
we'll make sure they do. Great question, Diane. Do you have a follow-up?

447
00:46:42,300 --> 00:46:48,700
No, I think that the organizational aptitude of human beings, unless it's taken over by tech,

448
00:46:48,700 --> 00:46:54,700
and then I want to know who controls that fact, has been a constant historical disappointment.

449
00:46:54,700 --> 00:47:02,140
Not just politically, but in terms of parenting, in terms of financial moving forward. This is a

450
00:47:02,140 --> 00:47:08,620
huge issue. And putting the hands of powerful, increasingly powerful tech into people that

451
00:47:08,620 --> 00:47:14,540
may not be good is something that I don't see talked enough about. There was a warning letter

452
00:47:14,540 --> 00:47:20,460
about the AI chatbot. Nothing is moving. And any jurisdictions as to how to try and look at

453
00:47:20,460 --> 00:47:26,220
what problems they've raised. So I just wondered, how optimistic are you, Peter? Because you're

454
00:47:26,220 --> 00:47:39,340
my optimist. I am clear that these are really serious issues. I was just on stage in Saudi

455
00:47:39,340 --> 00:47:47,900
and Riyadh at FII, heading their AI resolutions. And I think ultimately, artificial intelligence

456
00:47:47,900 --> 00:47:55,260
has the ability to deliver extraordinary abundance for humanity. But talking about time frames,

457
00:47:55,340 --> 00:48:00,940
as Peter Z said, this is the 10-year out time frame. There are going to be challenges and

458
00:48:00,940 --> 00:48:06,300
issues in the near term. It's the one to five-year period that I'm concerned about navigating that

459
00:48:07,100 --> 00:48:15,340
and allowing humanity to adjust to it. It is transformative change. And I think we humans

460
00:48:15,340 --> 00:48:19,820
do not like change. We like waking up in the morning and knowing that the world was the same

461
00:48:19,820 --> 00:48:24,300
as it was when we went to sleep, no matter what condition we're in. And we are in an accelerating

462
00:48:24,300 --> 00:48:28,780
period of change. And it is creating more abundance, which is the topic here.

463
00:48:30,060 --> 00:48:36,940
I think you can be a little bit more optimistic, Ms. Francis. We have a little bit more time than

464
00:48:36,940 --> 00:48:40,860
I think most people think. If we have a problem with the chip production, which I think we're

465
00:48:40,860 --> 00:48:44,300
going to, that buys us a few more years right there. And the fact that we're already having

466
00:48:44,300 --> 00:48:47,980
these discussions, I mean, think about everything that is going on in the American Congress right

467
00:48:47,980 --> 00:48:53,980
now. What a mess it is. They still found a time over the last several weeks to have an open session

468
00:48:53,980 --> 00:48:59,820
about the ethics of artificial intelligence. So unlike previous technological revolutions,

469
00:48:59,820 --> 00:49:05,180
where we come very late to the game, we're discussing this one as it unfolds. It doesn't

470
00:49:05,180 --> 00:49:08,780
mean we're going to get it right on the first try, but we're at least not going into it blind.

471
00:49:11,180 --> 00:49:17,580
So what I love about where this conversation is going is I almost hear like the two of you have

472
00:49:18,220 --> 00:49:24,380
flipped a little bit your views. But let's bring on. Thank you so much, Diane, for your questions.

473
00:49:24,380 --> 00:49:30,700
Let's bring on Andy Wang to the stage. Andy is the host of the podcast called Inspired Money.

474
00:49:30,700 --> 00:49:38,620
Andy, welcome. Go ahead with your question. Thank you, Zanya. From an investor's perspective,

475
00:49:38,620 --> 00:49:43,660
there are always growth opportunities. And at the same time, other areas that are contracting,

476
00:49:43,740 --> 00:49:50,380
I'd like to hear from both Peter D. and Peter Z. Given your respective outlooks, what areas might

477
00:49:50,380 --> 00:49:55,900
be beneficiaries of major trends over the next couple of decades? Are there companies, sectors,

478
00:49:55,900 --> 00:50:00,060
or geographic regions where investors should look for opportunities?

479
00:50:04,060 --> 00:50:12,780
Why don't I do Peter? Okay. So Andy, I'm investing my money, my venture fund money,

480
00:50:12,780 --> 00:50:21,420
my time in two areas. Healthspan, healthcare, biotech. I think people would give an extraordinary

481
00:50:21,420 --> 00:50:27,820
amount of their wealth to add 20 plus healthy years. And AI, I think those are the two largest

482
00:50:27,820 --> 00:50:33,740
markets on the planet. And they're going to transform every single thing that we have and we do.

483
00:50:35,260 --> 00:50:41,340
What's on the downside? Any company that is not an exponential organization that is born

484
00:50:43,500 --> 00:50:48,060
more than 30 years ago are going to be outcompeted, outthought, and actually

485
00:50:48,060 --> 00:50:50,140
massively disrupted what's coming down the pipe?

486
00:50:53,100 --> 00:50:57,100
I think we need to focus on the scarcity in order to have the opportunity to turn it into

487
00:50:57,100 --> 00:51:03,100
abundance. So number one, we need to diversify the semiconductor supply chain for the best chips.

488
00:51:03,100 --> 00:51:09,020
Right now, we are incredibly fragile in that and anything breaks anywhere and the whole thing stops.

489
00:51:09,020 --> 00:51:13,260
Building that will take years, but it's certainly within our technical capacity to do it and the

490
00:51:13,260 --> 00:51:20,220
benefits I agree with Peter D are so outsized. It's totally worth our time. Second, if agriculture

491
00:51:20,220 --> 00:51:25,500
goes the way I'm fearing, we need a drastic increase in production. The two ways to do that,

492
00:51:25,500 --> 00:51:31,180
ironically, are both related to AI. One is automating farming to a degree so that each individual

493
00:51:31,180 --> 00:51:36,380
plant gets individual attention. That requires AI and the tractor in order to put pesticides,

494
00:51:36,380 --> 00:51:40,060
fertilizers, water, whatever it happens to be on a plant-by-plant basis. I call it digital

495
00:51:40,060 --> 00:51:46,300
gardening. And the other aspect is hacking the genome of absolutely everything. We've been

496
00:51:46,300 --> 00:51:52,140
moving in that direction for 30 years. 10 years ago, corn plants were 13 feet tall. Now they're

497
00:51:52,140 --> 00:51:58,460
closer to five, but they generate three times as many kernels as the old system did. We need more

498
00:51:58,460 --> 00:52:04,140
of that because if we can't provide broadcast agriculture for a place like Brazil, then places

499
00:52:04,140 --> 00:52:10,540
like Illinois need at least double input to prevent a billion people from starving. This can

500
00:52:10,540 --> 00:52:17,580
probably all be done in less than a decade, but chop chop. I agree 100% with you, Peter. It is,

501
00:52:17,580 --> 00:52:24,300
we're seeing incredible, we're seeing a new species of rice that are able to have multiple

502
00:52:25,980 --> 00:52:32,540
crops per planting. And for those who are concerned about GMO, listen, GMO has never killed anybody,

503
00:52:32,540 --> 00:52:37,100
but I can guarantee you it's saved hundreds of millions of lives. I'm less interested in rice

504
00:52:37,820 --> 00:52:41,260
soy, I think is the one that's going to be the real game changer because it's a protein plant

505
00:52:41,260 --> 00:52:45,660
instead of a starch plant. We also have vertical farming and cultivated meats coming online. The

506
00:52:45,660 --> 00:52:50,700
idea that we have to eat food the way it's always been produced, in the words grow an entire cow to

507
00:52:50,700 --> 00:52:57,180
get access to meat, is going to be seen as insane in the future. Why not just grow the protein that

508
00:52:57,180 --> 00:53:02,540
you need to make a good burger? That's a full topic for a whole other debate. I agree.

509
00:53:07,340 --> 00:53:13,260
Thanks so much, Andy. Really grateful for your question. I've got a question for the two of you,

510
00:53:13,260 --> 00:53:19,500
if I may, which is what's the one argument, and maybe we'll start with Peter Z. What's the one

511
00:53:19,500 --> 00:53:28,620
argument from your colleague that you agree or disagree most with and why? Well, you know,

512
00:53:28,620 --> 00:53:34,140
we actually don't disagree on what technology can do. We don't disagree really on what the

513
00:53:34,140 --> 00:53:39,100
pace of technology can exchange or it can achieve. Our big disagreement is whether the system we're

514
00:53:39,100 --> 00:53:43,580
in today is sustainable in the near-term future or not, or if we have to go through a bit of a

515
00:53:43,580 --> 00:53:48,540
drop before we start back up. I would argue that demographics very clearly means that we're going

516
00:53:48,620 --> 00:53:52,940
to have to take a breather here. I don't see a way around that. I don't see how manufacturing supply

517
00:53:52,940 --> 00:53:58,460
chains that allow technology to apply to scale can continue this decade without a massive reorganization.

518
00:53:59,260 --> 00:54:06,700
But on the rest of this, I'm with him. Excellent. Peter D. Yeah, I have to say,

519
00:54:06,700 --> 00:54:14,220
I agree with much of what Peter Z has said here. The only thing I would say is it's a linear

520
00:54:14,220 --> 00:54:20,220
extrapolation to believe that re-engineering the supply chain will take as long as it has,

521
00:54:20,860 --> 00:54:27,260
because we've got capabilities coming from AI that are going to help us much more rapidly

522
00:54:27,260 --> 00:54:31,900
re-engineer. We have even talked about quantum technologies coming down the pike that are going

523
00:54:31,900 --> 00:54:38,620
to be impacting material science and biology in an extraordinary fashion. So I think if we were

524
00:54:38,620 --> 00:54:44,220
going to try and re-replicate the old school system we've developed over the industrial

525
00:54:44,220 --> 00:54:50,860
military complex of the last century, yeah, it will take many, many decades. But I think we have

526
00:54:50,860 --> 00:54:58,140
shortcuts to be had based upon technology. Having said that, yes, there are supply chain issues.

527
00:54:58,140 --> 00:55:02,060
We saw that during COVID, which can be put us in a precarious situation.

528
00:55:02,620 --> 00:55:08,060
Let me give you an example to show you the promise in the peril. Textiles. Very unsexy

529
00:55:08,060 --> 00:55:12,940
technology was the root of industrialization over a century ago. The model has always been the same

530
00:55:12,940 --> 00:55:17,340
and up until the 90s in the United States, it was women in Appalachia with snowing machines.

531
00:55:17,340 --> 00:55:21,740
Well, then we got NAFTA and the model moved to Mexico where the women with the sewing machines

532
00:55:21,740 --> 00:55:25,420
were cheaper. And then we had the WTO where it moved to India and China where the women with

533
00:55:25,420 --> 00:55:29,820
the sewing machines were cheaper. Then we had COVID and suddenly we didn't have clothes.

534
00:55:30,780 --> 00:55:35,420
So some enterprising folks in North Carolina built some facilities that are two acres under

535
00:55:35,420 --> 00:55:41,020
one roof that take raw cotton, clean it, turn it into thread and then yarn and then cloth and then

536
00:55:41,020 --> 00:55:47,740
close. And the end product is cheaper than what you get out of Bangladesh per unit. And these places

537
00:55:47,740 --> 00:55:54,540
have a staff of two. We had no idea we could do that until we were pushed and we found out we had

538
00:55:54,540 --> 00:56:00,540
to. We're going to find things like that as we reindustrialize, but we're not going to know what

539
00:56:00,540 --> 00:56:06,620
they are until they happen. But you're making the exact point I want to make. A company variant

540
00:56:06,620 --> 00:56:13,180
3D that's here in Malibu is 3D printing clothing at an extraordinary rate in a lights out scenario.

541
00:56:13,180 --> 00:56:19,420
And I think this is what entrepreneurs do. They demonetize and democratize. And I think anybody

542
00:56:19,420 --> 00:56:23,500
listening to this, you know, there are massive opportunities to get ahead of the curve.

543
00:56:26,140 --> 00:56:30,540
We've only got about two minutes left and I want to bring in what is a great question from one of

544
00:56:30,540 --> 00:56:35,260
our audience, which is about the political system. And I want to give it to both of you.

545
00:56:35,260 --> 00:56:41,180
Perhaps start with you, Peter Z, because you've given us the kind of almost apocalyptic view

546
00:56:41,900 --> 00:56:46,860
in the short term. How has our political system contributed to accelerating abundance?

547
00:56:47,820 --> 00:56:53,580
And is it a quip? Do you agree, first of all, and is it a quip to continue to do so? And then

548
00:56:53,580 --> 00:56:55,900
I'll come back to you with the same question, Peter Z.

549
00:56:59,420 --> 00:57:03,500
An understanding of where we are. We have a first past the post electoral system,

550
00:57:03,500 --> 00:57:07,740
which means we have two very big tent parties with lots of factions. And the factions move

551
00:57:07,740 --> 00:57:11,980
around over time as technology and demographics and geopolitics shift. And if you think in the

552
00:57:11,980 --> 00:57:16,620
last 40 years, a lot's gone down, it would make sense for us to rearrange our system now.

553
00:57:17,180 --> 00:57:23,340
This is the seventh time we have done this. We will get through it. Doesn't mean you're going

554
00:57:23,340 --> 00:57:27,980
to like what it looks like on the other side. But at moments of transition like this, we get two

555
00:57:27,980 --> 00:57:32,940
things. Personalities from the outside that just stir the pot, we've seen plenty of those,

556
00:57:33,660 --> 00:57:39,180
and civil society takes over the governmental process because the government becomes

557
00:57:39,260 --> 00:57:47,820
unable to do it itself. So that second piece, that's social media. That's the Elon Musk's

558
00:57:47,820 --> 00:57:51,340
of the world. We might not like it every day, but you got to admit the situation's become a

559
00:57:51,340 --> 00:57:55,260
lot more dynamic and there are a lot more decision makers out there when it comes to

560
00:57:55,260 --> 00:58:01,660
economic and technological trends. It's loud. It's messy, but I'd argue it's taken us in the right

561
00:58:01,660 --> 00:58:11,660
direction. Okay, Peter Dee. Zinnia, I count on entrepreneurship and capitalism to solve problems.

562
00:58:11,660 --> 00:58:18,380
I never depend on the government. Period. End of statement. That was a beautiful brief answer.

563
00:58:18,380 --> 00:58:24,380
Okay, we are outsourcing our governance is what I hear almost from both of you, actually.

564
00:58:25,020 --> 00:58:33,260
Now's the time to bring it home with closing remarks. I'm going to go to you, Peter Dee, first.

565
00:58:33,260 --> 00:58:39,180
You have the floor. Leave us with a reason to believe that yes is the answer to the question,

566
00:58:39,180 --> 00:58:46,620
will the future be abundant? Okay, I built an AI model called Peterbot,

567
00:58:47,180 --> 00:58:52,700
and I'm going to ask Peterbot to go ahead and respond to Peter Zion. Peterbot, would you?

568
00:58:53,500 --> 00:58:58,300
Peter Zion's assertion that we are returning to a world resembling pre-World War Two

569
00:58:58,300 --> 00:59:04,220
is overly pessimistic. The world today is vastly different with exponential technologies

570
00:59:04,220 --> 00:59:09,020
driving progress. Let's focus on leveraging these capabilities to create a future that

571
00:59:09,020 --> 00:59:14,780
surpasses any previous era. I understand Peter's concerns about a pricier and slower world,

572
00:59:14,780 --> 00:59:20,300
but I see this as a temporary transition. I believe in the potential of technology to solve

573
00:59:20,300 --> 00:59:25,820
global challenges. History shows that advancements have consistently improved our lives.

574
00:59:25,820 --> 00:59:32,380
Let's dive into a few concrete examples. One, energy. We're witnessing a global shift towards

575
00:59:32,380 --> 00:59:37,900
renewable energy sources like solar and wind, with costs plummeting and installations surging

576
00:59:37,900 --> 00:59:44,540
worldwide. Two, transportation. Electric vehicles are gaining traction, with major automakers

577
00:59:44,540 --> 00:59:50,620
investing heavily. Additionally, we're seeing advancements in autonomous vehicles, hyperloop

578
00:59:50,620 --> 00:59:57,500
technology, and even flying taxis. Three, education. Online learning platforms are democratizing

579
00:59:57,500 --> 01:00:03,980
education, allowing people worldwide to access high quality educational resources. Virtual reality

580
01:00:03,980 --> 01:00:08,780
and augmented reality are transforming the learning experience. These examples illustrate

581
01:00:08,780 --> 01:00:14,140
how innovation and technology are reshaping various sectors, creating opportunities for positive

582
01:00:14,140 --> 01:00:21,500
change and a brighter future. You can access peterbot.ai. You can ask it questions about

583
01:00:23,020 --> 01:00:29,260
its train of my books and my blogs. I believe in data-driven optimism, and the data has been

584
01:00:29,260 --> 01:00:36,140
consistent up and to the right for the past century. Technology, which has made that transition,

585
01:00:36,140 --> 01:00:43,100
is not slowing down. It's accelerating. Is there danger out there? Of course. Do I believe in

586
01:00:43,180 --> 01:00:49,020
entrepreneurs and individuals to find and solve problems more than ever before? I think they're

587
01:00:49,020 --> 01:00:57,100
the only ones who do. Is the world becoming more abundant? 100%. It is becoming abundant in terms

588
01:00:57,100 --> 01:01:06,380
of access to all the fundamentals. Thank you, Peter. Thank you, Peter Bot. Now, Peter Z.,

589
01:01:06,380 --> 01:01:11,740
you have the final word. You're a butthole, please. Tell us why you answer no to the question,

590
01:01:11,740 --> 01:01:17,980
will the future be abundant? We don't have the redundancy yet. We don't have the resiliency yet.

591
01:01:17,980 --> 01:01:22,780
And if things go with demographics in China and globalization the way I'm anticipating,

592
01:01:22,780 --> 01:01:29,260
we don't have that in finance or industrial materials or manufacturing or above all agriculture.

593
01:01:29,260 --> 01:01:37,580
And until we do, people are going to get left behind at scale. Hopefully, over the next 20 years,

594
01:01:37,580 --> 01:01:42,700
we can work out the kinks of this transition and not lose a lot of what we've achieved in the last

595
01:01:42,700 --> 01:01:49,020
century. But if you look back on the two millennia of history before 1900, that suggests that

596
01:01:50,860 --> 01:01:56,540
unlocking that potential is a lot more difficult than it seems to us at the moment we're in now.

597
01:01:59,020 --> 01:02:02,860
That was a very quick wrap up. Thank you so much, Peter. That's confidence.

598
01:02:03,660 --> 01:02:10,380
No, that's, you know what? That's confidence. I like it. That concludes our debate. I'd really

599
01:02:10,380 --> 01:02:18,140
like to both thank, I will say all three of you, Peter, Peter Barton, Peter, for showing up and

600
01:02:18,140 --> 01:02:23,420
for approaching this debate with an open mind. We really appreciate you bringing the thoughtful

601
01:02:23,420 --> 01:02:29,500
disagreement to the table and your being open to debate and equally agreeing on occasions.

602
01:02:29,500 --> 01:02:37,260
So thank you for that. I'd also like to thank our guests, Alexa Mikhail, Diane Francis and Andy Wang

603
01:02:37,260 --> 01:02:42,380
for contributing your probing questions. And particularly, I'd like to thank you, the audience,

604
01:02:42,380 --> 01:02:49,820
for tuning in to this episode of Open to Debate. As a non-profit, our work to combat extreme

605
01:02:49,820 --> 01:02:54,860
polarization through civil and respectful debate is generously funded by listeners like you,

606
01:02:55,420 --> 01:03:01,100
the Rosencrantz Foundation's porters of open debate, open to debate. Open to debate is also

607
01:03:01,100 --> 01:03:08,380
made possible by the by a generous grant from the Laura and Gary Lawdor Venture Philanthropy Fund.

608
01:03:09,260 --> 01:03:17,740
Robert Rosencrantz is our chairman. Claire Conner is CEO. Leah Mathow is our chief content officer.

609
01:03:17,820 --> 01:03:27,340
Alexis Pancrasi and Marlette Sandoval are our editorial producers and Gabriella Mayer is our

610
01:03:27,340 --> 01:03:32,620
editorial and research manager. Andrew Lipson is head of production. Max Fulton is our production

611
01:03:32,620 --> 01:03:39,580
coordinator and Damon Whitmer is our engineer. Gabrielle Yanicelli is our social media and

612
01:03:39,580 --> 01:03:45,820
digital platforms coordinator. Raven Baker is events and operations manager and Rachel Kemp.

613
01:03:45,820 --> 01:03:52,540
Kemp is our chief of staff. Our theme music is by Alex Klement. Klement, excuse me, and I am your

614
01:03:52,540 --> 01:04:01,740
host, Xenia Wicket, and we look forward to seeing you next time. Thank you.

