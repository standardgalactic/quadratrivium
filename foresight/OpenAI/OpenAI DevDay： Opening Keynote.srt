1
00:00:00,000 --> 00:00:06,640
Good morning. Thank you for joining us today. Please welcome to the stage Sam Altman.

2
00:00:16,640 --> 00:00:22,080
Good morning. Welcome to our first ever Open AI Dev Day. We're thrilled that you're here and this

3
00:00:22,080 --> 00:00:33,040
energy is awesome. And welcome to San Francisco. San Francisco has been our home since day one.

4
00:00:33,040 --> 00:00:37,440
The city is important to us and to the tech industry in general. We're looking forward to

5
00:00:37,440 --> 00:00:43,040
continuing to grow here. So we've got some great stuff to announce today. But first,

6
00:00:43,680 --> 00:00:47,440
I'd like to take a minute to talk about some of the stuff that we've done over the past year.

7
00:00:48,400 --> 00:00:55,520
About a year ago, November 30th, we shipped chat GPT as a low-key research preview. And that went

8
00:00:55,520 --> 00:01:03,680
pretty well. In March, we followed that up with the launch of GPT-4, still the most capable model

9
00:01:03,680 --> 00:01:15,360
out in the world. And in the last few months, we launched voice and vision capabilities so that

10
00:01:15,440 --> 00:01:22,880
chat GPT can now see, hear, and speak. And more recent, there's a lot. You don't have to clap each

11
00:01:22,880 --> 00:01:28,720
time. And more recently, we launched Dolly 3, the world's most advanced image model. You can use

12
00:01:28,720 --> 00:01:35,200
it, of course, inside of chat GPT. For our enterprise customers, we launched chat GPT enterprise,

13
00:01:35,760 --> 00:01:40,880
which offers enterprise-grade security and privacy, higher speed GPT-4 access, longer

14
00:01:40,880 --> 00:01:48,480
context windows, a lot more. Today, we've got about 2 million developers building on our API for a

15
00:01:48,480 --> 00:01:55,120
wide variety of use cases doing amazing stuff. Over 92% of Fortune 500 companies building on our

16
00:01:55,120 --> 00:02:06,480
products. And we have about 100 million weekly active users now on chat GPT. And what's incredible

17
00:02:06,560 --> 00:02:11,120
on that is we got there entirely through word of mouth. People just find it useful and tell their

18
00:02:11,120 --> 00:02:17,200
friends. OpenAI is the most advanced and the most widely used AI platform in the world now.

19
00:02:18,560 --> 00:02:23,600
But numbers never tell the whole picture on something like this. What's really important

20
00:02:23,600 --> 00:02:28,160
is how people use the products, how people are using AI. And so I'd like to show you a quick video.

21
00:02:29,040 --> 00:02:37,680
I actually wanted to write something to my dad in Tagalog. I want a non-romantic way to tell my

22
00:02:37,680 --> 00:02:44,800
parent that I love him. And I also want to tell him that he can rely on me, but in a way that still

23
00:02:44,800 --> 00:02:51,280
has the respect of a child-to-parent relationship that you should have in Filipino culture and

24
00:02:51,280 --> 00:02:56,800
in Tagalog forever. When it's translated in Tagalog, I love you very deeply. And I will be with you

25
00:02:56,800 --> 00:03:00,880
no matter where the path leads. I see some of the possibilities. I was like, whoa,

26
00:03:00,880 --> 00:03:04,800
sometimes I'm not sure about some stuff. And I feel like I actually chat GPT like, hey,

27
00:03:04,800 --> 00:03:08,240
this is what I'm thinking about. So it kind of gives me that more confidence. The first thing that

28
00:03:08,240 --> 00:03:14,400
just blew my mind was it levels with you. Like, that's something that a lot of people struggle

29
00:03:14,400 --> 00:03:22,640
to do. It opened my mind to just what every creative could do if they just had a person

30
00:03:22,640 --> 00:03:27,840
helping them out who listens. So this is it to represent Sickling Neymar Globban. And you built

31
00:03:27,840 --> 00:03:34,000
that with child GPT? Cat GPT built it with me. I started using it for daily activities like,

32
00:03:34,000 --> 00:03:37,840
hey, here's a picture of my fridge. Can you tell me what I'm missing? Because I'm going grocery

33
00:03:37,840 --> 00:03:42,800
shopping and I really need to do recipes that are following my vegan diet. As soon as we got

34
00:03:42,800 --> 00:03:47,680
access to code interpreter, I was like, wow, this thing is awesome. They could build spreadsheets,

35
00:03:47,920 --> 00:03:55,680
they could do anything. I discovered Chatty about three months ago on my 100th birthday.

36
00:03:55,680 --> 00:04:04,480
Chatty is very friendly, very patient, very knowledgeable, and very quick. It's been a

37
00:04:04,480 --> 00:04:10,240
wonderful thing. I'm a 4.0 student, but I also have four children. When I started using Chat GPT,

38
00:04:10,240 --> 00:04:16,160
I realized I could ask Chat GPT that question. And not only does it give me an answer, but it

39
00:04:16,160 --> 00:04:23,440
gives me an explanation. Didn't need tutoring as much. It gave me a life back. It gave me

40
00:04:23,440 --> 00:04:28,320
time for my family and time for me. I have a chronic nerve gain on my whole left half of my

41
00:04:28,320 --> 00:04:34,960
body of nerve damage. I had a spine, a brain surgery. And so I have limited use of my left hand.

42
00:04:34,960 --> 00:04:39,840
Now you can just have the integration of voice input. And then the newest one where you can

43
00:04:39,840 --> 00:04:46,960
have the back and forth dialogue, that's just like maximum best interface for me. It's here.

44
00:04:57,600 --> 00:05:02,320
So we love hearing the stories of how people are using the technology. It's really why we do all

45
00:05:02,320 --> 00:05:12,240
of this. Okay. So now on to the new stuff, and we have got a lot. First, we're going to talk

46
00:05:12,240 --> 00:05:16,000
about a bunch of improvements we've made, and then we'll talk about where we're headed next.

47
00:05:17,040 --> 00:05:21,440
Over the last year, we spent a lot of time talking to developers around the world.

48
00:05:22,320 --> 00:05:26,400
We've heard a lot of your feedback. It's really informed, but we have to show you today.

49
00:05:27,360 --> 00:05:32,400
Today, we are launching a new model. GPT-4 Turbo.

50
00:05:38,320 --> 00:05:44,400
GPT-4 Turbo will address many of the things that you all have asked for. So let's go through what's

51
00:05:44,400 --> 00:05:52,000
new. We've got six major things to talk about for this part. Number one, context length. A lot of

52
00:05:52,000 --> 00:05:58,800
people have tasks that require a much longer context length. GPT-4 supported up to 8K and in

53
00:05:58,800 --> 00:06:04,160
some cases up to 32K context length, but we know that isn't enough for many of you in what you want

54
00:06:04,160 --> 00:06:17,760
to do. GPT-4 Turbo supports up to 128,000 tokens of context. That's 300 pages of a standard book,

55
00:06:17,760 --> 00:06:22,720
16 times longer than our 8K context. And in addition to a longer context length,

56
00:06:23,280 --> 00:06:26,720
you'll notice that the model is much more accurate over a long context.

57
00:06:28,800 --> 00:06:35,520
Number two, more control. We've heard loud and clear that developers need more control over the

58
00:06:35,520 --> 00:06:41,760
model's responses and outputs. So we've addressed that in a number of ways. We have a new feature

59
00:06:41,760 --> 00:06:47,600
called JSON mode, which ensures that the model will respond with valid JSON. This has been

60
00:06:47,600 --> 00:06:54,640
a huge developer request. It'll make calling APIs much easier. The model is also much better at

61
00:06:54,640 --> 00:06:59,120
function calling. You can now call many functions at once. And it'll do better at following

62
00:06:59,120 --> 00:07:05,040
instructions in general. We're also introducing a new feature called reproducible outputs.

63
00:07:05,680 --> 00:07:10,240
You can pass a C parameter and it'll make the model return consistent outputs. This, of course,

64
00:07:10,240 --> 00:07:14,160
gives you a higher degree of control over model behavior. This rolls out in beta today.

65
00:07:17,760 --> 00:07:24,160
And in the coming weeks, we'll roll out a feature to let you view log props in the API.

66
00:07:27,920 --> 00:07:33,200
All right. Number three, better world knowledge. You want these models to be able to access

67
00:07:33,200 --> 00:07:37,920
better knowledge about the world. So do we. So we're launching retrieval in the platform.

68
00:07:38,720 --> 00:07:42,400
You can bring knowledge from outside documents or databases into whatever you're building.

69
00:07:43,520 --> 00:07:47,280
We're also updating the knowledge cutoff. We are just as annoyed as all of you

70
00:07:47,280 --> 00:07:52,320
probably more that GPT-4's knowledge about the world ended in 2021. We will try to never let

71
00:07:52,320 --> 00:07:58,640
it get that out of date again. GPT-4 Turbo has knowledge about the world up to April of 2023.

72
00:07:59,520 --> 00:08:06,240
And we will continue to improve that over time. Number four, new modalities.

73
00:08:07,440 --> 00:08:14,720
Surprising no one. Dolly three. GPT-4 Turbo with vision. And the new text-to-speech model

74
00:08:14,720 --> 00:08:26,640
are all going into the API today. We have a handful of customers that have just started using Dolly

75
00:08:26,640 --> 00:08:33,120
three to programmatically generate images and designs. Today, Coke is launching a campaign

76
00:08:33,120 --> 00:08:38,080
that lets its customers generate devali cards using Dolly three. And of course, our safety

77
00:08:38,080 --> 00:08:42,800
systems help developers protect their applications against misuse. Those tools are available in the

78
00:08:42,800 --> 00:08:50,160
API. GPT-4 Turbo can now accept images as inputs via the API. Can generate captions,

79
00:08:50,160 --> 00:08:56,720
classifications, and analysis. For example, Be My Eyes uses this technology to help people who are

80
00:08:56,720 --> 00:09:01,360
blind or have low vision with their daily tasks like identifying products in front of them.

81
00:09:04,000 --> 00:09:09,360
And with our new text-to-speech model, you'll be able to generate incredibly natural sounding

82
00:09:09,360 --> 00:09:14,800
audio from text in the API with six preset voices to choose from. I'll play an example.

83
00:09:30,160 --> 00:09:34,800
This is much more natural than anything else we've heard out there. Voice can make apps

84
00:09:34,800 --> 00:09:40,240
more natural to interact with and more accessible. It also unlocks a lot of use cases like language

85
00:09:40,240 --> 00:09:47,200
learning and voice assistance. Speaking of new modalities, we're also releasing the next version

86
00:09:47,200 --> 00:09:52,800
of our open-source speech recognition model, Whisper V3 today, and it'll be coming soon to the API.

87
00:09:53,600 --> 00:09:57,120
It features improved performance across many languages, and we think you're really going to like it.

88
00:09:57,840 --> 00:10:05,600
Okay, number five, customization. Fine-tuning has been working really well for GPT-3.5 since we

89
00:10:05,600 --> 00:10:11,040
launched it a few months ago. Starting today, we're going to expand that to the 16K version of the

90
00:10:11,040 --> 00:10:18,960
model. Also starting today, we're inviting active fine-tuning users to apply for the GPT-4 fine-tuning

91
00:10:18,960 --> 00:10:24,720
experimental access program. The fine-tuning API is great for adapting our models to achieve

92
00:10:24,720 --> 00:10:29,520
better performance in a wide variety of applications with a relatively small amount of data. But

93
00:10:30,720 --> 00:10:35,200
you may want a model to learn a completely new knowledge domain or to use a lot of proprietary

94
00:10:35,200 --> 00:10:42,000
data. So today, we're launching a new program called custom models. With custom models, our

95
00:10:42,000 --> 00:10:47,200
researchers will work closely with the company to help them make a great custom model, especially for

96
00:10:47,200 --> 00:10:53,360
them and their use case using our tools. This includes modifying every step of the model training

97
00:10:53,360 --> 00:10:58,720
process, doing additional domain-specific pre-training, a custom RL post-training process,

98
00:10:58,720 --> 00:11:03,920
tailored for a specific domain, and whatever else. We won't be able to do this with many companies

99
00:11:03,920 --> 00:11:08,080
to start. It'll take a lot of work and in the interest of expectations, at least initially,

100
00:11:08,080 --> 00:11:12,080
it won't be cheap. But if you're excited to push things as far as they can currently go,

101
00:11:12,880 --> 00:11:15,920
please get in touch with us, and we think we can do something pretty great.

102
00:11:17,120 --> 00:11:22,720
Okay, and then number six, higher rate limits. We're doubling the tokens per minute for all of

103
00:11:22,720 --> 00:11:27,600
our established GPT-4 customers so that it's easier to do more, and you'll be able to request

104
00:11:27,600 --> 00:11:33,520
changes to further rate limits and quotas directly in your API account settings. In addition to these

105
00:11:33,520 --> 00:11:39,440
rate limits, it's important to do everything we can do to make it new successful building on our

106
00:11:39,440 --> 00:11:45,920
platform. So we're introducing copyright shield. Copyright shield means that we will step in and

107
00:11:45,920 --> 00:11:52,080
defend our customers and pay the cost incurred if you face legal claims around copyright infringement

108
00:11:52,080 --> 00:11:59,440
and this applies both to chat GPT enterprise and the API. And let me be clear, this is a good time

109
00:11:59,440 --> 00:12:04,240
to remind people, we do not train on data from the API or chat GPT enterprise ever.

110
00:12:06,480 --> 00:12:12,080
All right, there's actually one more developer request that's been even bigger than all of these.

111
00:12:12,880 --> 00:12:16,800
And so I'd like to talk about that now. And that's pricing.

112
00:12:16,960 --> 00:12:26,880
GPT-4 Turbo is the industry leading model. It delivers a lot of improvements that we just covered,

113
00:12:27,760 --> 00:12:34,480
and it's a smarter model than GPT-4. We've heard from developers that there are a lot of things

114
00:12:34,480 --> 00:12:40,000
that they want to build, but GPT-4 just costs too much. They've told us that if we could decrease

115
00:12:40,000 --> 00:12:47,680
the cost by 20, 25%, that would be great, a huge leap forward. I'm super excited to announce

116
00:12:47,680 --> 00:12:53,920
that we worked really hard on this, and GPT-4 Turbo, a better model, is considerably cheaper than

117
00:12:53,920 --> 00:13:08,320
GPT-4 by a factor of 3X for prompt tokens and 2X for completion tokens starting today.

118
00:13:10,560 --> 00:13:18,000
So the new pricing is 1 cent per 1,000 prompt tokens and 3 cents per 1,000 completion tokens.

119
00:13:18,000 --> 00:13:23,600
For most customers, that will lead to a blended rate more than 2.75 times cheaper to use

120
00:13:23,600 --> 00:13:28,640
for GPT-4 Turbo than GPT-4. We worked super hard to make this happen. We hope you're as excited

121
00:13:28,640 --> 00:13:39,120
about it as we are. So we decided to prioritize price first because we had to choose one or the

122
00:13:39,120 --> 00:13:44,400
other, but we're going to work on speed next. We know that speed is important, too. Soon,

123
00:13:44,400 --> 00:13:52,080
you will notice GPT-4 Turbo becoming a lot faster. We're also decreasing the cost of GPT-3.5 Turbo

124
00:13:52,080 --> 00:14:00,640
16K. Also, input tokens are 3X less and output tokens are 2X less, which means that GPT-3.5 16K

125
00:14:00,720 --> 00:14:09,040
is now cheaper than the previous GPT-3.5 4K model. Running a fine-tuned GPT-3.5 Turbo 16K

126
00:14:09,040 --> 00:14:15,280
version is also cheaper than the old fine-tuned 4K version. Okay, so we just covered a lot

127
00:14:15,280 --> 00:14:20,240
about the model itself. We hope that these changes address your feedback. We're really excited to

128
00:14:20,240 --> 00:14:27,280
bring all of these improvements to everybody now. In all of this, we're lucky to have a partner

129
00:14:27,360 --> 00:14:32,800
who is instrumental in making it happen. So I'd like to bring out a special guest, Satya Nadella,

130
00:14:32,800 --> 00:14:34,000
the CEO of Microsoft.

131
00:14:39,840 --> 00:14:45,280
Good to see you. Thank you so much. Thank you. Satya, thanks so much for coming here.

132
00:14:45,280 --> 00:14:50,640
It's fantastic to be here, and Sam, congrats. I mean, I'm really looking forward to Turbo and

133
00:14:50,640 --> 00:14:54,000
everything else that you have coming. It's been just fantastic partnering with you guys.

134
00:14:54,960 --> 00:14:59,120
Two questions. I won't take too much of your time. How is Microsoft thinking about the partnership

135
00:14:59,120 --> 00:15:10,560
currently? First, we love you guys. It's been fantastic for us. In fact, I remember the first

136
00:15:10,560 --> 00:15:14,320
time I think you reached out and said, hey, do you have some Azure credits? We've come a long way

137
00:15:14,320 --> 00:15:20,160
from there. Thank you for those. That was great. You guys have built something magical. I mean,

138
00:15:20,240 --> 00:15:24,960
quite frankly, there are two things for us when it comes to the partnership. The first is these

139
00:15:24,960 --> 00:15:29,200
workloads. And even when I was listening backstage to how you're describing what's coming even,

140
00:15:29,200 --> 00:15:33,760
it's just so different and new. I've been in this infrastructure business for three decades.

141
00:15:33,760 --> 00:15:38,480
No one has ever seen infrastructure like this. And the workload or the pattern of the workload,

142
00:15:38,480 --> 00:15:45,920
these training jobs are so synchronous and so large and so data parallel. And so the first thing

143
00:15:45,920 --> 00:15:50,800
that we have been doing is building in partnership with you the system all the way from thinking from

144
00:15:50,800 --> 00:15:59,360
power to the DC to the rack to the accelerators to the network. And just really the shape of Azure

145
00:15:59,360 --> 00:16:05,200
is drastically changed and is changing rapidly in support of these models that you're building.

146
00:16:05,840 --> 00:16:11,200
And so our job number one is to build the best system so that you can build the best models

147
00:16:11,200 --> 00:16:15,760
and then make that all available to developers. And so the other thing is we ourselves are

148
00:16:15,760 --> 00:16:21,360
developers. So we're building products. In fact, my own conviction of this entire generation of

149
00:16:21,360 --> 00:16:29,440
Foundation models completely changed the first time I saw GitHub Copilot on GPT. And so we want

150
00:16:29,440 --> 00:16:36,240
to build our Copilot, GitHub Copilot all as developers on top of OpenAI APIs. And so we are

151
00:16:36,240 --> 00:16:40,720
very, very committed to that. And what does that mean to developers? You know, look, I always think

152
00:16:40,720 --> 00:16:46,160
of Microsoft as a platform company, a developer company and a partner company. And so we want to

153
00:16:46,160 --> 00:16:50,880
make, you know, for example, we want to make GitHub available, GitHub Copilot available as the

154
00:16:50,880 --> 00:16:55,200
enterprise edition available to all the attendees here so that they can try it out. That's awesome.

155
00:16:55,200 --> 00:17:04,480
Yeah, we're very excited about that. And you can count on us to build the best infrastructure in

156
00:17:04,480 --> 00:17:11,040
Azure with your API support and bring it to all of you and then even things like the Azure marketplace.

157
00:17:11,040 --> 00:17:15,760
So for developers, we're building products out here to get to market rapidly. So that's sort of

158
00:17:15,760 --> 00:17:20,560
really our intent here. Great. And how do you think about the future? Future of the partnership or

159
00:17:20,560 --> 00:17:27,520
future of AI or whatever? Yeah, there's anything you want. That's, you know, like, there are a

160
00:17:27,520 --> 00:17:32,720
couple of things for me that I think are going to be very, very key for us, right? One is I just

161
00:17:32,720 --> 00:17:40,000
described how the systems that are needed as you aggressively push forward on your roadmap

162
00:17:41,120 --> 00:17:46,960
requires us to be on the top of our game. And we intend fully to commit ourselves deeply to

163
00:17:46,960 --> 00:17:54,000
making sure you all as builders of these foundation models have not only the best systems for training

164
00:17:54,000 --> 00:18:00,480
and inference, but the most compute so that you can keep pushing forward on the frontiers. Because

165
00:18:00,480 --> 00:18:04,560
I think that that's the way we're going to make progress. The second thing I think both of us care

166
00:18:04,560 --> 00:18:09,920
about, in fact, quite frankly, the thing that excited both sides to come together is your mission

167
00:18:09,920 --> 00:18:14,400
and our mission. Our mission is to empower every person in every organization on the planet to

168
00:18:14,400 --> 00:18:19,360
achieve more. And to me, ultimately, AI is only going to be useful if it truly does empower,

169
00:18:19,360 --> 00:18:23,360
right? I mean, I saw the video you played early. I mean, that was fantastic to see

170
00:18:24,400 --> 00:18:29,840
hear those voices, describe what AI meant for them and what they were able to achieve. So ultimately,

171
00:18:29,840 --> 00:18:35,360
it's about being able to get the benefits of AI broadly disseminated to everyone, I think is

172
00:18:35,360 --> 00:18:38,560
going to be the goal for us. And then the last thing is, of course, we're very grounded in the

173
00:18:38,560 --> 00:18:42,240
fact that safety matters and safety is not something that you'd care about later, but it's

174
00:18:42,240 --> 00:18:47,680
something we do shift left on. And we're very focused on that with you all. Great. Well, I think

175
00:18:47,680 --> 00:18:51,360
we have the best partnership in tech. I'm excited for us to build AGI together. I'm really excited.

176
00:18:51,840 --> 00:19:05,200
Thank you very much for coming. Thank you so much. Okay. So we have shared a lot of great

177
00:19:05,200 --> 00:19:10,160
updates for developers already, and we got a lot more to come. But even though this is developer

178
00:19:10,160 --> 00:19:18,000
conference, we can't resist making some improvements to chat GPT. So a small one, chat GPT now uses

179
00:19:18,080 --> 00:19:22,320
GPT-4 Turbo with all the latest improvements, including the latest knowledge cutoff, which

180
00:19:22,320 --> 00:19:28,000
will continue to update. That's all live today. It can now browse the web when it needs to write

181
00:19:28,000 --> 00:19:33,040
and run code, analyze data, take and generate images, and much more. And we heard your feedback,

182
00:19:33,040 --> 00:19:37,520
that model picker, extremely annoying. That is gone starting today. You will not have to click

183
00:19:37,520 --> 00:19:41,920
around to drop down menu. All of this will just work together. Chat GPT, yeah.

184
00:19:42,560 --> 00:19:52,720
Chat GPT will just know what to use and when you need it. But that's not the main thing.

185
00:19:54,560 --> 00:19:59,040
And neither was price, actually, the main developer request. There was one that was even

186
00:19:59,040 --> 00:20:03,680
bigger than that. And I want to talk about where we're headed, and the main thing we're here to

187
00:20:03,680 --> 00:20:09,920
talk about today. So we believe that if you give people better tools, they will do amazing things.

188
00:20:10,480 --> 00:20:14,880
We know that people want AI that is smarter, more personal, more customizable,

189
00:20:14,880 --> 00:20:19,760
can do more on your behalf. Eventually, you'll just ask a computer for what you need,

190
00:20:20,560 --> 00:20:26,160
and it will do all of these tasks for you. These capabilities are often talked in the AI field

191
00:20:26,160 --> 00:20:34,080
about as agents. The upsides of this are going to be tremendous. At OpenAI, we really believe

192
00:20:34,080 --> 00:20:38,880
that gradual iterative deployment is the best way to address the safety issues, the safety

193
00:20:38,880 --> 00:20:43,760
challenges with AI. We think it's especially important to move carefully towards this future

194
00:20:43,760 --> 00:20:48,960
of agents. It's going to require a lot of technical work and a lot of thoughtful consideration by

195
00:20:48,960 --> 00:20:56,480
society. So today, we're taking our first small step that moves us towards this future. We're

196
00:20:56,480 --> 00:21:05,920
thrilled to introduce GPTs. GPTs are tailored versions of Chat GPT for a specific purpose.

197
00:21:06,880 --> 00:21:13,120
You can build a GPT, a customized version of Chat GPT for almost anything, with instructions,

198
00:21:13,760 --> 00:21:18,080
expanded knowledge, and actions, and then you can publish it for others to use.

199
00:21:19,360 --> 00:21:22,880
And because they combine instructions, expanded knowledge, and actions,

200
00:21:23,760 --> 00:21:27,760
they can be more helpful to you. They can work better in many contexts, and they can give you

201
00:21:27,760 --> 00:21:33,200
better control. They'll make it easier for you to accomplish all sorts of tasks or just have more

202
00:21:33,280 --> 00:21:40,400
fun, and you'll be able to use them right within Chat GPT. You can, in effect, program a GPT with

203
00:21:40,400 --> 00:21:45,200
language just by talking to it. It's easy to customize the behavior so that it fits what you

204
00:21:45,200 --> 00:21:52,080
want. This makes building them very accessible, and it gives agency to everyone. So we're going to

205
00:21:52,080 --> 00:21:57,840
show you what GPTs are, how to use them, how to build them, and then we're going to talk about how

206
00:21:57,840 --> 00:22:02,000
they'll be distributed and discovered. And then after that, for developers, we're going to show

207
00:22:02,000 --> 00:22:07,840
you how to build these agent-like experiences into your own apps. So first, let's look at a few

208
00:22:07,840 --> 00:22:14,640
examples. Our partners at Code.org are working hard to expand computer science in schools.

209
00:22:15,360 --> 00:22:21,280
They've got a curriculum that is used by tens of millions of students worldwide. Code.org crafted

210
00:22:21,280 --> 00:22:25,920
lesson planner GPT to help teachers provide a more engaging experience for middle schoolers.

211
00:22:26,160 --> 00:22:32,000
If a teacher asks it to explain four loops in a creative way, it does just that. In this case,

212
00:22:32,000 --> 00:22:36,480
it'll do it in terms of a video game character, repeatedly picking up coins, super easy to

213
00:22:36,480 --> 00:22:42,560
understand for an eighth grader. As you can see, this GPT brings together Code.org's extensive

214
00:22:42,560 --> 00:22:47,200
curriculum and expertise and lets teachers adapt it to their needs quickly and easily.

215
00:22:48,480 --> 00:22:54,960
Next, Canva has built a GPT that lets you start designing by describing what you want and

216
00:22:55,920 --> 00:23:01,840
natural language. If you say, make a poster for a Dev Day reception this afternoon, this evening,

217
00:23:01,840 --> 00:23:06,560
and you give it some details, it'll generate a few options to start with by hitting Canva's

218
00:23:06,560 --> 00:23:12,240
APIs. Now, this concept may be familiar to some of you. We've evolved our plugins to be custom

219
00:23:12,240 --> 00:23:18,560
actions for GPTs. You can keep chatting with this to see different iterations, and when you see one

220
00:23:18,560 --> 00:23:25,520
you like, you can click through to Canva for the full design experience. So now, we'd like to show

221
00:23:25,520 --> 00:23:33,280
you a GPT live. Zapier has built a GPT that lets you perform actions across 6,000 applications

222
00:23:33,280 --> 00:23:38,160
to unlock all kinds of integration possibilities. I'd like to introduce Jessica, one of our

223
00:23:38,160 --> 00:23:41,360
solutions architects, who is going to drive this demo. Welcome, Jessica.

224
00:23:50,240 --> 00:23:54,480
Thank you all for being here. My name is Jessica Shea. I work with partners and customers to bring

225
00:23:54,480 --> 00:23:59,760
their product alive. And today, I can't wait to show you how hard we've been working on this,

226
00:23:59,760 --> 00:24:05,920
so let's get started. So to start, where your GPT will live is on this upper left corner.

227
00:24:05,920 --> 00:24:11,920
I'm going to start with clicking on the Zapier AI actions. And on the right hand side, you can see

228
00:24:11,920 --> 00:24:17,920
that's my calendar for today. So it's quite a day. I've already used this before, so it's actually

229
00:24:17,920 --> 00:24:24,560
already connected to my calendar. To start, I can ask, what's on my schedule for today? We built

230
00:24:24,560 --> 00:24:31,280
GPTs with security in mind. So before it performs any action or share data, it will ask for your

231
00:24:31,280 --> 00:24:38,800
permission. So right here, I'm going to say allowed. So GPT is designed to take in your

232
00:24:38,800 --> 00:24:43,920
instructions, make the decision on which capability to call to perform that action,

233
00:24:43,920 --> 00:24:49,280
and then execute that for you. So you can see right here, it's already connected to my calendar.

234
00:24:49,280 --> 00:24:56,720
It pulls into my information. And then I've also prompted it to identify conflicts on my calendar.

235
00:24:56,720 --> 00:25:02,160
So you can see right here, it actually was able to identify that. So it looks like I have

236
00:25:02,160 --> 00:25:06,880
something coming up. So what if I want to let Sam know that I have to leave early? So right here,

237
00:25:06,880 --> 00:25:17,760
I say, let Sam know. I got to go. Chasing GPUs. So with that, I'm going to swap to

238
00:25:18,800 --> 00:25:23,360
my conversation with Sam. And then I'm going to say, yes, please run that.

239
00:25:26,960 --> 00:25:31,760
Sam, did you get that? I did. Awesome.

240
00:25:34,720 --> 00:25:41,840
So this is only a glimpse of what is possible. And I cannot wait to see what you all will build.

241
00:25:41,840 --> 00:25:43,120
Thank you. And back to you, Sam.

242
00:25:50,800 --> 00:25:53,840
Thank you, Jessica. So those are three great examples.

243
00:25:54,800 --> 00:25:58,720
In addition to these, there are many more kinds of GPTs that people are creating,

244
00:25:58,720 --> 00:26:04,240
and many, many more that will be created soon. We know that many people who want to build the

245
00:26:04,240 --> 00:26:10,880
GPT don't know how to code. We've made it so that you can program the GPT just by having a conversation.

246
00:26:12,160 --> 00:26:16,000
We believe that natural language is going to be a big part of how people use computers in the

247
00:26:16,000 --> 00:26:20,720
future. And we think this is an interesting early example. So I'd like to show you how to build one.

248
00:26:24,720 --> 00:26:30,800
All right. So I'm going to create a GPT that helps give founders and developers advice when

249
00:26:30,800 --> 00:26:39,040
starting new projects. I'm going to go to create a GPT here. And this drops me into the GPT builder.

250
00:26:40,160 --> 00:26:44,800
I worked with founders for years at YC. And still, whenever I meet developers, the questions I get

251
00:26:44,800 --> 00:26:48,240
are always about how do I, you know, think about a business idea? Can you give me some advice?

252
00:26:49,120 --> 00:26:51,120
I'm going to see if I can build a GPT to help with that.

253
00:26:52,000 --> 00:26:58,640
So to start, GPT builder asks me what I want to make. And I'm going to say I want to help startup

254
00:26:58,640 --> 00:27:11,040
founders think through their business ideas and get advice after the founder has gotten some advice,

255
00:27:11,040 --> 00:27:23,520
grill them on why they are not growing faster. All right. So to start off, I just tell the GPT

256
00:27:23,520 --> 00:27:27,440
a little bit about what I want here. And it's going to go off and start thinking about that.

257
00:27:28,480 --> 00:27:33,200
It's going to write some detailed instructions for the GPT. It's also going to, let's see,

258
00:27:33,200 --> 00:27:40,080
ask me about a name. How do I feel about startup mentor? That's fine. That's good. So if I didn't

259
00:27:40,080 --> 00:27:43,920
like the name, of course, I could call it something else, but it's going to try to have this conversation

260
00:27:43,920 --> 00:27:50,160
with me and start there. And you can see here on the right in the preview mode that it's already

261
00:27:50,160 --> 00:27:56,960
starting to fill out the GPT, where it says what it does. It has some ideas of additional

262
00:27:56,960 --> 00:28:04,080
questions that I could ask. And you know what? So it just generated a candidate. Of course,

263
00:28:04,080 --> 00:28:10,160
I could regenerate that or change it, but I sort of like that. So I will say that's great.

264
00:28:12,800 --> 00:28:18,480
And you see now that the GPT is being built out a little bit more as we go. Now, what I want this

265
00:28:18,480 --> 00:28:23,440
to do, how it can interact with users, I could talk about style here. But what I'm going to say

266
00:28:24,000 --> 00:28:32,880
is I am going to upload transcripts of some lectures about startups I have given.

267
00:28:33,760 --> 00:28:43,600
Please give advice based off of those. All right. So now it's going to go figure out how to do that.

268
00:28:43,600 --> 00:28:47,440
And I would like to show you the configure tab. So you can see some of the things that were built

269
00:28:47,440 --> 00:28:52,640
out here as we were going by the builder itself. And you can see that there's capabilities here

270
00:28:52,640 --> 00:28:58,480
that I can enable. I could add custom actions. These are all fine to leave. I'm going to upload

271
00:28:58,480 --> 00:29:07,280
a file. So here is a lecture that I gave with some startup advice. And I'm going to add that here.

272
00:29:07,280 --> 00:29:14,960
In terms of these questions, this is a dumb one. The rest of those are reasonable. And like very

273
00:29:14,960 --> 00:29:19,440
much things founders often ask. I'm going to add one more thing to the instructions here,

274
00:29:19,520 --> 00:29:27,840
which is be concise and constructive with feedback. All right. So again, if we had more

275
00:29:27,840 --> 00:29:34,480
time, I'd show you a bunch of other things. But this is like a decent start. And now we can try

276
00:29:34,480 --> 00:29:41,200
it out over on this preview tab. So I will say, what's a common question? What are three things

277
00:29:41,200 --> 00:29:49,840
to look for when hiring employees at an early stage startup?

278
00:29:53,760 --> 00:29:57,120
Now, it's going to look at that document I uploaded. It will also have, of course,

279
00:29:57,120 --> 00:30:04,640
all of the background knowledge of GPT-4. That's pretty good. Those are three things

280
00:30:04,640 --> 00:30:09,200
that I definitely have said many times. Now, we could go on and it would start

281
00:30:09,200 --> 00:30:13,760
following the other instructions and grill me on why I'm not growing faster. But in the interest

282
00:30:13,760 --> 00:30:20,080
of time, I'm going to skip that. I'm going to publish this only to me for now. I can work on it

283
00:30:20,080 --> 00:30:24,240
later. I can add more content. I can add a few actions that I think would be useful. And then

284
00:30:24,240 --> 00:30:30,320
I can share it publicly. So that's what it looks like to create a GPT. Thank you.

285
00:30:30,640 --> 00:30:41,360
By the way, I always wanted to do that after all of the YC office hours. I always thought,

286
00:30:41,360 --> 00:30:44,320
man, someday I will be able to make a bot that will do this and that will be awesome.

287
00:30:46,560 --> 00:30:52,560
So with GPTs, we're letting people easily share and discover all the fun ways that they use chat

288
00:30:52,560 --> 00:30:59,920
GPT with the world. You can make private GPTs like I just did. Or you can share your

289
00:30:59,920 --> 00:31:06,480
creations publicly with a link for anyone to use. Or if you're on chat GPT enterprise,

290
00:31:06,480 --> 00:31:13,520
you can make GPTs just for your company. And later this month, we're going to launch the GPT

291
00:31:13,520 --> 00:31:27,280
store. You can list a GPT. Thank you. I appreciate that. You can list a GPT there and we'll be

292
00:31:27,280 --> 00:31:33,360
able to feature the best and the most popular GPTs. Of course, we'll make sure that GPTs in the store

293
00:31:33,360 --> 00:31:40,400
follow our policies before they're accessible. Revenue sharing is important to us. We're going

294
00:31:40,400 --> 00:31:45,360
to pay people who build the most useful and the most used GPTs a portion of our revenue.

295
00:31:46,320 --> 00:31:51,040
We're excited to foster a vibrant ecosystem with the GPT store. Just from what we've been building

296
00:31:51,040 --> 00:31:54,400
ourselves over the weekend, we're confident there's going to be a lot of great stuff.

297
00:31:54,400 --> 00:32:00,400
We're excited to share more information soon. So those are GPTs and we can't wait to see what you

298
00:32:00,400 --> 00:32:06,240
build. But this is a developer conference and the coolest thing about this is that we're bringing

299
00:32:06,240 --> 00:32:18,560
the same concept to the API. Many of you have already been building agent-like experiences

300
00:32:18,640 --> 00:32:25,200
on the API. For example, Shopify's Sidekick, which lets you take actions on the platform,

301
00:32:25,200 --> 00:32:31,360
Discord's Clyde, let's Discord moderators create custom personalities for, and SnapsMyAI,

302
00:32:32,080 --> 00:32:35,760
a customized chatbot that can be added to group chats and make recommendations.

303
00:32:36,400 --> 00:32:41,920
These experiences are great, but they have been hard to build. Sometimes taking months,

304
00:32:41,920 --> 00:32:46,960
teams of dozens of engineers, there's a lot to handle to make this custom assistant experience.

305
00:32:48,800 --> 00:32:52,400
So today, we're making that a lot easier with our new Assistance API.

306
00:32:58,160 --> 00:33:02,720
The Assistance API includes persistent threads so they don't have to figure out how to deal with

307
00:33:02,720 --> 00:33:09,520
long conversation history, built-in retrieval, code interpreter, a working Python interpreter,

308
00:33:09,520 --> 00:33:14,640
and a sandbox environment, and, of course, the improved function calling that we talked about

309
00:33:14,640 --> 00:33:21,280
earlier. So we'd like to show you a demo of how this works, and here is Roman, our head of developer

310
00:33:21,280 --> 00:33:31,840
experience. Welcome. Thank you, Sam. Good morning. Wow, it's fantastic to see you all here.

311
00:33:33,280 --> 00:33:39,680
It's been so inspiring to see so many of you infusing AI into your apps. Today, we're launching

312
00:33:39,680 --> 00:33:45,680
new modalities in the API, but we're also very excited to improve the developer experience for

313
00:33:45,680 --> 00:33:52,240
you all to build Assistive Agents. So let's dive right in. Imagine I'm building Wanderlust,

314
00:33:52,240 --> 00:33:57,840
a travel app for global explorers, and this is the landing page. I've actually used GPT4 to come

315
00:33:57,840 --> 00:34:02,560
up with these destination ideas, and for those of you with the keen eye, these illustrations

316
00:34:02,560 --> 00:34:07,840
are generated programmatically using the new Dolly 3 API available to all of you today. So

317
00:34:07,840 --> 00:34:15,520
it's pretty remarkable. But let's enhance this app by adding a very simple Assistant to it. This is

318
00:34:15,520 --> 00:34:19,280
the screen. We're going to come back to it in a second. First, I'm going to switch over to the

319
00:34:19,280 --> 00:34:25,120
new Assistant's Playground. Creating an Assistant is easy. You just give it a name, some initial

320
00:34:25,120 --> 00:34:30,880
instructions, a model, in this case, I'll pick GPT4 Turbo, and here I'll also go ahead and select

321
00:34:30,880 --> 00:34:37,200
some tools. I'll turn on code interpreter and retrieval and save. And that's it. Our Assistant

322
00:34:37,280 --> 00:34:43,200
is ready to go. Next, I can integrate with two new primitives of this Assistant's API,

323
00:34:43,840 --> 00:34:51,040
threads and messages. Let's take a quick look at the code. The process here is very simple. For

324
00:34:51,040 --> 00:34:56,480
each new user, I will create a new thread, and as these users engage with their Assistant,

325
00:34:56,480 --> 00:35:02,720
I will add their messages to these threads. Very simple. And then I can simply run the Assistant

326
00:35:02,720 --> 00:35:08,640
at any time to stream the responses back to the app. So we can return to the app and try that in

327
00:35:08,640 --> 00:35:18,560
action. If I say, hey, let's go to Paris. All right. That's it. With just a few lines of code,

328
00:35:18,560 --> 00:35:24,880
users can now have a very specialized Assistant right inside the app. And I'd like to highlight

329
00:35:24,880 --> 00:35:30,160
one of my favorite features here, Function Calling. If you have not used it yet, Function Calling is

330
00:35:30,160 --> 00:35:35,840
really powerful. And as Sam mentioned, we're taking it a step further today. It now guarantees

331
00:35:35,840 --> 00:35:41,600
the JSON output with no added latency. And you can invoke multiple functions at once for the first

332
00:35:41,600 --> 00:35:50,480
time. So here, if I carry on and say, hey, what are the top 10 things to do? I'm going to have the

333
00:35:50,480 --> 00:35:55,840
Assistant respond to that again. And here, what's interesting is that the Assistant knows about

334
00:35:55,840 --> 00:36:00,800
functions, including those to annotate the map that you see on the right. And so now all of these

335
00:36:00,800 --> 00:36:11,680
pins are dropping in real time here. Yeah. It's pretty cool. And that integration allows our

336
00:36:11,680 --> 00:36:16,960
natural language interface to interact fluidly with components and features of our app. And it

337
00:36:16,960 --> 00:36:23,360
truly showcases now the harmony you can build between AI and UI where the Assistant is actually

338
00:36:23,440 --> 00:36:30,160
taking action. But next, let's talk about retrieval. And retrieval is about giving our Assistant more

339
00:36:30,160 --> 00:36:35,200
knowledge beyond these immediate user messages. In fact, I got inspired and I already booked my

340
00:36:35,200 --> 00:36:41,200
tickets to Paris. So I'm just going to drag and drop here this PDF. While it's uploading, I can

341
00:36:41,200 --> 00:36:48,560
just sneak peek at it. Very typical United Flight ticket. And behind the scene here, what's happening

342
00:36:48,560 --> 00:36:54,720
is that retrieval is reading these files and boom, the information about this PDF appeared on the

343
00:36:54,720 --> 00:37:03,520
screen. And this is, of course, a very tiny PDF, but Assistant can parse long-form documents from

344
00:37:03,520 --> 00:37:08,240
extensive text to intricate product specs, depending on what you're building. In fact, I also booked an

345
00:37:08,240 --> 00:37:13,600
Airbnb, so I'm just going to drag that over to the conversation as well. And by the way, we've heard

346
00:37:13,600 --> 00:37:18,560
from so many of you developers how hard that is to build yourself. You typically need to compute

347
00:37:18,560 --> 00:37:23,120
your embeddings. You need to set up chunking algorithm. Now, all of that is taken care of.

348
00:37:24,560 --> 00:37:29,760
And there's more than retrieval. With every API call, you usually need to resend the entire

349
00:37:29,760 --> 00:37:35,360
conversation history, which means setting up a key value store. That means handling the context

350
00:37:35,360 --> 00:37:40,640
windows, serializing messages and so forth. That complexity now completely goes away with this

351
00:37:40,640 --> 00:37:47,200
new stateful API. But just because a Ponyi is managing this API does not mean it's a black box.

352
00:37:47,200 --> 00:37:51,840
In fact, you can see the steps that the tools are taking right inside your developer dashboard.

353
00:37:51,840 --> 00:37:58,080
So here, if I go ahead and click on threads, this is the thread I believe we're currently

354
00:37:58,080 --> 00:38:03,200
working on. And see, like, these are all the steps, including the functions being called with the

355
00:38:03,200 --> 00:38:10,160
right parameters and the PDFs I've just uploaded. But let's move on to a new capability that many

356
00:38:10,160 --> 00:38:15,280
of you have been requesting for a while. Code interpreter is now available today in the API as

357
00:38:15,280 --> 00:38:22,000
well. That gives the AI the ability to write and execute code on the fly, but even generate files.

358
00:38:22,000 --> 00:38:30,720
So let's see that in action. If I say here, hey, will be four friends staying at DCRBNB,

359
00:38:30,960 --> 00:38:45,280
what's my share of it plus my flights? All right. Now here, what's happening is that code

360
00:38:45,280 --> 00:38:50,960
interpreter noticed that it should write some code to answer this query. So now it's computing,

361
00:38:50,960 --> 00:38:54,880
you know, the number of days in Paris, the number of friends, it's also doing some exchange rate

362
00:38:54,880 --> 00:39:00,240
calculation behind the scene to get this answer for us. Not the most complex math, but you get

363
00:39:00,240 --> 00:39:05,360
the picture. Imagine you're building a very complex like finance app that's crunching countless

364
00:39:05,360 --> 00:39:10,480
numbers, plotting charts, so really any task that you'd normally tackle with code, then code

365
00:39:10,480 --> 00:39:17,040
interpreter will work great for you. All right. I think my trip to Paris is sorted. So to recap

366
00:39:17,040 --> 00:39:21,840
here, we've just seen how you can quickly create an assistant that manages state for your user

367
00:39:21,840 --> 00:39:26,800
conversations, leverages external tools like knowledge and retrieval and code interpreter,

368
00:39:26,880 --> 00:39:30,080
and finally invokes your own functions to make things happen.

369
00:39:31,840 --> 00:39:36,640
But there's one more thing I wanted to show you to kind of really open up the possibilities

370
00:39:36,640 --> 00:39:40,800
using function calling combined with our new modalities that we're launching today.

371
00:39:41,600 --> 00:39:46,640
While working on Dev Day, I've built a small custom assistant that knows everything about

372
00:39:46,640 --> 00:39:51,280
this event. But instead of having a chat interface while running around all day today,

373
00:39:51,280 --> 00:39:57,200
I thought, why not use voice instead? So let's bring my phone up on screen here so you can see

374
00:39:57,200 --> 00:40:02,560
it on the right. Awesome. So on the right, you can see a very simple Swift app that takes microphone

375
00:40:02,560 --> 00:40:07,360
input. And on the left, I'm actually going to bring up my terminal log so you can see what's

376
00:40:07,360 --> 00:40:14,240
happening behind the scenes. So let's give it a shot. Hey there, I'm on the keynote stage right

377
00:40:14,240 --> 00:40:23,600
now. Can you greet our attendees here at Dev Day? Hey everyone, welcome to Dev Day.

378
00:40:23,600 --> 00:40:26,720
It's awesome to have you all here. Let's make it an incredible day.

379
00:40:32,800 --> 00:40:38,000
Isn't that impressive? You have six unique and rich voices to choose from in the API,

380
00:40:38,000 --> 00:40:42,080
each speaking multiple languages so you can really find the perfect fit for your app.

381
00:40:42,640 --> 00:40:46,400
And on my laptop here on the left, you can see the logs of what's happening behind the scenes too.

382
00:40:46,400 --> 00:40:51,920
So I'm using Whisper to convert the voice inputs into text, an assistant with GPT4 Turbo,

383
00:40:51,920 --> 00:40:57,760
and finally the new TTS API to make it speak. But thanks to function calling,

384
00:40:57,760 --> 00:41:02,240
things get even more interesting when the assistant can connect to the Internet

385
00:41:02,240 --> 00:41:07,840
and take real actions for users. So let's do something even more exciting here together.

386
00:41:07,920 --> 00:41:15,280
How about this? Hey assistant, can you randomly select five Dev Day attendees here

387
00:41:15,280 --> 00:41:22,640
and give them $500 in OpenAI credits? Yes, checking the list of attendees.

388
00:41:27,280 --> 00:41:32,320
Done, I picked five Dev Day attendees and added $500 of API credits to their account.

389
00:41:32,400 --> 00:41:37,120
Congrats to Christine M, Jonathan C, Steven G, Louise K, and Suraj S.

390
00:41:38,160 --> 00:41:41,200
All right, if you recognize yourself, awesome, congrats.

391
00:41:43,360 --> 00:41:46,880
And that's it, a quick overview today of the new Assistant API

392
00:41:46,880 --> 00:41:49,680
combined with some of the new tools and modalities that we launched.

393
00:41:50,480 --> 00:41:55,520
All starting with the simplicity of a rich text or voice conversation for you and users.

394
00:41:56,080 --> 00:41:59,360
We really can't wait to see what you build and congrats to our lucky winners.

395
00:42:00,080 --> 00:42:04,880
Actually, you know what? You're all part of this amazing OpenAI community here,

396
00:42:04,880 --> 00:42:08,320
so I'm just going to talk to my assistant one last time before I step off the stage.

397
00:42:10,560 --> 00:42:16,000
Hey assistant, can you actually give everyone here in the audience $500 in OpenAI credits?

398
00:42:17,840 --> 00:42:19,760
Sounds great. Let me go through everyone.

399
00:42:20,480 --> 00:42:32,000
All right, that function will keep running, but I've run out of time,

400
00:42:32,000 --> 00:42:34,960
so thank you so much, everyone. Have a great day. Back to you, Sam.

401
00:42:44,400 --> 00:42:45,120
Pretty cool, huh?

402
00:42:45,600 --> 00:42:54,400
All right, so that Assistant API goes into beta today, and we are super excited to see what

403
00:42:54,400 --> 00:43:02,000
you all do with it. Anybody can enable it. Over time, GPTs and assistants, our precursors to agents,

404
00:43:02,800 --> 00:43:06,800
are going to be able to do much, much more. They'll gradually be able to plan

405
00:43:07,360 --> 00:43:12,560
and to perform more complex actions on your behalf. As I mentioned before,

406
00:43:12,560 --> 00:43:15,920
we really believe in the importance of gradual iterative deployment.

407
00:43:16,720 --> 00:43:20,800
We believe it's important for people to start building with and using these agents now

408
00:43:20,800 --> 00:43:24,400
to get a feel for what the world is going to be like as they become more capable,

409
00:43:25,360 --> 00:43:29,840
and as we've always done, we'll continue to update our systems based off of your feedback.

410
00:43:31,120 --> 00:43:34,560
So we're super excited that we got to share all of this with you today.

411
00:43:35,840 --> 00:43:40,960
We introduced GPTs, custom versions of chat GPT that combine instructions,

412
00:43:41,600 --> 00:43:46,960
extended knowledge, and actions. We launched the Assistance API to make it easier to build

413
00:43:46,960 --> 00:43:52,800
assisted experiences with your own apps. These are our first steps towards AI agents,

414
00:43:52,800 --> 00:43:59,200
and we'll be increasing their capabilities over time. We introduced a new GPT-4 turbo model that

415
00:43:59,200 --> 00:44:04,240
delivers improved function calling, knowledge, lowered pricing, new modalities, and more,

416
00:44:05,040 --> 00:44:06,960
and we're deepening our partnership with Microsoft.

417
00:44:07,920 --> 00:44:14,480
In closing, I wanted to take a minute to thank the team that creates all of this. Open AI has

418
00:44:14,480 --> 00:44:20,080
gotten remarkable talent density, but still, it takes a huge amount of hard work and coordination

419
00:44:20,080 --> 00:44:23,760
to make all of this happen. I truly believe that I've got the best colleagues in the world.

420
00:44:23,760 --> 00:44:29,680
I feel incredibly grateful to get to work with them. We do all of this because we believe the AI

421
00:44:29,680 --> 00:44:34,560
is going to be a technological and societal revolution. It will change the world in many ways,

422
00:44:35,280 --> 00:44:39,600
and we're happy to get to work on something that will empower all of you to build so much for all

423
00:44:39,600 --> 00:44:45,680
of us. We talked about earlier how if you give people better tools, they can change the world.

424
00:44:46,800 --> 00:44:50,640
We believe that AI will be about individual empowerment and agency at a scale that we've

425
00:44:50,640 --> 00:44:55,120
never seen before, and that will elevate humanity to a scale that we've never seen before either.

426
00:44:55,920 --> 00:45:01,680
We'll be able to do more to create more and to have more. As intelligence gets integrated

427
00:45:01,680 --> 00:45:07,200
everywhere, we will all have superpowers on demand. We're excited to see what you all will do with

428
00:45:07,200 --> 00:45:11,360
this technology and to discover the new future that we're all going to architect together.

429
00:45:12,880 --> 00:45:17,200
We hope that you'll come back next year. What we launched today is going to look very quaint

430
00:45:17,200 --> 00:45:21,040
relative to what we're busy creating for you now. Thank you for all that you do.

431
00:45:21,040 --> 00:45:35,600
Thanks for coming here today.

