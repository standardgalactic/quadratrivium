{"text": " Welcome, everyone. I want to start just saying thanks, everyone, for coming. This is kind of crazy. I'm Evan. I made Elm. It's very exciting to be here. So I want to say thanks one, thanks for folks for coming, thanks to Thibaut and Guillaume for setting things up, and then thanks to everyone who is helping get the technology set up, and then this thank you is like outer proportion. So thank you to who had the L have this tail. I really appreciate that. But yeah, so thanks, everyone, for coming. And I want to emphasize sort of a question that has sort of guided Elm for the last couple of years, which is how do I grow Elm code? And so this is a question that somehow always sounds topical. So who remembers Elm before the Elm architecture? Before the Elm architecture? Okay, there are people out there. Okay. So there was a time when that didn't exist and people would say how do I write a program? And so we sort of observed, okay, maybe we can call this thing there's a model, there's an update of you. We saw that pattern, and they were like, okay, that's cool. How do I grow an Elm program? Okay. So we had some more examples. And showed it, okay, you can reuse functions in this kind of way to help make a view. And people were like, okay, cool. But how do you grow an Elm program? So I want to take the next step in perhaps a never ending journey. And we're going to do that by tracing the life of a file. So we'll see it start small and gradually grow, and then grow a bit more, and then eventually break off into two. And I think as we go through this path, it won't necessarily be surprising or difficult. But I think it's hard to see if you're coming from JavaScript. So before we get started with the life of a file, I want to start with some JavaScript folk knowledge that may be leading people astray. So one thing that I see a lot is this idea that shorter files are better. So an extreme example of this is when I was doing the benchmark comparison between React and a bunch of other frameworks in Elm, the Ember one just had so many files, I just didn't get it. This is a greater than file. And it just felt like this surely isn't the easiest way. So when I see this thought process, it sort of feels bizarre to me. And so the way I can understand it is the context is as the lines of code increases, the probability of sneaky mutation approaches one. It's going to happen if you're writing JavaScript code. So if you have a thousand lines of code, there's going to be some object that accidentally gets shared, and two people are going to be mutating it. It's just going to happen. So therefore, for shorter files, it fills this very useful function. Another thing that people just know in JavaScript is you have to get the architecture right from the beginning or you're doomed. It's just not going to work out for your project. This you barely need a justification because obviously I'm sure many of us have seen this play out in companies we either work for or people we know. And the justification behind it is refactoring is very risky. Sometimes it's cheaper to just rewrite the code. And I think that accounts for some of the churn in JavaScript frameworks. People like, well, this didn't work. I could try to fix it, but it'd be just as easy to try a different thing that maybe doesn't suck. So we have these sort of intuitions and habits that are grown out of the actual constraints of JavaScript and the languages we use. But in Elm, the probability of sneaking mutation is zero. If you have a thousand lines or 10,000 lines, it's just like not possible that a value gets shared and suddenly there's spooky action at a distance between these two chunks of code. So this whole premise is gone. And so I don't see how we can draw the same conclusion anymore. Similarly, refactoring is cheap and reliable. Like you have types to help you out. The compiler is going to guide you through the process. So you can end up changing 10 or 20 files and be pretty confident to end that things are fine. So again, this premise is gone. And so this idea that the architecture has to be right from the start doesn't really play out in practice. So the big thing to note here is that the way Elma's design changes how you should grow a code base. And we have a lot of habits that come from, like we don't even necessarily all know the justification of these things, but we know like, oh, that file seems too long. That's probably, like we have these senses that guide how we write code. So the rest of the talk is sort of challenging these and providing a new way of seeing code that can help grow a program. Okay. So the life of a file. We might start out with a nice little file. Let's say I, and the blue is like the model, let's say the data structure and then there's some logic. And maybe this is, I have a personal like reading list and I want to just keep track of the books that I'm interested in. And maybe I have 200 lines of code. I'm not crazy. And so I add some features. I want to be able to mark the books as read or not. And maybe I want to reorder them depending on if one starts to seem more exciting. And so now I have about 400 lines. And I think a lot of folks at this point would be like, like something's wrong. There's a problem. That's generally not, that's not how I would approach programming in Elm. It's not how things work in Standard and Mellor or Camel or Haskell. It's just like having a file this long is pretty standard. So if I go through the compiler, like that's, I'd say the average. And so maybe add some more features. I can add annotations to each book of quotes that I really like. Things I want to remember. So now I have like 600 lines of code. And it's like, okay, now it's surely it's a problem. Not really. I don't know. I think you shouldn't be too scared of a file growing long. So this is something that will typically happen. Now, at this point, it's likely that I'll say, you know what, I think it'd be good to have the data structure for like my library where I can reorder books and a data structure for books. Where is it read or not? What are my notes? And then I can start to organize my code around those two data structures. So I can say, okay, mark this book as red, add this note. And so the functions in my code start to organize around those data structures. So, hey, we discovered this better data structure. So the next step that may happen is we split around the data structure, right? So once we discover that there's this other like chunk that we can grab onto, that can become the heart of a nice module. And so this is the typical process that I always follow. It's just basically grow until I find a data structure that I can split on. And if I don't find it, it's fine. So I'd encourage folks to sort of play with this in your own code. And sort of if you're feeling uncomfortable, like, oh, this seems like I have too much code here, just like push into that feeling and like see if it actually is warranted. Like, is there actually a problem? Or is it just like a feeling that you have based on experiences in other languages? So, okay. So at this point, this is basically just like an unsubstantiated claim. Let's see some more concrete examples, right? Ones where the code is more elaborate than lines. So, okay. So I want to look at two examples. One is the sort of settings. So you can imagine this is like the settings you'd have in a Facebook or Twitter or Pinterest or whatever. Like, do you get email notifications? Do you want video audio play? Do you want to use location? These kinds of things. And you could just say no, but they want to give you the option to say no. The other situation is checkbox is a bunch of fruits. Maybe I'm going to, you're going to get lunch and you are able to pick out which fruits you want, then you can have that one. So before we dig into this, I want to sort of take a second to and ask people, like, what are the questions and concerns when you see these two that pop into your mind? Like, when you think about how the code is probably going to look, what pops into your mind? Okay. Yeah. Someone said, oh, oh. Okay. Okay. Okay. We're good. We're good. Someone said generic checkbox list. So yeah, this idea of like, how do we share? Like, clearly we have checkboxes here. Like, sharing needs to happen. Okay. This, I'm going to proceed by showing how I would address these and then we'll see if that intuition plays out. So when I look at the settings, the first question I ask is, how do I model this information? Right? So do I use a record where I say there's email, there's video, there's location? Do I use a list of pairs where the string would be email and notifications true? Autoplay false? A location false? Do I choose a dictionary? Which would work similarly? But now it's unique on these things. Or do I do this other one that's, I have a list of strings. These are all options. So email, autoplay location, and then a set of which ones are selected. So this would just be email. And we can think of more. It's a good idea to get in the habit of just thinking, what are all the possible ways I can represent this? So at this point, you want to say, okay, well, which one should I do? So one trade-off here is this one gives us the benefit of types, right? So if we're messing around in our code and someone misspells email or misspells one of these things, the compiler is going to give us some help. So that's nice. And these other ones are stringly typed. So if there's some misspelling, it's sorry. Like, things are going to go weird. Another thing to think about is the order in this one is just determined by the view. So in my model, in my record, I can update however I want. It can appear however I want it to appear in my code. But ultimately in the view, I'm going to say, show the email, show the notification, show this. And if our designer says, okay, we actually want to move, use location above because everyone wants to turn that off and no one can find it, we get a lot of support tickets and they're really mad at us. So I get that. Just change it. And then it becomes very easy in this world. With this one, the order is stable, but you can actually change it in the update. So in the same time we're upping a bool from true to false, we could just swap, reverse the list. And so suddenly the UI is totally different based on stuff that's happening in the update code. So someone writing update code has to think about what was it that that designer said a while ago about support tickets. This one, order is dependent on the keys. It's just like not a good idea. And this one, the order is stable again. So it seems like we've got a pretty clear winner in this case. So let's run with this. So here's the initial version of it. We can check stuff. And we can, this is kind of small. But we can see people messing with the record. Oops. Okay. So when we look at the code, can people see this okay? Okay. The model is what we talked about. We have the record with our boolean fields. And the defaults, you know, everything needs to be true, right? We need autoplay to get that ad money. We need location on so that it can be location-specific advertising. Okay. I notice you're in the neighborhood of, and we need the email so that they can notify you to log in and see the autoplay has. And then in our update, things are relatively straightforward. We have a way to toggle each of these things. And if I mess up and say I want the model's email, it's like, hey, I think you have a typo. So we're getting that benefit that we wanted. And finally, we have a view. So we have a field set. There's labels. And each one contains a checkbox that we say, okay, here's the email notifications one. Is it checked? Here's the autoplay. Is it checked? Et cetera. Now, one of the things that you can do is say, okay, these actually are pretty much exactly the same. So we can factor out some of this code. So I can say view checkbox. I don't know if it makes sense to start with the type, but I practiced this so I know what it is. But we can essentially chop out this code, which appears a bunch of times, and fill in the blanks. So checked is checked. Message, description, and then where did my mouse go? Okay, there it is. And then we can say let's just replace all of these with the checkbox. Okay, so is it code shorter? Not really. But if we are applying styles to all of these in the same way, now it's a lot easier. We can do it in one place and be sure that it happens everywhere. So this is a nice refactor given the current state of affairs. So let's see if I did it right. Yeah, okay, cool. So we come back, we have this going. It's nice. And so we get a new feature, which is autoplay customizations. So instead of just autoplay, we want people to be able to use should it play audio by default? And should it play on Wi-Fi only or will people allow it on cellular data as well? So when we go back, the thing to look at is our model again. So one way to deal with this is, well, okay, we have two new things. So we have autoplay audio and autoplay Wi-Fi. I'm going to call it without Wi-Fi. I don't know because it helps me understand what the bull would be. And then we can go mess with our view. But this is kind of lame because we can do it that way and a designer will say, well, I want it to be where if there's no video autoplay, then you can't mess with the autoplay settings. Like you're not doing that. So those should be disabled. So suddenly we have this interaction between these three fields where we always have to check autoplay before we show this and that determines whether it's disabled. So we're starting to get these dependencies. So a better way to represent this would be to just actually model it directly. So autoplay is offer on. And if it's on, there's audio or without Wi-Fi. So in this version of reality, you can't mess with any of these options without pattern matching on or off. So if you want to change them, you have to say, okay, let me expand the autoplay. If it's off, oh, I don't need to deal with it. And that also means in your view, you handle these two scenarios and you say, okay, is autoplay on? In which case, I can show these things. If it's off, then I don't. So it's sort of forcing any future user of this code base to understand that there's a dependency between these fields. Now we say, okay, we'll show this to the designer again. But the thing is, if we turn things off, we lose all of our options. So we want those to be preserved. Some users will toggle this a lot and it's annoying. So what we can do is say, okay, type alias autoplay settings. And then we can actually just have it on both, but still force people to go through the on off check before you're doing any logic. So and then this will play out throughout the course of the code. We can a way to approach this was, well, now we have this autoplay idea. Maybe we can start to write some helper functions to make it nice to work with. So maybe we can say toggle autoplay and it switches between on and off in a nice way. And so as we create these helper functions, we start to have functions that are all built around the data structure, which is that pattern I was talking about. So once you start to see these kinds of chunks of code, you get these units that can break out and make your code nicer. Okay. So we have that going. So now we come to fruits. And at this point, the question asked yourself is like, do you think it's going to work out the same way? So yeah, so let's take a look. So again, we can choose between different data structures and I picked the same ones. So record, list of things, dictionary, the list of options and which ones are selected. So in this case, our constraints are very different. So we work at like fruits.com, I don't know. And the fruit availability, it's seasonal. We want to bring you the freshest seasonal fruits for your region. And like maybe we're out of bananas today. So we don't want to just let people say, oh, I definitely only want bananas. I'm sorry. Here's a mango. So if we use a record, does that mean we would have to ship code every time availability changed in a particular region? So that doesn't seem great. But in all these others, we can just load the options from the server. That seems like a benefit. From there, one thing we might consider is, well, which of these will be easier to just use? Which one will the code come out nicer? So in this case, we'll probably use list.map to do an update. We can scan through and say, if it's this fruit, then I'll toggle it or not. With dictionary, you can use update and say, okay, I want to change this particular fruit. And with this one, we can use set, insert and remove. So we don't have to ever mess with this. We can just say, okay, they want to add this to their set of their selected set, and they want to remove that one. And again, we have the ordering problems from before where maybe our head of fruit marketing is like, we need to put bananas up at the top because that's higher margin, and that's what we're all about here at fruits.com. Or maybe someone else is like, well, we really should put mangoes up at the top, think about the nutritional content, think about the bottom line. So there might be some need to change this around. Perhaps dynamically. So again, dictionary isn't ideal for that kind of scenario. So let's go with this one where it'll be kind of nice to add and remove things to the selection, and we can mess with the order quite easily. Okay, so now we can go look at our fruit situation. Which, and then we can just select, it's great. And if we look at how this goes, we have our fruit list, which is very stable, and then selected, which is changing as we mess with stuff. Okay, so let's check out how this code works. Fruits. Okay, so in our model we say we have two things, the fruits that are available, and the ones that are selected. And for our initial model, we're just pre-populating with some fruits, but you could load this from the server. And our selected set is none are selected. And then update logic, appreciate forward. If a fruit is selected, add it to the selected set. If it's deselected, remove it from the selected set. And then is this going to fit? Okay, cool. So in our view code, we again have a field set. Okay, you can see the mouse here. We have our field set, and then we're mapping over all the fruits. And so when we do that, we say, okay, I have a fruit. Is it in the selected fruit set? If so, it's checked. And then we draw things in a way that looks quite similar to what we saw in the previous example. So it's checkbox, whether it's checked or not, what the title is. But the thing that's actually interesting about this code isn't the shared part. The part that they have in common is, like, whatever, seven lines. It's not very crazy. And the chances that they're going to stay exactly the same between these two different chunks of code is very low. So thinking, like, focusing on just this, like, oh, I've seen a checkbox before somewhere. Like, doesn't really give you a lot in terms of the structure of your program. So at this point, we have a pretty good fruit set going on, fruit.com, business is booming, margins are good. Okay, but a new feature comes along, which is only two fruits can be selected. We have all these folks out there who want, like, three fruits, six fruits even. We don't have the distribution channels for that. So we want to cap out at two fruits per person, you know, pick a favorite, like, pick a side. So this is kind of a tricky situation we have found ourselves in. So we have this set, and we kind of need to limit the size somehow. Oh, oh, there's one other constraint, which is we need to check out a different fruit. No. Fruit's one, maybe. No. Okay, I deleted a file that I should not have deleted. But the thing that I wanted to show was we want to maintain the order that they were selected. So if I select apple, then apricot, then banana, I want the oldest thing to be the one that's forgotten. So I want to keep the most recently selected as I go through things. So with a set, it's really hard to keep track of what was the order that things were added. We can remove one of the things, but we don't know which of the two it was. You'll get this very wonky behavior. So at this point, we can ask, well, maybe it'd be good to think about the data structure we're using. So we want to choose two fruits in particular. So maybe we say, okay, so I'm going to choose a string and a string. But what happens when nothing's selected? We need to account for zero selections, one selection, two selections. So that's no good. Maybe we can say maybe string. So all of these can be optionally selected. But there's this weird case where if one thing is selected, we don't know if it's going to be the left or the right thing. So this doesn't seem great either. So maybe we can say, okay, there should be this type two, and it's either zero or one or two. Okay, that's pretty nice. You can imagine inserting into zero, you go to one, inserting into two, and then in two, you maintain some order moving things along. And that design seems okay, but we know head of fruits marketing. He's going to say, okay, well, in tropical areas, we can actually give them more fruits, so they're going to want a limit of three. But in Iceland, they only get half cucumbers there. That's just the rule. I don't know. That is actually how it works. So we're probably not going to be able to just stick with two. There may be some places where we need three or different limits. So another way we could do this is just a list of string and then limit the size. So essentially add to the front and take things, drop things off the back. So I don't know. It doesn't seem perfect. Clearly, you can just add 20 things to it. But it sort of has potential. So let's explore that route. So instead of this being empty, this is an empty list. Oops. The cursor just disappears. Anyway, so when we select something, we want to say list.take2 fruit on the front of our selected list. So this is saying, put the fruit on the front and then just take the front two. So whatever else is there, we'll drop it. And then when we deselect, we can say list.filter. The fruit should not, any fruit, that's not the one we, that's a lot of nots in one sentence. We want to only keep fruits. You get it. We want that fruit to be deselected. And then in our checkbox code, we want to say and said list.member. And I think that's everything except we don't need that anymore. Okay. So let's see if I did this right. Hey. And so you can see it's maintaining the order that I clicked things. So if I, I don't know, it's kind of hard to remember. It's easy if you go in order and you can see. It's working nicely. Okay. So we're maintaining our two fruits per person situation. But when we come look back at our update code, it's getting, it feels like trickier, right? And as we grow fruits.com, like maybe someone won't realize the take two is not, oh, just some fine choice. It's like, head of fruits marketing decided that was two and you can't change that stuff. So we want to have some more security around this code. So one way we can do that is to start to break out the particular stuff around that data structure. So we, we know there's this selection list. We can make a function that is along these lines. So let's do it in the update part. Insert, oops, insert fruit list. I'm going to leave off types for now just for speed. And then I can say here, insert fruit. And then I can also say remove fruit from the list. And we'll do it the same way. So this code gets a bunch simpler as well. Remove fruit. And we can do the same thing with the checking for membership below. Now at this point it's sort of coalescing into, oh, there's this kind of data structure that's specifically about maintaining just two things in, in the list. So I'm going to check for time to see how much live coding I should do. Okay. Well, let's, let's start to follow this idea of like, we're starting to recognize a data structure. So let's try to break that out. So I can say fruit list. And I have this type alias fruit, selected fruit. So we're starting to see the, the beginnings of a, of a module, like things that we can box off and put in their own place. So I'm going to just skip ahead to a version of this in a different module. So the ideas, we have this thing called a bounded set. And yeah, no, I shouldn't skip ahead to this. That was a bad idea. So let's say, okay, we have this and we were going to put it in a new module, the selected fruit module. Exposing a selected fruit. And then in our fruits module, we can get rid of that. And we can import as selected fruits. And then we just have to go through and make a couple changes here. Oh, we'll come back to that. Selected fruit, that insert, remove, et cetera. So this is also selected fruit. We're kind of leaking details here. Okay. Let's see it. Okay. Check. Does this work? No. Selected fruits. It's singular. There's also a stray print. Spelling. It's nice that, yeah. Oh, geez. What the heck? Okay. Just imagine there wasn't a compiler there. Or just like, maybe that's wrong. I don't know. Okay. So this is still working. But we can kind of improve things by sort of closing down this module. Right now, we're exposing everything. But we could do better by saying, okay, from the outside, no one knows how selected fruit is implemented. It happens to be a list of string, but no one needs to know. So we have to do a little bit of selected. I'm disenchanted with this naming choice. Okay. So now, from the outside, no one knows how the particulars of this are implemented. So let's just run it. This is supposed to not work. So we're using list.member on a selected fruit, but we don't actually know the implementation deals of that anymore. And our selected, we're saying it's a list, but we don't have access to that information anymore. So we need to add, how do I make an empty selected fruit? And that would be selected fruit is empty. And then we need to test for membership. And then we can just say list member fruit list. Oh, it's still broken because they didn't actually change the broken code. So here we say selected fruit is empty. And then member, we say selected fruit member. Cool. So now we've sort of hidden all these implementation details, but we can do slightly better. So maybe we want to make a guarantee about the size in this data structure. So we can say we'll actually give the maximum size when we say it's empty or not. And then in all these cases, max size. So instead of taking two, we take the max size. And instead of removing, no, we do keep this the same, but we just have to keep the max size around. And then here we don't care about the max size. We just want to check. So we should have an error because we're just calling empty without saying how big it should be. Two. All right. And then things should work again. Cool. So at this point, we sort of taken all this complexity around maintaining the only two things are selected and put it in its own module. So the benefits of this is that when I'm reading through my normal code, all I know is there's some way to select fruits. I can say how many. And then I can insert and remove. And these things will just work out nicely. And I can check if something is a member of that. So you can go one level crazier with this, which we shouldn't get into, but you can. So the idea was you could generalize it so that it's a list of anything, not of strings or particular fruits. And then everything works the same, right? You choose the size. You can insert things into it. You can remove things from it. You can check membership. So all of these designs are possible. And the question is, which one is right for your situation, right? Should you go like, all right, I'm writing my own data structure that's generic in all sorts of things. And I'm going to optimize it. Or is it like, look, it's just a list. It's not a big deal. We're probably not going to get it wrong. And so that depends on what's likely to happen. Maybe at fruits.com, you'd make one choice. But at the new fruit stand startup, I don't know, they want to make different choices. Okay. So the big lesson here is that we started with two things that look basically the same and ended up with entirely different ways of approaching them. That was all about the data structure, right? And it is true that they share checkboxes, but that's such a small fraction of the actual difficult things that are going to happen in your code that it makes sense to emphasize the data structure instead. So I want to put a little extra emphasis on the module, right? So I showed this bounded set idea and it had, there's a bounded set. If it's empty, you can insert things into it. You can remove things from it. You can check membership. Now, the most important part of this module is the exposing line. Okay. So I'm not exposing everything in this module. And specifically, I'm not exposing the implementation of bounded set. So no one from outside can mess with the maximum size. And as long as these functions work, things are going to work. So I want to point out two little benefits that come from this. So if you reduce the public API to your module, if the implementation is hidden and if the public API works, the code works everywhere, right? So if I try to break this code by messing with these functions and I can't do it, anyone else who uses this code won't be able to do it either. So this is actually really nice for testing because it means you can test the public API very extensively. And that doesn't mean you have to test every particular usage, right? Using this data structure somewhere doesn't mean I can introduce bugs into that data structure retroactively. If it works, it's going to work well. The other thing that's nice is you get it easier refactoring. So I can change how things are implemented without worrying what's going to happen outside. And this happens in a couple ways. One is say there's an insert help function that's doing some extra special stuff. I know that it's not exposed outside, so I can mess with that. Arguments, add arguments, change shuffle things around and be sure that this is not going to have any effect in any other modules. I'm not going to have to go hunt stuff down. That's also nice because it means I don't have to worry about if it's used in 10 different places across the code, did they need it to work in a very particular way in each of those cases? And I'm covering all those cases. I can just say, oh, it's not publicly exposed. If it works in this file, it works. So the other thing that you can do by creating modules in this way is maintain invariance. So in our case, that's only two fruits. But generally speaking, this means there are rules that cannot be enforced entirely through data structure design. So we had our two, which is zero, one or two, but that wouldn't let us decide how many we want. So we now have a data structure that can let us decide. And by hiding all the details, we can still maintain that rule in a safe way, even though we can't do it purely through data. And one cool thing about finding invariance like this is that they're excellent for fuzz tests. So I know that whatever I do with this, if I say my bounded set has two things, no matter how many times I call insert, it should just have two things. So by thinking in this way, you also set yourself up to write tests that are nice and are checking the kinds of things you're worried about. So I want to add some warnings to this advice. So first, if you find yourself writing get and set, right, so we hid the max size, but maybe someone's like, well, I want the max size. I won't do a bad thing with it. Okay, this is a bad sign. This is a bad sign when you have get and set. So the whole point of having a module was that we were able to hide implementation details and say, if you use this public API, it will work. And inside, you don't have to worry about that. We tested it. We know it's good. Setters, their whole point is to expose those details. So you've done all this work to put it in a module, and we went through that together. It was like, it took too long. And now you're going to give setters that just totally defeat that entire exercise. So just use a record if you have data where you want people to have access, rather than hiding the details, then exposing get and setters. It's like, these details aren't hidden. So don't do the work to hide them. So another way to say this is expose as little as possible, but no less. Some things do need to be publicly available. So this shouldn't just be like, hide everything. That's better. The other thing is don't overdo it. So I'd wait until I have a problem in practice, and then solve that problem. So the goal shouldn't be let's just write modules, because modules help with this kind of stuff. It should be, hey, I'm having trouble understanding this code. I came back to it after a month, and it seemed kind of confusing. Maybe I can find parts that I can make things nicer. So if you find yourself asking, how do I make the sidebar reusable? Okay, try to remember to ask yourself why. Are you going to have multiple sidebars? Maybe not. In which case, like, why would you do the work to do that? If you are going to have multiple ones, a thing to think is, are these cases the same, or are they similar? If we're just talking about the HTML is going to look similar, but how it works behind the scenes is fundamentally different in both cases. I think it's probably not a good idea to, like, try to get all into how do we share code between these two. Focus on the data structure instead. Another thing that might happen is as you're growing your record, you don't have any interesting types. You don't have that autoplay thing where these fields are dependent on that field. It's just a bunch of independent stuff. If they're all independent, there's no problem. If I just have fields that have no relationship to each other, and I change one, there's not a chance that there's some bug elsewhere. But if I do have that relationship, that's a potential to start finding a data structure and do better modeling. So I'd say, like, don't be afraid to just grow your record and try to find these connections and how things fit together, as opposed to preemptively, like, ah, I'm worried about this code, so I'm just going to change it. So, yeah, just as there's premature optimization, there's premature refactoring. It's a thing, it's fun, right? It's like you get to play code golf at work. I don't think employers should encourage that, but people like to do it. Okay, so to take a step back, we saw how a file tends to grow, right? And if we focus on the data structures, we end up with these nice categorizations where, like, when I'm searching through a code base even, I say, hey, where's that stuff that's related to books? It's probably in the module about books, right? As opposed to, well, there's this update subdirectory, and all the update code is there, and the book stuff is just like, it's related to books. So, yeah, so big lessons are focus on data structures and choose the best representation available. So, like, actually think through as many cases as you can, and the others build modules around types and try to expose as little as possible, but no less. So, yeah, so I hope this will be a nice next advice in the, how do I grow my Elm code? And one of my goals was to write this up. So, I actually started a book that is about functional programming in Elm, and the goal of this book was essentially to write this talk so that people could read it online and it would work out. It turns out it's very hard to write that whole live coding section. So, instead, what I ended up with is some nice stuff about recursion and graphs. It's fun. Hopefully, I'll be able to distill this down into another chapter that actually emphasizes these things in a way where you don't have to see the live talk. But, yeah, so that's the life of a file. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 8.44, "text": " Welcome, everyone. I want to start just saying thanks, everyone, for coming. This is kind", "tokens": [50364, 4027, 11, 1518, 13, 286, 528, 281, 722, 445, 1566, 3231, 11, 1518, 11, 337, 1348, 13, 639, 307, 733, 50786], "temperature": 0.0, "avg_logprob": -0.302932341893514, "compression_ratio": 1.714975845410628, "no_speech_prob": 0.2431933879852295}, {"id": 1, "seek": 0, "start": 8.44, "end": 18.080000000000002, "text": " of crazy. I'm Evan. I made Elm. It's very exciting to be here. So I want to say thanks", "tokens": [50786, 295, 3219, 13, 286, 478, 22613, 13, 286, 1027, 2699, 76, 13, 467, 311, 588, 4670, 281, 312, 510, 13, 407, 286, 528, 281, 584, 3231, 51268], "temperature": 0.0, "avg_logprob": -0.302932341893514, "compression_ratio": 1.714975845410628, "no_speech_prob": 0.2431933879852295}, {"id": 2, "seek": 0, "start": 18.080000000000002, "end": 23.080000000000002, "text": " one, thanks for folks for coming, thanks to Thibaut and Guillaume for setting things up,", "tokens": [51268, 472, 11, 3231, 337, 4024, 337, 1348, 11, 3231, 281, 334, 897, 1375, 293, 2694, 5291, 2540, 337, 3287, 721, 493, 11, 51518], "temperature": 0.0, "avg_logprob": -0.302932341893514, "compression_ratio": 1.714975845410628, "no_speech_prob": 0.2431933879852295}, {"id": 3, "seek": 0, "start": 23.080000000000002, "end": 29.28, "text": " and then thanks to everyone who is helping get the technology set up, and then this thank", "tokens": [51518, 293, 550, 3231, 281, 1518, 567, 307, 4315, 483, 264, 2899, 992, 493, 11, 293, 550, 341, 1309, 51828], "temperature": 0.0, "avg_logprob": -0.302932341893514, "compression_ratio": 1.714975845410628, "no_speech_prob": 0.2431933879852295}, {"id": 4, "seek": 2928, "start": 29.28, "end": 37.52, "text": " you is like outer proportion. So thank you to who had the L have this tail. I really", "tokens": [50364, 291, 307, 411, 10847, 16068, 13, 407, 1309, 291, 281, 567, 632, 264, 441, 362, 341, 6838, 13, 286, 534, 50776], "temperature": 0.0, "avg_logprob": -0.20577239990234375, "compression_ratio": 1.4262295081967213, "no_speech_prob": 0.003467558417469263}, {"id": 5, "seek": 2928, "start": 37.52, "end": 46.92, "text": " appreciate that. But yeah, so thanks, everyone, for coming. And I want to emphasize sort of", "tokens": [50776, 4449, 300, 13, 583, 1338, 11, 370, 3231, 11, 1518, 11, 337, 1348, 13, 400, 286, 528, 281, 16078, 1333, 295, 51246], "temperature": 0.0, "avg_logprob": -0.20577239990234375, "compression_ratio": 1.4262295081967213, "no_speech_prob": 0.003467558417469263}, {"id": 6, "seek": 2928, "start": 46.92, "end": 54.8, "text": " a question that has sort of guided Elm for the last couple of years, which is how do", "tokens": [51246, 257, 1168, 300, 575, 1333, 295, 19663, 2699, 76, 337, 264, 1036, 1916, 295, 924, 11, 597, 307, 577, 360, 51640], "temperature": 0.0, "avg_logprob": -0.20577239990234375, "compression_ratio": 1.4262295081967213, "no_speech_prob": 0.003467558417469263}, {"id": 7, "seek": 5480, "start": 54.8, "end": 60.64, "text": " I grow Elm code? And so this is a question that somehow always sounds topical. So who", "tokens": [50364, 286, 1852, 2699, 76, 3089, 30, 400, 370, 341, 307, 257, 1168, 300, 6063, 1009, 3263, 1192, 804, 13, 407, 567, 50656], "temperature": 0.0, "avg_logprob": -0.20791791190563794, "compression_ratio": 1.7653061224489797, "no_speech_prob": 0.029634272679686546}, {"id": 8, "seek": 5480, "start": 60.64, "end": 66.32, "text": " remembers Elm before the Elm architecture? Before the Elm architecture? Okay, there", "tokens": [50656, 26228, 2699, 76, 949, 264, 2699, 76, 9482, 30, 4546, 264, 2699, 76, 9482, 30, 1033, 11, 456, 50940], "temperature": 0.0, "avg_logprob": -0.20791791190563794, "compression_ratio": 1.7653061224489797, "no_speech_prob": 0.029634272679686546}, {"id": 9, "seek": 5480, "start": 66.32, "end": 70.16, "text": " are people out there. Okay. So there was a time when that didn't exist and people would", "tokens": [50940, 366, 561, 484, 456, 13, 1033, 13, 407, 456, 390, 257, 565, 562, 300, 994, 380, 2514, 293, 561, 576, 51132], "temperature": 0.0, "avg_logprob": -0.20791791190563794, "compression_ratio": 1.7653061224489797, "no_speech_prob": 0.029634272679686546}, {"id": 10, "seek": 5480, "start": 70.16, "end": 74.96, "text": " say how do I write a program? And so we sort of observed, okay, maybe we can call this", "tokens": [51132, 584, 577, 360, 286, 2464, 257, 1461, 30, 400, 370, 321, 1333, 295, 13095, 11, 1392, 11, 1310, 321, 393, 818, 341, 51372], "temperature": 0.0, "avg_logprob": -0.20791791190563794, "compression_ratio": 1.7653061224489797, "no_speech_prob": 0.029634272679686546}, {"id": 11, "seek": 5480, "start": 74.96, "end": 78.4, "text": " thing there's a model, there's an update of you. We saw that pattern, and they were like,", "tokens": [51372, 551, 456, 311, 257, 2316, 11, 456, 311, 364, 5623, 295, 291, 13, 492, 1866, 300, 5102, 11, 293, 436, 645, 411, 11, 51544], "temperature": 0.0, "avg_logprob": -0.20791791190563794, "compression_ratio": 1.7653061224489797, "no_speech_prob": 0.029634272679686546}, {"id": 12, "seek": 5480, "start": 78.4, "end": 84.28, "text": " okay, that's cool. How do I grow an Elm program? Okay. So we had some more examples.", "tokens": [51544, 1392, 11, 300, 311, 1627, 13, 1012, 360, 286, 1852, 364, 2699, 76, 1461, 30, 1033, 13, 407, 321, 632, 512, 544, 5110, 13, 51838], "temperature": 0.0, "avg_logprob": -0.20791791190563794, "compression_ratio": 1.7653061224489797, "no_speech_prob": 0.029634272679686546}, {"id": 13, "seek": 8428, "start": 84.68, "end": 90.8, "text": " And showed it, okay, you can reuse functions in this kind of way to help make a view. And", "tokens": [50384, 400, 4712, 309, 11, 1392, 11, 291, 393, 26225, 6828, 294, 341, 733, 295, 636, 281, 854, 652, 257, 1910, 13, 400, 50690], "temperature": 0.0, "avg_logprob": -0.15048688771773358, "compression_ratio": 1.51931330472103, "no_speech_prob": 0.0010954049648717046}, {"id": 14, "seek": 8428, "start": 90.8, "end": 95.24000000000001, "text": " people were like, okay, cool. But how do you grow an Elm program? So I want to take the", "tokens": [50690, 561, 645, 411, 11, 1392, 11, 1627, 13, 583, 577, 360, 291, 1852, 364, 2699, 76, 1461, 30, 407, 286, 528, 281, 747, 264, 50912], "temperature": 0.0, "avg_logprob": -0.15048688771773358, "compression_ratio": 1.51931330472103, "no_speech_prob": 0.0010954049648717046}, {"id": 15, "seek": 8428, "start": 95.24000000000001, "end": 102.72, "text": " next step in perhaps a never ending journey. And we're going to do that by tracing the", "tokens": [50912, 958, 1823, 294, 4317, 257, 1128, 8121, 4671, 13, 400, 321, 434, 516, 281, 360, 300, 538, 25262, 264, 51286], "temperature": 0.0, "avg_logprob": -0.15048688771773358, "compression_ratio": 1.51931330472103, "no_speech_prob": 0.0010954049648717046}, {"id": 16, "seek": 8428, "start": 102.72, "end": 109.92, "text": " life of a file. So we'll see it start small and gradually grow, and then grow a bit more,", "tokens": [51286, 993, 295, 257, 3991, 13, 407, 321, 603, 536, 309, 722, 1359, 293, 13145, 1852, 11, 293, 550, 1852, 257, 857, 544, 11, 51646], "temperature": 0.0, "avg_logprob": -0.15048688771773358, "compression_ratio": 1.51931330472103, "no_speech_prob": 0.0010954049648717046}, {"id": 17, "seek": 10992, "start": 109.96000000000001, "end": 116.28, "text": " and then eventually break off into two. And I think as we go through this path, it won't", "tokens": [50366, 293, 550, 4728, 1821, 766, 666, 732, 13, 400, 286, 519, 382, 321, 352, 807, 341, 3100, 11, 309, 1582, 380, 50682], "temperature": 0.0, "avg_logprob": -0.11396464636159498, "compression_ratio": 1.5535714285714286, "no_speech_prob": 0.0065801311284303665}, {"id": 18, "seek": 10992, "start": 116.28, "end": 121.92, "text": " necessarily be surprising or difficult. But I think it's hard to see if you're coming", "tokens": [50682, 4725, 312, 8830, 420, 2252, 13, 583, 286, 519, 309, 311, 1152, 281, 536, 498, 291, 434, 1348, 50964], "temperature": 0.0, "avg_logprob": -0.11396464636159498, "compression_ratio": 1.5535714285714286, "no_speech_prob": 0.0065801311284303665}, {"id": 19, "seek": 10992, "start": 121.92, "end": 127.24000000000001, "text": " from JavaScript. So before we get started with the life of a file, I want to start with", "tokens": [50964, 490, 15778, 13, 407, 949, 321, 483, 1409, 365, 264, 993, 295, 257, 3991, 11, 286, 528, 281, 722, 365, 51230], "temperature": 0.0, "avg_logprob": -0.11396464636159498, "compression_ratio": 1.5535714285714286, "no_speech_prob": 0.0065801311284303665}, {"id": 20, "seek": 10992, "start": 127.24000000000001, "end": 134.4, "text": " some JavaScript folk knowledge that may be leading people astray. So one thing that I", "tokens": [51230, 512, 15778, 15748, 3601, 300, 815, 312, 5775, 561, 5357, 3458, 13, 407, 472, 551, 300, 286, 51588], "temperature": 0.0, "avg_logprob": -0.11396464636159498, "compression_ratio": 1.5535714285714286, "no_speech_prob": 0.0065801311284303665}, {"id": 21, "seek": 13440, "start": 134.48000000000002, "end": 141.28, "text": " see a lot is this idea that shorter files are better. So an extreme example of this is when I", "tokens": [50368, 536, 257, 688, 307, 341, 1558, 300, 11639, 7098, 366, 1101, 13, 407, 364, 8084, 1365, 295, 341, 307, 562, 286, 50708], "temperature": 0.0, "avg_logprob": -0.15818722017349734, "compression_ratio": 1.5757575757575757, "no_speech_prob": 0.014470784924924374}, {"id": 22, "seek": 13440, "start": 141.28, "end": 148.96, "text": " was doing the benchmark comparison between React and a bunch of other frameworks in Elm,", "tokens": [50708, 390, 884, 264, 18927, 9660, 1296, 30644, 293, 257, 3840, 295, 661, 29834, 294, 2699, 76, 11, 51092], "temperature": 0.0, "avg_logprob": -0.15818722017349734, "compression_ratio": 1.5757575757575757, "no_speech_prob": 0.014470784924924374}, {"id": 23, "seek": 13440, "start": 149.84, "end": 155.20000000000002, "text": " the Ember one just had so many files, I just didn't get it. This is a greater than file.", "tokens": [51136, 264, 3968, 607, 472, 445, 632, 370, 867, 7098, 11, 286, 445, 994, 380, 483, 309, 13, 639, 307, 257, 5044, 813, 3991, 13, 51404], "temperature": 0.0, "avg_logprob": -0.15818722017349734, "compression_ratio": 1.5757575757575757, "no_speech_prob": 0.014470784924924374}, {"id": 24, "seek": 13440, "start": 156.08, "end": 163.36, "text": " And it just felt like this surely isn't the easiest way. So when I see this thought process,", "tokens": [51448, 400, 309, 445, 2762, 411, 341, 11468, 1943, 380, 264, 12889, 636, 13, 407, 562, 286, 536, 341, 1194, 1399, 11, 51812], "temperature": 0.0, "avg_logprob": -0.15818722017349734, "compression_ratio": 1.5757575757575757, "no_speech_prob": 0.014470784924924374}, {"id": 25, "seek": 16336, "start": 163.4, "end": 171.52, "text": " it sort of feels bizarre to me. And so the way I can understand it is the context is as the lines", "tokens": [50366, 309, 1333, 295, 3417, 18265, 281, 385, 13, 400, 370, 264, 636, 286, 393, 1223, 309, 307, 264, 4319, 307, 382, 264, 3876, 50772], "temperature": 0.0, "avg_logprob": -0.15215062080545627, "compression_ratio": 1.6753246753246753, "no_speech_prob": 0.00020943944400642067}, {"id": 26, "seek": 16336, "start": 171.52, "end": 177.12, "text": " of code increases, the probability of sneaky mutation approaches one. It's going to happen if", "tokens": [50772, 295, 3089, 8637, 11, 264, 8482, 295, 39518, 27960, 11587, 472, 13, 467, 311, 516, 281, 1051, 498, 51052], "temperature": 0.0, "avg_logprob": -0.15215062080545627, "compression_ratio": 1.6753246753246753, "no_speech_prob": 0.00020943944400642067}, {"id": 27, "seek": 16336, "start": 177.12, "end": 181.64000000000001, "text": " you're writing JavaScript code. So if you have a thousand lines of code, there's going to be some", "tokens": [51052, 291, 434, 3579, 15778, 3089, 13, 407, 498, 291, 362, 257, 4714, 3876, 295, 3089, 11, 456, 311, 516, 281, 312, 512, 51278], "temperature": 0.0, "avg_logprob": -0.15215062080545627, "compression_ratio": 1.6753246753246753, "no_speech_prob": 0.00020943944400642067}, {"id": 28, "seek": 16336, "start": 181.64000000000001, "end": 185.44000000000003, "text": " object that accidentally gets shared, and two people are going to be mutating it. It's just going", "tokens": [51278, 2657, 300, 15715, 2170, 5507, 11, 293, 732, 561, 366, 516, 281, 312, 5839, 990, 309, 13, 467, 311, 445, 516, 51468], "temperature": 0.0, "avg_logprob": -0.15215062080545627, "compression_ratio": 1.6753246753246753, "no_speech_prob": 0.00020943944400642067}, {"id": 29, "seek": 18544, "start": 185.44, "end": 195.76, "text": " to happen. So therefore, for shorter files, it fills this very useful function. Another thing that", "tokens": [50364, 281, 1051, 13, 407, 4412, 11, 337, 11639, 7098, 11, 309, 22498, 341, 588, 4420, 2445, 13, 3996, 551, 300, 50880], "temperature": 0.0, "avg_logprob": -0.16494326645068907, "compression_ratio": 1.568, "no_speech_prob": 0.012597278691828251}, {"id": 30, "seek": 18544, "start": 195.76, "end": 200.64, "text": " people just know in JavaScript is you have to get the architecture right from the beginning or", "tokens": [50880, 561, 445, 458, 294, 15778, 307, 291, 362, 281, 483, 264, 9482, 558, 490, 264, 2863, 420, 51124], "temperature": 0.0, "avg_logprob": -0.16494326645068907, "compression_ratio": 1.568, "no_speech_prob": 0.012597278691828251}, {"id": 31, "seek": 18544, "start": 200.64, "end": 207.2, "text": " you're doomed. It's just not going to work out for your project. This you barely need a justification", "tokens": [51124, 291, 434, 33847, 13, 467, 311, 445, 406, 516, 281, 589, 484, 337, 428, 1716, 13, 639, 291, 10268, 643, 257, 31591, 51452], "temperature": 0.0, "avg_logprob": -0.16494326645068907, "compression_ratio": 1.568, "no_speech_prob": 0.012597278691828251}, {"id": 32, "seek": 18544, "start": 207.2, "end": 213.92, "text": " because obviously I'm sure many of us have seen this play out in companies we either work for or", "tokens": [51452, 570, 2745, 286, 478, 988, 867, 295, 505, 362, 1612, 341, 862, 484, 294, 3431, 321, 2139, 589, 337, 420, 51788], "temperature": 0.0, "avg_logprob": -0.16494326645068907, "compression_ratio": 1.568, "no_speech_prob": 0.012597278691828251}, {"id": 33, "seek": 21392, "start": 213.92, "end": 222.56, "text": " people we know. And the justification behind it is refactoring is very risky. Sometimes it's cheaper", "tokens": [50364, 561, 321, 458, 13, 400, 264, 31591, 2261, 309, 307, 1895, 578, 3662, 307, 588, 21137, 13, 4803, 309, 311, 12284, 50796], "temperature": 0.0, "avg_logprob": -0.10573095144684781, "compression_ratio": 1.5528455284552845, "no_speech_prob": 0.0007541341474279761}, {"id": 34, "seek": 21392, "start": 222.56, "end": 227.76, "text": " to just rewrite the code. And I think that accounts for some of the churn in JavaScript", "tokens": [50796, 281, 445, 28132, 264, 3089, 13, 400, 286, 519, 300, 9402, 337, 512, 295, 264, 417, 925, 294, 15778, 51056], "temperature": 0.0, "avg_logprob": -0.10573095144684781, "compression_ratio": 1.5528455284552845, "no_speech_prob": 0.0007541341474279761}, {"id": 35, "seek": 21392, "start": 227.76, "end": 232.72, "text": " frameworks. People like, well, this didn't work. I could try to fix it, but it'd be just as easy", "tokens": [51056, 29834, 13, 3432, 411, 11, 731, 11, 341, 994, 380, 589, 13, 286, 727, 853, 281, 3191, 309, 11, 457, 309, 1116, 312, 445, 382, 1858, 51304], "temperature": 0.0, "avg_logprob": -0.10573095144684781, "compression_ratio": 1.5528455284552845, "no_speech_prob": 0.0007541341474279761}, {"id": 36, "seek": 21392, "start": 232.72, "end": 240.39999999999998, "text": " to try a different thing that maybe doesn't suck. So we have these sort of intuitions and habits", "tokens": [51304, 281, 853, 257, 819, 551, 300, 1310, 1177, 380, 9967, 13, 407, 321, 362, 613, 1333, 295, 16224, 626, 293, 14100, 51688], "temperature": 0.0, "avg_logprob": -0.10573095144684781, "compression_ratio": 1.5528455284552845, "no_speech_prob": 0.0007541341474279761}, {"id": 37, "seek": 24040, "start": 240.4, "end": 246.8, "text": " that are grown out of the actual constraints of JavaScript and the languages we use. But in Elm,", "tokens": [50364, 300, 366, 7709, 484, 295, 264, 3539, 18491, 295, 15778, 293, 264, 8650, 321, 764, 13, 583, 294, 2699, 76, 11, 50684], "temperature": 0.0, "avg_logprob": -0.12947608612395906, "compression_ratio": 1.496, "no_speech_prob": 0.0013627867447212338}, {"id": 38, "seek": 24040, "start": 247.6, "end": 251.84, "text": " the probability of sneaking mutation is zero. If you have a thousand lines or 10,000 lines,", "tokens": [50724, 264, 8482, 295, 48525, 27960, 307, 4018, 13, 759, 291, 362, 257, 4714, 3876, 420, 1266, 11, 1360, 3876, 11, 50936], "temperature": 0.0, "avg_logprob": -0.12947608612395906, "compression_ratio": 1.496, "no_speech_prob": 0.0013627867447212338}, {"id": 39, "seek": 24040, "start": 251.84, "end": 257.04, "text": " it's just like not possible that a value gets shared and suddenly there's spooky action at", "tokens": [50936, 309, 311, 445, 411, 406, 1944, 300, 257, 2158, 2170, 5507, 293, 5800, 456, 311, 30510, 3069, 412, 51196], "temperature": 0.0, "avg_logprob": -0.12947608612395906, "compression_ratio": 1.496, "no_speech_prob": 0.0013627867447212338}, {"id": 40, "seek": 24040, "start": 257.04, "end": 263.76, "text": " a distance between these two chunks of code. So this whole premise is gone. And so I don't see", "tokens": [51196, 257, 4560, 1296, 613, 732, 24004, 295, 3089, 13, 407, 341, 1379, 22045, 307, 2780, 13, 400, 370, 286, 500, 380, 536, 51532], "temperature": 0.0, "avg_logprob": -0.12947608612395906, "compression_ratio": 1.496, "no_speech_prob": 0.0013627867447212338}, {"id": 41, "seek": 26376, "start": 263.76, "end": 270.88, "text": " how we can draw the same conclusion anymore. Similarly, refactoring is cheap and reliable.", "tokens": [50364, 577, 321, 393, 2642, 264, 912, 10063, 3602, 13, 13157, 11, 1895, 578, 3662, 307, 7084, 293, 12924, 13, 50720], "temperature": 0.0, "avg_logprob": -0.09259733262952867, "compression_ratio": 1.6051502145922747, "no_speech_prob": 0.004747246392071247}, {"id": 42, "seek": 26376, "start": 270.88, "end": 275.28, "text": " Like you have types to help you out. The compiler is going to guide you through the process. So", "tokens": [50720, 1743, 291, 362, 3467, 281, 854, 291, 484, 13, 440, 31958, 307, 516, 281, 5934, 291, 807, 264, 1399, 13, 407, 50940], "temperature": 0.0, "avg_logprob": -0.09259733262952867, "compression_ratio": 1.6051502145922747, "no_speech_prob": 0.004747246392071247}, {"id": 43, "seek": 26376, "start": 276.08, "end": 281.03999999999996, "text": " you can end up changing 10 or 20 files and be pretty confident to end that things are fine.", "tokens": [50980, 291, 393, 917, 493, 4473, 1266, 420, 945, 7098, 293, 312, 1238, 6679, 281, 917, 300, 721, 366, 2489, 13, 51228], "temperature": 0.0, "avg_logprob": -0.09259733262952867, "compression_ratio": 1.6051502145922747, "no_speech_prob": 0.004747246392071247}, {"id": 44, "seek": 26376, "start": 281.68, "end": 286.96, "text": " So again, this premise is gone. And so this idea that the architecture has to be right from the", "tokens": [51260, 407, 797, 11, 341, 22045, 307, 2780, 13, 400, 370, 341, 1558, 300, 264, 9482, 575, 281, 312, 558, 490, 264, 51524], "temperature": 0.0, "avg_logprob": -0.09259733262952867, "compression_ratio": 1.6051502145922747, "no_speech_prob": 0.004747246392071247}, {"id": 45, "seek": 28696, "start": 286.96, "end": 296.71999999999997, "text": " start doesn't really play out in practice. So the big thing to note here is that the way Elma's", "tokens": [50364, 722, 1177, 380, 534, 862, 484, 294, 3124, 13, 407, 264, 955, 551, 281, 3637, 510, 307, 300, 264, 636, 2699, 1696, 311, 50852], "temperature": 0.0, "avg_logprob": -0.1291585312676184, "compression_ratio": 1.5761316872427984, "no_speech_prob": 0.0021131597459316254}, {"id": 46, "seek": 28696, "start": 296.71999999999997, "end": 301.84, "text": " design changes how you should grow a code base. And we have a lot of habits that come from,", "tokens": [50852, 1715, 2962, 577, 291, 820, 1852, 257, 3089, 3096, 13, 400, 321, 362, 257, 688, 295, 14100, 300, 808, 490, 11, 51108], "temperature": 0.0, "avg_logprob": -0.1291585312676184, "compression_ratio": 1.5761316872427984, "no_speech_prob": 0.0021131597459316254}, {"id": 47, "seek": 28696, "start": 301.84, "end": 305.59999999999997, "text": " like we don't even necessarily all know the justification of these things, but we know like,", "tokens": [51108, 411, 321, 500, 380, 754, 4725, 439, 458, 264, 31591, 295, 613, 721, 11, 457, 321, 458, 411, 11, 51296], "temperature": 0.0, "avg_logprob": -0.1291585312676184, "compression_ratio": 1.5761316872427984, "no_speech_prob": 0.0021131597459316254}, {"id": 48, "seek": 28696, "start": 305.59999999999997, "end": 311.2, "text": " oh, that file seems too long. That's probably, like we have these senses that guide how we write code.", "tokens": [51296, 1954, 11, 300, 3991, 2544, 886, 938, 13, 663, 311, 1391, 11, 411, 321, 362, 613, 17057, 300, 5934, 577, 321, 2464, 3089, 13, 51576], "temperature": 0.0, "avg_logprob": -0.1291585312676184, "compression_ratio": 1.5761316872427984, "no_speech_prob": 0.0021131597459316254}, {"id": 49, "seek": 31120, "start": 312.15999999999997, "end": 316.88, "text": " So the rest of the talk is sort of challenging these and providing a new way of seeing code", "tokens": [50412, 407, 264, 1472, 295, 264, 751, 307, 1333, 295, 7595, 613, 293, 6530, 257, 777, 636, 295, 2577, 3089, 50648], "temperature": 0.0, "avg_logprob": -0.11156644821166992, "compression_ratio": 1.598326359832636, "no_speech_prob": 0.0027521816082298756}, {"id": 50, "seek": 31120, "start": 317.44, "end": 326.24, "text": " that can help grow a program. Okay. So the life of a file. We might start out with a nice little", "tokens": [50676, 300, 393, 854, 1852, 257, 1461, 13, 1033, 13, 407, 264, 993, 295, 257, 3991, 13, 492, 1062, 722, 484, 365, 257, 1481, 707, 51116], "temperature": 0.0, "avg_logprob": -0.11156644821166992, "compression_ratio": 1.598326359832636, "no_speech_prob": 0.0027521816082298756}, {"id": 51, "seek": 31120, "start": 326.24, "end": 332.4, "text": " file. Let's say I, and the blue is like the model, let's say the data structure and then there's", "tokens": [51116, 3991, 13, 961, 311, 584, 286, 11, 293, 264, 3344, 307, 411, 264, 2316, 11, 718, 311, 584, 264, 1412, 3877, 293, 550, 456, 311, 51424], "temperature": 0.0, "avg_logprob": -0.11156644821166992, "compression_ratio": 1.598326359832636, "no_speech_prob": 0.0027521816082298756}, {"id": 52, "seek": 31120, "start": 332.4, "end": 338.32, "text": " some logic. And maybe this is, I have a personal like reading list and I want to just keep track", "tokens": [51424, 512, 9952, 13, 400, 1310, 341, 307, 11, 286, 362, 257, 2973, 411, 3760, 1329, 293, 286, 528, 281, 445, 1066, 2837, 51720], "temperature": 0.0, "avg_logprob": -0.11156644821166992, "compression_ratio": 1.598326359832636, "no_speech_prob": 0.0027521816082298756}, {"id": 53, "seek": 33832, "start": 338.4, "end": 346.32, "text": " of the books that I'm interested in. And maybe I have 200 lines of code. I'm not crazy. And so I", "tokens": [50368, 295, 264, 3642, 300, 286, 478, 3102, 294, 13, 400, 1310, 286, 362, 2331, 3876, 295, 3089, 13, 286, 478, 406, 3219, 13, 400, 370, 286, 50764], "temperature": 0.0, "avg_logprob": -0.08882324582054502, "compression_ratio": 1.6623376623376624, "no_speech_prob": 0.003167889080941677}, {"id": 54, "seek": 33832, "start": 346.32, "end": 352.15999999999997, "text": " add some features. I want to be able to mark the books as read or not. And maybe I want to reorder", "tokens": [50764, 909, 512, 4122, 13, 286, 528, 281, 312, 1075, 281, 1491, 264, 3642, 382, 1401, 420, 406, 13, 400, 1310, 286, 528, 281, 319, 4687, 51056], "temperature": 0.0, "avg_logprob": -0.08882324582054502, "compression_ratio": 1.6623376623376624, "no_speech_prob": 0.003167889080941677}, {"id": 55, "seek": 33832, "start": 352.15999999999997, "end": 359.84, "text": " them depending on if one starts to seem more exciting. And so now I have about 400 lines.", "tokens": [51056, 552, 5413, 322, 498, 472, 3719, 281, 1643, 544, 4670, 13, 400, 370, 586, 286, 362, 466, 8423, 3876, 13, 51440], "temperature": 0.0, "avg_logprob": -0.08882324582054502, "compression_ratio": 1.6623376623376624, "no_speech_prob": 0.003167889080941677}, {"id": 56, "seek": 33832, "start": 359.84, "end": 365.36, "text": " And I think a lot of folks at this point would be like, like something's wrong. There's a problem.", "tokens": [51440, 400, 286, 519, 257, 688, 295, 4024, 412, 341, 935, 576, 312, 411, 11, 411, 746, 311, 2085, 13, 821, 311, 257, 1154, 13, 51716], "temperature": 0.0, "avg_logprob": -0.08882324582054502, "compression_ratio": 1.6623376623376624, "no_speech_prob": 0.003167889080941677}, {"id": 57, "seek": 36536, "start": 366.16, "end": 372.32, "text": " That's generally not, that's not how I would approach programming in Elm. It's not how things", "tokens": [50404, 663, 311, 5101, 406, 11, 300, 311, 406, 577, 286, 576, 3109, 9410, 294, 2699, 76, 13, 467, 311, 406, 577, 721, 50712], "temperature": 0.0, "avg_logprob": -0.18840988159179686, "compression_ratio": 1.5546218487394958, "no_speech_prob": 0.0010979539947584271}, {"id": 58, "seek": 36536, "start": 372.32, "end": 377.52000000000004, "text": " work in Standard and Mellor or Camel or Haskell. It's just like having a file this long is pretty", "tokens": [50712, 589, 294, 21298, 293, 376, 898, 284, 420, 6886, 338, 420, 8646, 43723, 13, 467, 311, 445, 411, 1419, 257, 3991, 341, 938, 307, 1238, 50972], "temperature": 0.0, "avg_logprob": -0.18840988159179686, "compression_ratio": 1.5546218487394958, "no_speech_prob": 0.0010979539947584271}, {"id": 59, "seek": 36536, "start": 377.52000000000004, "end": 384.88, "text": " standard. So if I go through the compiler, like that's, I'd say the average. And so maybe add", "tokens": [50972, 3832, 13, 407, 498, 286, 352, 807, 264, 31958, 11, 411, 300, 311, 11, 286, 1116, 584, 264, 4274, 13, 400, 370, 1310, 909, 51340], "temperature": 0.0, "avg_logprob": -0.18840988159179686, "compression_ratio": 1.5546218487394958, "no_speech_prob": 0.0010979539947584271}, {"id": 60, "seek": 36536, "start": 384.88, "end": 389.6, "text": " some more features. I can add annotations to each book of quotes that I really like.", "tokens": [51340, 512, 544, 4122, 13, 286, 393, 909, 25339, 763, 281, 1184, 1446, 295, 19963, 300, 286, 534, 411, 13, 51576], "temperature": 0.0, "avg_logprob": -0.18840988159179686, "compression_ratio": 1.5546218487394958, "no_speech_prob": 0.0010979539947584271}, {"id": 61, "seek": 38960, "start": 390.56, "end": 396.88, "text": " Things I want to remember. So now I have like 600 lines of code. And it's like, okay, now it's", "tokens": [50412, 9514, 286, 528, 281, 1604, 13, 407, 586, 286, 362, 411, 11849, 3876, 295, 3089, 13, 400, 309, 311, 411, 11, 1392, 11, 586, 309, 311, 50728], "temperature": 0.0, "avg_logprob": -0.11418739954630534, "compression_ratio": 1.6632302405498283, "no_speech_prob": 0.003374913241714239}, {"id": 62, "seek": 38960, "start": 396.88, "end": 403.44, "text": " surely it's a problem. Not really. I don't know. I think you shouldn't be too scared of a file", "tokens": [50728, 11468, 309, 311, 257, 1154, 13, 1726, 534, 13, 286, 500, 380, 458, 13, 286, 519, 291, 4659, 380, 312, 886, 5338, 295, 257, 3991, 51056], "temperature": 0.0, "avg_logprob": -0.11418739954630534, "compression_ratio": 1.6632302405498283, "no_speech_prob": 0.003374913241714239}, {"id": 63, "seek": 38960, "start": 403.44, "end": 407.68, "text": " growing long. So this is something that will typically happen. Now, at this point, it's likely", "tokens": [51056, 4194, 938, 13, 407, 341, 307, 746, 300, 486, 5850, 1051, 13, 823, 11, 412, 341, 935, 11, 309, 311, 3700, 51268], "temperature": 0.0, "avg_logprob": -0.11418739954630534, "compression_ratio": 1.6632302405498283, "no_speech_prob": 0.003374913241714239}, {"id": 64, "seek": 38960, "start": 407.68, "end": 412.72, "text": " that I'll say, you know what, I think it'd be good to have the data structure for like my library", "tokens": [51268, 300, 286, 603, 584, 11, 291, 458, 437, 11, 286, 519, 309, 1116, 312, 665, 281, 362, 264, 1412, 3877, 337, 411, 452, 6405, 51520], "temperature": 0.0, "avg_logprob": -0.11418739954630534, "compression_ratio": 1.6632302405498283, "no_speech_prob": 0.003374913241714239}, {"id": 65, "seek": 38960, "start": 412.72, "end": 418.64000000000004, "text": " where I can reorder books and a data structure for books. Where is it read or not? What are my notes?", "tokens": [51520, 689, 286, 393, 319, 4687, 3642, 293, 257, 1412, 3877, 337, 3642, 13, 2305, 307, 309, 1401, 420, 406, 30, 708, 366, 452, 5570, 30, 51816], "temperature": 0.0, "avg_logprob": -0.11418739954630534, "compression_ratio": 1.6632302405498283, "no_speech_prob": 0.003374913241714239}, {"id": 66, "seek": 41960, "start": 419.6, "end": 425.52000000000004, "text": " And then I can start to organize my code around those two data structures. So I can say, okay,", "tokens": [50364, 400, 550, 286, 393, 722, 281, 13859, 452, 3089, 926, 729, 732, 1412, 9227, 13, 407, 286, 393, 584, 11, 1392, 11, 50660], "temperature": 0.0, "avg_logprob": -0.11668799785857505, "compression_ratio": 1.892156862745098, "no_speech_prob": 0.0002865971182473004}, {"id": 67, "seek": 41960, "start": 425.52000000000004, "end": 430.72, "text": " mark this book as red, add this note. And so the functions in my code start to organize around", "tokens": [50660, 1491, 341, 1446, 382, 2182, 11, 909, 341, 3637, 13, 400, 370, 264, 6828, 294, 452, 3089, 722, 281, 13859, 926, 50920], "temperature": 0.0, "avg_logprob": -0.11668799785857505, "compression_ratio": 1.892156862745098, "no_speech_prob": 0.0002865971182473004}, {"id": 68, "seek": 41960, "start": 430.72, "end": 438.48, "text": " those data structures. So, hey, we discovered this better data structure. So the next step that", "tokens": [50920, 729, 1412, 9227, 13, 407, 11, 4177, 11, 321, 6941, 341, 1101, 1412, 3877, 13, 407, 264, 958, 1823, 300, 51308], "temperature": 0.0, "avg_logprob": -0.11668799785857505, "compression_ratio": 1.892156862745098, "no_speech_prob": 0.0002865971182473004}, {"id": 69, "seek": 41960, "start": 438.48, "end": 445.52000000000004, "text": " may happen is we split around the data structure, right? So once we discover that there's this other", "tokens": [51308, 815, 1051, 307, 321, 7472, 926, 264, 1412, 3877, 11, 558, 30, 407, 1564, 321, 4411, 300, 456, 311, 341, 661, 51660], "temperature": 0.0, "avg_logprob": -0.11668799785857505, "compression_ratio": 1.892156862745098, "no_speech_prob": 0.0002865971182473004}, {"id": 70, "seek": 44552, "start": 445.76, "end": 453.03999999999996, "text": " like chunk that we can grab onto, that can become the heart of a nice module. And so this is the", "tokens": [50376, 411, 16635, 300, 321, 393, 4444, 3911, 11, 300, 393, 1813, 264, 1917, 295, 257, 1481, 10088, 13, 400, 370, 341, 307, 264, 50740], "temperature": 0.0, "avg_logprob": -0.09151022911071777, "compression_ratio": 1.6085106382978724, "no_speech_prob": 0.0005355793400667608}, {"id": 71, "seek": 44552, "start": 453.03999999999996, "end": 458.79999999999995, "text": " typical process that I always follow. It's just basically grow until I find a data structure", "tokens": [50740, 7476, 1399, 300, 286, 1009, 1524, 13, 467, 311, 445, 1936, 1852, 1826, 286, 915, 257, 1412, 3877, 51028], "temperature": 0.0, "avg_logprob": -0.09151022911071777, "compression_ratio": 1.6085106382978724, "no_speech_prob": 0.0005355793400667608}, {"id": 72, "seek": 44552, "start": 458.79999999999995, "end": 466.79999999999995, "text": " that I can split on. And if I don't find it, it's fine. So I'd encourage folks to sort of", "tokens": [51028, 300, 286, 393, 7472, 322, 13, 400, 498, 286, 500, 380, 915, 309, 11, 309, 311, 2489, 13, 407, 286, 1116, 5373, 4024, 281, 1333, 295, 51428], "temperature": 0.0, "avg_logprob": -0.09151022911071777, "compression_ratio": 1.6085106382978724, "no_speech_prob": 0.0005355793400667608}, {"id": 73, "seek": 44552, "start": 466.79999999999995, "end": 472.0, "text": " play with this in your own code. And sort of if you're feeling uncomfortable, like, oh, this seems", "tokens": [51428, 862, 365, 341, 294, 428, 1065, 3089, 13, 400, 1333, 295, 498, 291, 434, 2633, 10532, 11, 411, 11, 1954, 11, 341, 2544, 51688], "temperature": 0.0, "avg_logprob": -0.09151022911071777, "compression_ratio": 1.6085106382978724, "no_speech_prob": 0.0005355793400667608}, {"id": 74, "seek": 47200, "start": 472.08, "end": 477.6, "text": " like I have too much code here, just like push into that feeling and like see if it actually", "tokens": [50368, 411, 286, 362, 886, 709, 3089, 510, 11, 445, 411, 2944, 666, 300, 2633, 293, 411, 536, 498, 309, 767, 50644], "temperature": 0.0, "avg_logprob": -0.09183075030644734, "compression_ratio": 1.6008583690987124, "no_speech_prob": 0.0012436311226338148}, {"id": 75, "seek": 47200, "start": 478.48, "end": 482.88, "text": " is warranted. Like, is there actually a problem? Or is it just like a feeling that you have based", "tokens": [50688, 307, 16354, 292, 13, 1743, 11, 307, 456, 767, 257, 1154, 30, 1610, 307, 309, 445, 411, 257, 2633, 300, 291, 362, 2361, 50908], "temperature": 0.0, "avg_logprob": -0.09183075030644734, "compression_ratio": 1.6008583690987124, "no_speech_prob": 0.0012436311226338148}, {"id": 76, "seek": 47200, "start": 482.88, "end": 488.8, "text": " on experiences in other languages? So, okay. So at this point, this is basically just like", "tokens": [50908, 322, 5235, 294, 661, 8650, 30, 407, 11, 1392, 13, 407, 412, 341, 935, 11, 341, 307, 1936, 445, 411, 51204], "temperature": 0.0, "avg_logprob": -0.09183075030644734, "compression_ratio": 1.6008583690987124, "no_speech_prob": 0.0012436311226338148}, {"id": 77, "seek": 47200, "start": 488.8, "end": 495.44, "text": " an unsubstantiated claim. Let's see some more concrete examples, right? Ones where the code", "tokens": [51204, 364, 2693, 836, 372, 11520, 770, 3932, 13, 961, 311, 536, 512, 544, 9859, 5110, 11, 558, 30, 1282, 279, 689, 264, 3089, 51536], "temperature": 0.0, "avg_logprob": -0.09183075030644734, "compression_ratio": 1.6008583690987124, "no_speech_prob": 0.0012436311226338148}, {"id": 78, "seek": 49544, "start": 495.44, "end": 506.48, "text": " is more elaborate than lines. So, okay. So I want to look at two examples. One is", "tokens": [50364, 307, 544, 20945, 813, 3876, 13, 407, 11, 1392, 13, 407, 286, 528, 281, 574, 412, 732, 5110, 13, 1485, 307, 50916], "temperature": 0.0, "avg_logprob": -0.11137691788051439, "compression_ratio": 1.5589519650655022, "no_speech_prob": 0.008166204206645489}, {"id": 79, "seek": 49544, "start": 507.6, "end": 511.04, "text": " the sort of settings. So you can imagine this is like the settings you'd have in", "tokens": [50972, 264, 1333, 295, 6257, 13, 407, 291, 393, 3811, 341, 307, 411, 264, 6257, 291, 1116, 362, 294, 51144], "temperature": 0.0, "avg_logprob": -0.11137691788051439, "compression_ratio": 1.5589519650655022, "no_speech_prob": 0.008166204206645489}, {"id": 80, "seek": 49544, "start": 512.16, "end": 516.4, "text": " a Facebook or Twitter or Pinterest or whatever. Like, do you get email notifications? Do you", "tokens": [51200, 257, 4384, 420, 5794, 420, 37986, 420, 2035, 13, 1743, 11, 360, 291, 483, 3796, 13426, 30, 1144, 291, 51412], "temperature": 0.0, "avg_logprob": -0.11137691788051439, "compression_ratio": 1.5589519650655022, "no_speech_prob": 0.008166204206645489}, {"id": 81, "seek": 49544, "start": 516.4, "end": 523.76, "text": " want video audio play? Do you want to use location? These kinds of things. And you could just say no,", "tokens": [51412, 528, 960, 6278, 862, 30, 1144, 291, 528, 281, 764, 4914, 30, 1981, 3685, 295, 721, 13, 400, 291, 727, 445, 584, 572, 11, 51780], "temperature": 0.0, "avg_logprob": -0.11137691788051439, "compression_ratio": 1.5589519650655022, "no_speech_prob": 0.008166204206645489}, {"id": 82, "seek": 52376, "start": 523.76, "end": 531.12, "text": " but they want to give you the option to say no. The other situation is checkbox is a bunch of", "tokens": [50364, 457, 436, 528, 281, 976, 291, 264, 3614, 281, 584, 572, 13, 440, 661, 2590, 307, 1520, 4995, 307, 257, 3840, 295, 50732], "temperature": 0.0, "avg_logprob": -0.09899272918701171, "compression_ratio": 1.7374100719424461, "no_speech_prob": 0.0006157784955576062}, {"id": 83, "seek": 52376, "start": 531.12, "end": 536.88, "text": " fruits. Maybe I'm going to, you're going to get lunch and you are able to pick out which fruits", "tokens": [50732, 12148, 13, 2704, 286, 478, 516, 281, 11, 291, 434, 516, 281, 483, 6349, 293, 291, 366, 1075, 281, 1888, 484, 597, 12148, 51020], "temperature": 0.0, "avg_logprob": -0.09899272918701171, "compression_ratio": 1.7374100719424461, "no_speech_prob": 0.0006157784955576062}, {"id": 84, "seek": 52376, "start": 536.88, "end": 541.4399999999999, "text": " you want, then you can have that one. So before we dig into this, I want to sort of take a second", "tokens": [51020, 291, 528, 11, 550, 291, 393, 362, 300, 472, 13, 407, 949, 321, 2528, 666, 341, 11, 286, 528, 281, 1333, 295, 747, 257, 1150, 51248], "temperature": 0.0, "avg_logprob": -0.09899272918701171, "compression_ratio": 1.7374100719424461, "no_speech_prob": 0.0006157784955576062}, {"id": 85, "seek": 52376, "start": 541.4399999999999, "end": 548.88, "text": " to and ask people, like, what are the questions and concerns when you see these two that pop into", "tokens": [51248, 281, 293, 1029, 561, 11, 411, 11, 437, 366, 264, 1651, 293, 7389, 562, 291, 536, 613, 732, 300, 1665, 666, 51620], "temperature": 0.0, "avg_logprob": -0.09899272918701171, "compression_ratio": 1.7374100719424461, "no_speech_prob": 0.0006157784955576062}, {"id": 86, "seek": 52376, "start": 548.88, "end": 552.96, "text": " your mind? Like, when you think about how the code is probably going to look, what pops into your", "tokens": [51620, 428, 1575, 30, 1743, 11, 562, 291, 519, 466, 577, 264, 3089, 307, 1391, 516, 281, 574, 11, 437, 16795, 666, 428, 51824], "temperature": 0.0, "avg_logprob": -0.09899272918701171, "compression_ratio": 1.7374100719424461, "no_speech_prob": 0.0006157784955576062}, {"id": 87, "seek": 55296, "start": 552.96, "end": 572.96, "text": " mind? Okay. Yeah. Someone said, oh, oh. Okay. Okay. Okay. We're good. We're good. Someone said generic", "tokens": [50364, 1575, 30, 1033, 13, 865, 13, 8734, 848, 11, 1954, 11, 1954, 13, 1033, 13, 1033, 13, 1033, 13, 492, 434, 665, 13, 492, 434, 665, 13, 8734, 848, 19577, 51364], "temperature": 0.0, "avg_logprob": -0.2193458496578156, "compression_ratio": 1.4779411764705883, "no_speech_prob": 0.0030722415540367365}, {"id": 88, "seek": 55296, "start": 572.96, "end": 579.12, "text": " checkbox list. So yeah, this idea of like, how do we share? Like, clearly we have checkboxes here.", "tokens": [51364, 1520, 4995, 1329, 13, 407, 1338, 11, 341, 1558, 295, 411, 11, 577, 360, 321, 2073, 30, 1743, 11, 4448, 321, 362, 1520, 4995, 279, 510, 13, 51672], "temperature": 0.0, "avg_logprob": -0.2193458496578156, "compression_ratio": 1.4779411764705883, "no_speech_prob": 0.0030722415540367365}, {"id": 89, "seek": 57912, "start": 579.12, "end": 588.48, "text": " Like, sharing needs to happen. Okay. This, I'm going to proceed by showing how I would address", "tokens": [50364, 1743, 11, 5414, 2203, 281, 1051, 13, 1033, 13, 639, 11, 286, 478, 516, 281, 8991, 538, 4099, 577, 286, 576, 2985, 50832], "temperature": 0.0, "avg_logprob": -0.09986466987460267, "compression_ratio": 1.6125, "no_speech_prob": 0.0013646846637129784}, {"id": 90, "seek": 57912, "start": 588.48, "end": 594.64, "text": " these and then we'll see if that intuition plays out. So when I look at the settings, the first", "tokens": [50832, 613, 293, 550, 321, 603, 536, 498, 300, 24002, 5749, 484, 13, 407, 562, 286, 574, 412, 264, 6257, 11, 264, 700, 51140], "temperature": 0.0, "avg_logprob": -0.09986466987460267, "compression_ratio": 1.6125, "no_speech_prob": 0.0013646846637129784}, {"id": 91, "seek": 57912, "start": 594.64, "end": 601.04, "text": " question I ask is, how do I model this information? Right? So do I use a record where I say there's", "tokens": [51140, 1168, 286, 1029, 307, 11, 577, 360, 286, 2316, 341, 1589, 30, 1779, 30, 407, 360, 286, 764, 257, 2136, 689, 286, 584, 456, 311, 51460], "temperature": 0.0, "avg_logprob": -0.09986466987460267, "compression_ratio": 1.6125, "no_speech_prob": 0.0013646846637129784}, {"id": 92, "seek": 57912, "start": 601.04, "end": 608.16, "text": " email, there's video, there's location? Do I use a list of pairs where the string would be email", "tokens": [51460, 3796, 11, 456, 311, 960, 11, 456, 311, 4914, 30, 1144, 286, 764, 257, 1329, 295, 15494, 689, 264, 6798, 576, 312, 3796, 51816], "temperature": 0.0, "avg_logprob": -0.09986466987460267, "compression_ratio": 1.6125, "no_speech_prob": 0.0013646846637129784}, {"id": 93, "seek": 60816, "start": 608.16, "end": 617.04, "text": " and notifications true? Autoplay false? A location false? Do I choose a dictionary? Which would work", "tokens": [50364, 293, 13426, 2074, 30, 6049, 404, 8376, 7908, 30, 316, 4914, 7908, 30, 1144, 286, 2826, 257, 25890, 30, 3013, 576, 589, 50808], "temperature": 0.0, "avg_logprob": -0.15306556559054652, "compression_ratio": 1.6244897959183673, "no_speech_prob": 0.0014524997677654028}, {"id": 94, "seek": 60816, "start": 617.04, "end": 623.76, "text": " similarly? But now it's unique on these things. Or do I do this other one that's, I have a list of", "tokens": [50808, 14138, 30, 583, 586, 309, 311, 3845, 322, 613, 721, 13, 1610, 360, 286, 360, 341, 661, 472, 300, 311, 11, 286, 362, 257, 1329, 295, 51144], "temperature": 0.0, "avg_logprob": -0.15306556559054652, "compression_ratio": 1.6244897959183673, "no_speech_prob": 0.0014524997677654028}, {"id": 95, "seek": 60816, "start": 623.76, "end": 628.64, "text": " strings. These are all options. So email, autoplay location, and then a set of which ones are selected.", "tokens": [51144, 13985, 13, 1981, 366, 439, 3956, 13, 407, 3796, 11, 31090, 8376, 4914, 11, 293, 550, 257, 992, 295, 597, 2306, 366, 8209, 13, 51388], "temperature": 0.0, "avg_logprob": -0.15306556559054652, "compression_ratio": 1.6244897959183673, "no_speech_prob": 0.0014524997677654028}, {"id": 96, "seek": 60816, "start": 628.64, "end": 636.56, "text": " So this would just be email. And we can think of more. It's a good idea to get in the habit of", "tokens": [51388, 407, 341, 576, 445, 312, 3796, 13, 400, 321, 393, 519, 295, 544, 13, 467, 311, 257, 665, 1558, 281, 483, 294, 264, 7164, 295, 51784], "temperature": 0.0, "avg_logprob": -0.15306556559054652, "compression_ratio": 1.6244897959183673, "no_speech_prob": 0.0014524997677654028}, {"id": 97, "seek": 63656, "start": 636.56, "end": 641.68, "text": " just thinking, what are all the possible ways I can represent this? So at this point, you want to", "tokens": [50364, 445, 1953, 11, 437, 366, 439, 264, 1944, 2098, 286, 393, 2906, 341, 30, 407, 412, 341, 935, 11, 291, 528, 281, 50620], "temperature": 0.0, "avg_logprob": -0.10255611056373233, "compression_ratio": 1.6090534979423867, "no_speech_prob": 0.0016200782265514135}, {"id": 98, "seek": 63656, "start": 641.68, "end": 649.5999999999999, "text": " say, okay, well, which one should I do? So one trade-off here is this one gives us the benefit", "tokens": [50620, 584, 11, 1392, 11, 731, 11, 597, 472, 820, 286, 360, 30, 407, 472, 4923, 12, 4506, 510, 307, 341, 472, 2709, 505, 264, 5121, 51016], "temperature": 0.0, "avg_logprob": -0.10255611056373233, "compression_ratio": 1.6090534979423867, "no_speech_prob": 0.0016200782265514135}, {"id": 99, "seek": 63656, "start": 649.5999999999999, "end": 656.0, "text": " of types, right? So if we're messing around in our code and someone misspells email or misspells", "tokens": [51016, 295, 3467, 11, 558, 30, 407, 498, 321, 434, 23258, 926, 294, 527, 3089, 293, 1580, 1713, 494, 43909, 3796, 420, 1713, 494, 43909, 51336], "temperature": 0.0, "avg_logprob": -0.10255611056373233, "compression_ratio": 1.6090534979423867, "no_speech_prob": 0.0016200782265514135}, {"id": 100, "seek": 63656, "start": 656.0, "end": 660.16, "text": " one of these things, the compiler is going to give us some help. So that's nice. And these other ones", "tokens": [51336, 472, 295, 613, 721, 11, 264, 31958, 307, 516, 281, 976, 505, 512, 854, 13, 407, 300, 311, 1481, 13, 400, 613, 661, 2306, 51544], "temperature": 0.0, "avg_logprob": -0.10255611056373233, "compression_ratio": 1.6090534979423867, "no_speech_prob": 0.0016200782265514135}, {"id": 101, "seek": 66016, "start": 660.48, "end": 666.24, "text": " are stringly typed. So if there's some misspelling, it's sorry. Like, things are going to go weird.", "tokens": [50380, 366, 6798, 356, 33941, 13, 407, 498, 456, 311, 512, 1713, 494, 2669, 11, 309, 311, 2597, 13, 1743, 11, 721, 366, 516, 281, 352, 3657, 13, 50668], "temperature": 0.0, "avg_logprob": -0.11110279295179579, "compression_ratio": 1.7008547008547008, "no_speech_prob": 0.014483381994068623}, {"id": 102, "seek": 66016, "start": 668.16, "end": 675.04, "text": " Another thing to think about is the order in this one is just determined by the view. So in my model,", "tokens": [50764, 3996, 551, 281, 519, 466, 307, 264, 1668, 294, 341, 472, 307, 445, 9540, 538, 264, 1910, 13, 407, 294, 452, 2316, 11, 51108], "temperature": 0.0, "avg_logprob": -0.11110279295179579, "compression_ratio": 1.7008547008547008, "no_speech_prob": 0.014483381994068623}, {"id": 103, "seek": 66016, "start": 675.04, "end": 680.0, "text": " in my record, I can update however I want. It can appear however I want it to appear in my code.", "tokens": [51108, 294, 452, 2136, 11, 286, 393, 5623, 4461, 286, 528, 13, 467, 393, 4204, 4461, 286, 528, 309, 281, 4204, 294, 452, 3089, 13, 51356], "temperature": 0.0, "avg_logprob": -0.11110279295179579, "compression_ratio": 1.7008547008547008, "no_speech_prob": 0.014483381994068623}, {"id": 104, "seek": 66016, "start": 680.0, "end": 684.64, "text": " But ultimately in the view, I'm going to say, show the email, show the notification, show this. And", "tokens": [51356, 583, 6284, 294, 264, 1910, 11, 286, 478, 516, 281, 584, 11, 855, 264, 3796, 11, 855, 264, 11554, 11, 855, 341, 13, 400, 51588], "temperature": 0.0, "avg_logprob": -0.11110279295179579, "compression_ratio": 1.7008547008547008, "no_speech_prob": 0.014483381994068623}, {"id": 105, "seek": 68464, "start": 684.64, "end": 690.72, "text": " if our designer says, okay, we actually want to move, use location above because everyone wants", "tokens": [50364, 498, 527, 11795, 1619, 11, 1392, 11, 321, 767, 528, 281, 1286, 11, 764, 4914, 3673, 570, 1518, 2738, 50668], "temperature": 0.0, "avg_logprob": -0.15240886688232422, "compression_ratio": 1.6394849785407726, "no_speech_prob": 0.0021469404455274343}, {"id": 106, "seek": 68464, "start": 690.72, "end": 694.64, "text": " to turn that off and no one can find it, we get a lot of support tickets and they're really mad at", "tokens": [50668, 281, 1261, 300, 766, 293, 572, 472, 393, 915, 309, 11, 321, 483, 257, 688, 295, 1406, 12628, 293, 436, 434, 534, 5244, 412, 50864], "temperature": 0.0, "avg_logprob": -0.15240886688232422, "compression_ratio": 1.6394849785407726, "no_speech_prob": 0.0021469404455274343}, {"id": 107, "seek": 68464, "start": 694.64, "end": 702.64, "text": " us. So I get that. Just change it. And then it becomes very easy in this world. With this one,", "tokens": [50864, 505, 13, 407, 286, 483, 300, 13, 1449, 1319, 309, 13, 400, 550, 309, 3643, 588, 1858, 294, 341, 1002, 13, 2022, 341, 472, 11, 51264], "temperature": 0.0, "avg_logprob": -0.15240886688232422, "compression_ratio": 1.6394849785407726, "no_speech_prob": 0.0021469404455274343}, {"id": 108, "seek": 68464, "start": 702.64, "end": 710.56, "text": " the order is stable, but you can actually change it in the update. So in the same time we're", "tokens": [51264, 264, 1668, 307, 8351, 11, 457, 291, 393, 767, 1319, 309, 294, 264, 5623, 13, 407, 294, 264, 912, 565, 321, 434, 51660], "temperature": 0.0, "avg_logprob": -0.15240886688232422, "compression_ratio": 1.6394849785407726, "no_speech_prob": 0.0021469404455274343}, {"id": 109, "seek": 71056, "start": 710.56, "end": 715.5999999999999, "text": " upping a bool from true to false, we could just swap, reverse the list. And so suddenly the UI", "tokens": [50364, 344, 3759, 257, 748, 401, 490, 2074, 281, 7908, 11, 321, 727, 445, 18135, 11, 9943, 264, 1329, 13, 400, 370, 5800, 264, 15682, 50616], "temperature": 0.0, "avg_logprob": -0.13654886881510417, "compression_ratio": 1.6725352112676057, "no_speech_prob": 0.002180654788389802}, {"id": 110, "seek": 71056, "start": 715.5999999999999, "end": 720.0799999999999, "text": " is totally different based on stuff that's happening in the update code. So someone writing", "tokens": [50616, 307, 3879, 819, 2361, 322, 1507, 300, 311, 2737, 294, 264, 5623, 3089, 13, 407, 1580, 3579, 50840], "temperature": 0.0, "avg_logprob": -0.13654886881510417, "compression_ratio": 1.6725352112676057, "no_speech_prob": 0.002180654788389802}, {"id": 111, "seek": 71056, "start": 720.0799999999999, "end": 724.4, "text": " update code has to think about what was it that that designer said a while ago about support tickets.", "tokens": [50840, 5623, 3089, 575, 281, 519, 466, 437, 390, 309, 300, 300, 11795, 848, 257, 1339, 2057, 466, 1406, 12628, 13, 51056], "temperature": 0.0, "avg_logprob": -0.13654886881510417, "compression_ratio": 1.6725352112676057, "no_speech_prob": 0.002180654788389802}, {"id": 112, "seek": 71056, "start": 726.7199999999999, "end": 734.0799999999999, "text": " This one, order is dependent on the keys. It's just like not a good idea. And this one,", "tokens": [51172, 639, 472, 11, 1668, 307, 12334, 322, 264, 9317, 13, 467, 311, 445, 411, 406, 257, 665, 1558, 13, 400, 341, 472, 11, 51540], "temperature": 0.0, "avg_logprob": -0.13654886881510417, "compression_ratio": 1.6725352112676057, "no_speech_prob": 0.002180654788389802}, {"id": 113, "seek": 71056, "start": 734.0799999999999, "end": 739.76, "text": " the order is stable again. So it seems like we've got a pretty clear winner in this case. So let's", "tokens": [51540, 264, 1668, 307, 8351, 797, 13, 407, 309, 2544, 411, 321, 600, 658, 257, 1238, 1850, 8507, 294, 341, 1389, 13, 407, 718, 311, 51824], "temperature": 0.0, "avg_logprob": -0.13654886881510417, "compression_ratio": 1.6725352112676057, "no_speech_prob": 0.002180654788389802}, {"id": 114, "seek": 73976, "start": 740.64, "end": 756.08, "text": " run with this. So here's the initial version of it. We can check stuff. And we can, this is kind of", "tokens": [50408, 1190, 365, 341, 13, 407, 510, 311, 264, 5883, 3037, 295, 309, 13, 492, 393, 1520, 1507, 13, 400, 321, 393, 11, 341, 307, 733, 295, 51180], "temperature": 0.0, "avg_logprob": -0.1676114456994193, "compression_ratio": 1.3566433566433567, "no_speech_prob": 0.0010973048629239202}, {"id": 115, "seek": 73976, "start": 756.08, "end": 767.6, "text": " small. But we can see people messing with the record. Oops. Okay. So when we look at the code,", "tokens": [51180, 1359, 13, 583, 321, 393, 536, 561, 23258, 365, 264, 2136, 13, 21726, 13, 1033, 13, 407, 562, 321, 574, 412, 264, 3089, 11, 51756], "temperature": 0.0, "avg_logprob": -0.1676114456994193, "compression_ratio": 1.3566433566433567, "no_speech_prob": 0.0010973048629239202}, {"id": 116, "seek": 76760, "start": 767.6, "end": 775.28, "text": " can people see this okay? Okay. The model is what we talked about. We have the record with our", "tokens": [50364, 393, 561, 536, 341, 1392, 30, 1033, 13, 440, 2316, 307, 437, 321, 2825, 466, 13, 492, 362, 264, 2136, 365, 527, 50748], "temperature": 0.0, "avg_logprob": -0.13397356476446595, "compression_ratio": 1.575, "no_speech_prob": 0.000882125343196094}, {"id": 117, "seek": 76760, "start": 775.28, "end": 780.64, "text": " boolean fields. And the defaults, you know, everything needs to be true, right? We need", "tokens": [50748, 748, 4812, 282, 7909, 13, 400, 264, 7576, 82, 11, 291, 458, 11, 1203, 2203, 281, 312, 2074, 11, 558, 30, 492, 643, 51016], "temperature": 0.0, "avg_logprob": -0.13397356476446595, "compression_ratio": 1.575, "no_speech_prob": 0.000882125343196094}, {"id": 118, "seek": 76760, "start": 781.2, "end": 788.32, "text": " autoplay to get that ad money. We need location on so that it can be location-specific advertising.", "tokens": [51044, 31090, 8376, 281, 483, 300, 614, 1460, 13, 492, 643, 4914, 322, 370, 300, 309, 393, 312, 4914, 12, 29258, 13097, 13, 51400], "temperature": 0.0, "avg_logprob": -0.13397356476446595, "compression_ratio": 1.575, "no_speech_prob": 0.000882125343196094}, {"id": 119, "seek": 76760, "start": 788.32, "end": 793.12, "text": " Okay. I notice you're in the neighborhood of, and we need the email so that they can notify you", "tokens": [51400, 1033, 13, 286, 3449, 291, 434, 294, 264, 7630, 295, 11, 293, 321, 643, 264, 3796, 370, 300, 436, 393, 36560, 291, 51640], "temperature": 0.0, "avg_logprob": -0.13397356476446595, "compression_ratio": 1.575, "no_speech_prob": 0.000882125343196094}, {"id": 120, "seek": 79312, "start": 793.12, "end": 802.16, "text": " to log in and see the autoplay has. And then in our update, things are relatively straightforward.", "tokens": [50364, 281, 3565, 294, 293, 536, 264, 31090, 8376, 575, 13, 400, 550, 294, 527, 5623, 11, 721, 366, 7226, 15325, 13, 50816], "temperature": 0.0, "avg_logprob": -0.1134432601928711, "compression_ratio": 1.3623188405797102, "no_speech_prob": 0.0008288886747322977}, {"id": 121, "seek": 79312, "start": 804.0, "end": 810.72, "text": " We have a way to toggle each of these things. And if I mess up and say I want the model's", "tokens": [50908, 492, 362, 257, 636, 281, 31225, 1184, 295, 613, 721, 13, 400, 498, 286, 2082, 493, 293, 584, 286, 528, 264, 2316, 311, 51244], "temperature": 0.0, "avg_logprob": -0.1134432601928711, "compression_ratio": 1.3623188405797102, "no_speech_prob": 0.0008288886747322977}, {"id": 122, "seek": 81072, "start": 810.96, "end": 820.64, "text": " email, it's like, hey, I think you have a typo. So we're getting that benefit that we wanted.", "tokens": [50376, 3796, 11, 309, 311, 411, 11, 4177, 11, 286, 519, 291, 362, 257, 2125, 78, 13, 407, 321, 434, 1242, 300, 5121, 300, 321, 1415, 13, 50860], "temperature": 0.0, "avg_logprob": -0.13602120876312257, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.006687923334538937}, {"id": 123, "seek": 81072, "start": 823.6800000000001, "end": 830.96, "text": " And finally, we have a view. So we have a field set. There's labels. And each one contains a", "tokens": [51012, 400, 2721, 11, 321, 362, 257, 1910, 13, 407, 321, 362, 257, 2519, 992, 13, 821, 311, 16949, 13, 400, 1184, 472, 8306, 257, 51376], "temperature": 0.0, "avg_logprob": -0.13602120876312257, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.006687923334538937}, {"id": 124, "seek": 81072, "start": 830.96, "end": 838.4, "text": " checkbox that we say, okay, here's the email notifications one. Is it checked? Here's the", "tokens": [51376, 1520, 4995, 300, 321, 584, 11, 1392, 11, 510, 311, 264, 3796, 13426, 472, 13, 1119, 309, 10033, 30, 1692, 311, 264, 51748], "temperature": 0.0, "avg_logprob": -0.13602120876312257, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.006687923334538937}, {"id": 125, "seek": 83840, "start": 838.4, "end": 845.12, "text": " autoplay. Is it checked? Et cetera. Now, one of the things that you can do is say, okay,", "tokens": [50364, 31090, 8376, 13, 1119, 309, 10033, 30, 3790, 11458, 13, 823, 11, 472, 295, 264, 721, 300, 291, 393, 360, 307, 584, 11, 1392, 11, 50700], "temperature": 0.0, "avg_logprob": -0.11054500373634132, "compression_ratio": 1.4606741573033708, "no_speech_prob": 0.00029088565497659147}, {"id": 126, "seek": 83840, "start": 845.12, "end": 849.1999999999999, "text": " these actually are pretty much exactly the same. So we can factor out some of this code.", "tokens": [50700, 613, 767, 366, 1238, 709, 2293, 264, 912, 13, 407, 321, 393, 5952, 484, 512, 295, 341, 3089, 13, 50904], "temperature": 0.0, "avg_logprob": -0.11054500373634132, "compression_ratio": 1.4606741573033708, "no_speech_prob": 0.00029088565497659147}, {"id": 127, "seek": 83840, "start": 850.24, "end": 862.64, "text": " So I can say view checkbox. I don't know if it makes sense to start with the type,", "tokens": [50956, 407, 286, 393, 584, 1910, 1520, 4995, 13, 286, 500, 380, 458, 498, 309, 1669, 2020, 281, 722, 365, 264, 2010, 11, 51576], "temperature": 0.0, "avg_logprob": -0.11054500373634132, "compression_ratio": 1.4606741573033708, "no_speech_prob": 0.00029088565497659147}, {"id": 128, "seek": 86264, "start": 862.64, "end": 874.48, "text": " but I practiced this so I know what it is. But we can essentially chop out this code,", "tokens": [50364, 457, 286, 19268, 341, 370, 286, 458, 437, 309, 307, 13, 583, 321, 393, 4476, 7931, 484, 341, 3089, 11, 50956], "temperature": 0.0, "avg_logprob": -0.19899126823912275, "compression_ratio": 1.291044776119403, "no_speech_prob": 0.0010319045977666974}, {"id": 129, "seek": 86264, "start": 874.48, "end": 885.52, "text": " which appears a bunch of times, and fill in the blanks. So checked is checked. Message,", "tokens": [50956, 597, 7038, 257, 3840, 295, 1413, 11, 293, 2836, 294, 264, 8247, 82, 13, 407, 10033, 307, 10033, 13, 45947, 11, 51508], "temperature": 0.0, "avg_logprob": -0.19899126823912275, "compression_ratio": 1.291044776119403, "no_speech_prob": 0.0010319045977666974}, {"id": 130, "seek": 88552, "start": 886.4, "end": 895.84, "text": " description, and then where did my mouse go? Okay, there it is. And then we can say let's just", "tokens": [50408, 3855, 11, 293, 550, 689, 630, 452, 9719, 352, 30, 1033, 11, 456, 309, 307, 13, 400, 550, 321, 393, 584, 718, 311, 445, 50880], "temperature": 0.0, "avg_logprob": -0.21549249649047852, "compression_ratio": 1.3257575757575757, "no_speech_prob": 0.002672068541869521}, {"id": 131, "seek": 88552, "start": 895.84, "end": 909.68, "text": " replace all of these with the checkbox. Okay, so is it code shorter? Not really.", "tokens": [50880, 7406, 439, 295, 613, 365, 264, 1520, 4995, 13, 1033, 11, 370, 307, 309, 3089, 11639, 30, 1726, 534, 13, 51572], "temperature": 0.0, "avg_logprob": -0.21549249649047852, "compression_ratio": 1.3257575757575757, "no_speech_prob": 0.002672068541869521}, {"id": 132, "seek": 90968, "start": 910.64, "end": 916.88, "text": " But if we are applying styles to all of these in the same way, now it's a lot", "tokens": [50412, 583, 498, 321, 366, 9275, 13273, 281, 439, 295, 613, 294, 264, 912, 636, 11, 586, 309, 311, 257, 688, 50724], "temperature": 0.0, "avg_logprob": -0.0820714391843237, "compression_ratio": 1.5155555555555555, "no_speech_prob": 0.001726198592223227}, {"id": 133, "seek": 90968, "start": 916.88, "end": 920.4799999999999, "text": " easier. We can do it in one place and be sure that it happens everywhere. So this is a nice", "tokens": [50724, 3571, 13, 492, 393, 360, 309, 294, 472, 1081, 293, 312, 988, 300, 309, 2314, 5315, 13, 407, 341, 307, 257, 1481, 50904], "temperature": 0.0, "avg_logprob": -0.0820714391843237, "compression_ratio": 1.5155555555555555, "no_speech_prob": 0.001726198592223227}, {"id": 134, "seek": 90968, "start": 920.4799999999999, "end": 928.56, "text": " refactor given the current state of affairs. So let's see if I did it right. Yeah, okay, cool.", "tokens": [50904, 1895, 15104, 2212, 264, 2190, 1785, 295, 17478, 13, 407, 718, 311, 536, 498, 286, 630, 309, 558, 13, 865, 11, 1392, 11, 1627, 13, 51308], "temperature": 0.0, "avg_logprob": -0.0820714391843237, "compression_ratio": 1.5155555555555555, "no_speech_prob": 0.001726198592223227}, {"id": 135, "seek": 90968, "start": 930.64, "end": 935.1999999999999, "text": " So we come back, we have this going. It's nice. And so we get a new feature,", "tokens": [51412, 407, 321, 808, 646, 11, 321, 362, 341, 516, 13, 467, 311, 1481, 13, 400, 370, 321, 483, 257, 777, 4111, 11, 51640], "temperature": 0.0, "avg_logprob": -0.0820714391843237, "compression_ratio": 1.5155555555555555, "no_speech_prob": 0.001726198592223227}, {"id": 136, "seek": 93520, "start": 936.08, "end": 941.5200000000001, "text": " which is autoplay customizations. So instead of just autoplay, we want people to be able to use", "tokens": [50408, 597, 307, 31090, 8376, 2375, 14455, 13, 407, 2602, 295, 445, 31090, 8376, 11, 321, 528, 561, 281, 312, 1075, 281, 764, 50680], "temperature": 0.0, "avg_logprob": -0.13226891818799472, "compression_ratio": 1.521505376344086, "no_speech_prob": 0.0037023441400378942}, {"id": 137, "seek": 93520, "start": 941.5200000000001, "end": 949.76, "text": " should it play audio by default? And should it play on Wi-Fi only or will people allow it on", "tokens": [50680, 820, 309, 862, 6278, 538, 7576, 30, 400, 820, 309, 862, 322, 14035, 12, 13229, 787, 420, 486, 561, 2089, 309, 322, 51092], "temperature": 0.0, "avg_logprob": -0.13226891818799472, "compression_ratio": 1.521505376344086, "no_speech_prob": 0.0037023441400378942}, {"id": 138, "seek": 93520, "start": 949.76, "end": 956.6400000000001, "text": " cellular data as well? So when we go back, the thing to look at is our model again. So one way", "tokens": [51092, 29267, 1412, 382, 731, 30, 407, 562, 321, 352, 646, 11, 264, 551, 281, 574, 412, 307, 527, 2316, 797, 13, 407, 472, 636, 51436], "temperature": 0.0, "avg_logprob": -0.13226891818799472, "compression_ratio": 1.521505376344086, "no_speech_prob": 0.0037023441400378942}, {"id": 139, "seek": 95664, "start": 956.64, "end": 964.8, "text": " to deal with this is, well, okay, we have two new things. So we have autoplay audio and autoplay", "tokens": [50364, 281, 2028, 365, 341, 307, 11, 731, 11, 1392, 11, 321, 362, 732, 777, 721, 13, 407, 321, 362, 31090, 8376, 6278, 293, 31090, 8376, 50772], "temperature": 0.0, "avg_logprob": -0.124235999584198, "compression_ratio": 1.516304347826087, "no_speech_prob": 0.026715261861681938}, {"id": 140, "seek": 95664, "start": 967.52, "end": 976.08, "text": " Wi-Fi. I'm going to call it without Wi-Fi. I don't know because it helps me understand", "tokens": [50908, 14035, 12, 13229, 13, 286, 478, 516, 281, 818, 309, 1553, 14035, 12, 13229, 13, 286, 500, 380, 458, 570, 309, 3665, 385, 1223, 51336], "temperature": 0.0, "avg_logprob": -0.124235999584198, "compression_ratio": 1.516304347826087, "no_speech_prob": 0.026715261861681938}, {"id": 141, "seek": 95664, "start": 976.08, "end": 982.24, "text": " what the bull would be. And then we can go mess with our view. But this is kind of lame because", "tokens": [51336, 437, 264, 4693, 576, 312, 13, 400, 550, 321, 393, 352, 2082, 365, 527, 1910, 13, 583, 341, 307, 733, 295, 27635, 570, 51644], "temperature": 0.0, "avg_logprob": -0.124235999584198, "compression_ratio": 1.516304347826087, "no_speech_prob": 0.026715261861681938}, {"id": 142, "seek": 98224, "start": 982.8, "end": 990.0, "text": " we can do it that way and a designer will say, well, I want it to be where if there's no video", "tokens": [50392, 321, 393, 360, 309, 300, 636, 293, 257, 11795, 486, 584, 11, 731, 11, 286, 528, 309, 281, 312, 689, 498, 456, 311, 572, 960, 50752], "temperature": 0.0, "avg_logprob": -0.14189978267835535, "compression_ratio": 1.6741071428571428, "no_speech_prob": 0.0008951114723458886}, {"id": 143, "seek": 98224, "start": 990.0, "end": 994.5600000000001, "text": " autoplay, then you can't mess with the autoplay settings. Like you're not doing that. So those", "tokens": [50752, 31090, 8376, 11, 550, 291, 393, 380, 2082, 365, 264, 31090, 8376, 6257, 13, 1743, 291, 434, 406, 884, 300, 13, 407, 729, 50980], "temperature": 0.0, "avg_logprob": -0.14189978267835535, "compression_ratio": 1.6741071428571428, "no_speech_prob": 0.0008951114723458886}, {"id": 144, "seek": 98224, "start": 994.5600000000001, "end": 1000.0, "text": " should be disabled. So suddenly we have this interaction between these three fields where", "tokens": [50980, 820, 312, 15191, 13, 407, 5800, 321, 362, 341, 9285, 1296, 613, 1045, 7909, 689, 51252], "temperature": 0.0, "avg_logprob": -0.14189978267835535, "compression_ratio": 1.6741071428571428, "no_speech_prob": 0.0008951114723458886}, {"id": 145, "seek": 98224, "start": 1001.92, "end": 1006.64, "text": " we always have to check autoplay before we show this and that determines whether it's disabled.", "tokens": [51348, 321, 1009, 362, 281, 1520, 31090, 8376, 949, 321, 855, 341, 293, 300, 24799, 1968, 309, 311, 15191, 13, 51584], "temperature": 0.0, "avg_logprob": -0.14189978267835535, "compression_ratio": 1.6741071428571428, "no_speech_prob": 0.0008951114723458886}, {"id": 146, "seek": 100664, "start": 1006.64, "end": 1011.68, "text": " So we're starting to get these dependencies. So a better way to represent this would be", "tokens": [50364, 407, 321, 434, 2891, 281, 483, 613, 36606, 13, 407, 257, 1101, 636, 281, 2906, 341, 576, 312, 50616], "temperature": 0.0, "avg_logprob": -0.12484631639845828, "compression_ratio": 1.328358208955224, "no_speech_prob": 0.0005876449868083}, {"id": 147, "seek": 100664, "start": 1012.4, "end": 1022.16, "text": " to just actually model it directly. So autoplay is offer on. And if it's on, there's audio", "tokens": [50652, 281, 445, 767, 2316, 309, 3838, 13, 407, 31090, 8376, 307, 2626, 322, 13, 400, 498, 309, 311, 322, 11, 456, 311, 6278, 51140], "temperature": 0.0, "avg_logprob": -0.12484631639845828, "compression_ratio": 1.328358208955224, "no_speech_prob": 0.0005876449868083}, {"id": 148, "seek": 102216, "start": 1023.12, "end": 1039.76, "text": " or without Wi-Fi. So in this version of reality, you can't mess with any of these options without", "tokens": [50412, 420, 1553, 14035, 12, 13229, 13, 407, 294, 341, 3037, 295, 4103, 11, 291, 393, 380, 2082, 365, 604, 295, 613, 3956, 1553, 51244], "temperature": 0.0, "avg_logprob": -0.11211950374099444, "compression_ratio": 1.4087591240875912, "no_speech_prob": 0.001224539359100163}, {"id": 149, "seek": 102216, "start": 1039.76, "end": 1045.36, "text": " pattern matching on or off. So if you want to change them, you have to say, okay, let me expand", "tokens": [51244, 5102, 14324, 322, 420, 766, 13, 407, 498, 291, 528, 281, 1319, 552, 11, 291, 362, 281, 584, 11, 1392, 11, 718, 385, 5268, 51524], "temperature": 0.0, "avg_logprob": -0.11211950374099444, "compression_ratio": 1.4087591240875912, "no_speech_prob": 0.001224539359100163}, {"id": 150, "seek": 104536, "start": 1045.4399999999998, "end": 1051.76, "text": " the autoplay. If it's off, oh, I don't need to deal with it. And that also means in your view,", "tokens": [50368, 264, 31090, 8376, 13, 759, 309, 311, 766, 11, 1954, 11, 286, 500, 380, 643, 281, 2028, 365, 309, 13, 400, 300, 611, 1355, 294, 428, 1910, 11, 50684], "temperature": 0.0, "avg_logprob": -0.12888717651367188, "compression_ratio": 1.6695652173913043, "no_speech_prob": 0.0193721242249012}, {"id": 151, "seek": 104536, "start": 1052.6399999999999, "end": 1056.6399999999999, "text": " you handle these two scenarios and you say, okay, is autoplay on? In which case, I can show these", "tokens": [50728, 291, 4813, 613, 732, 15077, 293, 291, 584, 11, 1392, 11, 307, 31090, 8376, 322, 30, 682, 597, 1389, 11, 286, 393, 855, 613, 50928], "temperature": 0.0, "avg_logprob": -0.12888717651367188, "compression_ratio": 1.6695652173913043, "no_speech_prob": 0.0193721242249012}, {"id": 152, "seek": 104536, "start": 1056.6399999999999, "end": 1062.7199999999998, "text": " things. If it's off, then I don't. So it's sort of forcing any future user of this code base", "tokens": [50928, 721, 13, 759, 309, 311, 766, 11, 550, 286, 500, 380, 13, 407, 309, 311, 1333, 295, 19030, 604, 2027, 4195, 295, 341, 3089, 3096, 51232], "temperature": 0.0, "avg_logprob": -0.12888717651367188, "compression_ratio": 1.6695652173913043, "no_speech_prob": 0.0193721242249012}, {"id": 153, "seek": 104536, "start": 1062.7199999999998, "end": 1070.1599999999999, "text": " to understand that there's a dependency between these fields. Now we say, okay, we'll show this to", "tokens": [51232, 281, 1223, 300, 456, 311, 257, 33621, 1296, 613, 7909, 13, 823, 321, 584, 11, 1392, 11, 321, 603, 855, 341, 281, 51604], "temperature": 0.0, "avg_logprob": -0.12888717651367188, "compression_ratio": 1.6695652173913043, "no_speech_prob": 0.0193721242249012}, {"id": 154, "seek": 107016, "start": 1070.16, "end": 1077.52, "text": " the designer again. But the thing is, if we turn things off, we lose all of our options. So we want", "tokens": [50364, 264, 11795, 797, 13, 583, 264, 551, 307, 11, 498, 321, 1261, 721, 766, 11, 321, 3624, 439, 295, 527, 3956, 13, 407, 321, 528, 50732], "temperature": 0.0, "avg_logprob": -0.0971532540443616, "compression_ratio": 1.5106382978723405, "no_speech_prob": 0.0076809353195130825}, {"id": 155, "seek": 107016, "start": 1077.52, "end": 1086.0, "text": " those to be preserved. Some users will toggle this a lot and it's annoying. So what we can do is say,", "tokens": [50732, 729, 281, 312, 22242, 13, 2188, 5022, 486, 31225, 341, 257, 688, 293, 309, 311, 11304, 13, 407, 437, 321, 393, 360, 307, 584, 11, 51156], "temperature": 0.0, "avg_logprob": -0.0971532540443616, "compression_ratio": 1.5106382978723405, "no_speech_prob": 0.0076809353195130825}, {"id": 156, "seek": 107016, "start": 1086.0, "end": 1098.3200000000002, "text": " okay, type alias autoplay settings. And then we can actually just have it on both,", "tokens": [51156, 1392, 11, 2010, 419, 4609, 31090, 8376, 6257, 13, 400, 550, 321, 393, 767, 445, 362, 309, 322, 1293, 11, 51772], "temperature": 0.0, "avg_logprob": -0.0971532540443616, "compression_ratio": 1.5106382978723405, "no_speech_prob": 0.0076809353195130825}, {"id": 157, "seek": 109832, "start": 1098.32, "end": 1103.04, "text": " but still force people to go through the on off check before you're doing any logic.", "tokens": [50364, 457, 920, 3464, 561, 281, 352, 807, 264, 322, 766, 1520, 949, 291, 434, 884, 604, 9952, 13, 50600], "temperature": 0.0, "avg_logprob": -0.12067139148712158, "compression_ratio": 1.6320754716981132, "no_speech_prob": 0.0004165537829976529}, {"id": 158, "seek": 109832, "start": 1105.2, "end": 1108.3999999999999, "text": " So and then this will play out throughout the course of the code. We can", "tokens": [50708, 407, 293, 550, 341, 486, 862, 484, 3710, 264, 1164, 295, 264, 3089, 13, 492, 393, 50868], "temperature": 0.0, "avg_logprob": -0.12067139148712158, "compression_ratio": 1.6320754716981132, "no_speech_prob": 0.0004165537829976529}, {"id": 159, "seek": 109832, "start": 1114.24, "end": 1119.28, "text": " a way to approach this was, well, now we have this autoplay idea. Maybe we can start to write", "tokens": [51160, 257, 636, 281, 3109, 341, 390, 11, 731, 11, 586, 321, 362, 341, 31090, 8376, 1558, 13, 2704, 321, 393, 722, 281, 2464, 51412], "temperature": 0.0, "avg_logprob": -0.12067139148712158, "compression_ratio": 1.6320754716981132, "no_speech_prob": 0.0004165537829976529}, {"id": 160, "seek": 109832, "start": 1119.28, "end": 1124.8799999999999, "text": " some helper functions to make it nice to work with. So maybe we can say toggle autoplay and it", "tokens": [51412, 512, 36133, 6828, 281, 652, 309, 1481, 281, 589, 365, 13, 407, 1310, 321, 393, 584, 31225, 31090, 8376, 293, 309, 51692], "temperature": 0.0, "avg_logprob": -0.12067139148712158, "compression_ratio": 1.6320754716981132, "no_speech_prob": 0.0004165537829976529}, {"id": 161, "seek": 112488, "start": 1124.96, "end": 1129.68, "text": " switches between on and off in a nice way. And so as we create these helper functions, we start to", "tokens": [50368, 19458, 1296, 322, 293, 766, 294, 257, 1481, 636, 13, 400, 370, 382, 321, 1884, 613, 36133, 6828, 11, 321, 722, 281, 50604], "temperature": 0.0, "avg_logprob": -0.09226742176094441, "compression_ratio": 1.703862660944206, "no_speech_prob": 0.000881493091583252}, {"id": 162, "seek": 112488, "start": 1129.68, "end": 1134.96, "text": " have functions that are all built around the data structure, which is that pattern I was talking about.", "tokens": [50604, 362, 6828, 300, 366, 439, 3094, 926, 264, 1412, 3877, 11, 597, 307, 300, 5102, 286, 390, 1417, 466, 13, 50868], "temperature": 0.0, "avg_logprob": -0.09226742176094441, "compression_ratio": 1.703862660944206, "no_speech_prob": 0.000881493091583252}, {"id": 163, "seek": 112488, "start": 1134.96, "end": 1140.0, "text": " So once you start to see these kinds of chunks of code, you get these units that can break out and", "tokens": [50868, 407, 1564, 291, 722, 281, 536, 613, 3685, 295, 24004, 295, 3089, 11, 291, 483, 613, 6815, 300, 393, 1821, 484, 293, 51120], "temperature": 0.0, "avg_logprob": -0.09226742176094441, "compression_ratio": 1.703862660944206, "no_speech_prob": 0.000881493091583252}, {"id": 164, "seek": 112488, "start": 1140.0, "end": 1150.3200000000002, "text": " make your code nicer. Okay. So we have that going. So now we come to fruits. And at this point,", "tokens": [51120, 652, 428, 3089, 22842, 13, 1033, 13, 407, 321, 362, 300, 516, 13, 407, 586, 321, 808, 281, 12148, 13, 400, 412, 341, 935, 11, 51636], "temperature": 0.0, "avg_logprob": -0.09226742176094441, "compression_ratio": 1.703862660944206, "no_speech_prob": 0.000881493091583252}, {"id": 165, "seek": 115032, "start": 1150.32, "end": 1153.2, "text": " the question asked yourself is like, do you think it's going to work out the same way?", "tokens": [50364, 264, 1168, 2351, 1803, 307, 411, 11, 360, 291, 519, 309, 311, 516, 281, 589, 484, 264, 912, 636, 30, 50508], "temperature": 0.0, "avg_logprob": -0.13302873571713766, "compression_ratio": 1.6304347826086956, "no_speech_prob": 0.0027528274804353714}, {"id": 166, "seek": 115032, "start": 1155.84, "end": 1161.12, "text": " So yeah, so let's take a look. So again, we can choose between different data structures and", "tokens": [50640, 407, 1338, 11, 370, 718, 311, 747, 257, 574, 13, 407, 797, 11, 321, 393, 2826, 1296, 819, 1412, 9227, 293, 50904], "temperature": 0.0, "avg_logprob": -0.13302873571713766, "compression_ratio": 1.6304347826086956, "no_speech_prob": 0.0027528274804353714}, {"id": 167, "seek": 115032, "start": 1161.76, "end": 1168.24, "text": " I picked the same ones. So record, list of things, dictionary, the list of options and which ones", "tokens": [50936, 286, 6183, 264, 912, 2306, 13, 407, 2136, 11, 1329, 295, 721, 11, 25890, 11, 264, 1329, 295, 3956, 293, 597, 2306, 51260], "temperature": 0.0, "avg_logprob": -0.13302873571713766, "compression_ratio": 1.6304347826086956, "no_speech_prob": 0.0027528274804353714}, {"id": 168, "seek": 115032, "start": 1168.24, "end": 1177.4399999999998, "text": " are selected. So in this case, our constraints are very different. So we work at like fruits.com,", "tokens": [51260, 366, 8209, 13, 407, 294, 341, 1389, 11, 527, 18491, 366, 588, 819, 13, 407, 321, 589, 412, 411, 12148, 13, 1112, 11, 51720], "temperature": 0.0, "avg_logprob": -0.13302873571713766, "compression_ratio": 1.6304347826086956, "no_speech_prob": 0.0027528274804353714}, {"id": 169, "seek": 117744, "start": 1177.44, "end": 1183.92, "text": " I don't know. And the fruit availability, it's seasonal. We want to bring you the freshest", "tokens": [50364, 286, 500, 380, 458, 13, 400, 264, 6773, 17945, 11, 309, 311, 27421, 13, 492, 528, 281, 1565, 291, 264, 4451, 377, 50688], "temperature": 0.0, "avg_logprob": -0.11855275432268779, "compression_ratio": 1.581896551724138, "no_speech_prob": 0.000430089799920097}, {"id": 170, "seek": 117744, "start": 1183.92, "end": 1190.3200000000002, "text": " seasonal fruits for your region. And like maybe we're out of bananas today. So we don't want to", "tokens": [50688, 27421, 12148, 337, 428, 4458, 13, 400, 411, 1310, 321, 434, 484, 295, 22742, 965, 13, 407, 321, 500, 380, 528, 281, 51008], "temperature": 0.0, "avg_logprob": -0.11855275432268779, "compression_ratio": 1.581896551724138, "no_speech_prob": 0.000430089799920097}, {"id": 171, "seek": 117744, "start": 1190.3200000000002, "end": 1195.2, "text": " just let people say, oh, I definitely only want bananas. I'm sorry. Here's a mango.", "tokens": [51008, 445, 718, 561, 584, 11, 1954, 11, 286, 2138, 787, 528, 22742, 13, 286, 478, 2597, 13, 1692, 311, 257, 23481, 13, 51252], "temperature": 0.0, "avg_logprob": -0.11855275432268779, "compression_ratio": 1.581896551724138, "no_speech_prob": 0.000430089799920097}, {"id": 172, "seek": 117744, "start": 1198.16, "end": 1204.8, "text": " So if we use a record, does that mean we would have to ship code every time availability changed", "tokens": [51400, 407, 498, 321, 764, 257, 2136, 11, 775, 300, 914, 321, 576, 362, 281, 5374, 3089, 633, 565, 17945, 3105, 51732], "temperature": 0.0, "avg_logprob": -0.11855275432268779, "compression_ratio": 1.581896551724138, "no_speech_prob": 0.000430089799920097}, {"id": 173, "seek": 120480, "start": 1204.8, "end": 1211.76, "text": " in a particular region? So that doesn't seem great. But in all these others, we can just load", "tokens": [50364, 294, 257, 1729, 4458, 30, 407, 300, 1177, 380, 1643, 869, 13, 583, 294, 439, 613, 2357, 11, 321, 393, 445, 3677, 50712], "temperature": 0.0, "avg_logprob": -0.10129791799217763, "compression_ratio": 1.5738396624472575, "no_speech_prob": 0.001063252566382289}, {"id": 174, "seek": 120480, "start": 1211.76, "end": 1218.8, "text": " the options from the server. That seems like a benefit. From there, one thing we might consider", "tokens": [50712, 264, 3956, 490, 264, 7154, 13, 663, 2544, 411, 257, 5121, 13, 3358, 456, 11, 472, 551, 321, 1062, 1949, 51064], "temperature": 0.0, "avg_logprob": -0.10129791799217763, "compression_ratio": 1.5738396624472575, "no_speech_prob": 0.001063252566382289}, {"id": 175, "seek": 120480, "start": 1218.8, "end": 1223.44, "text": " is, well, which of these will be easier to just use? Which one will the code come out nicer?", "tokens": [51064, 307, 11, 731, 11, 597, 295, 613, 486, 312, 3571, 281, 445, 764, 30, 3013, 472, 486, 264, 3089, 808, 484, 22842, 30, 51296], "temperature": 0.0, "avg_logprob": -0.10129791799217763, "compression_ratio": 1.5738396624472575, "no_speech_prob": 0.001063252566382289}, {"id": 176, "seek": 120480, "start": 1223.44, "end": 1228.32, "text": " So in this case, we'll probably use list.map to do an update. We can scan through and say,", "tokens": [51296, 407, 294, 341, 1389, 11, 321, 603, 1391, 764, 1329, 13, 24223, 281, 360, 364, 5623, 13, 492, 393, 11049, 807, 293, 584, 11, 51540], "temperature": 0.0, "avg_logprob": -0.10129791799217763, "compression_ratio": 1.5738396624472575, "no_speech_prob": 0.001063252566382289}, {"id": 177, "seek": 122832, "start": 1228.3999999999999, "end": 1235.28, "text": " if it's this fruit, then I'll toggle it or not. With dictionary, you can use update and say,", "tokens": [50368, 498, 309, 311, 341, 6773, 11, 550, 286, 603, 31225, 309, 420, 406, 13, 2022, 25890, 11, 291, 393, 764, 5623, 293, 584, 11, 50712], "temperature": 0.0, "avg_logprob": -0.0906223333798922, "compression_ratio": 1.735159817351598, "no_speech_prob": 0.0027542526368051767}, {"id": 178, "seek": 122832, "start": 1235.28, "end": 1243.12, "text": " okay, I want to change this particular fruit. And with this one, we can use set, insert and", "tokens": [50712, 1392, 11, 286, 528, 281, 1319, 341, 1729, 6773, 13, 400, 365, 341, 472, 11, 321, 393, 764, 992, 11, 8969, 293, 51104], "temperature": 0.0, "avg_logprob": -0.0906223333798922, "compression_ratio": 1.735159817351598, "no_speech_prob": 0.0027542526368051767}, {"id": 179, "seek": 122832, "start": 1243.12, "end": 1247.52, "text": " remove. So we don't have to ever mess with this. We can just say, okay, they want to add this to", "tokens": [51104, 4159, 13, 407, 321, 500, 380, 362, 281, 1562, 2082, 365, 341, 13, 492, 393, 445, 584, 11, 1392, 11, 436, 528, 281, 909, 341, 281, 51324], "temperature": 0.0, "avg_logprob": -0.0906223333798922, "compression_ratio": 1.735159817351598, "no_speech_prob": 0.0027542526368051767}, {"id": 180, "seek": 122832, "start": 1247.52, "end": 1254.32, "text": " their set of their selected set, and they want to remove that one. And again, we have the ordering", "tokens": [51324, 641, 992, 295, 641, 8209, 992, 11, 293, 436, 528, 281, 4159, 300, 472, 13, 400, 797, 11, 321, 362, 264, 21739, 51664], "temperature": 0.0, "avg_logprob": -0.0906223333798922, "compression_ratio": 1.735159817351598, "no_speech_prob": 0.0027542526368051767}, {"id": 181, "seek": 125432, "start": 1254.32, "end": 1263.6, "text": " problems from before where maybe our head of fruit marketing is like, we need to put bananas up at", "tokens": [50364, 2740, 490, 949, 689, 1310, 527, 1378, 295, 6773, 6370, 307, 411, 11, 321, 643, 281, 829, 22742, 493, 412, 50828], "temperature": 0.0, "avg_logprob": -0.12494759863995492, "compression_ratio": 1.7079646017699115, "no_speech_prob": 0.01824367418885231}, {"id": 182, "seek": 125432, "start": 1263.6, "end": 1272.1599999999999, "text": " the top because that's higher margin, and that's what we're all about here at fruits.com. Or maybe", "tokens": [50828, 264, 1192, 570, 300, 311, 2946, 10270, 11, 293, 300, 311, 437, 321, 434, 439, 466, 510, 412, 12148, 13, 1112, 13, 1610, 1310, 51256], "temperature": 0.0, "avg_logprob": -0.12494759863995492, "compression_ratio": 1.7079646017699115, "no_speech_prob": 0.01824367418885231}, {"id": 183, "seek": 125432, "start": 1272.1599999999999, "end": 1276.8799999999999, "text": " someone else is like, well, we really should put mangoes up at the top, think about the nutritional", "tokens": [51256, 1580, 1646, 307, 411, 11, 731, 11, 321, 534, 820, 829, 23481, 279, 493, 412, 264, 1192, 11, 519, 466, 264, 34707, 51492], "temperature": 0.0, "avg_logprob": -0.12494759863995492, "compression_ratio": 1.7079646017699115, "no_speech_prob": 0.01824367418885231}, {"id": 184, "seek": 125432, "start": 1276.8799999999999, "end": 1284.0, "text": " content, think about the bottom line. So there might be some need to change this around.", "tokens": [51492, 2701, 11, 519, 466, 264, 2767, 1622, 13, 407, 456, 1062, 312, 512, 643, 281, 1319, 341, 926, 13, 51848], "temperature": 0.0, "avg_logprob": -0.12494759863995492, "compression_ratio": 1.7079646017699115, "no_speech_prob": 0.01824367418885231}, {"id": 185, "seek": 128432, "start": 1284.32, "end": 1288.56, "text": " Perhaps dynamically. So again, dictionary isn't ideal for that kind of scenario.", "tokens": [50364, 10517, 43492, 13, 407, 797, 11, 25890, 1943, 380, 7157, 337, 300, 733, 295, 9005, 13, 50576], "temperature": 0.0, "avg_logprob": -0.10216663224356515, "compression_ratio": 1.5138121546961325, "no_speech_prob": 0.0004166955186519772}, {"id": 186, "seek": 128432, "start": 1290.0, "end": 1298.3999999999999, "text": " So let's go with this one where it'll be kind of nice to add and remove things to the selection,", "tokens": [50648, 407, 718, 311, 352, 365, 341, 472, 689, 309, 603, 312, 733, 295, 1481, 281, 909, 293, 4159, 721, 281, 264, 9450, 11, 51068], "temperature": 0.0, "avg_logprob": -0.10216663224356515, "compression_ratio": 1.5138121546961325, "no_speech_prob": 0.0004166955186519772}, {"id": 187, "seek": 128432, "start": 1298.3999999999999, "end": 1305.9199999999998, "text": " and we can mess with the order quite easily. Okay, so now we can go look at our fruit situation.", "tokens": [51068, 293, 321, 393, 2082, 365, 264, 1668, 1596, 3612, 13, 1033, 11, 370, 586, 321, 393, 352, 574, 412, 527, 6773, 2590, 13, 51444], "temperature": 0.0, "avg_logprob": -0.10216663224356515, "compression_ratio": 1.5138121546961325, "no_speech_prob": 0.0004166955186519772}, {"id": 188, "seek": 130592, "start": 1306.0, "end": 1316.24, "text": " Which, and then we can just select, it's great. And if we look at how this goes,", "tokens": [50368, 3013, 11, 293, 550, 321, 393, 445, 3048, 11, 309, 311, 869, 13, 400, 498, 321, 574, 412, 577, 341, 1709, 11, 50880], "temperature": 0.0, "avg_logprob": -0.15087244033813477, "compression_ratio": 1.4094488188976377, "no_speech_prob": 0.0030737968627363443}, {"id": 189, "seek": 130592, "start": 1319.1200000000001, "end": 1327.04, "text": " we have our fruit list, which is very stable, and then selected, which is changing as we mess with", "tokens": [51024, 321, 362, 527, 6773, 1329, 11, 597, 307, 588, 8351, 11, 293, 550, 8209, 11, 597, 307, 4473, 382, 321, 2082, 365, 51420], "temperature": 0.0, "avg_logprob": -0.15087244033813477, "compression_ratio": 1.4094488188976377, "no_speech_prob": 0.0030737968627363443}, {"id": 190, "seek": 132704, "start": 1327.04, "end": 1343.44, "text": " stuff. Okay, so let's check out how this code works. Fruits. Okay, so in our model we say", "tokens": [50364, 1507, 13, 1033, 11, 370, 718, 311, 1520, 484, 577, 341, 3089, 1985, 13, 479, 894, 1208, 13, 1033, 11, 370, 294, 527, 2316, 321, 584, 51184], "temperature": 0.0, "avg_logprob": -0.11507792350573418, "compression_ratio": 1.518716577540107, "no_speech_prob": 0.0022500939667224884}, {"id": 191, "seek": 132704, "start": 1344.24, "end": 1349.92, "text": " we have two things, the fruits that are available, and the ones that are selected. And for our", "tokens": [51224, 321, 362, 732, 721, 11, 264, 12148, 300, 366, 2435, 11, 293, 264, 2306, 300, 366, 8209, 13, 400, 337, 527, 51508], "temperature": 0.0, "avg_logprob": -0.11507792350573418, "compression_ratio": 1.518716577540107, "no_speech_prob": 0.0022500939667224884}, {"id": 192, "seek": 132704, "start": 1349.92, "end": 1355.84, "text": " initial model, we're just pre-populating with some fruits, but you could load this from the server.", "tokens": [51508, 5883, 2316, 11, 321, 434, 445, 659, 12, 13872, 12162, 365, 512, 12148, 11, 457, 291, 727, 3677, 341, 490, 264, 7154, 13, 51804], "temperature": 0.0, "avg_logprob": -0.11507792350573418, "compression_ratio": 1.518716577540107, "no_speech_prob": 0.0022500939667224884}, {"id": 193, "seek": 135584, "start": 1356.8, "end": 1366.24, "text": " And our selected set is none are selected. And then update logic, appreciate forward. If a fruit", "tokens": [50412, 400, 527, 8209, 992, 307, 6022, 366, 8209, 13, 400, 550, 5623, 9952, 11, 4449, 2128, 13, 759, 257, 6773, 50884], "temperature": 0.0, "avg_logprob": -0.1363650606824206, "compression_ratio": 1.6529411764705881, "no_speech_prob": 0.0006663335370831192}, {"id": 194, "seek": 135584, "start": 1366.24, "end": 1370.9599999999998, "text": " is selected, add it to the selected set. If it's deselected, remove it from the selected set.", "tokens": [50884, 307, 8209, 11, 909, 309, 281, 264, 8209, 992, 13, 759, 309, 311, 730, 14664, 292, 11, 4159, 309, 490, 264, 8209, 992, 13, 51120], "temperature": 0.0, "avg_logprob": -0.1363650606824206, "compression_ratio": 1.6529411764705881, "no_speech_prob": 0.0006663335370831192}, {"id": 195, "seek": 135584, "start": 1372.6399999999999, "end": 1380.3999999999999, "text": " And then is this going to fit? Okay, cool. So in our view code, we again have a field set.", "tokens": [51204, 400, 550, 307, 341, 516, 281, 3318, 30, 1033, 11, 1627, 13, 407, 294, 527, 1910, 3089, 11, 321, 797, 362, 257, 2519, 992, 13, 51592], "temperature": 0.0, "avg_logprob": -0.1363650606824206, "compression_ratio": 1.6529411764705881, "no_speech_prob": 0.0006663335370831192}, {"id": 196, "seek": 138040, "start": 1381.0400000000002, "end": 1388.3200000000002, "text": " Okay, you can see the mouse here. We have our field set, and then we're mapping over all the", "tokens": [50396, 1033, 11, 291, 393, 536, 264, 9719, 510, 13, 492, 362, 527, 2519, 992, 11, 293, 550, 321, 434, 18350, 670, 439, 264, 50760], "temperature": 0.0, "avg_logprob": -0.1061172848656064, "compression_ratio": 1.6460176991150441, "no_speech_prob": 0.0005437302752397954}, {"id": 197, "seek": 138040, "start": 1388.3200000000002, "end": 1396.16, "text": " fruits. And so when we do that, we say, okay, I have a fruit. Is it in the selected fruit set?", "tokens": [50760, 12148, 13, 400, 370, 562, 321, 360, 300, 11, 321, 584, 11, 1392, 11, 286, 362, 257, 6773, 13, 1119, 309, 294, 264, 8209, 6773, 992, 30, 51152], "temperature": 0.0, "avg_logprob": -0.1061172848656064, "compression_ratio": 1.6460176991150441, "no_speech_prob": 0.0005437302752397954}, {"id": 198, "seek": 138040, "start": 1396.16, "end": 1402.48, "text": " If so, it's checked. And then we draw things in a way that looks quite similar to what we saw", "tokens": [51152, 759, 370, 11, 309, 311, 10033, 13, 400, 550, 321, 2642, 721, 294, 257, 636, 300, 1542, 1596, 2531, 281, 437, 321, 1866, 51468], "temperature": 0.0, "avg_logprob": -0.1061172848656064, "compression_ratio": 1.6460176991150441, "no_speech_prob": 0.0005437302752397954}, {"id": 199, "seek": 138040, "start": 1402.48, "end": 1408.0, "text": " in the previous example. So it's checkbox, whether it's checked or not, what the title is.", "tokens": [51468, 294, 264, 3894, 1365, 13, 407, 309, 311, 1520, 4995, 11, 1968, 309, 311, 10033, 420, 406, 11, 437, 264, 4876, 307, 13, 51744], "temperature": 0.0, "avg_logprob": -0.1061172848656064, "compression_ratio": 1.6460176991150441, "no_speech_prob": 0.0005437302752397954}, {"id": 200, "seek": 141040, "start": 1410.5600000000002, "end": 1415.8400000000001, "text": " But the thing that's actually interesting about this code isn't the shared part. The part that", "tokens": [50372, 583, 264, 551, 300, 311, 767, 1880, 466, 341, 3089, 1943, 380, 264, 5507, 644, 13, 440, 644, 300, 50636], "temperature": 0.0, "avg_logprob": -0.09885592209665399, "compression_ratio": 1.644927536231884, "no_speech_prob": 0.000519005348905921}, {"id": 201, "seek": 141040, "start": 1415.8400000000001, "end": 1422.48, "text": " they have in common is, like, whatever, seven lines. It's not very crazy. And the chances that", "tokens": [50636, 436, 362, 294, 2689, 307, 11, 411, 11, 2035, 11, 3407, 3876, 13, 467, 311, 406, 588, 3219, 13, 400, 264, 10486, 300, 50968], "temperature": 0.0, "avg_logprob": -0.09885592209665399, "compression_ratio": 1.644927536231884, "no_speech_prob": 0.000519005348905921}, {"id": 202, "seek": 141040, "start": 1422.48, "end": 1427.1200000000001, "text": " they're going to stay exactly the same between these two different chunks of code is very low.", "tokens": [50968, 436, 434, 516, 281, 1754, 2293, 264, 912, 1296, 613, 732, 819, 24004, 295, 3089, 307, 588, 2295, 13, 51200], "temperature": 0.0, "avg_logprob": -0.09885592209665399, "compression_ratio": 1.644927536231884, "no_speech_prob": 0.000519005348905921}, {"id": 203, "seek": 141040, "start": 1427.1200000000001, "end": 1432.64, "text": " So thinking, like, focusing on just this, like, oh, I've seen a checkbox before somewhere.", "tokens": [51200, 407, 1953, 11, 411, 11, 8416, 322, 445, 341, 11, 411, 11, 1954, 11, 286, 600, 1612, 257, 1520, 4995, 949, 4079, 13, 51476], "temperature": 0.0, "avg_logprob": -0.09885592209665399, "compression_ratio": 1.644927536231884, "no_speech_prob": 0.000519005348905921}, {"id": 204, "seek": 141040, "start": 1433.8400000000001, "end": 1437.76, "text": " Like, doesn't really give you a lot in terms of the structure of your program.", "tokens": [51536, 1743, 11, 1177, 380, 534, 976, 291, 257, 688, 294, 2115, 295, 264, 3877, 295, 428, 1461, 13, 51732], "temperature": 0.0, "avg_logprob": -0.09885592209665399, "compression_ratio": 1.644927536231884, "no_speech_prob": 0.000519005348905921}, {"id": 205, "seek": 143776, "start": 1437.84, "end": 1444.0, "text": " So at this point, we have a pretty good fruit set going on, fruit.com, business is booming,", "tokens": [50368, 407, 412, 341, 935, 11, 321, 362, 257, 1238, 665, 6773, 992, 516, 322, 11, 6773, 13, 1112, 11, 1606, 307, 45883, 11, 50676], "temperature": 0.0, "avg_logprob": -0.13401166598002115, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.0005354780005291104}, {"id": 206, "seek": 143776, "start": 1444.8, "end": 1452.32, "text": " margins are good. Okay, but a new feature comes along, which is only two fruits can be selected.", "tokens": [50716, 30317, 366, 665, 13, 1033, 11, 457, 257, 777, 4111, 1487, 2051, 11, 597, 307, 787, 732, 12148, 393, 312, 8209, 13, 51092], "temperature": 0.0, "avg_logprob": -0.13401166598002115, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.0005354780005291104}, {"id": 207, "seek": 143776, "start": 1452.32, "end": 1456.24, "text": " We have all these folks out there who want, like, three fruits, six fruits even.", "tokens": [51092, 492, 362, 439, 613, 4024, 484, 456, 567, 528, 11, 411, 11, 1045, 12148, 11, 2309, 12148, 754, 13, 51288], "temperature": 0.0, "avg_logprob": -0.13401166598002115, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.0005354780005291104}, {"id": 208, "seek": 143776, "start": 1457.84, "end": 1460.56, "text": " We don't have the distribution channels for that.", "tokens": [51368, 492, 500, 380, 362, 264, 7316, 9235, 337, 300, 13, 51504], "temperature": 0.0, "avg_logprob": -0.13401166598002115, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.0005354780005291104}, {"id": 209, "seek": 146056, "start": 1461.12, "end": 1468.8, "text": " So we want to cap out at two fruits per person, you know, pick a favorite, like, pick a side.", "tokens": [50392, 407, 321, 528, 281, 1410, 484, 412, 732, 12148, 680, 954, 11, 291, 458, 11, 1888, 257, 2954, 11, 411, 11, 1888, 257, 1252, 13, 50776], "temperature": 0.0, "avg_logprob": -0.13051557540893555, "compression_ratio": 1.5393258426966292, "no_speech_prob": 0.0015237756306305528}, {"id": 210, "seek": 146056, "start": 1471.36, "end": 1478.8, "text": " So this is kind of a tricky situation we have found ourselves in. So we have this set,", "tokens": [50904, 407, 341, 307, 733, 295, 257, 12414, 2590, 321, 362, 1352, 4175, 294, 13, 407, 321, 362, 341, 992, 11, 51276], "temperature": 0.0, "avg_logprob": -0.13051557540893555, "compression_ratio": 1.5393258426966292, "no_speech_prob": 0.0015237756306305528}, {"id": 211, "seek": 146056, "start": 1478.8, "end": 1485.28, "text": " and we kind of need to limit the size somehow. Oh, oh, there's one other constraint, which is", "tokens": [51276, 293, 321, 733, 295, 643, 281, 4948, 264, 2744, 6063, 13, 876, 11, 1954, 11, 456, 311, 472, 661, 25534, 11, 597, 307, 51600], "temperature": 0.0, "avg_logprob": -0.13051557540893555, "compression_ratio": 1.5393258426966292, "no_speech_prob": 0.0015237756306305528}, {"id": 212, "seek": 148528, "start": 1485.28, "end": 1494.56, "text": " we need to check out a different fruit. No. Fruit's one, maybe. No.", "tokens": [50364, 321, 643, 281, 1520, 484, 257, 819, 6773, 13, 883, 13, 39989, 311, 472, 11, 1310, 13, 883, 13, 50828], "temperature": 0.0, "avg_logprob": -0.14274722735087078, "compression_ratio": 1.4563758389261745, "no_speech_prob": 0.0003682099049910903}, {"id": 213, "seek": 148528, "start": 1498.8799999999999, "end": 1501.36, "text": " Okay, I deleted a file that I should not have deleted.", "tokens": [51044, 1033, 11, 286, 22981, 257, 3991, 300, 286, 820, 406, 362, 22981, 13, 51168], "temperature": 0.0, "avg_logprob": -0.14274722735087078, "compression_ratio": 1.4563758389261745, "no_speech_prob": 0.0003682099049910903}, {"id": 214, "seek": 148528, "start": 1504.16, "end": 1510.48, "text": " But the thing that I wanted to show was we want to maintain the order that they were selected.", "tokens": [51308, 583, 264, 551, 300, 286, 1415, 281, 855, 390, 321, 528, 281, 6909, 264, 1668, 300, 436, 645, 8209, 13, 51624], "temperature": 0.0, "avg_logprob": -0.14274722735087078, "compression_ratio": 1.4563758389261745, "no_speech_prob": 0.0003682099049910903}, {"id": 215, "seek": 151048, "start": 1510.48, "end": 1515.52, "text": " So if I select apple, then apricot, then banana, I want the oldest thing to be the one that's", "tokens": [50364, 407, 498, 286, 3048, 10606, 11, 550, 1882, 1341, 310, 11, 550, 14194, 11, 286, 528, 264, 14026, 551, 281, 312, 264, 472, 300, 311, 50616], "temperature": 0.0, "avg_logprob": -0.07683156716703164, "compression_ratio": 1.6682027649769586, "no_speech_prob": 0.00043683918192982674}, {"id": 216, "seek": 151048, "start": 1515.52, "end": 1520.4, "text": " forgotten. So I want to keep the most recently selected as I go through things.", "tokens": [50616, 11832, 13, 407, 286, 528, 281, 1066, 264, 881, 3938, 8209, 382, 286, 352, 807, 721, 13, 50860], "temperature": 0.0, "avg_logprob": -0.07683156716703164, "compression_ratio": 1.6682027649769586, "no_speech_prob": 0.00043683918192982674}, {"id": 217, "seek": 151048, "start": 1523.76, "end": 1529.1200000000001, "text": " So with a set, it's really hard to keep track of what was the order that things were added. We", "tokens": [51028, 407, 365, 257, 992, 11, 309, 311, 534, 1152, 281, 1066, 2837, 295, 437, 390, 264, 1668, 300, 721, 645, 3869, 13, 492, 51296], "temperature": 0.0, "avg_logprob": -0.07683156716703164, "compression_ratio": 1.6682027649769586, "no_speech_prob": 0.00043683918192982674}, {"id": 218, "seek": 151048, "start": 1529.1200000000001, "end": 1533.28, "text": " can remove one of the things, but we don't know which of the two it was. You'll get this very", "tokens": [51296, 393, 4159, 472, 295, 264, 721, 11, 457, 321, 500, 380, 458, 597, 295, 264, 732, 309, 390, 13, 509, 603, 483, 341, 588, 51504], "temperature": 0.0, "avg_logprob": -0.07683156716703164, "compression_ratio": 1.6682027649769586, "no_speech_prob": 0.00043683918192982674}, {"id": 219, "seek": 153328, "start": 1533.28, "end": 1541.28, "text": " wonky behavior. So at this point, we can ask, well, maybe it'd be good to think about the", "tokens": [50364, 1582, 4133, 5223, 13, 407, 412, 341, 935, 11, 321, 393, 1029, 11, 731, 11, 1310, 309, 1116, 312, 665, 281, 519, 466, 264, 50764], "temperature": 0.0, "avg_logprob": -0.0777545417706991, "compression_ratio": 1.6294642857142858, "no_speech_prob": 0.0030684485100209713}, {"id": 220, "seek": 153328, "start": 1541.28, "end": 1546.16, "text": " data structure we're using. So we want to choose two fruits in particular. So maybe we say, okay,", "tokens": [50764, 1412, 3877, 321, 434, 1228, 13, 407, 321, 528, 281, 2826, 732, 12148, 294, 1729, 13, 407, 1310, 321, 584, 11, 1392, 11, 51008], "temperature": 0.0, "avg_logprob": -0.0777545417706991, "compression_ratio": 1.6294642857142858, "no_speech_prob": 0.0030684485100209713}, {"id": 221, "seek": 153328, "start": 1546.16, "end": 1552.6399999999999, "text": " so I'm going to choose a string and a string. But what happens when nothing's selected? We", "tokens": [51008, 370, 286, 478, 516, 281, 2826, 257, 6798, 293, 257, 6798, 13, 583, 437, 2314, 562, 1825, 311, 8209, 30, 492, 51332], "temperature": 0.0, "avg_logprob": -0.0777545417706991, "compression_ratio": 1.6294642857142858, "no_speech_prob": 0.0030684485100209713}, {"id": 222, "seek": 153328, "start": 1552.6399999999999, "end": 1556.72, "text": " need to account for zero selections, one selection, two selections. So that's no good.", "tokens": [51332, 643, 281, 2696, 337, 4018, 47829, 11, 472, 9450, 11, 732, 47829, 13, 407, 300, 311, 572, 665, 13, 51536], "temperature": 0.0, "avg_logprob": -0.0777545417706991, "compression_ratio": 1.6294642857142858, "no_speech_prob": 0.0030684485100209713}, {"id": 223, "seek": 155672, "start": 1557.44, "end": 1559.2, "text": " Maybe we can say maybe string.", "tokens": [50400, 2704, 321, 393, 584, 1310, 6798, 13, 50488], "temperature": 0.0, "avg_logprob": -0.10950487509541128, "compression_ratio": 1.6649214659685865, "no_speech_prob": 0.002885053399950266}, {"id": 224, "seek": 155672, "start": 1562.72, "end": 1568.4, "text": " So all of these can be optionally selected. But there's this weird case where if one thing is", "tokens": [50664, 407, 439, 295, 613, 393, 312, 3614, 379, 8209, 13, 583, 456, 311, 341, 3657, 1389, 689, 498, 472, 551, 307, 50948], "temperature": 0.0, "avg_logprob": -0.10950487509541128, "compression_ratio": 1.6649214659685865, "no_speech_prob": 0.002885053399950266}, {"id": 225, "seek": 155672, "start": 1568.4, "end": 1574.08, "text": " selected, we don't know if it's going to be the left or the right thing. So this doesn't seem great", "tokens": [50948, 8209, 11, 321, 500, 380, 458, 498, 309, 311, 516, 281, 312, 264, 1411, 420, 264, 558, 551, 13, 407, 341, 1177, 380, 1643, 869, 51232], "temperature": 0.0, "avg_logprob": -0.10950487509541128, "compression_ratio": 1.6649214659685865, "no_speech_prob": 0.002885053399950266}, {"id": 226, "seek": 155672, "start": 1574.08, "end": 1583.84, "text": " either. So maybe we can say, okay, there should be this type two, and it's either zero or one", "tokens": [51232, 2139, 13, 407, 1310, 321, 393, 584, 11, 1392, 11, 456, 820, 312, 341, 2010, 732, 11, 293, 309, 311, 2139, 4018, 420, 472, 51720], "temperature": 0.0, "avg_logprob": -0.10950487509541128, "compression_ratio": 1.6649214659685865, "no_speech_prob": 0.002885053399950266}, {"id": 227, "seek": 158384, "start": 1584.56, "end": 1591.36, "text": " or two. Okay, that's pretty nice. You can imagine inserting into zero, you go to one,", "tokens": [50400, 420, 732, 13, 1033, 11, 300, 311, 1238, 1481, 13, 509, 393, 3811, 46567, 666, 4018, 11, 291, 352, 281, 472, 11, 50740], "temperature": 0.0, "avg_logprob": -0.11704632120394926, "compression_ratio": 1.622568093385214, "no_speech_prob": 0.0010978135978803039}, {"id": 228, "seek": 158384, "start": 1591.36, "end": 1596.56, "text": " inserting into two, and then in two, you maintain some order moving things along.", "tokens": [50740, 46567, 666, 732, 11, 293, 550, 294, 732, 11, 291, 6909, 512, 1668, 2684, 721, 2051, 13, 51000], "temperature": 0.0, "avg_logprob": -0.11704632120394926, "compression_ratio": 1.622568093385214, "no_speech_prob": 0.0010978135978803039}, {"id": 229, "seek": 158384, "start": 1598.08, "end": 1602.6399999999999, "text": " And that design seems okay, but we know head of fruits marketing.", "tokens": [51076, 400, 300, 1715, 2544, 1392, 11, 457, 321, 458, 1378, 295, 12148, 6370, 13, 51304], "temperature": 0.0, "avg_logprob": -0.11704632120394926, "compression_ratio": 1.622568093385214, "no_speech_prob": 0.0010978135978803039}, {"id": 230, "seek": 158384, "start": 1604.0, "end": 1607.28, "text": " He's going to say, okay, well, in tropical areas, we can actually give them more fruits,", "tokens": [51372, 634, 311, 516, 281, 584, 11, 1392, 11, 731, 11, 294, 22857, 3179, 11, 321, 393, 767, 976, 552, 544, 12148, 11, 51536], "temperature": 0.0, "avg_logprob": -0.11704632120394926, "compression_ratio": 1.622568093385214, "no_speech_prob": 0.0010978135978803039}, {"id": 231, "seek": 158384, "start": 1607.28, "end": 1612.6399999999999, "text": " so they're going to want a limit of three. But in Iceland, they only get half cucumbers there.", "tokens": [51536, 370, 436, 434, 516, 281, 528, 257, 4948, 295, 1045, 13, 583, 294, 28004, 11, 436, 787, 483, 1922, 43354, 456, 13, 51804], "temperature": 0.0, "avg_logprob": -0.11704632120394926, "compression_ratio": 1.622568093385214, "no_speech_prob": 0.0010978135978803039}, {"id": 232, "seek": 161264, "start": 1612.64, "end": 1614.96, "text": " That's just the rule. I don't know. That is actually how it works.", "tokens": [50364, 663, 311, 445, 264, 4978, 13, 286, 500, 380, 458, 13, 663, 307, 767, 577, 309, 1985, 13, 50480], "temperature": 0.0, "avg_logprob": -0.10797363143783432, "compression_ratio": 1.6535433070866141, "no_speech_prob": 0.0012409675400704145}, {"id": 233, "seek": 161264, "start": 1617.68, "end": 1621.6000000000001, "text": " So we're probably not going to be able to just stick with two. There may be some", "tokens": [50616, 407, 321, 434, 1391, 406, 516, 281, 312, 1075, 281, 445, 2897, 365, 732, 13, 821, 815, 312, 512, 50812], "temperature": 0.0, "avg_logprob": -0.10797363143783432, "compression_ratio": 1.6535433070866141, "no_speech_prob": 0.0012409675400704145}, {"id": 234, "seek": 161264, "start": 1621.6000000000001, "end": 1625.92, "text": " places where we need three or different limits. So another way we could do this is just a list", "tokens": [50812, 3190, 689, 321, 643, 1045, 420, 819, 10406, 13, 407, 1071, 636, 321, 727, 360, 341, 307, 445, 257, 1329, 51028], "temperature": 0.0, "avg_logprob": -0.10797363143783432, "compression_ratio": 1.6535433070866141, "no_speech_prob": 0.0012409675400704145}, {"id": 235, "seek": 161264, "start": 1626.5600000000002, "end": 1632.16, "text": " of string and then limit the size. So essentially add to the front and take things,", "tokens": [51060, 295, 6798, 293, 550, 4948, 264, 2744, 13, 407, 4476, 909, 281, 264, 1868, 293, 747, 721, 11, 51340], "temperature": 0.0, "avg_logprob": -0.10797363143783432, "compression_ratio": 1.6535433070866141, "no_speech_prob": 0.0012409675400704145}, {"id": 236, "seek": 161264, "start": 1632.16, "end": 1639.2, "text": " drop things off the back. So I don't know. It doesn't seem perfect. Clearly, you can just add", "tokens": [51340, 3270, 721, 766, 264, 646, 13, 407, 286, 500, 380, 458, 13, 467, 1177, 380, 1643, 2176, 13, 24120, 11, 291, 393, 445, 909, 51692], "temperature": 0.0, "avg_logprob": -0.10797363143783432, "compression_ratio": 1.6535433070866141, "no_speech_prob": 0.0012409675400704145}, {"id": 237, "seek": 163920, "start": 1639.2, "end": 1645.1200000000001, "text": " 20 things to it. But it sort of has potential. So let's explore that route.", "tokens": [50364, 945, 721, 281, 309, 13, 583, 309, 1333, 295, 575, 3995, 13, 407, 718, 311, 6839, 300, 7955, 13, 50660], "temperature": 0.0, "avg_logprob": -0.11815653817128327, "compression_ratio": 1.3846153846153846, "no_speech_prob": 0.0009371376363560557}, {"id": 238, "seek": 163920, "start": 1648.0800000000002, "end": 1652.96, "text": " So instead of this being empty, this is an empty list. Oops.", "tokens": [50808, 407, 2602, 295, 341, 885, 6707, 11, 341, 307, 364, 6707, 1329, 13, 21726, 13, 51052], "temperature": 0.0, "avg_logprob": -0.11815653817128327, "compression_ratio": 1.3846153846153846, "no_speech_prob": 0.0009371376363560557}, {"id": 239, "seek": 163920, "start": 1656.64, "end": 1662.32, "text": " The cursor just disappears. Anyway, so when we select something, we want to say", "tokens": [51236, 440, 28169, 445, 25527, 13, 5684, 11, 370, 562, 321, 3048, 746, 11, 321, 528, 281, 584, 51520], "temperature": 0.0, "avg_logprob": -0.11815653817128327, "compression_ratio": 1.3846153846153846, "no_speech_prob": 0.0009371376363560557}, {"id": 240, "seek": 166232, "start": 1662.8, "end": 1673.52, "text": " list.take2 fruit on the front of our selected list. So this is saying, put the fruit on the", "tokens": [50388, 1329, 13, 27612, 17, 6773, 322, 264, 1868, 295, 527, 8209, 1329, 13, 407, 341, 307, 1566, 11, 829, 264, 6773, 322, 264, 50924], "temperature": 0.0, "avg_logprob": -0.16468701491484772, "compression_ratio": 1.6163522012578617, "no_speech_prob": 0.0030677549075335264}, {"id": 241, "seek": 166232, "start": 1673.52, "end": 1676.8799999999999, "text": " front and then just take the front two. So whatever else is there, we'll drop it.", "tokens": [50924, 1868, 293, 550, 445, 747, 264, 1868, 732, 13, 407, 2035, 1646, 307, 456, 11, 321, 603, 3270, 309, 13, 51092], "temperature": 0.0, "avg_logprob": -0.16468701491484772, "compression_ratio": 1.6163522012578617, "no_speech_prob": 0.0030677549075335264}, {"id": 242, "seek": 166232, "start": 1679.84, "end": 1688.6399999999999, "text": " And then when we deselect, we can say list.filter. The fruit should not, any fruit,", "tokens": [51240, 400, 550, 562, 321, 730, 14664, 11, 321, 393, 584, 1329, 13, 19776, 391, 13, 440, 6773, 820, 406, 11, 604, 6773, 11, 51680], "temperature": 0.0, "avg_logprob": -0.16468701491484772, "compression_ratio": 1.6163522012578617, "no_speech_prob": 0.0030677549075335264}, {"id": 243, "seek": 168864, "start": 1688.64, "end": 1695.1200000000001, "text": " that's not the one we, that's a lot of nots in one sentence. We want to only keep fruits.", "tokens": [50364, 300, 311, 406, 264, 472, 321, 11, 300, 311, 257, 688, 295, 406, 82, 294, 472, 8174, 13, 492, 528, 281, 787, 1066, 12148, 13, 50688], "temperature": 0.0, "avg_logprob": -0.1466991666337134, "compression_ratio": 1.5324675324675325, "no_speech_prob": 0.001047560479491949}, {"id": 244, "seek": 168864, "start": 1697.76, "end": 1701.68, "text": " You get it. We want that fruit to be deselected.", "tokens": [50820, 509, 483, 309, 13, 492, 528, 300, 6773, 281, 312, 730, 14664, 292, 13, 51016], "temperature": 0.0, "avg_logprob": -0.1466991666337134, "compression_ratio": 1.5324675324675325, "no_speech_prob": 0.001047560479491949}, {"id": 245, "seek": 168864, "start": 1704.48, "end": 1713.68, "text": " And then in our checkbox code, we want to say and said list.member. And I think that's everything", "tokens": [51156, 400, 550, 294, 527, 1520, 4995, 3089, 11, 321, 528, 281, 584, 293, 848, 1329, 13, 38249, 13, 400, 286, 519, 300, 311, 1203, 51616], "temperature": 0.0, "avg_logprob": -0.1466991666337134, "compression_ratio": 1.5324675324675325, "no_speech_prob": 0.001047560479491949}, {"id": 246, "seek": 171368, "start": 1714.24, "end": 1720.72, "text": " except we don't need that anymore. Okay. So let's see if I did this right.", "tokens": [50392, 3993, 321, 500, 380, 643, 300, 3602, 13, 1033, 13, 407, 718, 311, 536, 498, 286, 630, 341, 558, 13, 50716], "temperature": 0.0, "avg_logprob": -0.12070724644611791, "compression_ratio": 1.6208530805687205, "no_speech_prob": 0.0016218275995925069}, {"id": 247, "seek": 171368, "start": 1723.92, "end": 1729.04, "text": " Hey. And so you can see it's maintaining the order that I clicked things. So if I,", "tokens": [50876, 1911, 13, 400, 370, 291, 393, 536, 309, 311, 14916, 264, 1668, 300, 286, 23370, 721, 13, 407, 498, 286, 11, 51132], "temperature": 0.0, "avg_logprob": -0.12070724644611791, "compression_ratio": 1.6208530805687205, "no_speech_prob": 0.0016218275995925069}, {"id": 248, "seek": 171368, "start": 1731.44, "end": 1735.3600000000001, "text": " I don't know, it's kind of hard to remember. It's easy if you go in order and you can see.", "tokens": [51252, 286, 500, 380, 458, 11, 309, 311, 733, 295, 1152, 281, 1604, 13, 467, 311, 1858, 498, 291, 352, 294, 1668, 293, 291, 393, 536, 13, 51448], "temperature": 0.0, "avg_logprob": -0.12070724644611791, "compression_ratio": 1.6208530805687205, "no_speech_prob": 0.0016218275995925069}, {"id": 249, "seek": 171368, "start": 1735.3600000000001, "end": 1741.52, "text": " It's working nicely. Okay. So we're maintaining our two fruits per person situation. But when", "tokens": [51448, 467, 311, 1364, 9594, 13, 1033, 13, 407, 321, 434, 14916, 527, 732, 12148, 680, 954, 2590, 13, 583, 562, 51756], "temperature": 0.0, "avg_logprob": -0.12070724644611791, "compression_ratio": 1.6208530805687205, "no_speech_prob": 0.0016218275995925069}, {"id": 250, "seek": 174152, "start": 1741.52, "end": 1749.52, "text": " we come look back at our update code, it's getting, it feels like trickier, right? And as we grow", "tokens": [50364, 321, 808, 574, 646, 412, 527, 5623, 3089, 11, 309, 311, 1242, 11, 309, 3417, 411, 4282, 811, 11, 558, 30, 400, 382, 321, 1852, 50764], "temperature": 0.0, "avg_logprob": -0.11688902798820944, "compression_ratio": 1.5860655737704918, "no_speech_prob": 0.0011328760301694274}, {"id": 251, "seek": 174152, "start": 1749.52, "end": 1759.92, "text": " fruits.com, like maybe someone won't realize the take two is not, oh, just some fine choice. It's", "tokens": [50764, 12148, 13, 1112, 11, 411, 1310, 1580, 1582, 380, 4325, 264, 747, 732, 307, 406, 11, 1954, 11, 445, 512, 2489, 3922, 13, 467, 311, 51284], "temperature": 0.0, "avg_logprob": -0.11688902798820944, "compression_ratio": 1.5860655737704918, "no_speech_prob": 0.0011328760301694274}, {"id": 252, "seek": 174152, "start": 1759.92, "end": 1764.56, "text": " like, head of fruits marketing decided that was two and you can't change that stuff. So we want", "tokens": [51284, 411, 11, 1378, 295, 12148, 6370, 3047, 300, 390, 732, 293, 291, 393, 380, 1319, 300, 1507, 13, 407, 321, 528, 51516], "temperature": 0.0, "avg_logprob": -0.11688902798820944, "compression_ratio": 1.5860655737704918, "no_speech_prob": 0.0011328760301694274}, {"id": 253, "seek": 174152, "start": 1764.56, "end": 1770.4, "text": " to have some more security around this code. So one way we can do that is to start to break out", "tokens": [51516, 281, 362, 512, 544, 3825, 926, 341, 3089, 13, 407, 472, 636, 321, 393, 360, 300, 307, 281, 722, 281, 1821, 484, 51808], "temperature": 0.0, "avg_logprob": -0.11688902798820944, "compression_ratio": 1.5860655737704918, "no_speech_prob": 0.0011328760301694274}, {"id": 254, "seek": 177152, "start": 1772.48, "end": 1779.44, "text": " the particular stuff around that data structure. So we, we know there's this selection list.", "tokens": [50412, 264, 1729, 1507, 926, 300, 1412, 3877, 13, 407, 321, 11, 321, 458, 456, 311, 341, 9450, 1329, 13, 50760], "temperature": 0.0, "avg_logprob": -0.17219004034996033, "compression_ratio": 1.2058823529411764, "no_speech_prob": 0.00039177393773570657}, {"id": 255, "seek": 177152, "start": 1779.44, "end": 1781.52, "text": " We can make a function that is", "tokens": [50760, 492, 393, 652, 257, 2445, 300, 307, 50864], "temperature": 0.0, "avg_logprob": -0.17219004034996033, "compression_ratio": 1.2058823529411764, "no_speech_prob": 0.00039177393773570657}, {"id": 256, "seek": 178152, "start": 1781.6, "end": 1796.8799999999999, "text": " along these lines. So let's do it in the update part. Insert, oops, insert fruit list.", "tokens": [50368, 2051, 613, 3876, 13, 407, 718, 311, 360, 309, 294, 264, 5623, 644, 13, 36487, 11, 34166, 11, 8969, 6773, 1329, 13, 51132], "temperature": 0.0, "avg_logprob": -0.2762412792298852, "compression_ratio": 1.275229357798165, "no_speech_prob": 0.034592460840940475}, {"id": 257, "seek": 178152, "start": 1802.24, "end": 1805.12, "text": " I'm going to leave off types for now just for speed.", "tokens": [51400, 286, 478, 516, 281, 1856, 766, 3467, 337, 586, 445, 337, 3073, 13, 51544], "temperature": 0.0, "avg_logprob": -0.2762412792298852, "compression_ratio": 1.275229357798165, "no_speech_prob": 0.034592460840940475}, {"id": 258, "seek": 180512, "start": 1806.08, "end": 1816.2399999999998, "text": " And then I can say here, insert fruit. And then I can also say remove fruit from the list.", "tokens": [50412, 400, 550, 286, 393, 584, 510, 11, 8969, 6773, 13, 400, 550, 286, 393, 611, 584, 4159, 6773, 490, 264, 1329, 13, 50920], "temperature": 0.0, "avg_logprob": -0.19809875121483436, "compression_ratio": 1.416, "no_speech_prob": 0.000803565897513181}, {"id": 259, "seek": 180512, "start": 1817.4399999999998, "end": 1818.6399999999999, "text": " And we'll do it the same way.", "tokens": [50980, 400, 321, 603, 360, 309, 264, 912, 636, 13, 51040], "temperature": 0.0, "avg_logprob": -0.19809875121483436, "compression_ratio": 1.416, "no_speech_prob": 0.000803565897513181}, {"id": 260, "seek": 180512, "start": 1826.7199999999998, "end": 1830.8, "text": " So this code gets a bunch simpler as well. Remove fruit.", "tokens": [51444, 407, 341, 3089, 2170, 257, 3840, 18587, 382, 731, 13, 18831, 6773, 13, 51648], "temperature": 0.0, "avg_logprob": -0.19809875121483436, "compression_ratio": 1.416, "no_speech_prob": 0.000803565897513181}, {"id": 261, "seek": 183080, "start": 1831.76, "end": 1838.8, "text": " And we can do the same thing with the checking for membership below. Now at this point it's sort", "tokens": [50412, 400, 321, 393, 360, 264, 912, 551, 365, 264, 8568, 337, 16560, 2507, 13, 823, 412, 341, 935, 309, 311, 1333, 50764], "temperature": 0.0, "avg_logprob": -0.13143935074677338, "compression_ratio": 1.5051020408163265, "no_speech_prob": 0.0005029314197599888}, {"id": 262, "seek": 183080, "start": 1838.8, "end": 1844.72, "text": " of coalescing into, oh, there's this kind of data structure that's specifically about maintaining", "tokens": [50764, 295, 598, 4229, 2175, 666, 11, 1954, 11, 456, 311, 341, 733, 295, 1412, 3877, 300, 311, 4682, 466, 14916, 51060], "temperature": 0.0, "avg_logprob": -0.13143935074677338, "compression_ratio": 1.5051020408163265, "no_speech_prob": 0.0005029314197599888}, {"id": 263, "seek": 183080, "start": 1844.72, "end": 1851.2, "text": " just two things in, in the list. So I'm going to check for time to see how much live coding I should", "tokens": [51060, 445, 732, 721, 294, 11, 294, 264, 1329, 13, 407, 286, 478, 516, 281, 1520, 337, 565, 281, 536, 577, 709, 1621, 17720, 286, 820, 51384], "temperature": 0.0, "avg_logprob": -0.13143935074677338, "compression_ratio": 1.5051020408163265, "no_speech_prob": 0.0005029314197599888}, {"id": 264, "seek": 185120, "start": 1851.2, "end": 1860.4, "text": " do. Okay. Well, let's, let's start to follow this idea of like, we're starting to recognize", "tokens": [50364, 360, 13, 1033, 13, 1042, 11, 718, 311, 11, 718, 311, 722, 281, 1524, 341, 1558, 295, 411, 11, 321, 434, 2891, 281, 5521, 50824], "temperature": 0.0, "avg_logprob": -0.12005101144313812, "compression_ratio": 1.4304635761589404, "no_speech_prob": 0.0029792082495987415}, {"id": 265, "seek": 185120, "start": 1860.4, "end": 1866.56, "text": " a data structure. So let's try to break that out. So I can say fruit list.", "tokens": [50824, 257, 1412, 3877, 13, 407, 718, 311, 853, 281, 1821, 300, 484, 13, 407, 286, 393, 584, 6773, 1329, 13, 51132], "temperature": 0.0, "avg_logprob": -0.12005101144313812, "compression_ratio": 1.4304635761589404, "no_speech_prob": 0.0029792082495987415}, {"id": 266, "seek": 185120, "start": 1869.68, "end": 1874.0800000000002, "text": " And I have this type alias fruit, selected fruit.", "tokens": [51288, 400, 286, 362, 341, 2010, 419, 4609, 6773, 11, 8209, 6773, 13, 51508], "temperature": 0.0, "avg_logprob": -0.12005101144313812, "compression_ratio": 1.4304635761589404, "no_speech_prob": 0.0029792082495987415}, {"id": 267, "seek": 187408, "start": 1874.6399999999999, "end": 1885.28, "text": " So we're starting to see the, the beginnings of a, of a module, like things that we can", "tokens": [50392, 407, 321, 434, 2891, 281, 536, 264, 11, 264, 37281, 295, 257, 11, 295, 257, 10088, 11, 411, 721, 300, 321, 393, 50924], "temperature": 0.0, "avg_logprob": -0.12820610318865094, "compression_ratio": 1.5209580838323353, "no_speech_prob": 0.0004950608126819134}, {"id": 268, "seek": 187408, "start": 1886.3999999999999, "end": 1892.0, "text": " box off and put in their own place. So I'm going to just skip ahead to a version of this", "tokens": [50980, 2424, 766, 293, 829, 294, 641, 1065, 1081, 13, 407, 286, 478, 516, 281, 445, 10023, 2286, 281, 257, 3037, 295, 341, 51260], "temperature": 0.0, "avg_logprob": -0.12820610318865094, "compression_ratio": 1.5209580838323353, "no_speech_prob": 0.0004950608126819134}, {"id": 269, "seek": 187408, "start": 1892.0, "end": 1897.84, "text": " in a different module. So the ideas, we have this thing called a bounded set.", "tokens": [51260, 294, 257, 819, 10088, 13, 407, 264, 3487, 11, 321, 362, 341, 551, 1219, 257, 37498, 992, 13, 51552], "temperature": 0.0, "avg_logprob": -0.12820610318865094, "compression_ratio": 1.5209580838323353, "no_speech_prob": 0.0004950608126819134}, {"id": 270, "seek": 189784, "start": 1898.56, "end": 1902.9599999999998, "text": " And yeah, no, I shouldn't skip ahead to this. That was a bad idea.", "tokens": [50400, 400, 1338, 11, 572, 11, 286, 4659, 380, 10023, 2286, 281, 341, 13, 663, 390, 257, 1578, 1558, 13, 50620], "temperature": 0.0, "avg_logprob": -0.17104310648781912, "compression_ratio": 1.2949640287769784, "no_speech_prob": 0.0015241998480632901}, {"id": 271, "seek": 189784, "start": 1906.0, "end": 1909.1999999999998, "text": " So let's say, okay, we have this and we were going to put it in a new module,", "tokens": [50772, 407, 718, 311, 584, 11, 1392, 11, 321, 362, 341, 293, 321, 645, 516, 281, 829, 309, 294, 257, 777, 10088, 11, 50932], "temperature": 0.0, "avg_logprob": -0.17104310648781912, "compression_ratio": 1.2949640287769784, "no_speech_prob": 0.0015241998480632901}, {"id": 272, "seek": 189784, "start": 1909.1999999999998, "end": 1916.1599999999999, "text": " the selected fruit module. Exposing", "tokens": [50932, 264, 8209, 6773, 10088, 13, 21391, 6110, 51280], "temperature": 0.0, "avg_logprob": -0.17104310648781912, "compression_ratio": 1.2949640287769784, "no_speech_prob": 0.0015241998480632901}, {"id": 273, "seek": 191616, "start": 1916.16, "end": 1931.68, "text": " a selected fruit. And then in our fruits module, we can get rid of that. And we can import", "tokens": [50364, 257, 8209, 6773, 13, 400, 550, 294, 527, 12148, 10088, 11, 321, 393, 483, 3973, 295, 300, 13, 400, 321, 393, 974, 51140], "temperature": 0.0, "avg_logprob": -0.2616134811850155, "compression_ratio": 1.4, "no_speech_prob": 0.008309424854815006}, {"id": 274, "seek": 191616, "start": 1936.88, "end": 1940.0800000000002, "text": " as selected fruits. And then", "tokens": [51400, 382, 8209, 12148, 13, 400, 550, 51560], "temperature": 0.0, "avg_logprob": -0.2616134811850155, "compression_ratio": 1.4, "no_speech_prob": 0.008309424854815006}, {"id": 275, "seek": 194008, "start": 1940.3999999999999, "end": 1951.28, "text": " we just have to go through and make a couple changes here. Oh, we'll come back to that.", "tokens": [50380, 321, 445, 362, 281, 352, 807, 293, 652, 257, 1916, 2962, 510, 13, 876, 11, 321, 603, 808, 646, 281, 300, 13, 50924], "temperature": 0.0, "avg_logprob": -0.15173502226133603, "compression_ratio": 1.4382022471910112, "no_speech_prob": 0.00048723837244324386}, {"id": 276, "seek": 194008, "start": 1955.12, "end": 1962.3999999999999, "text": " Selected fruit, that insert, remove, et cetera. So this is also selected fruit.", "tokens": [51116, 13638, 292, 6773, 11, 300, 8969, 11, 4159, 11, 1030, 11458, 13, 407, 341, 307, 611, 8209, 6773, 13, 51480], "temperature": 0.0, "avg_logprob": -0.15173502226133603, "compression_ratio": 1.4382022471910112, "no_speech_prob": 0.00048723837244324386}, {"id": 277, "seek": 194008, "start": 1963.6799999999998, "end": 1968.3999999999999, "text": " We're kind of leaking details here. Okay. Let's see it. Okay. Check. Does this work? No.", "tokens": [51544, 492, 434, 733, 295, 32856, 4365, 510, 13, 1033, 13, 961, 311, 536, 309, 13, 1033, 13, 6881, 13, 4402, 341, 589, 30, 883, 13, 51780], "temperature": 0.0, "avg_logprob": -0.15173502226133603, "compression_ratio": 1.4382022471910112, "no_speech_prob": 0.00048723837244324386}, {"id": 278, "seek": 196840, "start": 1969.2, "end": 1974.24, "text": " Selected fruits. It's singular.", "tokens": [50404, 13638, 292, 12148, 13, 467, 311, 20010, 13, 50656], "temperature": 0.0, "avg_logprob": -0.3210993849712869, "compression_ratio": 0.9583333333333334, "no_speech_prob": 0.0020820361096411943}, {"id": 279, "seek": 196840, "start": 1984.3200000000002, "end": 1991.6000000000001, "text": " There's also a stray print. Spelling.", "tokens": [51160, 821, 311, 611, 257, 36219, 4482, 13, 3550, 2669, 13, 51524], "temperature": 0.0, "avg_logprob": -0.3210993849712869, "compression_ratio": 0.9583333333333334, "no_speech_prob": 0.0020820361096411943}, {"id": 280, "seek": 199840, "start": 1998.88, "end": 2001.68, "text": " It's nice that, yeah. Oh, geez. What the heck?", "tokens": [50388, 467, 311, 1481, 300, 11, 1338, 13, 876, 11, 46108, 13, 708, 264, 12872, 30, 50528], "temperature": 0.0, "avg_logprob": -0.2754117924234141, "compression_ratio": 1.2203389830508475, "no_speech_prob": 0.000841996748931706}, {"id": 281, "seek": 199840, "start": 2006.3200000000002, "end": 2021.76, "text": " Okay. Just imagine there wasn't a compiler there. Or just like, maybe that's wrong. I don't know.", "tokens": [50760, 1033, 13, 1449, 3811, 456, 2067, 380, 257, 31958, 456, 13, 1610, 445, 411, 11, 1310, 300, 311, 2085, 13, 286, 500, 380, 458, 13, 51532], "temperature": 0.0, "avg_logprob": -0.2754117924234141, "compression_ratio": 1.2203389830508475, "no_speech_prob": 0.000841996748931706}, {"id": 282, "seek": 202176, "start": 2022.72, "end": 2028.8799999999999, "text": " Okay. So this is still working. But we can kind of improve things by sort of closing down this", "tokens": [50412, 1033, 13, 407, 341, 307, 920, 1364, 13, 583, 321, 393, 733, 295, 3470, 721, 538, 1333, 295, 10377, 760, 341, 50720], "temperature": 0.0, "avg_logprob": -0.1609202505837024, "compression_ratio": 1.4635416666666667, "no_speech_prob": 0.001030955114401877}, {"id": 283, "seek": 202176, "start": 2028.8799999999999, "end": 2034.08, "text": " module. Right now, we're exposing everything. But we could do better by saying, okay, from the", "tokens": [50720, 10088, 13, 1779, 586, 11, 321, 434, 33178, 1203, 13, 583, 321, 727, 360, 1101, 538, 1566, 11, 1392, 11, 490, 264, 50980], "temperature": 0.0, "avg_logprob": -0.1609202505837024, "compression_ratio": 1.4635416666666667, "no_speech_prob": 0.001030955114401877}, {"id": 284, "seek": 202176, "start": 2034.08, "end": 2042.0, "text": " outside, no one knows how selected fruit is implemented. It happens to be a list of string,", "tokens": [50980, 2380, 11, 572, 472, 3255, 577, 8209, 6773, 307, 12270, 13, 467, 2314, 281, 312, 257, 1329, 295, 6798, 11, 51376], "temperature": 0.0, "avg_logprob": -0.1609202505837024, "compression_ratio": 1.4635416666666667, "no_speech_prob": 0.001030955114401877}, {"id": 285, "seek": 204200, "start": 2042.08, "end": 2053.44, "text": " but no one needs to know. So we have to do a little bit of selected.", "tokens": [50368, 457, 572, 472, 2203, 281, 458, 13, 407, 321, 362, 281, 360, 257, 707, 857, 295, 8209, 13, 50936], "temperature": 0.0, "avg_logprob": -0.15362024307250977, "compression_ratio": 1.1956521739130435, "no_speech_prob": 0.0038175128865987062}, {"id": 286, "seek": 204200, "start": 2055.84, "end": 2059.2, "text": " I'm disenchanted with this naming choice.", "tokens": [51056, 286, 478, 717, 40765, 15587, 365, 341, 25290, 3922, 13, 51224], "temperature": 0.0, "avg_logprob": -0.15362024307250977, "compression_ratio": 1.1956521739130435, "no_speech_prob": 0.0038175128865987062}, {"id": 287, "seek": 205920, "start": 2059.2, "end": 2072.24, "text": " Okay. So now, from the outside, no one knows how the particulars of this are implemented.", "tokens": [50364, 1033, 13, 407, 586, 11, 490, 264, 2380, 11, 572, 472, 3255, 577, 264, 21861, 685, 295, 341, 366, 12270, 13, 51016], "temperature": 0.0, "avg_logprob": -0.11174305023685578, "compression_ratio": 1.4102564102564104, "no_speech_prob": 0.0017252406105399132}, {"id": 288, "seek": 205920, "start": 2072.7999999999997, "end": 2075.12, "text": " So let's just run it. This is supposed to not work.", "tokens": [51044, 407, 718, 311, 445, 1190, 309, 13, 639, 307, 3442, 281, 406, 589, 13, 51160], "temperature": 0.0, "avg_logprob": -0.11174305023685578, "compression_ratio": 1.4102564102564104, "no_speech_prob": 0.0017252406105399132}, {"id": 289, "seek": 205920, "start": 2078.48, "end": 2083.8399999999997, "text": " So we're using list.member on a selected fruit, but we don't actually know the", "tokens": [51328, 407, 321, 434, 1228, 1329, 13, 38249, 322, 257, 8209, 6773, 11, 457, 321, 500, 380, 767, 458, 264, 51596], "temperature": 0.0, "avg_logprob": -0.11174305023685578, "compression_ratio": 1.4102564102564104, "no_speech_prob": 0.0017252406105399132}, {"id": 290, "seek": 208384, "start": 2083.92, "end": 2090.2400000000002, "text": " implementation deals of that anymore. And our selected, we're saying it's a list,", "tokens": [50368, 11420, 11215, 295, 300, 3602, 13, 400, 527, 8209, 11, 321, 434, 1566, 309, 311, 257, 1329, 11, 50684], "temperature": 0.0, "avg_logprob": -0.12247131181799847, "compression_ratio": 1.5919540229885059, "no_speech_prob": 0.0011502692941576242}, {"id": 291, "seek": 208384, "start": 2090.2400000000002, "end": 2095.44, "text": " but we don't have access to that information anymore. So we need to add, how do I make an", "tokens": [50684, 457, 321, 500, 380, 362, 2105, 281, 300, 1589, 3602, 13, 407, 321, 643, 281, 909, 11, 577, 360, 286, 652, 364, 50944], "temperature": 0.0, "avg_logprob": -0.12247131181799847, "compression_ratio": 1.5919540229885059, "no_speech_prob": 0.0011502692941576242}, {"id": 292, "seek": 208384, "start": 2095.44, "end": 2107.6800000000003, "text": " empty selected fruit? And that would be selected fruit is empty. And then we need to test for membership.", "tokens": [50944, 6707, 8209, 6773, 30, 400, 300, 576, 312, 8209, 6773, 307, 6707, 13, 400, 550, 321, 643, 281, 1500, 337, 16560, 13, 51556], "temperature": 0.0, "avg_logprob": -0.12247131181799847, "compression_ratio": 1.5919540229885059, "no_speech_prob": 0.0011502692941576242}, {"id": 293, "seek": 211384, "start": 2114.7200000000003, "end": 2121.04, "text": " And then we can just say list member fruit list.", "tokens": [50408, 400, 550, 321, 393, 445, 584, 1329, 4006, 6773, 1329, 13, 50724], "temperature": 0.0, "avg_logprob": -0.20643267808137117, "compression_ratio": 1.532846715328467, "no_speech_prob": 0.0006460188888013363}, {"id": 294, "seek": 211384, "start": 2124.88, "end": 2127.6800000000003, "text": " Oh, it's still broken because they didn't actually change the broken code.", "tokens": [50916, 876, 11, 309, 311, 920, 5463, 570, 436, 994, 380, 767, 1319, 264, 5463, 3089, 13, 51056], "temperature": 0.0, "avg_logprob": -0.20643267808137117, "compression_ratio": 1.532846715328467, "no_speech_prob": 0.0006460188888013363}, {"id": 295, "seek": 211384, "start": 2129.6800000000003, "end": 2135.92, "text": " So here we say selected fruit is empty. And then member, we say selected fruit member.", "tokens": [51156, 407, 510, 321, 584, 8209, 6773, 307, 6707, 13, 400, 550, 4006, 11, 321, 584, 8209, 6773, 4006, 13, 51468], "temperature": 0.0, "avg_logprob": -0.20643267808137117, "compression_ratio": 1.532846715328467, "no_speech_prob": 0.0006460188888013363}, {"id": 296, "seek": 213592, "start": 2136.56, "end": 2146.7200000000003, "text": " Cool. So now we've sort of hidden all these implementation details, but we can do slightly", "tokens": [50396, 8561, 13, 407, 586, 321, 600, 1333, 295, 7633, 439, 613, 11420, 4365, 11, 457, 321, 393, 360, 4748, 50904], "temperature": 0.0, "avg_logprob": -0.146707637493427, "compression_ratio": 1.4628571428571429, "no_speech_prob": 0.0016466286033391953}, {"id": 297, "seek": 213592, "start": 2146.7200000000003, "end": 2154.56, "text": " better. So maybe we want to make a guarantee about the size in this data structure. So we can say", "tokens": [50904, 1101, 13, 407, 1310, 321, 528, 281, 652, 257, 10815, 466, 264, 2744, 294, 341, 1412, 3877, 13, 407, 321, 393, 584, 51296], "temperature": 0.0, "avg_logprob": -0.146707637493427, "compression_ratio": 1.4628571428571429, "no_speech_prob": 0.0016466286033391953}, {"id": 298, "seek": 213592, "start": 2154.56, "end": 2158.64, "text": " we'll actually give the maximum size when we say it's empty or not.", "tokens": [51296, 321, 603, 767, 976, 264, 6674, 2744, 562, 321, 584, 309, 311, 6707, 420, 406, 13, 51500], "temperature": 0.0, "avg_logprob": -0.146707637493427, "compression_ratio": 1.4628571428571429, "no_speech_prob": 0.0016466286033391953}, {"id": 299, "seek": 215864, "start": 2158.8799999999997, "end": 2170.08, "text": " And then in all these cases, max size. So instead of taking two, we take the max size.", "tokens": [50376, 400, 550, 294, 439, 613, 3331, 11, 11469, 2744, 13, 407, 2602, 295, 1940, 732, 11, 321, 747, 264, 11469, 2744, 13, 50936], "temperature": 0.0, "avg_logprob": -0.15362280490351657, "compression_ratio": 1.5169491525423728, "no_speech_prob": 0.0012050449149683118}, {"id": 300, "seek": 215864, "start": 2174.08, "end": 2181.2799999999997, "text": " And instead of removing, no, we do keep this the same, but we just have to keep the max size", "tokens": [51136, 400, 2602, 295, 12720, 11, 572, 11, 321, 360, 1066, 341, 264, 912, 11, 457, 321, 445, 362, 281, 1066, 264, 11469, 2744, 51496], "temperature": 0.0, "avg_logprob": -0.15362280490351657, "compression_ratio": 1.5169491525423728, "no_speech_prob": 0.0012050449149683118}, {"id": 301, "seek": 218128, "start": 2181.28, "end": 2185.44, "text": " around. And then here we don't care about the max size. We just want to check.", "tokens": [50364, 926, 13, 400, 550, 510, 321, 500, 380, 1127, 466, 264, 11469, 2744, 13, 492, 445, 528, 281, 1520, 13, 50572], "temperature": 0.0, "avg_logprob": -0.11678376609896436, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.0053727594204247}, {"id": 302, "seek": 218128, "start": 2186.7200000000003, "end": 2192.4, "text": " So we should have an error because we're just calling empty without saying how big it should be.", "tokens": [50636, 407, 321, 820, 362, 364, 6713, 570, 321, 434, 445, 5141, 6707, 1553, 1566, 577, 955, 309, 820, 312, 13, 50920], "temperature": 0.0, "avg_logprob": -0.11678376609896436, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.0053727594204247}, {"id": 303, "seek": 218128, "start": 2196.48, "end": 2202.88, "text": " Two. All right. And then things should work again. Cool.", "tokens": [51124, 4453, 13, 1057, 558, 13, 400, 550, 721, 820, 589, 797, 13, 8561, 13, 51444], "temperature": 0.0, "avg_logprob": -0.11678376609896436, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.0053727594204247}, {"id": 304, "seek": 218128, "start": 2205.28, "end": 2210.48, "text": " So at this point, we sort of taken all this complexity around maintaining the only two", "tokens": [51564, 407, 412, 341, 935, 11, 321, 1333, 295, 2726, 439, 341, 14024, 926, 14916, 264, 787, 732, 51824], "temperature": 0.0, "avg_logprob": -0.11678376609896436, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.0053727594204247}, {"id": 305, "seek": 221048, "start": 2210.48, "end": 2215.52, "text": " things are selected and put it in its own module. So the benefits of this is that when I'm reading", "tokens": [50364, 721, 366, 8209, 293, 829, 309, 294, 1080, 1065, 10088, 13, 407, 264, 5311, 295, 341, 307, 300, 562, 286, 478, 3760, 50616], "temperature": 0.0, "avg_logprob": -0.0913973331451416, "compression_ratio": 1.6041666666666667, "no_speech_prob": 0.0023522551637142897}, {"id": 306, "seek": 221048, "start": 2215.52, "end": 2222.32, "text": " through my normal code, all I know is there's some way to select fruits. I can say how many.", "tokens": [50616, 807, 452, 2710, 3089, 11, 439, 286, 458, 307, 456, 311, 512, 636, 281, 3048, 12148, 13, 286, 393, 584, 577, 867, 13, 50956], "temperature": 0.0, "avg_logprob": -0.0913973331451416, "compression_ratio": 1.6041666666666667, "no_speech_prob": 0.0023522551637142897}, {"id": 307, "seek": 221048, "start": 2223.2, "end": 2228.32, "text": " And then I can insert and remove. And these things will just work out nicely. And I can check if", "tokens": [51000, 400, 550, 286, 393, 8969, 293, 4159, 13, 400, 613, 721, 486, 445, 589, 484, 9594, 13, 400, 286, 393, 1520, 498, 51256], "temperature": 0.0, "avg_logprob": -0.0913973331451416, "compression_ratio": 1.6041666666666667, "no_speech_prob": 0.0023522551637142897}, {"id": 308, "seek": 221048, "start": 2228.32, "end": 2234.96, "text": " something is a member of that. So you can go one level crazier with this, which we shouldn't get", "tokens": [51256, 746, 307, 257, 4006, 295, 300, 13, 407, 291, 393, 352, 472, 1496, 2094, 33352, 365, 341, 11, 597, 321, 4659, 380, 483, 51588], "temperature": 0.0, "avg_logprob": -0.0913973331451416, "compression_ratio": 1.6041666666666667, "no_speech_prob": 0.0023522551637142897}, {"id": 309, "seek": 223496, "start": 2234.96, "end": 2241.12, "text": " into, but you can. So the idea was you could generalize it so that it's a list of anything,", "tokens": [50364, 666, 11, 457, 291, 393, 13, 407, 264, 1558, 390, 291, 727, 2674, 1125, 309, 370, 300, 309, 311, 257, 1329, 295, 1340, 11, 50672], "temperature": 0.0, "avg_logprob": -0.08238645761954684, "compression_ratio": 1.6917562724014337, "no_speech_prob": 0.007329016923904419}, {"id": 310, "seek": 223496, "start": 2241.12, "end": 2246.08, "text": " not of strings or particular fruits. And then everything works the same, right? You choose", "tokens": [50672, 406, 295, 13985, 420, 1729, 12148, 13, 400, 550, 1203, 1985, 264, 912, 11, 558, 30, 509, 2826, 50920], "temperature": 0.0, "avg_logprob": -0.08238645761954684, "compression_ratio": 1.6917562724014337, "no_speech_prob": 0.007329016923904419}, {"id": 311, "seek": 223496, "start": 2246.08, "end": 2251.2, "text": " the size. You can insert things into it. You can remove things from it. You can check membership.", "tokens": [50920, 264, 2744, 13, 509, 393, 8969, 721, 666, 309, 13, 509, 393, 4159, 721, 490, 309, 13, 509, 393, 1520, 16560, 13, 51176], "temperature": 0.0, "avg_logprob": -0.08238645761954684, "compression_ratio": 1.6917562724014337, "no_speech_prob": 0.007329016923904419}, {"id": 312, "seek": 223496, "start": 2251.76, "end": 2257.92, "text": " So all of these designs are possible. And the question is, which one is right for your situation,", "tokens": [51204, 407, 439, 295, 613, 11347, 366, 1944, 13, 400, 264, 1168, 307, 11, 597, 472, 307, 558, 337, 428, 2590, 11, 51512], "temperature": 0.0, "avg_logprob": -0.08238645761954684, "compression_ratio": 1.6917562724014337, "no_speech_prob": 0.007329016923904419}, {"id": 313, "seek": 223496, "start": 2257.92, "end": 2262.08, "text": " right? Should you go like, all right, I'm writing my own data structure that's generic in all", "tokens": [51512, 558, 30, 6454, 291, 352, 411, 11, 439, 558, 11, 286, 478, 3579, 452, 1065, 1412, 3877, 300, 311, 19577, 294, 439, 51720], "temperature": 0.0, "avg_logprob": -0.08238645761954684, "compression_ratio": 1.6917562724014337, "no_speech_prob": 0.007329016923904419}, {"id": 314, "seek": 226208, "start": 2262.08, "end": 2266.88, "text": " sorts of things. And I'm going to optimize it. Or is it like, look, it's just a list. It's not a", "tokens": [50364, 7527, 295, 721, 13, 400, 286, 478, 516, 281, 19719, 309, 13, 1610, 307, 309, 411, 11, 574, 11, 309, 311, 445, 257, 1329, 13, 467, 311, 406, 257, 50604], "temperature": 0.0, "avg_logprob": -0.13688377940326657, "compression_ratio": 1.582995951417004, "no_speech_prob": 0.001499903853982687}, {"id": 315, "seek": 226208, "start": 2266.88, "end": 2271.2799999999997, "text": " big deal. We're probably not going to get it wrong. And so that depends on what's likely to happen.", "tokens": [50604, 955, 2028, 13, 492, 434, 1391, 406, 516, 281, 483, 309, 2085, 13, 400, 370, 300, 5946, 322, 437, 311, 3700, 281, 1051, 13, 50824], "temperature": 0.0, "avg_logprob": -0.13688377940326657, "compression_ratio": 1.582995951417004, "no_speech_prob": 0.001499903853982687}, {"id": 316, "seek": 226208, "start": 2271.84, "end": 2278.3199999999997, "text": " Maybe at fruits.com, you'd make one choice. But at the new fruit stand startup, I don't know,", "tokens": [50852, 2704, 412, 12148, 13, 1112, 11, 291, 1116, 652, 472, 3922, 13, 583, 412, 264, 777, 6773, 1463, 18578, 11, 286, 500, 380, 458, 11, 51176], "temperature": 0.0, "avg_logprob": -0.13688377940326657, "compression_ratio": 1.582995951417004, "no_speech_prob": 0.001499903853982687}, {"id": 317, "seek": 226208, "start": 2278.3199999999997, "end": 2288.16, "text": " they want to make different choices. Okay. So the big lesson here is that we started with two things", "tokens": [51176, 436, 528, 281, 652, 819, 7994, 13, 1033, 13, 407, 264, 955, 6898, 510, 307, 300, 321, 1409, 365, 732, 721, 51668], "temperature": 0.0, "avg_logprob": -0.13688377940326657, "compression_ratio": 1.582995951417004, "no_speech_prob": 0.001499903853982687}, {"id": 318, "seek": 228816, "start": 2288.16, "end": 2293.6, "text": " that look basically the same and ended up with entirely different ways of approaching them.", "tokens": [50364, 300, 574, 1936, 264, 912, 293, 4590, 493, 365, 7696, 819, 2098, 295, 14908, 552, 13, 50636], "temperature": 0.0, "avg_logprob": -0.0836131380892348, "compression_ratio": 1.6134453781512605, "no_speech_prob": 0.0016218599630519748}, {"id": 319, "seek": 228816, "start": 2293.6, "end": 2298.08, "text": " That was all about the data structure, right? And it is true that they share checkboxes, but that's", "tokens": [50636, 663, 390, 439, 466, 264, 1412, 3877, 11, 558, 30, 400, 309, 307, 2074, 300, 436, 2073, 1520, 4995, 279, 11, 457, 300, 311, 50860], "temperature": 0.0, "avg_logprob": -0.0836131380892348, "compression_ratio": 1.6134453781512605, "no_speech_prob": 0.0016218599630519748}, {"id": 320, "seek": 228816, "start": 2298.08, "end": 2303.12, "text": " such a small fraction of the actual difficult things that are going to happen in your code", "tokens": [50860, 1270, 257, 1359, 14135, 295, 264, 3539, 2252, 721, 300, 366, 516, 281, 1051, 294, 428, 3089, 51112], "temperature": 0.0, "avg_logprob": -0.0836131380892348, "compression_ratio": 1.6134453781512605, "no_speech_prob": 0.0016218599630519748}, {"id": 321, "seek": 228816, "start": 2303.12, "end": 2310.56, "text": " that it makes sense to emphasize the data structure instead. So I want to put a little extra emphasis", "tokens": [51112, 300, 309, 1669, 2020, 281, 16078, 264, 1412, 3877, 2602, 13, 407, 286, 528, 281, 829, 257, 707, 2857, 16271, 51484], "temperature": 0.0, "avg_logprob": -0.0836131380892348, "compression_ratio": 1.6134453781512605, "no_speech_prob": 0.0016218599630519748}, {"id": 322, "seek": 231056, "start": 2310.56, "end": 2318.64, "text": " on the module, right? So I showed this bounded set idea and it had, there's a bounded set.", "tokens": [50364, 322, 264, 10088, 11, 558, 30, 407, 286, 4712, 341, 37498, 992, 1558, 293, 309, 632, 11, 456, 311, 257, 37498, 992, 13, 50768], "temperature": 0.0, "avg_logprob": -0.10412152270053296, "compression_ratio": 1.6830357142857142, "no_speech_prob": 0.017692048102617264}, {"id": 323, "seek": 231056, "start": 2319.44, "end": 2324.7999999999997, "text": " If it's empty, you can insert things into it. You can remove things from it. You can check", "tokens": [50808, 759, 309, 311, 6707, 11, 291, 393, 8969, 721, 666, 309, 13, 509, 393, 4159, 721, 490, 309, 13, 509, 393, 1520, 51076], "temperature": 0.0, "avg_logprob": -0.10412152270053296, "compression_ratio": 1.6830357142857142, "no_speech_prob": 0.017692048102617264}, {"id": 324, "seek": 231056, "start": 2324.7999999999997, "end": 2332.08, "text": " membership. Now, the most important part of this module is the exposing line. Okay. So I'm not", "tokens": [51076, 16560, 13, 823, 11, 264, 881, 1021, 644, 295, 341, 10088, 307, 264, 33178, 1622, 13, 1033, 13, 407, 286, 478, 406, 51440], "temperature": 0.0, "avg_logprob": -0.10412152270053296, "compression_ratio": 1.6830357142857142, "no_speech_prob": 0.017692048102617264}, {"id": 325, "seek": 231056, "start": 2332.08, "end": 2336.7999999999997, "text": " exposing everything in this module. And specifically, I'm not exposing the implementation of bounded", "tokens": [51440, 33178, 1203, 294, 341, 10088, 13, 400, 4682, 11, 286, 478, 406, 33178, 264, 11420, 295, 37498, 51676], "temperature": 0.0, "avg_logprob": -0.10412152270053296, "compression_ratio": 1.6830357142857142, "no_speech_prob": 0.017692048102617264}, {"id": 326, "seek": 233680, "start": 2336.8, "end": 2343.52, "text": " set. So no one from outside can mess with the maximum size. And as long as these functions work,", "tokens": [50364, 992, 13, 407, 572, 472, 490, 2380, 393, 2082, 365, 264, 6674, 2744, 13, 400, 382, 938, 382, 613, 6828, 589, 11, 50700], "temperature": 0.0, "avg_logprob": -0.08251791615639964, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.00475020008161664}, {"id": 327, "seek": 233680, "start": 2344.2400000000002, "end": 2349.52, "text": " things are going to work. So I want to point out two little benefits that come from this.", "tokens": [50736, 721, 366, 516, 281, 589, 13, 407, 286, 528, 281, 935, 484, 732, 707, 5311, 300, 808, 490, 341, 13, 51000], "temperature": 0.0, "avg_logprob": -0.08251791615639964, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.00475020008161664}, {"id": 328, "seek": 233680, "start": 2349.52, "end": 2356.96, "text": " So if you reduce the public API to your module, if the implementation is hidden and if the public", "tokens": [51000, 407, 498, 291, 5407, 264, 1908, 9362, 281, 428, 10088, 11, 498, 264, 11420, 307, 7633, 293, 498, 264, 1908, 51372], "temperature": 0.0, "avg_logprob": -0.08251791615639964, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.00475020008161664}, {"id": 329, "seek": 233680, "start": 2356.96, "end": 2364.48, "text": " API works, the code works everywhere, right? So if I try to break this code by messing with", "tokens": [51372, 9362, 1985, 11, 264, 3089, 1985, 5315, 11, 558, 30, 407, 498, 286, 853, 281, 1821, 341, 3089, 538, 23258, 365, 51748], "temperature": 0.0, "avg_logprob": -0.08251791615639964, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.00475020008161664}, {"id": 330, "seek": 236448, "start": 2364.56, "end": 2371.44, "text": " these functions and I can't do it, anyone else who uses this code won't be able to do it either.", "tokens": [50368, 613, 6828, 293, 286, 393, 380, 360, 309, 11, 2878, 1646, 567, 4960, 341, 3089, 1582, 380, 312, 1075, 281, 360, 309, 2139, 13, 50712], "temperature": 0.0, "avg_logprob": -0.06484394506974654, "compression_ratio": 1.6974169741697418, "no_speech_prob": 0.0005971898208372295}, {"id": 331, "seek": 236448, "start": 2372.4, "end": 2376.96, "text": " So this is actually really nice for testing because it means you can test the public API", "tokens": [50760, 407, 341, 307, 767, 534, 1481, 337, 4997, 570, 309, 1355, 291, 393, 1500, 264, 1908, 9362, 50988], "temperature": 0.0, "avg_logprob": -0.06484394506974654, "compression_ratio": 1.6974169741697418, "no_speech_prob": 0.0005971898208372295}, {"id": 332, "seek": 236448, "start": 2376.96, "end": 2381.28, "text": " very extensively. And that doesn't mean you have to test every particular usage, right? Using", "tokens": [50988, 588, 32636, 13, 400, 300, 1177, 380, 914, 291, 362, 281, 1500, 633, 1729, 14924, 11, 558, 30, 11142, 51204], "temperature": 0.0, "avg_logprob": -0.06484394506974654, "compression_ratio": 1.6974169741697418, "no_speech_prob": 0.0005971898208372295}, {"id": 333, "seek": 236448, "start": 2381.84, "end": 2385.52, "text": " this data structure somewhere doesn't mean I can introduce bugs into that data structure", "tokens": [51232, 341, 1412, 3877, 4079, 1177, 380, 914, 286, 393, 5366, 15120, 666, 300, 1412, 3877, 51416], "temperature": 0.0, "avg_logprob": -0.06484394506974654, "compression_ratio": 1.6974169741697418, "no_speech_prob": 0.0005971898208372295}, {"id": 334, "seek": 236448, "start": 2385.52, "end": 2390.48, "text": " retroactively. If it works, it's going to work well. The other thing that's nice is you get", "tokens": [51416, 18820, 45679, 13, 759, 309, 1985, 11, 309, 311, 516, 281, 589, 731, 13, 440, 661, 551, 300, 311, 1481, 307, 291, 483, 51664], "temperature": 0.0, "avg_logprob": -0.06484394506974654, "compression_ratio": 1.6974169741697418, "no_speech_prob": 0.0005971898208372295}, {"id": 335, "seek": 239048, "start": 2390.56, "end": 2396.88, "text": " it easier refactoring. So I can change how things are implemented without worrying what's", "tokens": [50368, 309, 3571, 1895, 578, 3662, 13, 407, 286, 393, 1319, 577, 721, 366, 12270, 1553, 18788, 437, 311, 50684], "temperature": 0.0, "avg_logprob": -0.103540561510169, "compression_ratio": 1.7279411764705883, "no_speech_prob": 0.0012244858080521226}, {"id": 336, "seek": 239048, "start": 2396.88, "end": 2402.08, "text": " going to happen outside. And this happens in a couple ways. One is say there's an insert help", "tokens": [50684, 516, 281, 1051, 2380, 13, 400, 341, 2314, 294, 257, 1916, 2098, 13, 1485, 307, 584, 456, 311, 364, 8969, 854, 50944], "temperature": 0.0, "avg_logprob": -0.103540561510169, "compression_ratio": 1.7279411764705883, "no_speech_prob": 0.0012244858080521226}, {"id": 337, "seek": 239048, "start": 2402.08, "end": 2408.88, "text": " function that's doing some extra special stuff. I know that it's not exposed outside, so I can", "tokens": [50944, 2445, 300, 311, 884, 512, 2857, 2121, 1507, 13, 286, 458, 300, 309, 311, 406, 9495, 2380, 11, 370, 286, 393, 51284], "temperature": 0.0, "avg_logprob": -0.103540561510169, "compression_ratio": 1.7279411764705883, "no_speech_prob": 0.0012244858080521226}, {"id": 338, "seek": 239048, "start": 2408.88, "end": 2414.8, "text": " mess with that. Arguments, add arguments, change shuffle things around and be sure that this is", "tokens": [51284, 2082, 365, 300, 13, 40081, 4697, 11, 909, 12869, 11, 1319, 39426, 721, 926, 293, 312, 988, 300, 341, 307, 51580], "temperature": 0.0, "avg_logprob": -0.103540561510169, "compression_ratio": 1.7279411764705883, "no_speech_prob": 0.0012244858080521226}, {"id": 339, "seek": 239048, "start": 2414.8, "end": 2418.72, "text": " not going to have any effect in any other modules. I'm not going to have to go hunt stuff down.", "tokens": [51580, 406, 516, 281, 362, 604, 1802, 294, 604, 661, 16679, 13, 286, 478, 406, 516, 281, 362, 281, 352, 12454, 1507, 760, 13, 51776], "temperature": 0.0, "avg_logprob": -0.103540561510169, "compression_ratio": 1.7279411764705883, "no_speech_prob": 0.0012244858080521226}, {"id": 340, "seek": 241872, "start": 2419.3599999999997, "end": 2424.3199999999997, "text": " That's also nice because it means I don't have to worry about if it's used in 10 different", "tokens": [50396, 663, 311, 611, 1481, 570, 309, 1355, 286, 500, 380, 362, 281, 3292, 466, 498, 309, 311, 1143, 294, 1266, 819, 50644], "temperature": 0.0, "avg_logprob": -0.08254301071166992, "compression_ratio": 1.6, "no_speech_prob": 0.0010628338204696774}, {"id": 341, "seek": 241872, "start": 2424.3199999999997, "end": 2430.0, "text": " places across the code, did they need it to work in a very particular way in each of those cases?", "tokens": [50644, 3190, 2108, 264, 3089, 11, 630, 436, 643, 309, 281, 589, 294, 257, 588, 1729, 636, 294, 1184, 295, 729, 3331, 30, 50928], "temperature": 0.0, "avg_logprob": -0.08254301071166992, "compression_ratio": 1.6, "no_speech_prob": 0.0010628338204696774}, {"id": 342, "seek": 241872, "start": 2430.0, "end": 2434.8799999999997, "text": " And I'm covering all those cases. I can just say, oh, it's not publicly exposed. If it works in", "tokens": [50928, 400, 286, 478, 10322, 439, 729, 3331, 13, 286, 393, 445, 584, 11, 1954, 11, 309, 311, 406, 14843, 9495, 13, 759, 309, 1985, 294, 51172], "temperature": 0.0, "avg_logprob": -0.08254301071166992, "compression_ratio": 1.6, "no_speech_prob": 0.0010628338204696774}, {"id": 343, "seek": 241872, "start": 2434.8799999999997, "end": 2443.3599999999997, "text": " this file, it works. So the other thing that you can do by creating modules in this way is maintain", "tokens": [51172, 341, 3991, 11, 309, 1985, 13, 407, 264, 661, 551, 300, 291, 393, 360, 538, 4084, 16679, 294, 341, 636, 307, 6909, 51596], "temperature": 0.0, "avg_logprob": -0.08254301071166992, "compression_ratio": 1.6, "no_speech_prob": 0.0010628338204696774}, {"id": 344, "seek": 244336, "start": 2443.36, "end": 2449.28, "text": " invariance. So in our case, that's only two fruits. But generally speaking, this means there are", "tokens": [50364, 33270, 719, 13, 407, 294, 527, 1389, 11, 300, 311, 787, 732, 12148, 13, 583, 5101, 4124, 11, 341, 1355, 456, 366, 50660], "temperature": 0.0, "avg_logprob": -0.08735620674966764, "compression_ratio": 1.7536764705882353, "no_speech_prob": 0.005377636291086674}, {"id": 345, "seek": 244336, "start": 2449.28, "end": 2454.96, "text": " rules that cannot be enforced entirely through data structure design. So we had our two, which is", "tokens": [50660, 4474, 300, 2644, 312, 40953, 7696, 807, 1412, 3877, 1715, 13, 407, 321, 632, 527, 732, 11, 597, 307, 50944], "temperature": 0.0, "avg_logprob": -0.08735620674966764, "compression_ratio": 1.7536764705882353, "no_speech_prob": 0.005377636291086674}, {"id": 346, "seek": 244336, "start": 2454.96, "end": 2460.7200000000003, "text": " zero, one or two, but that wouldn't let us decide how many we want. So we now have a data structure", "tokens": [50944, 4018, 11, 472, 420, 732, 11, 457, 300, 2759, 380, 718, 505, 4536, 577, 867, 321, 528, 13, 407, 321, 586, 362, 257, 1412, 3877, 51232], "temperature": 0.0, "avg_logprob": -0.08735620674966764, "compression_ratio": 1.7536764705882353, "no_speech_prob": 0.005377636291086674}, {"id": 347, "seek": 244336, "start": 2460.7200000000003, "end": 2466.7200000000003, "text": " that can let us decide. And by hiding all the details, we can still maintain that rule in a", "tokens": [51232, 300, 393, 718, 505, 4536, 13, 400, 538, 10596, 439, 264, 4365, 11, 321, 393, 920, 6909, 300, 4978, 294, 257, 51532], "temperature": 0.0, "avg_logprob": -0.08735620674966764, "compression_ratio": 1.7536764705882353, "no_speech_prob": 0.005377636291086674}, {"id": 348, "seek": 244336, "start": 2466.7200000000003, "end": 2471.6, "text": " safe way, even though we can't do it purely through data. And one cool thing about finding", "tokens": [51532, 3273, 636, 11, 754, 1673, 321, 393, 380, 360, 309, 17491, 807, 1412, 13, 400, 472, 1627, 551, 466, 5006, 51776], "temperature": 0.0, "avg_logprob": -0.08735620674966764, "compression_ratio": 1.7536764705882353, "no_speech_prob": 0.005377636291086674}, {"id": 349, "seek": 247160, "start": 2471.6, "end": 2477.68, "text": " invariance like this is that they're excellent for fuzz tests. So I know that whatever I do with", "tokens": [50364, 33270, 719, 411, 341, 307, 300, 436, 434, 7103, 337, 283, 16740, 6921, 13, 407, 286, 458, 300, 2035, 286, 360, 365, 50668], "temperature": 0.0, "avg_logprob": -0.0632609092083174, "compression_ratio": 1.6218487394957983, "no_speech_prob": 0.002112035173922777}, {"id": 350, "seek": 247160, "start": 2477.68, "end": 2483.2, "text": " this, if I say my bounded set has two things, no matter how many times I call insert, it should", "tokens": [50668, 341, 11, 498, 286, 584, 452, 37498, 992, 575, 732, 721, 11, 572, 1871, 577, 867, 1413, 286, 818, 8969, 11, 309, 820, 50944], "temperature": 0.0, "avg_logprob": -0.0632609092083174, "compression_ratio": 1.6218487394957983, "no_speech_prob": 0.002112035173922777}, {"id": 351, "seek": 247160, "start": 2483.2, "end": 2489.2799999999997, "text": " just have two things. So by thinking in this way, you also set yourself up to write tests that", "tokens": [50944, 445, 362, 732, 721, 13, 407, 538, 1953, 294, 341, 636, 11, 291, 611, 992, 1803, 493, 281, 2464, 6921, 300, 51248], "temperature": 0.0, "avg_logprob": -0.0632609092083174, "compression_ratio": 1.6218487394957983, "no_speech_prob": 0.002112035173922777}, {"id": 352, "seek": 247160, "start": 2489.2799999999997, "end": 2495.6, "text": " are nice and are checking the kinds of things you're worried about. So I want to add some warnings", "tokens": [51248, 366, 1481, 293, 366, 8568, 264, 3685, 295, 721, 291, 434, 5804, 466, 13, 407, 286, 528, 281, 909, 512, 30009, 51564], "temperature": 0.0, "avg_logprob": -0.0632609092083174, "compression_ratio": 1.6218487394957983, "no_speech_prob": 0.002112035173922777}, {"id": 353, "seek": 249560, "start": 2496.16, "end": 2503.8399999999997, "text": " to this advice. So first, if you find yourself writing get and set, right, so we hid the max", "tokens": [50392, 281, 341, 5192, 13, 407, 700, 11, 498, 291, 915, 1803, 3579, 483, 293, 992, 11, 558, 11, 370, 321, 16253, 264, 11469, 50776], "temperature": 0.0, "avg_logprob": -0.11118379750646147, "compression_ratio": 1.6890459363957597, "no_speech_prob": 0.008299026638269424}, {"id": 354, "seek": 249560, "start": 2503.8399999999997, "end": 2508.56, "text": " size, but maybe someone's like, well, I want the max size. I won't do a bad thing with it.", "tokens": [50776, 2744, 11, 457, 1310, 1580, 311, 411, 11, 731, 11, 286, 528, 264, 11469, 2744, 13, 286, 1582, 380, 360, 257, 1578, 551, 365, 309, 13, 51012], "temperature": 0.0, "avg_logprob": -0.11118379750646147, "compression_ratio": 1.6890459363957597, "no_speech_prob": 0.008299026638269424}, {"id": 355, "seek": 249560, "start": 2510.48, "end": 2515.2799999999997, "text": " Okay, this is a bad sign. This is a bad sign when you have get and set. So the whole point of having", "tokens": [51108, 1033, 11, 341, 307, 257, 1578, 1465, 13, 639, 307, 257, 1578, 1465, 562, 291, 362, 483, 293, 992, 13, 407, 264, 1379, 935, 295, 1419, 51348], "temperature": 0.0, "avg_logprob": -0.11118379750646147, "compression_ratio": 1.6890459363957597, "no_speech_prob": 0.008299026638269424}, {"id": 356, "seek": 249560, "start": 2515.2799999999997, "end": 2520.72, "text": " a module was that we were able to hide implementation details and say, if you use this public API,", "tokens": [51348, 257, 10088, 390, 300, 321, 645, 1075, 281, 6479, 11420, 4365, 293, 584, 11, 498, 291, 764, 341, 1908, 9362, 11, 51620], "temperature": 0.0, "avg_logprob": -0.11118379750646147, "compression_ratio": 1.6890459363957597, "no_speech_prob": 0.008299026638269424}, {"id": 357, "seek": 249560, "start": 2520.72, "end": 2524.72, "text": " it will work. And inside, you don't have to worry about that. We tested it. We know it's good.", "tokens": [51620, 309, 486, 589, 13, 400, 1854, 11, 291, 500, 380, 362, 281, 3292, 466, 300, 13, 492, 8246, 309, 13, 492, 458, 309, 311, 665, 13, 51820], "temperature": 0.0, "avg_logprob": -0.11118379750646147, "compression_ratio": 1.6890459363957597, "no_speech_prob": 0.008299026638269424}, {"id": 358, "seek": 252560, "start": 2525.8399999999997, "end": 2534.0, "text": " Setters, their whole point is to expose those details. So you've done all this work to put", "tokens": [50376, 8928, 1559, 11, 641, 1379, 935, 307, 281, 19219, 729, 4365, 13, 407, 291, 600, 1096, 439, 341, 589, 281, 829, 50784], "temperature": 0.0, "avg_logprob": -0.14027540580086087, "compression_ratio": 1.60352422907489, "no_speech_prob": 0.0003049478982575238}, {"id": 359, "seek": 252560, "start": 2534.0, "end": 2538.08, "text": " it in a module, and we went through that together. It was like, it took too long.", "tokens": [50784, 309, 294, 257, 10088, 11, 293, 321, 1437, 807, 300, 1214, 13, 467, 390, 411, 11, 309, 1890, 886, 938, 13, 50988], "temperature": 0.0, "avg_logprob": -0.14027540580086087, "compression_ratio": 1.60352422907489, "no_speech_prob": 0.0003049478982575238}, {"id": 360, "seek": 252560, "start": 2542.7999999999997, "end": 2549.36, "text": " And now you're going to give setters that just totally defeat that entire exercise. So just use", "tokens": [51224, 400, 586, 291, 434, 516, 281, 976, 992, 1559, 300, 445, 3879, 11785, 300, 2302, 5380, 13, 407, 445, 764, 51552], "temperature": 0.0, "avg_logprob": -0.14027540580086087, "compression_ratio": 1.60352422907489, "no_speech_prob": 0.0003049478982575238}, {"id": 361, "seek": 252560, "start": 2549.36, "end": 2554.0, "text": " a record if you have data where you want people to have access, rather than hiding the details,", "tokens": [51552, 257, 2136, 498, 291, 362, 1412, 689, 291, 528, 561, 281, 362, 2105, 11, 2831, 813, 10596, 264, 4365, 11, 51784], "temperature": 0.0, "avg_logprob": -0.14027540580086087, "compression_ratio": 1.60352422907489, "no_speech_prob": 0.0003049478982575238}, {"id": 362, "seek": 255400, "start": 2554.0, "end": 2560.0, "text": " then exposing get and setters. It's like, these details aren't hidden. So don't do the work to", "tokens": [50364, 550, 33178, 483, 293, 992, 1559, 13, 467, 311, 411, 11, 613, 4365, 3212, 380, 7633, 13, 407, 500, 380, 360, 264, 589, 281, 50664], "temperature": 0.0, "avg_logprob": -0.11512167930603028, "compression_ratio": 1.6460176991150441, "no_speech_prob": 0.0006062428583391011}, {"id": 363, "seek": 255400, "start": 2560.0, "end": 2566.24, "text": " hide them. So another way to say this is expose as little as possible, but no less. Some things", "tokens": [50664, 6479, 552, 13, 407, 1071, 636, 281, 584, 341, 307, 19219, 382, 707, 382, 1944, 11, 457, 572, 1570, 13, 2188, 721, 50976], "temperature": 0.0, "avg_logprob": -0.11512167930603028, "compression_ratio": 1.6460176991150441, "no_speech_prob": 0.0006062428583391011}, {"id": 364, "seek": 255400, "start": 2566.24, "end": 2571.44, "text": " do need to be publicly available. So this shouldn't just be like, hide everything. That's better.", "tokens": [50976, 360, 643, 281, 312, 14843, 2435, 13, 407, 341, 4659, 380, 445, 312, 411, 11, 6479, 1203, 13, 663, 311, 1101, 13, 51236], "temperature": 0.0, "avg_logprob": -0.11512167930603028, "compression_ratio": 1.6460176991150441, "no_speech_prob": 0.0006062428583391011}, {"id": 365, "seek": 255400, "start": 2573.04, "end": 2579.68, "text": " The other thing is don't overdo it. So I'd wait until I have a problem in practice,", "tokens": [51316, 440, 661, 551, 307, 500, 380, 670, 2595, 309, 13, 407, 286, 1116, 1699, 1826, 286, 362, 257, 1154, 294, 3124, 11, 51648], "temperature": 0.0, "avg_logprob": -0.11512167930603028, "compression_ratio": 1.6460176991150441, "no_speech_prob": 0.0006062428583391011}, {"id": 366, "seek": 257968, "start": 2579.68, "end": 2584.72, "text": " and then solve that problem. So the goal shouldn't be let's just write modules, because modules help", "tokens": [50364, 293, 550, 5039, 300, 1154, 13, 407, 264, 3387, 4659, 380, 312, 718, 311, 445, 2464, 16679, 11, 570, 16679, 854, 50616], "temperature": 0.0, "avg_logprob": -0.0938019704337072, "compression_ratio": 1.5901639344262295, "no_speech_prob": 0.00857151485979557}, {"id": 367, "seek": 257968, "start": 2584.72, "end": 2590.16, "text": " with this kind of stuff. It should be, hey, I'm having trouble understanding this code. I came", "tokens": [50616, 365, 341, 733, 295, 1507, 13, 467, 820, 312, 11, 4177, 11, 286, 478, 1419, 5253, 3701, 341, 3089, 13, 286, 1361, 50888], "temperature": 0.0, "avg_logprob": -0.0938019704337072, "compression_ratio": 1.5901639344262295, "no_speech_prob": 0.00857151485979557}, {"id": 368, "seek": 257968, "start": 2590.16, "end": 2594.96, "text": " back to it after a month, and it seemed kind of confusing. Maybe I can find parts that I can", "tokens": [50888, 646, 281, 309, 934, 257, 1618, 11, 293, 309, 6576, 733, 295, 13181, 13, 2704, 286, 393, 915, 3166, 300, 286, 393, 51128], "temperature": 0.0, "avg_logprob": -0.0938019704337072, "compression_ratio": 1.5901639344262295, "no_speech_prob": 0.00857151485979557}, {"id": 369, "seek": 257968, "start": 2596.08, "end": 2603.04, "text": " make things nicer. So if you find yourself asking, how do I make the sidebar reusable? Okay, try to", "tokens": [51184, 652, 721, 22842, 13, 407, 498, 291, 915, 1803, 3365, 11, 577, 360, 286, 652, 264, 1252, 5356, 41807, 30, 1033, 11, 853, 281, 51532], "temperature": 0.0, "avg_logprob": -0.0938019704337072, "compression_ratio": 1.5901639344262295, "no_speech_prob": 0.00857151485979557}, {"id": 370, "seek": 260304, "start": 2603.12, "end": 2610.72, "text": " remember to ask yourself why. Are you going to have multiple sidebars? Maybe not. In which case,", "tokens": [50368, 1604, 281, 1029, 1803, 983, 13, 2014, 291, 516, 281, 362, 3866, 1252, 42162, 30, 2704, 406, 13, 682, 597, 1389, 11, 50748], "temperature": 0.0, "avg_logprob": -0.1029871823836346, "compression_ratio": 1.6724137931034482, "no_speech_prob": 0.012807835824787617}, {"id": 371, "seek": 260304, "start": 2610.72, "end": 2616.64, "text": " like, why would you do the work to do that? If you are going to have multiple ones, a thing to", "tokens": [50748, 411, 11, 983, 576, 291, 360, 264, 589, 281, 360, 300, 30, 759, 291, 366, 516, 281, 362, 3866, 2306, 11, 257, 551, 281, 51044], "temperature": 0.0, "avg_logprob": -0.1029871823836346, "compression_ratio": 1.6724137931034482, "no_speech_prob": 0.012807835824787617}, {"id": 372, "seek": 260304, "start": 2616.64, "end": 2623.12, "text": " think is, are these cases the same, or are they similar? If we're just talking about the HTML", "tokens": [51044, 519, 307, 11, 366, 613, 3331, 264, 912, 11, 420, 366, 436, 2531, 30, 759, 321, 434, 445, 1417, 466, 264, 17995, 51368], "temperature": 0.0, "avg_logprob": -0.1029871823836346, "compression_ratio": 1.6724137931034482, "no_speech_prob": 0.012807835824787617}, {"id": 373, "seek": 260304, "start": 2623.12, "end": 2627.12, "text": " is going to look similar, but how it works behind the scenes is fundamentally different in both cases.", "tokens": [51368, 307, 516, 281, 574, 2531, 11, 457, 577, 309, 1985, 2261, 264, 8026, 307, 17879, 819, 294, 1293, 3331, 13, 51568], "temperature": 0.0, "avg_logprob": -0.1029871823836346, "compression_ratio": 1.6724137931034482, "no_speech_prob": 0.012807835824787617}, {"id": 374, "seek": 262712, "start": 2627.92, "end": 2633.92, "text": " I think it's probably not a good idea to, like, try to get all into how do we share code between", "tokens": [50404, 286, 519, 309, 311, 1391, 406, 257, 665, 1558, 281, 11, 411, 11, 853, 281, 483, 439, 666, 577, 360, 321, 2073, 3089, 1296, 50704], "temperature": 0.0, "avg_logprob": -0.10579149015657194, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.002319695893675089}, {"id": 375, "seek": 262712, "start": 2633.92, "end": 2639.6, "text": " these two. Focus on the data structure instead. Another thing that might happen is as you're", "tokens": [50704, 613, 732, 13, 21862, 322, 264, 1412, 3877, 2602, 13, 3996, 551, 300, 1062, 1051, 307, 382, 291, 434, 50988], "temperature": 0.0, "avg_logprob": -0.10579149015657194, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.002319695893675089}, {"id": 376, "seek": 262712, "start": 2639.6, "end": 2644.56, "text": " growing your record, you don't have any interesting types. You don't have that autoplay thing where", "tokens": [50988, 4194, 428, 2136, 11, 291, 500, 380, 362, 604, 1880, 3467, 13, 509, 500, 380, 362, 300, 31090, 8376, 551, 689, 51236], "temperature": 0.0, "avg_logprob": -0.10579149015657194, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.002319695893675089}, {"id": 377, "seek": 262712, "start": 2644.56, "end": 2649.12, "text": " these fields are dependent on that field. It's just a bunch of independent stuff.", "tokens": [51236, 613, 7909, 366, 12334, 322, 300, 2519, 13, 467, 311, 445, 257, 3840, 295, 6695, 1507, 13, 51464], "temperature": 0.0, "avg_logprob": -0.10579149015657194, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.002319695893675089}, {"id": 378, "seek": 264912, "start": 2649.3599999999997, "end": 2657.52, "text": " If they're all independent, there's no problem. If I just have fields that have no relationship", "tokens": [50376, 759, 436, 434, 439, 6695, 11, 456, 311, 572, 1154, 13, 759, 286, 445, 362, 7909, 300, 362, 572, 2480, 50784], "temperature": 0.0, "avg_logprob": -0.09228564814517373, "compression_ratio": 1.6491228070175439, "no_speech_prob": 0.001386570744216442}, {"id": 379, "seek": 264912, "start": 2657.52, "end": 2663.04, "text": " to each other, and I change one, there's not a chance that there's some bug elsewhere. But if I", "tokens": [50784, 281, 1184, 661, 11, 293, 286, 1319, 472, 11, 456, 311, 406, 257, 2931, 300, 456, 311, 512, 7426, 14517, 13, 583, 498, 286, 51060], "temperature": 0.0, "avg_logprob": -0.09228564814517373, "compression_ratio": 1.6491228070175439, "no_speech_prob": 0.001386570744216442}, {"id": 380, "seek": 264912, "start": 2663.04, "end": 2667.6, "text": " do have that relationship, that's a potential to start finding a data structure and do better", "tokens": [51060, 360, 362, 300, 2480, 11, 300, 311, 257, 3995, 281, 722, 5006, 257, 1412, 3877, 293, 360, 1101, 51288], "temperature": 0.0, "avg_logprob": -0.09228564814517373, "compression_ratio": 1.6491228070175439, "no_speech_prob": 0.001386570744216442}, {"id": 381, "seek": 264912, "start": 2667.6, "end": 2673.3599999999997, "text": " modeling. So I'd say, like, don't be afraid to just grow your record and try to find these", "tokens": [51288, 15983, 13, 407, 286, 1116, 584, 11, 411, 11, 500, 380, 312, 4638, 281, 445, 1852, 428, 2136, 293, 853, 281, 915, 613, 51576], "temperature": 0.0, "avg_logprob": -0.09228564814517373, "compression_ratio": 1.6491228070175439, "no_speech_prob": 0.001386570744216442}, {"id": 382, "seek": 267336, "start": 2674.2400000000002, "end": 2680.32, "text": " connections and how things fit together, as opposed to preemptively, like, ah, I'm worried", "tokens": [50408, 9271, 293, 577, 721, 3318, 1214, 11, 382, 8851, 281, 659, 4543, 3413, 11, 411, 11, 3716, 11, 286, 478, 5804, 50712], "temperature": 0.0, "avg_logprob": -0.1691129513275929, "compression_ratio": 1.538888888888889, "no_speech_prob": 0.008175769820809364}, {"id": 383, "seek": 267336, "start": 2680.32, "end": 2687.28, "text": " about this code, so I'm just going to change it. So, yeah, just as there's premature optimization,", "tokens": [50712, 466, 341, 3089, 11, 370, 286, 478, 445, 516, 281, 1319, 309, 13, 407, 11, 1338, 11, 445, 382, 456, 311, 34877, 19618, 11, 51060], "temperature": 0.0, "avg_logprob": -0.1691129513275929, "compression_ratio": 1.538888888888889, "no_speech_prob": 0.008175769820809364}, {"id": 384, "seek": 267336, "start": 2687.28, "end": 2693.2000000000003, "text": " there's premature refactoring. It's a thing, it's fun, right? It's like you get to play", "tokens": [51060, 456, 311, 34877, 1895, 578, 3662, 13, 467, 311, 257, 551, 11, 309, 311, 1019, 11, 558, 30, 467, 311, 411, 291, 483, 281, 862, 51356], "temperature": 0.0, "avg_logprob": -0.1691129513275929, "compression_ratio": 1.538888888888889, "no_speech_prob": 0.008175769820809364}, {"id": 385, "seek": 269320, "start": 2693.2, "end": 2701.7599999999998, "text": " code golf at work. I don't think employers should encourage that, but people like to do it.", "tokens": [50364, 3089, 12880, 412, 589, 13, 286, 500, 380, 519, 16744, 820, 5373, 300, 11, 457, 561, 411, 281, 360, 309, 13, 50792], "temperature": 0.0, "avg_logprob": -0.10684024321066367, "compression_ratio": 1.4397905759162304, "no_speech_prob": 0.039579421281814575}, {"id": 386, "seek": 269320, "start": 2703.52, "end": 2714.16, "text": " Okay, so to take a step back, we saw how a file tends to grow, right? And if we focus on", "tokens": [50880, 1033, 11, 370, 281, 747, 257, 1823, 646, 11, 321, 1866, 577, 257, 3991, 12258, 281, 1852, 11, 558, 30, 400, 498, 321, 1879, 322, 51412], "temperature": 0.0, "avg_logprob": -0.10684024321066367, "compression_ratio": 1.4397905759162304, "no_speech_prob": 0.039579421281814575}, {"id": 387, "seek": 269320, "start": 2714.16, "end": 2719.12, "text": " the data structures, we end up with these nice categorizations where, like, when I'm searching", "tokens": [51412, 264, 1412, 9227, 11, 321, 917, 493, 365, 613, 1481, 19250, 14455, 689, 11, 411, 11, 562, 286, 478, 10808, 51660], "temperature": 0.0, "avg_logprob": -0.10684024321066367, "compression_ratio": 1.4397905759162304, "no_speech_prob": 0.039579421281814575}, {"id": 388, "seek": 271912, "start": 2719.2, "end": 2724.0, "text": " through a code base even, I say, hey, where's that stuff that's related to books? It's probably in", "tokens": [50368, 807, 257, 3089, 3096, 754, 11, 286, 584, 11, 4177, 11, 689, 311, 300, 1507, 300, 311, 4077, 281, 3642, 30, 467, 311, 1391, 294, 50608], "temperature": 0.0, "avg_logprob": -0.12685064474741617, "compression_ratio": 1.7463235294117647, "no_speech_prob": 0.0041938056237995625}, {"id": 389, "seek": 271912, "start": 2724.0, "end": 2730.0, "text": " the module about books, right? As opposed to, well, there's this update subdirectory, and all the", "tokens": [50608, 264, 10088, 466, 3642, 11, 558, 30, 1018, 8851, 281, 11, 731, 11, 456, 311, 341, 5623, 31662, 11890, 827, 11, 293, 439, 264, 50908], "temperature": 0.0, "avg_logprob": -0.12685064474741617, "compression_ratio": 1.7463235294117647, "no_speech_prob": 0.0041938056237995625}, {"id": 390, "seek": 271912, "start": 2730.0, "end": 2737.44, "text": " update code is there, and the book stuff is just like, it's related to books. So, yeah, so big", "tokens": [50908, 5623, 3089, 307, 456, 11, 293, 264, 1446, 1507, 307, 445, 411, 11, 309, 311, 4077, 281, 3642, 13, 407, 11, 1338, 11, 370, 955, 51280], "temperature": 0.0, "avg_logprob": -0.12685064474741617, "compression_ratio": 1.7463235294117647, "no_speech_prob": 0.0041938056237995625}, {"id": 391, "seek": 271912, "start": 2737.44, "end": 2741.8399999999997, "text": " lessons are focus on data structures and choose the best representation available. So, like,", "tokens": [51280, 8820, 366, 1879, 322, 1412, 9227, 293, 2826, 264, 1151, 10290, 2435, 13, 407, 11, 411, 11, 51500], "temperature": 0.0, "avg_logprob": -0.12685064474741617, "compression_ratio": 1.7463235294117647, "no_speech_prob": 0.0041938056237995625}, {"id": 392, "seek": 271912, "start": 2741.8399999999997, "end": 2746.7999999999997, "text": " actually think through as many cases as you can, and the others build modules around types", "tokens": [51500, 767, 519, 807, 382, 867, 3331, 382, 291, 393, 11, 293, 264, 2357, 1322, 16679, 926, 3467, 51748], "temperature": 0.0, "avg_logprob": -0.12685064474741617, "compression_ratio": 1.7463235294117647, "no_speech_prob": 0.0041938056237995625}, {"id": 393, "seek": 274680, "start": 2747.36, "end": 2757.2000000000003, "text": " and try to expose as little as possible, but no less. So, yeah, so I hope this will be a nice", "tokens": [50392, 293, 853, 281, 19219, 382, 707, 382, 1944, 11, 457, 572, 1570, 13, 407, 11, 1338, 11, 370, 286, 1454, 341, 486, 312, 257, 1481, 50884], "temperature": 0.0, "avg_logprob": -0.13619332313537597, "compression_ratio": 1.4739583333333333, "no_speech_prob": 0.0009104593191295862}, {"id": 394, "seek": 274680, "start": 2757.2000000000003, "end": 2765.76, "text": " next advice in the, how do I grow my Elm code? And one of my goals was to write this up. So,", "tokens": [50884, 958, 5192, 294, 264, 11, 577, 360, 286, 1852, 452, 2699, 76, 3089, 30, 400, 472, 295, 452, 5493, 390, 281, 2464, 341, 493, 13, 407, 11, 51312], "temperature": 0.0, "avg_logprob": -0.13619332313537597, "compression_ratio": 1.4739583333333333, "no_speech_prob": 0.0009104593191295862}, {"id": 395, "seek": 274680, "start": 2765.76, "end": 2772.88, "text": " I actually started a book that is about functional programming in Elm, and the goal of this book", "tokens": [51312, 286, 767, 1409, 257, 1446, 300, 307, 466, 11745, 9410, 294, 2699, 76, 11, 293, 264, 3387, 295, 341, 1446, 51668], "temperature": 0.0, "avg_logprob": -0.13619332313537597, "compression_ratio": 1.4739583333333333, "no_speech_prob": 0.0009104593191295862}, {"id": 396, "seek": 277288, "start": 2772.88, "end": 2776.7200000000003, "text": " was essentially to write this talk so that people could read it online and it would work out.", "tokens": [50364, 390, 4476, 281, 2464, 341, 751, 370, 300, 561, 727, 1401, 309, 2950, 293, 309, 576, 589, 484, 13, 50556], "temperature": 0.0, "avg_logprob": -0.09297759797838, "compression_ratio": 1.5666666666666667, "no_speech_prob": 0.010968411341309547}, {"id": 397, "seek": 277288, "start": 2777.44, "end": 2783.36, "text": " It turns out it's very hard to write that whole live coding section. So, instead, what I ended", "tokens": [50592, 467, 4523, 484, 309, 311, 588, 1152, 281, 2464, 300, 1379, 1621, 17720, 3541, 13, 407, 11, 2602, 11, 437, 286, 4590, 50888], "temperature": 0.0, "avg_logprob": -0.09297759797838, "compression_ratio": 1.5666666666666667, "no_speech_prob": 0.010968411341309547}, {"id": 398, "seek": 277288, "start": 2783.36, "end": 2790.0, "text": " up with is some nice stuff about recursion and graphs. It's fun. Hopefully, I'll be able to", "tokens": [50888, 493, 365, 307, 512, 1481, 1507, 466, 20560, 313, 293, 24877, 13, 467, 311, 1019, 13, 10429, 11, 286, 603, 312, 1075, 281, 51220], "temperature": 0.0, "avg_logprob": -0.09297759797838, "compression_ratio": 1.5666666666666667, "no_speech_prob": 0.010968411341309547}, {"id": 399, "seek": 277288, "start": 2790.0, "end": 2794.96, "text": " distill this down into another chapter that actually emphasizes these things in a way where you", "tokens": [51220, 42923, 341, 760, 666, 1071, 7187, 300, 767, 48856, 613, 721, 294, 257, 636, 689, 291, 51468], "temperature": 0.0, "avg_logprob": -0.09297759797838, "compression_ratio": 1.5666666666666667, "no_speech_prob": 0.010968411341309547}, {"id": 400, "seek": 279496, "start": 2794.96, "end": 2812.0, "text": " don't have to see the live talk. But, yeah, so that's the life of a file. Thank you.", "tokens": [50364, 500, 380, 362, 281, 536, 264, 1621, 751, 13, 583, 11, 1338, 11, 370, 300, 311, 264, 993, 295, 257, 3991, 13, 1044, 291, 13, 51216], "temperature": 0.0, "avg_logprob": -0.17997603757040842, "compression_ratio": 1.0632911392405062, "no_speech_prob": 0.0035119480453431606}], "language": "en"}