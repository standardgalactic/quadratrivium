{"text": " What an incredible pleasure to be here with Jeffrey Hinton, one of the great minds and one of the great issues of our time. A man who helped create artificial intelligence was at the center of nearly every revolution in it and now has become perhaps the most articulate critic of where we're going. So an honor to be on stage with you. Thank you. During the moniker Godfather of AI, one of the things that AI has traditionally had problems with is humor, I asked AI if it could come up with a joke about the Godfather of AI and it actually wasn't that bad. It said he gave AI an offer it couldn't refuse, neural networks. It's not bad. Okay, that's not bad. It's good for AI. So let's begin with that. What I want to do in this conversation is very briefly step a little back into your foundational work, then go to where we are today and then talk about the future. So when you're building and you're designing neural networks and you're building computer systems that work like the human brain and that learn like the human brain and everybody else is saying, Jeff, this is not going to work. You push ahead and do you push ahead because you know that this is the best way to train computer systems or you do it for more spiritual reasons that you want to make a machine that is like us? I do it because the brain has to work somehow and it sure as hell doesn't work by manipulating symbolic expressions explicitly and so something like neural nets had to work. Also von Neumann and Turing believed that so that's a good start. So you're doing it because you think it's the best way forward? Yes, in the long run the best way forward. Because that decision has profound effects down the line. Okay, so you do that. You start building neural nets, you push forward and they become better than humans at certain limited tasks, right? At image recognition, at translation, some chemical work. I interviewed you in 2019 at Google I.O. and you said that it would be a long time before they could match us in reasoning and that's the big change that's happened over the last four years, right? They still can't match us but they're getting close. And how close are they getting and why? It's the big language models that are getting close and I don't really understand why they can do it but they can do little bits of reasoning. So my favorite example is I asked GPT-4, a puzzle that was given to me by a symbolic AI guy who thought it wouldn't be able to do it. I made the puzzle more difficult than it could still do it and the puzzle was the rooms in my house are painted blue or yellow or white. Yellow paint fades to white within a year. In two years' time I want them all to be white. What should I do and why? And it says you should paint the blue rooms white and then it says you should do that because blue won't fade to white and it says you don't need to paint the yellow rooms because they will fade to white. So it knew what I should do and it knew why and I was surprised that it could do that much reasoning already. And it's kind of an amazing example because when people critique these systems or they say they're not going to do much, they say they're mad libs, they're just word completion but that is not word completion. To you is that thinking? Yeah, that's thinking and when people say it's just autocomplete, a lot goes on in that word just autocomplete. If you think what it takes to predict the next word, you have to understand what's been said to be really good at predicting the next word. So people say it's just autocomplete or it's just statistics. Now there's a sense in which it is just statistics, but in that sense everything's just statistics. It's not the sense most people think of statistics as it keeps the counts of how many times this combination of words occurred and how many times that combination. It's not like that at all. It's inventing features and interactions between features to explain what comes next. So if it's just statistics and everything is just statistics, is there anything that we can do? Obviously it's not humor, maybe it's not reasoning. Is there anything that we can do that a sufficiently well-trained large language model with a sufficient number of parameters and a sufficient amount of compute could not do in the future? If the model is also trained on vision and picking things up and so on, then no. But is there anything that we can think of and any way we can think in any cognitive process that the machines will not be able to replicate? We're just a machine, we're a wonderful, incredibly complicated machine, but we're just a big neural net and there's no reason why an artificial neural net shouldn't be able to do everything we can do. Are we a big neural net that is more efficient than these new neural nets we're building or are we less efficient? It depends whether you're talking about speed of acquiring knowledge and how much knowledge you can acquire or whether you're talking about energy consumption. So in energy consumption, we're much more efficient. We're like 30 watts and one of these big language models, when you're training it, you train many copies of it each looking at different parts of the data. So it's more like a megawatt. So it's much more expensive in terms of energy, but all these copies can be learning different things from different parts of the data. So it's much more efficient in terms of acquiring knowledge from data. And it becomes only more efficient because each system can train each next system? Yes. So let's get to your critique. So the best summarization of your critique came from a conference at the Milken Institute about a month ago and it was Snoop Dogg and he said, I heard the old dude who created AI saying this is not safe because the AI's got their own mind and those motherfuckers going to start doing their own shit. Is that accurate? Is that an accurate summarization? They probably didn't have mothers. But the rest of what Dr. Dogg said is correct. Hang on. Yes. All right. So explain what you mean or what he means and how it applies to what you mean when they're going to start doing their own shit. What does that mean to you? Okay. So first I have to emphasize we're entering a period of huge uncertainty. Nobody really knows what's going to happen. And people whose opinion I respect have very different beliefs from me. Like Jan LeCun thinks everything's going to be fine. They're just going to help us. It's all going to be wonderful. But I think we have to take seriously the possibility that if they get to be smarter than us, which seems quite likely, and they have goals of their own, which seems quite likely, they may well develop the goal of taking control. And if they do that, we're in trouble. So okay. So let's let's go back to that in a second, but let's take Jan's position. So Jan LeCun was also one of the people who won the Turing Award and is also called the Godfather of AI. And I was recently interviewing him and he made the case. He said, look, technologies, all technologies can be used for good or ill, but some technologies have more of an inherent goodness. And AI has been built by humans, by good humans for good purposes. It's been trained on good books and good texts. It will have a bias towards good in the future. Do you believe that or not? I think AI that's been trained by good people will have a bias towards good. And AI that's been trained by bad people like Putin or somebody like that will have a bias towards bad. We know they're going to make battle robots. They're busy doing it in many different defense departments. So they're not going to necessarily be good since their primary purpose is going to be to kill people. So you believe that the risks of the bad uses of AI are whether they're more or less than the good uses of AI are so substantial, they deserve a lot of our thought right now. Certainly. Yes. For lethal autonomous weapons, they deserve a lot of our thought. Well, let's, okay, let's stick on lethal autonomous weapons because one of the things in this argument is that you are one of the few people who is really speaking about this as a risk, a real risk. Explain your hypothesis about why super powerful AI combined with the military could actually lead to more and more warfare. Okay. I don't actually want to answer that question. There's a separate question. Even if the AI isn't super intelligent, if defense departments use it for making battle robots, it's going to be very nasty, scary stuff. And it's going to lead, even if it's not super intelligent, and even if it doesn't have its own intentions, it just does what Putin tells it to. It's going to make it much easier, for example, for rich countries to invade poor countries. A present, there's a barrier to invading poor countries willy-nilly, which is you get dead citizens coming home. If they just dead battle robots, that's just great. The military industrial complex would love that. So you think that because, I mean, it's sort of a similar argument that people make with drones. If you can send a drone and you don't have to send an airplane with a pilot, you're more likely to send the drone, therefore you're more likely to attack. If you have a battle robot, it's that same thing squared. And that's your concern. That's my main concern with battle robots. It's a separate concern from what happens with super intelligent systems taking over for their own purposes. Before we get to super intelligent systems, let's talk about some of your other concerns. So in the litany of things that you're worried about, you obviously we have battle robots as one, you're also quite worried about inequality. Tell me more about this. So it's fairly clear, it's not certain, but it's fairly clear that these big language models will cause a big increase in productivity. So there's someone I know who answers letters of complaint for a health service. And he used to write these letters himself and now he just gets chat GPT to write the letters and it takes one-fifth of the amount of time to answer a complaint. So he can do five times as much work and so there are only five times fewer of him. Or maybe they'll just answer a lot more letters. Or they'll answer more letters, right? Or maybe they'll have more people because they'll be so efficient, right? More productivity leads to more getting more done. This is an unanswered question. But what we expect in the kind of society we live in is that if you get a big increase in productivity like that, the wealth isn't going to go to the people who are doing the work or the people who get unemployed, it's going to go to making the rich richer and the poor poorer. And that's very bad for society. Definitionally, or you think there's some feature of AI that will lead to that? No, it's not to do with AI, it's just what happens when you get an increase in productivity, particularly in a society that doesn't have strong unions. But now there are many economists who would take a different position and say that over time, and if you were to look at technology, right, we went from horses and horses and buggies and the horses and buggies went away and then we had cars and oh my gosh, the people who drove the horses lost their jobs and ATMs came along and suddenly bank tellers no longer need to do that. But we now employ many more bank tellers than we used to and we have many more people driving Ubers than we had people driving horses. So the argument what an economist would make to this would be, yes, there will be chair and there will be fewer people answering those letters, but there'll be many more higher cognitive things that will be done. How do you respond to that? I think the first thing I'd say is a loaf of bread used to cost a penny, then they invented economics and now it costs five dollars. So I don't entirely trust what economists say, particularly when they're dealing with a new situation that's never happened before. And superintelligence would be a new situation that never happened before, but even these big chatbots that are just replacing people whose job involves producing text, that's never happened before and I'm not sure how they can confidently predict that more jobs will be created than the number of jobs lost. I just have a little side note that in the green room, I introduced Jeff to, I have two of my three children are here, Alice and Zachary, they're somewhere out here, and he said to Alice, he said, are you going to go into media? And then he said, well, I'm not sure media will exist. And then Alice was asking, what should I do? And you said? Plumbing. Yes. Now explain. I mean, we have a number of plumbing problems at our house, it'd be wonderful if they were able to put in a new sink. Explain what jobs, a lot of young people out here, not just my children, but thinking about what careers to go into, what are the careers they should be looking at, what are the attributes of them? I'll give you a little story about being a carpenter. If you're a carpenter, it's fun making furniture, but it's a complete dead loss because machines can make furniture. If you're a carpenter, what you're good for is repairing furniture or fitting things into awkward spaces in old houses, making shelves in things that aren't quite square. So the jobs that are going to survive AI for a long time are jobs where you have to be very adaptable and physically skilled and plumbing is that kind of a job. How does manual dexterity is hard for a machine to replicate? It's still hard, and I think it's going to be longer before they can be really dexterous and get into awkward spaces. That's going to take longer than being good at answering text questions. Should I believe you? Because when we were on stage four years ago, you said reasoning. As long as somebody has a job that focuses on reasoning, they'll be able to last a dozen. Isn't the nature of AI such that we don't actually know where the next incredible improvement in performance will come? Maybe it will come in manual dexterity. Yeah, it's possible. So actually, let me ask you a question about that. So do you think when we look at AI and we look at the next five years of AI, the most impactful improvements we'll see will be in large language models and related to large language models? Or do you think it will be in something else? I think it'll probably be in multimodal large models. So they won't just be language models, they'll be doing vision. Actually, they'll be analyzing video. So they were able to train on all of the YouTube videos, for example. And you can understand a lot from things other than language. And when you do that, you need less language to reach the same performance. So the idea that they're going to be saturated because they've already used all the language there is, all the language is easy to get hold of. That's less of a concern if they're also using lots of other modalities. I mean, this gets at one of the, another argument that Jan, your fellow Godfather of AI makes is that language is so limited, right? There's so much information that we're conveying just beyond the word. In fact, I'm gesturing like mad, right? Which conveys some of the information as well as the lighting and all this. So your view is that may be true. Language is a limited vector for information, but soon it will be combined with other vectors. Absolutely. It's amazing what you can learn from language alone, but you're much better off learning from many modalities. Small children don't just learn from language alone. Right. So if you were, if your principal role right now was still researching AI, finding the next big thing, you would be doing multi-modal AI and trying to attach, say, visual AI systems to text-based AI systems? Yes, which is what they're doing now at Google. Google is making a system called Gemini, but fortunately, Demisabis talked about it a few days ago, and that's a multi-modal AI. Well, let me talk about actually something else at Google. So while you were there, Google invented the transformer network or invented the transformer architecture, generative pre-trained transformers. When did you realize that that would be so central and so important? It's interesting to me because it's this paper that comes out in 2017, and when it comes out, it's not as though firecrackers are left, you know, shot into the sky. It's six years later, five years later, that we suddenly realized the consequences. And it's interesting to think, what are the other papers out there that could be the same in five years? So with transformers, it was really only a couple of years later when Google developed BERT. So BERT made it very clear transformers were a huge breakthrough. I didn't immediately realize what a huge breakthrough they were, and I'm annoyed about that. It took me a couple of years to realize. Well, you know, the first time I ever heard the word transformer was talking to you on stage, and you were talking about transformers versus capsules, and this was right after it came out. Let's talk about one of the other critiques about language models and other models, which is soon, I mean, in fact, probably already they've absorbed all the organic data that has been created by humans. If I create an AI model right now, and I train it on the internet, it's trained on a bunch of stuff, mostly stuff made by humans, but a bunch of stuff made by AI, right? Yeah. And you're going to keep training AIs on stuff that has been created by AIs, whether it's text-based language model or whether it's a multimodal language model. Will that lead to the inevitable decay and corruption, as some people argue? Or is that just a thing we have to deal with? Or is it, as other people in the AI field, the greatest thing for training AIs, and we should just use synthetic data in AI? Okay. I don't actually know the answer to this technically. I suspect you have to take precautions, so you're not just training on data that you yourself generated or the some previous version of you generated. I suspect it's going to be possible to take those precautions, although it would be much easier if all fake data was marked fake. There is one example in AI where training on stuff from yourself helps a lot. So if you don't have much training data or rather you have a lot of unlabeled data and a small amount of labeled data, you can train a model to predict the labels on the labeled data and then you take that same model and train it to predict labels for unlabeled data and whatever it predicts, you tell it you were right. And that actually makes the model work better. How on earth does that work? Because on the whole it tends to be right. It's complicated. It's been analyzed much better in many years ago from acoustic modems. They did the same trick. So listening to this, I've had this realization on stage, you're a man who's very critical of where we're going, killer robots, income inequality. You also sound like somebody who loves this stuff. Yeah, I love this stuff. How could you not love making intelligent things? So let me get to maybe the most important question for the audience and for everyone here. We're now at this moment where a lot of people here love this stuff and they want to build it and they want to experiment. But we don't want negative consequences. We don't want increased income inequality. I don't want media to disappear. What are the choices and decisions and things we should be working on now to maximize the good, to maximize the creativity, but to limit the potential harms? So I think to answer that you have to distinguish many kinds of potential harm. So I'll distinguish like six of them for you. There's bias and discrimination. That is present now. It's not one of these future things we need to worry about. It's happening now. But it is something that I think is relatively easy to fix compared with all the other things. If you make your target, not be to have a completely unbiased system, but just to have a system that's significantly less biased than what it's replacing. So at present, you have old white men deciding whether the young black women should get mortgages. And if you just train on that data, you get a system that's equally biased. But you can analyze the bias. You can see how it's biased because it won't change its behavior. You can freeze it and then analyze it. And that should make it easier to correct for bias. So okay, that's bias and discrimination. I think we can do a lot about that. And I think it's important we do a lot about that, but it's doable. The next one is battle robots. That I'm really worried about because defense departments are going to build them. And I don't see how you could stop them doing it. Something like a Geneva Convention would be great. But those never happened until after they've been used with chemical weapons. It didn't happen until after the First World War, I believe. And so I think what may happen is people will use battle robots. We'll see just how absolutely awful they are. And then maybe we can get an international convention to prohibit them. So that's two. I mean, you could also tell the people building the AI to not sell their equipment to the military. You could try. Try. Okay, number three. The military has lots of money. Okay, number three, there's joblessness. You could try and do stuff to make sure the increase in productivity, some of that extra revenue that comes from the increase in productivity is going goes to helping the people who make jobless. If it turns out that there aren't as many jobs created as destroyed. That's a question of social policy. And what you really need for that is socialism. We're in Canada, so you can say socialism. Number four would be the warring echo chambers due to the big companies wanting you to click on things that make you indignant. And so giving you things that are more and more extreme. And so you end up in this echo chamber where you believe these crazy conspiracy theorists, if you're in the other echo chamber, or you believe the truth, if you're in my echo chamber. That's partly to do with the policies of the companies and maybe something could be done about that. But that would mean that is a problem that exists if it existed prior to large language models. And in fact, large language models could reverse it. Maybe. I mean, it's an open question of whether they can make it better or whether they make that problem worse. Yeah, it's a problem to do with AI, but it's not to do with large language models. It's a problem to do with AI in the sense that there's an algorithm using AI trained on our emotions that then pushes us in those directions. Okay. All right. So that's number four. Because the existential risk, which is the one I decided to talk about because a lot of people think is a joke. Right. So there was an editorial in Nature yesterday where they basically said, I'm fear-mongering about the existential risk is distracting attention from the actual risks. So they compared existential risk with actual risks, implying the existential risk wasn't actual. I think it's important that people understand it's not just science fiction. It's not just fear-mongering. It is a real risk that we need to think about, and we need to figure out in advance how to deal with it. So that's five, and there's one more, and I can't think what it is. How do you have a list that doesn't end on existential risk? I feel like that should be the end of the list. No, that was the end, but I thought if I talked about existential risk, I'd be able to remember the missing one while I talk about it, but I couldn't. All right. Well, let's talk about existential risk. What exactly explain exactly existential risk, how it happens? Or explain, as best you can imagine it, what it is that goes wrong that leads us to extinction or disappearance of humanity as a species? Okay. At a very general level, if you've got something a lot smarter than you that's very good at manipulating people, just at a very general level, are you confident people will stay in charge? And then you can go into specific scenarios for how people might lose control, even though they're the people creating this and giving it its goals. And one very obvious scenario is if you're given a goal and you want to be good at achieving it, what you need is as much control as possible. So for example, if I'm sitting in a boring seminar and I see a little dot of light on the ceiling, and then suddenly I notice that when I move, that dot of light moves, I realize this is the reflection from my watch, the sun is bouncing off my watch. And so the next thing I do is I don't start listening to the boring seminar again. I immediately try and figure out how to make it go this way and how to make it go that way. And once I got control of it, then maybe I'll listen to the seminar again. We have a very strong built in urge to get control and it's very sensible because the more control you get, the easier it is to achieve things. And I think AI will be able to derive that too. It's good to get control so you can achieve other goals. Wait, so you actually believe that getting control will be an innate feature of something that the AIs are trained on us, right? They act like us. They think like us because the neural architecture makes them like our human brains and because they're trained on all of our outputs. So you actually think that getting control of humans will be something that the AI is almost aspire to? No, I think they'll derive it as a way of achieving other goals. I think in us it's innate. I think I'm very dubious about saying things are really innate, but I think the desire to understand how things work is a very sensible desire to have and I think we have that. So we have that and then AIs will develop an ability to manipulate us and control us in a way that we can't respond to, right? That the manipulative AIs and even though good people will be able to use equally powerful AIs to counter these bad ones, you believe that we still could have an existential crisis? Yes. It's not clear to me. I mean, that makes the argument that the good people will have more resources than the bad people. I'm not sure about that and that good AI is going to be more powerful than bad AI and good AI is going to be able to regulate bad AI. And we have a situation like that at present where you have people using AI to create spam and you have people like Google using AI to filter out the spam and at present Google has more resources than the defenders of beating the attackers, but I don't see that it'll always be like that. I mean, even in cyber warfare where you have moments where it seems like the criminals are winning and sometimes where it seems like the defenders are winning. So you believe that there will be a battle like that over control of humans by super intelligent artificial intelligence? It may well be, yes. And I'm not convinced that good AI that's trying to stop bad AI getting control will win. Okay. So, all right. So before this existential risk happened, before bad AI does this, we have a lot of extremely smart people building a lot of extremely important things. What exactly can they do to most help limit this risk? So one thing you can do is before the AI gets super intelligent, you can do empirical work into how it goes wrong, how it tries to get control, whether it tries to get control. You don't know whether it would. But before it's smarter than us, I think the people developing it should be encouraged to put a lot of work into understanding how it might go wrong, understanding how it might try and take control away. And I think the government could maybe encourage the big companies developing it to put comparable resources, maybe not equal resources, but right now there's 99 very smart people trying to make it better and one very smart person trying to figure out how to stop it taking over. And maybe you want it more balanced. And so this is in some ways your role right now, the reason why you've left Google on good terms, but you want to be able to speak out and help participate in this conversation so more people can join that one and not the 99. Yeah. I would say it's very important for smart people to be working on that. But I'd also say it's very important not to think this is the only risk. There's all these other risks. And I've remembered the last one, which is fake news. So it's very important to try, for example, to mark everything that's fake as fake, whether we can do that technically, I don't know, but it'd be great if we could. Governments do it with counterfeit money. They won't allow counterfeit money because that reflects on their sort of central interest. They should try and do it with AI-generated stuff. I don't know whether they can. All right. So we're out of time. Give one specific to-do, something to read, a thought experiment, one thing to leave the audience with so they can go out here and think, OK, I'm going to do this. AI is the most powerful thing we've invented, and perhaps in our lifetimes, and I'm going to make it better to make it more likely it's a force for good in the next generation. So how could they make it more likely be a force for good? Yes. One final thought for everyone here. I actually don't have a plan for how to make it more likely to be good than bad, sorry. I think it's great that it's being developed because we didn't get to mention the huge numbers of good uses of it, like in medicine, in climate change, and so on. So I think progress in AI is inevitable and it's probably good, but we seriously ought to worry about mitigating all the bad side effects of it and worry about the existential threat. All right. Thank you everyone, an incredibly thoughtful, inspiring, interesting, phenomenally smart. Thank you to Jeffrey Hinton. Thank you. Thank you, Jeff. So great.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 13.56, "text": " What an incredible pleasure to be here with Jeffrey Hinton, one of the great minds and", "tokens": [50364, 708, 364, 4651, 6834, 281, 312, 510, 365, 28721, 389, 12442, 11, 472, 295, 264, 869, 9634, 293, 51042], "temperature": 0.0, "avg_logprob": -0.13900246731070584, "compression_ratio": 1.5727272727272728, "no_speech_prob": 0.22537842392921448}, {"id": 1, "seek": 0, "start": 13.56, "end": 15.16, "text": " one of the great issues of our time.", "tokens": [51042, 472, 295, 264, 869, 2663, 295, 527, 565, 13, 51122], "temperature": 0.0, "avg_logprob": -0.13900246731070584, "compression_ratio": 1.5727272727272728, "no_speech_prob": 0.22537842392921448}, {"id": 2, "seek": 0, "start": 15.16, "end": 19.64, "text": " A man who helped create artificial intelligence was at the center of nearly every revolution", "tokens": [51122, 316, 587, 567, 4254, 1884, 11677, 7599, 390, 412, 264, 3056, 295, 6217, 633, 8894, 51346], "temperature": 0.0, "avg_logprob": -0.13900246731070584, "compression_ratio": 1.5727272727272728, "no_speech_prob": 0.22537842392921448}, {"id": 3, "seek": 0, "start": 19.64, "end": 25.16, "text": " in it and now has become perhaps the most articulate critic of where we're going.", "tokens": [51346, 294, 309, 293, 586, 575, 1813, 4317, 264, 881, 30305, 7850, 295, 689, 321, 434, 516, 13, 51622], "temperature": 0.0, "avg_logprob": -0.13900246731070584, "compression_ratio": 1.5727272727272728, "no_speech_prob": 0.22537842392921448}, {"id": 4, "seek": 0, "start": 25.16, "end": 27.52, "text": " So an honor to be on stage with you.", "tokens": [51622, 407, 364, 5968, 281, 312, 322, 3233, 365, 291, 13, 51740], "temperature": 0.0, "avg_logprob": -0.13900246731070584, "compression_ratio": 1.5727272727272728, "no_speech_prob": 0.22537842392921448}, {"id": 5, "seek": 0, "start": 27.52, "end": 28.52, "text": " Thank you.", "tokens": [51740, 1044, 291, 13, 51790], "temperature": 0.0, "avg_logprob": -0.13900246731070584, "compression_ratio": 1.5727272727272728, "no_speech_prob": 0.22537842392921448}, {"id": 6, "seek": 2852, "start": 28.56, "end": 31.88, "text": " During the moniker Godfather of AI, one of the things that AI has traditionally had", "tokens": [50366, 6842, 264, 1108, 17314, 1265, 11541, 295, 7318, 11, 472, 295, 264, 721, 300, 7318, 575, 19067, 632, 50532], "temperature": 0.0, "avg_logprob": -0.15347515212164986, "compression_ratio": 1.7128712871287128, "no_speech_prob": 0.19830086827278137}, {"id": 7, "seek": 2852, "start": 31.88, "end": 36.32, "text": " problems with is humor, I asked AI if it could come up with a joke about the Godfather of", "tokens": [50532, 2740, 365, 307, 14318, 11, 286, 2351, 7318, 498, 309, 727, 808, 493, 365, 257, 7647, 466, 264, 1265, 11541, 295, 50754], "temperature": 0.0, "avg_logprob": -0.15347515212164986, "compression_ratio": 1.7128712871287128, "no_speech_prob": 0.19830086827278137}, {"id": 8, "seek": 2852, "start": 36.32, "end": 39.84, "text": " AI and it actually wasn't that bad.", "tokens": [50754, 7318, 293, 309, 767, 2067, 380, 300, 1578, 13, 50930], "temperature": 0.0, "avg_logprob": -0.15347515212164986, "compression_ratio": 1.7128712871287128, "no_speech_prob": 0.19830086827278137}, {"id": 9, "seek": 2852, "start": 39.84, "end": 44.24, "text": " It said he gave AI an offer it couldn't refuse, neural networks.", "tokens": [50930, 467, 848, 415, 2729, 7318, 364, 2626, 309, 2809, 380, 16791, 11, 18161, 9590, 13, 51150], "temperature": 0.0, "avg_logprob": -0.15347515212164986, "compression_ratio": 1.7128712871287128, "no_speech_prob": 0.19830086827278137}, {"id": 10, "seek": 2852, "start": 44.24, "end": 45.239999999999995, "text": " It's not bad.", "tokens": [51150, 467, 311, 406, 1578, 13, 51200], "temperature": 0.0, "avg_logprob": -0.15347515212164986, "compression_ratio": 1.7128712871287128, "no_speech_prob": 0.19830086827278137}, {"id": 11, "seek": 2852, "start": 45.239999999999995, "end": 46.239999999999995, "text": " Okay, that's not bad.", "tokens": [51200, 1033, 11, 300, 311, 406, 1578, 13, 51250], "temperature": 0.0, "avg_logprob": -0.15347515212164986, "compression_ratio": 1.7128712871287128, "no_speech_prob": 0.19830086827278137}, {"id": 12, "seek": 2852, "start": 46.239999999999995, "end": 47.239999999999995, "text": " It's good for AI.", "tokens": [51250, 467, 311, 665, 337, 7318, 13, 51300], "temperature": 0.0, "avg_logprob": -0.15347515212164986, "compression_ratio": 1.7128712871287128, "no_speech_prob": 0.19830086827278137}, {"id": 13, "seek": 2852, "start": 47.239999999999995, "end": 48.239999999999995, "text": " So let's begin with that.", "tokens": [51300, 407, 718, 311, 1841, 365, 300, 13, 51350], "temperature": 0.0, "avg_logprob": -0.15347515212164986, "compression_ratio": 1.7128712871287128, "no_speech_prob": 0.19830086827278137}, {"id": 14, "seek": 2852, "start": 48.239999999999995, "end": 52.16, "text": " What I want to do in this conversation is very briefly step a little back into your foundational", "tokens": [51350, 708, 286, 528, 281, 360, 294, 341, 3761, 307, 588, 10515, 1823, 257, 707, 646, 666, 428, 32195, 51546], "temperature": 0.0, "avg_logprob": -0.15347515212164986, "compression_ratio": 1.7128712871287128, "no_speech_prob": 0.19830086827278137}, {"id": 15, "seek": 2852, "start": 52.16, "end": 57.04, "text": " work, then go to where we are today and then talk about the future.", "tokens": [51546, 589, 11, 550, 352, 281, 689, 321, 366, 965, 293, 550, 751, 466, 264, 2027, 13, 51790], "temperature": 0.0, "avg_logprob": -0.15347515212164986, "compression_ratio": 1.7128712871287128, "no_speech_prob": 0.19830086827278137}, {"id": 16, "seek": 5704, "start": 57.04, "end": 61.28, "text": " So when you're building and you're designing neural networks and you're building computer", "tokens": [50364, 407, 562, 291, 434, 2390, 293, 291, 434, 14685, 18161, 9590, 293, 291, 434, 2390, 3820, 50576], "temperature": 0.0, "avg_logprob": -0.11168375015258789, "compression_ratio": 1.826839826839827, "no_speech_prob": 0.017063522711396217}, {"id": 17, "seek": 5704, "start": 61.28, "end": 66.4, "text": " systems that work like the human brain and that learn like the human brain and everybody", "tokens": [50576, 3652, 300, 589, 411, 264, 1952, 3567, 293, 300, 1466, 411, 264, 1952, 3567, 293, 2201, 50832], "temperature": 0.0, "avg_logprob": -0.11168375015258789, "compression_ratio": 1.826839826839827, "no_speech_prob": 0.017063522711396217}, {"id": 18, "seek": 5704, "start": 66.4, "end": 69.44, "text": " else is saying, Jeff, this is not going to work.", "tokens": [50832, 1646, 307, 1566, 11, 7506, 11, 341, 307, 406, 516, 281, 589, 13, 50984], "temperature": 0.0, "avg_logprob": -0.11168375015258789, "compression_ratio": 1.826839826839827, "no_speech_prob": 0.017063522711396217}, {"id": 19, "seek": 5704, "start": 69.44, "end": 75.68, "text": " You push ahead and do you push ahead because you know that this is the best way to train", "tokens": [50984, 509, 2944, 2286, 293, 360, 291, 2944, 2286, 570, 291, 458, 300, 341, 307, 264, 1151, 636, 281, 3847, 51296], "temperature": 0.0, "avg_logprob": -0.11168375015258789, "compression_ratio": 1.826839826839827, "no_speech_prob": 0.017063522711396217}, {"id": 20, "seek": 5704, "start": 75.68, "end": 81.0, "text": " computer systems or you do it for more spiritual reasons that you want to make a machine that", "tokens": [51296, 3820, 3652, 420, 291, 360, 309, 337, 544, 6960, 4112, 300, 291, 528, 281, 652, 257, 3479, 300, 51562], "temperature": 0.0, "avg_logprob": -0.11168375015258789, "compression_ratio": 1.826839826839827, "no_speech_prob": 0.017063522711396217}, {"id": 21, "seek": 5704, "start": 81.0, "end": 82.84, "text": " is like us?", "tokens": [51562, 307, 411, 505, 30, 51654], "temperature": 0.0, "avg_logprob": -0.11168375015258789, "compression_ratio": 1.826839826839827, "no_speech_prob": 0.017063522711396217}, {"id": 22, "seek": 8284, "start": 82.84, "end": 88.28, "text": " I do it because the brain has to work somehow and it sure as hell doesn't work by manipulating", "tokens": [50364, 286, 360, 309, 570, 264, 3567, 575, 281, 589, 6063, 293, 309, 988, 382, 4921, 1177, 380, 589, 538, 40805, 50636], "temperature": 0.0, "avg_logprob": -0.17579404830932618, "compression_ratio": 1.6422764227642277, "no_speech_prob": 0.01936452090740204}, {"id": 23, "seek": 8284, "start": 88.28, "end": 94.44, "text": " symbolic expressions explicitly and so something like neural nets had to work.", "tokens": [50636, 25755, 15277, 20803, 293, 370, 746, 411, 18161, 36170, 632, 281, 589, 13, 50944], "temperature": 0.0, "avg_logprob": -0.17579404830932618, "compression_ratio": 1.6422764227642277, "no_speech_prob": 0.01936452090740204}, {"id": 24, "seek": 8284, "start": 94.44, "end": 98.36, "text": " Also von Neumann and Turing believed that so that's a good start.", "tokens": [50944, 2743, 2957, 1734, 449, 969, 293, 314, 1345, 7847, 300, 370, 300, 311, 257, 665, 722, 13, 51140], "temperature": 0.0, "avg_logprob": -0.17579404830932618, "compression_ratio": 1.6422764227642277, "no_speech_prob": 0.01936452090740204}, {"id": 25, "seek": 8284, "start": 98.36, "end": 102.2, "text": " So you're doing it because you think it's the best way forward?", "tokens": [51140, 407, 291, 434, 884, 309, 570, 291, 519, 309, 311, 264, 1151, 636, 2128, 30, 51332], "temperature": 0.0, "avg_logprob": -0.17579404830932618, "compression_ratio": 1.6422764227642277, "no_speech_prob": 0.01936452090740204}, {"id": 26, "seek": 8284, "start": 102.2, "end": 104.64, "text": " Yes, in the long run the best way forward.", "tokens": [51332, 1079, 11, 294, 264, 938, 1190, 264, 1151, 636, 2128, 13, 51454], "temperature": 0.0, "avg_logprob": -0.17579404830932618, "compression_ratio": 1.6422764227642277, "no_speech_prob": 0.01936452090740204}, {"id": 27, "seek": 8284, "start": 104.64, "end": 108.92, "text": " Because that decision has profound effects down the line.", "tokens": [51454, 1436, 300, 3537, 575, 14382, 5065, 760, 264, 1622, 13, 51668], "temperature": 0.0, "avg_logprob": -0.17579404830932618, "compression_ratio": 1.6422764227642277, "no_speech_prob": 0.01936452090740204}, {"id": 28, "seek": 10892, "start": 109.32000000000001, "end": 110.64, "text": " Okay, so you do that.", "tokens": [50384, 1033, 11, 370, 291, 360, 300, 13, 50450], "temperature": 0.0, "avg_logprob": -0.18126646362908996, "compression_ratio": 1.5511811023622046, "no_speech_prob": 0.04265734553337097}, {"id": 29, "seek": 10892, "start": 110.64, "end": 115.64, "text": " You start building neural nets, you push forward and they become better than humans", "tokens": [50450, 509, 722, 2390, 18161, 36170, 11, 291, 2944, 2128, 293, 436, 1813, 1101, 813, 6255, 50700], "temperature": 0.0, "avg_logprob": -0.18126646362908996, "compression_ratio": 1.5511811023622046, "no_speech_prob": 0.04265734553337097}, {"id": 30, "seek": 10892, "start": 115.64, "end": 117.88, "text": " at certain limited tasks, right?", "tokens": [50700, 412, 1629, 5567, 9608, 11, 558, 30, 50812], "temperature": 0.0, "avg_logprob": -0.18126646362908996, "compression_ratio": 1.5511811023622046, "no_speech_prob": 0.04265734553337097}, {"id": 31, "seek": 10892, "start": 117.88, "end": 124.52, "text": " At image recognition, at translation, some chemical work.", "tokens": [50812, 1711, 3256, 11150, 11, 412, 12853, 11, 512, 7313, 589, 13, 51144], "temperature": 0.0, "avg_logprob": -0.18126646362908996, "compression_ratio": 1.5511811023622046, "no_speech_prob": 0.04265734553337097}, {"id": 32, "seek": 10892, "start": 124.52, "end": 130.8, "text": " I interviewed you in 2019 at Google I.O. and you said that it would be a long time before", "tokens": [51144, 286, 19770, 291, 294, 6071, 412, 3329, 286, 13, 46, 13, 293, 291, 848, 300, 309, 576, 312, 257, 938, 565, 949, 51458], "temperature": 0.0, "avg_logprob": -0.18126646362908996, "compression_ratio": 1.5511811023622046, "no_speech_prob": 0.04265734553337097}, {"id": 33, "seek": 10892, "start": 130.8, "end": 135.2, "text": " they could match us in reasoning and that's the big change that's happened over the last", "tokens": [51458, 436, 727, 2995, 505, 294, 21577, 293, 300, 311, 264, 955, 1319, 300, 311, 2011, 670, 264, 1036, 51678], "temperature": 0.0, "avg_logprob": -0.18126646362908996, "compression_ratio": 1.5511811023622046, "no_speech_prob": 0.04265734553337097}, {"id": 34, "seek": 10892, "start": 135.2, "end": 137.04, "text": " four years, right?", "tokens": [51678, 1451, 924, 11, 558, 30, 51770], "temperature": 0.0, "avg_logprob": -0.18126646362908996, "compression_ratio": 1.5511811023622046, "no_speech_prob": 0.04265734553337097}, {"id": 35, "seek": 13704, "start": 137.04, "end": 139.6, "text": " They still can't match us but they're getting close.", "tokens": [50364, 814, 920, 393, 380, 2995, 505, 457, 436, 434, 1242, 1998, 13, 50492], "temperature": 0.0, "avg_logprob": -0.11289968569416645, "compression_ratio": 1.684981684981685, "no_speech_prob": 0.008739428594708443}, {"id": 36, "seek": 13704, "start": 139.6, "end": 143.12, "text": " And how close are they getting and why?", "tokens": [50492, 400, 577, 1998, 366, 436, 1242, 293, 983, 30, 50668], "temperature": 0.0, "avg_logprob": -0.11289968569416645, "compression_ratio": 1.684981684981685, "no_speech_prob": 0.008739428594708443}, {"id": 37, "seek": 13704, "start": 143.12, "end": 147.72, "text": " It's the big language models that are getting close and I don't really understand why they", "tokens": [50668, 467, 311, 264, 955, 2856, 5245, 300, 366, 1242, 1998, 293, 286, 500, 380, 534, 1223, 983, 436, 50898], "temperature": 0.0, "avg_logprob": -0.11289968569416645, "compression_ratio": 1.684981684981685, "no_speech_prob": 0.008739428594708443}, {"id": 38, "seek": 13704, "start": 147.72, "end": 151.56, "text": " can do it but they can do little bits of reasoning.", "tokens": [50898, 393, 360, 309, 457, 436, 393, 360, 707, 9239, 295, 21577, 13, 51090], "temperature": 0.0, "avg_logprob": -0.11289968569416645, "compression_ratio": 1.684981684981685, "no_speech_prob": 0.008739428594708443}, {"id": 39, "seek": 13704, "start": 151.56, "end": 156.84, "text": " So my favorite example is I asked GPT-4, a puzzle that was given to me by a symbolic", "tokens": [51090, 407, 452, 2954, 1365, 307, 286, 2351, 26039, 51, 12, 19, 11, 257, 12805, 300, 390, 2212, 281, 385, 538, 257, 25755, 51354], "temperature": 0.0, "avg_logprob": -0.11289968569416645, "compression_ratio": 1.684981684981685, "no_speech_prob": 0.008739428594708443}, {"id": 40, "seek": 13704, "start": 156.84, "end": 160.07999999999998, "text": " AI guy who thought it wouldn't be able to do it.", "tokens": [51354, 7318, 2146, 567, 1194, 309, 2759, 380, 312, 1075, 281, 360, 309, 13, 51516], "temperature": 0.0, "avg_logprob": -0.11289968569416645, "compression_ratio": 1.684981684981685, "no_speech_prob": 0.008739428594708443}, {"id": 41, "seek": 13704, "start": 160.07999999999998, "end": 165.79999999999998, "text": " I made the puzzle more difficult than it could still do it and the puzzle was the rooms in", "tokens": [51516, 286, 1027, 264, 12805, 544, 2252, 813, 309, 727, 920, 360, 309, 293, 264, 12805, 390, 264, 9396, 294, 51802], "temperature": 0.0, "avg_logprob": -0.11289968569416645, "compression_ratio": 1.684981684981685, "no_speech_prob": 0.008739428594708443}, {"id": 42, "seek": 16580, "start": 165.8, "end": 170.4, "text": " my house are painted blue or yellow or white.", "tokens": [50364, 452, 1782, 366, 11797, 3344, 420, 5566, 420, 2418, 13, 50594], "temperature": 0.0, "avg_logprob": -0.10809995320217669, "compression_ratio": 2.004424778761062, "no_speech_prob": 0.02595001645386219}, {"id": 43, "seek": 16580, "start": 170.4, "end": 173.36, "text": " Yellow paint fades to white within a year.", "tokens": [50594, 17550, 4225, 32679, 281, 2418, 1951, 257, 1064, 13, 50742], "temperature": 0.0, "avg_logprob": -0.10809995320217669, "compression_ratio": 2.004424778761062, "no_speech_prob": 0.02595001645386219}, {"id": 44, "seek": 16580, "start": 173.36, "end": 175.76000000000002, "text": " In two years' time I want them all to be white.", "tokens": [50742, 682, 732, 924, 6, 565, 286, 528, 552, 439, 281, 312, 2418, 13, 50862], "temperature": 0.0, "avg_logprob": -0.10809995320217669, "compression_ratio": 2.004424778761062, "no_speech_prob": 0.02595001645386219}, {"id": 45, "seek": 16580, "start": 175.76000000000002, "end": 178.44, "text": " What should I do and why?", "tokens": [50862, 708, 820, 286, 360, 293, 983, 30, 50996], "temperature": 0.0, "avg_logprob": -0.10809995320217669, "compression_ratio": 2.004424778761062, "no_speech_prob": 0.02595001645386219}, {"id": 46, "seek": 16580, "start": 178.44, "end": 183.56, "text": " And it says you should paint the blue rooms white and then it says you should do that", "tokens": [50996, 400, 309, 1619, 291, 820, 4225, 264, 3344, 9396, 2418, 293, 550, 309, 1619, 291, 820, 360, 300, 51252], "temperature": 0.0, "avg_logprob": -0.10809995320217669, "compression_ratio": 2.004424778761062, "no_speech_prob": 0.02595001645386219}, {"id": 47, "seek": 16580, "start": 183.56, "end": 188.08, "text": " because blue won't fade to white and it says you don't need to paint the yellow rooms because", "tokens": [51252, 570, 3344, 1582, 380, 21626, 281, 2418, 293, 309, 1619, 291, 500, 380, 643, 281, 4225, 264, 5566, 9396, 570, 51478], "temperature": 0.0, "avg_logprob": -0.10809995320217669, "compression_ratio": 2.004424778761062, "no_speech_prob": 0.02595001645386219}, {"id": 48, "seek": 16580, "start": 188.08, "end": 189.92000000000002, "text": " they will fade to white.", "tokens": [51478, 436, 486, 21626, 281, 2418, 13, 51570], "temperature": 0.0, "avg_logprob": -0.10809995320217669, "compression_ratio": 2.004424778761062, "no_speech_prob": 0.02595001645386219}, {"id": 49, "seek": 16580, "start": 189.92000000000002, "end": 194.64000000000001, "text": " So it knew what I should do and it knew why and I was surprised that it could do that", "tokens": [51570, 407, 309, 2586, 437, 286, 820, 360, 293, 309, 2586, 983, 293, 286, 390, 6100, 300, 309, 727, 360, 300, 51806], "temperature": 0.0, "avg_logprob": -0.10809995320217669, "compression_ratio": 2.004424778761062, "no_speech_prob": 0.02595001645386219}, {"id": 50, "seek": 19464, "start": 194.64, "end": 196.04, "text": " much reasoning already.", "tokens": [50364, 709, 21577, 1217, 13, 50434], "temperature": 0.0, "avg_logprob": -0.17420905431111652, "compression_ratio": 1.8247011952191234, "no_speech_prob": 0.1806792914867401}, {"id": 51, "seek": 19464, "start": 196.04, "end": 201.04, "text": " And it's kind of an amazing example because when people critique these systems or they", "tokens": [50434, 400, 309, 311, 733, 295, 364, 2243, 1365, 570, 562, 561, 25673, 613, 3652, 420, 436, 50684], "temperature": 0.0, "avg_logprob": -0.17420905431111652, "compression_ratio": 1.8247011952191234, "no_speech_prob": 0.1806792914867401}, {"id": 52, "seek": 19464, "start": 201.04, "end": 204.0, "text": " say they're not going to do much, they say they're mad libs, they're just word completion", "tokens": [50684, 584, 436, 434, 406, 516, 281, 360, 709, 11, 436, 584, 436, 434, 5244, 375, 929, 11, 436, 434, 445, 1349, 19372, 50832], "temperature": 0.0, "avg_logprob": -0.17420905431111652, "compression_ratio": 1.8247011952191234, "no_speech_prob": 0.1806792914867401}, {"id": 53, "seek": 19464, "start": 204.0, "end": 205.79999999999998, "text": " but that is not word completion.", "tokens": [50832, 457, 300, 307, 406, 1349, 19372, 13, 50922], "temperature": 0.0, "avg_logprob": -0.17420905431111652, "compression_ratio": 1.8247011952191234, "no_speech_prob": 0.1806792914867401}, {"id": 54, "seek": 19464, "start": 205.79999999999998, "end": 207.79999999999998, "text": " To you is that thinking?", "tokens": [50922, 1407, 291, 307, 300, 1953, 30, 51022], "temperature": 0.0, "avg_logprob": -0.17420905431111652, "compression_ratio": 1.8247011952191234, "no_speech_prob": 0.1806792914867401}, {"id": 55, "seek": 19464, "start": 207.79999999999998, "end": 215.27999999999997, "text": " Yeah, that's thinking and when people say it's just autocomplete, a lot goes on in", "tokens": [51022, 865, 11, 300, 311, 1953, 293, 562, 561, 584, 309, 311, 445, 45833, 298, 17220, 11, 257, 688, 1709, 322, 294, 51396], "temperature": 0.0, "avg_logprob": -0.17420905431111652, "compression_ratio": 1.8247011952191234, "no_speech_prob": 0.1806792914867401}, {"id": 56, "seek": 19464, "start": 215.27999999999997, "end": 217.64, "text": " that word just autocomplete.", "tokens": [51396, 300, 1349, 445, 45833, 298, 17220, 13, 51514], "temperature": 0.0, "avg_logprob": -0.17420905431111652, "compression_ratio": 1.8247011952191234, "no_speech_prob": 0.1806792914867401}, {"id": 57, "seek": 19464, "start": 217.64, "end": 222.39999999999998, "text": " If you think what it takes to predict the next word, you have to understand what's been", "tokens": [51514, 759, 291, 519, 437, 309, 2516, 281, 6069, 264, 958, 1349, 11, 291, 362, 281, 1223, 437, 311, 668, 51752], "temperature": 0.0, "avg_logprob": -0.17420905431111652, "compression_ratio": 1.8247011952191234, "no_speech_prob": 0.1806792914867401}, {"id": 58, "seek": 22240, "start": 222.4, "end": 225.36, "text": " said to be really good at predicting the next word.", "tokens": [50364, 848, 281, 312, 534, 665, 412, 32884, 264, 958, 1349, 13, 50512], "temperature": 0.0, "avg_logprob": -0.13403353731856388, "compression_ratio": 1.9140625, "no_speech_prob": 0.33006975054740906}, {"id": 59, "seek": 22240, "start": 225.36, "end": 229.6, "text": " So people say it's just autocomplete or it's just statistics.", "tokens": [50512, 407, 561, 584, 309, 311, 445, 45833, 298, 17220, 420, 309, 311, 445, 12523, 13, 50724], "temperature": 0.0, "avg_logprob": -0.13403353731856388, "compression_ratio": 1.9140625, "no_speech_prob": 0.33006975054740906}, {"id": 60, "seek": 22240, "start": 229.6, "end": 236.36, "text": " Now there's a sense in which it is just statistics, but in that sense everything's just statistics.", "tokens": [50724, 823, 456, 311, 257, 2020, 294, 597, 309, 307, 445, 12523, 11, 457, 294, 300, 2020, 1203, 311, 445, 12523, 13, 51062], "temperature": 0.0, "avg_logprob": -0.13403353731856388, "compression_ratio": 1.9140625, "no_speech_prob": 0.33006975054740906}, {"id": 61, "seek": 22240, "start": 236.36, "end": 240.84, "text": " It's not the sense most people think of statistics as it keeps the counts of how many times this", "tokens": [51062, 467, 311, 406, 264, 2020, 881, 561, 519, 295, 12523, 382, 309, 5965, 264, 14893, 295, 577, 867, 1413, 341, 51286], "temperature": 0.0, "avg_logprob": -0.13403353731856388, "compression_ratio": 1.9140625, "no_speech_prob": 0.33006975054740906}, {"id": 62, "seek": 22240, "start": 240.84, "end": 244.08, "text": " combination of words occurred and how many times that combination.", "tokens": [51286, 6562, 295, 2283, 11068, 293, 577, 867, 1413, 300, 6562, 13, 51448], "temperature": 0.0, "avg_logprob": -0.13403353731856388, "compression_ratio": 1.9140625, "no_speech_prob": 0.33006975054740906}, {"id": 63, "seek": 22240, "start": 244.08, "end": 245.08, "text": " It's not like that at all.", "tokens": [51448, 467, 311, 406, 411, 300, 412, 439, 13, 51498], "temperature": 0.0, "avg_logprob": -0.13403353731856388, "compression_ratio": 1.9140625, "no_speech_prob": 0.33006975054740906}, {"id": 64, "seek": 22240, "start": 245.08, "end": 250.04000000000002, "text": " It's inventing features and interactions between features to explain what comes next.", "tokens": [51498, 467, 311, 7962, 278, 4122, 293, 13280, 1296, 4122, 281, 2903, 437, 1487, 958, 13, 51746], "temperature": 0.0, "avg_logprob": -0.13403353731856388, "compression_ratio": 1.9140625, "no_speech_prob": 0.33006975054740906}, {"id": 65, "seek": 25004, "start": 250.04, "end": 255.56, "text": " So if it's just statistics and everything is just statistics, is there anything that", "tokens": [50364, 407, 498, 309, 311, 445, 12523, 293, 1203, 307, 445, 12523, 11, 307, 456, 1340, 300, 50640], "temperature": 0.0, "avg_logprob": -0.13117788333703975, "compression_ratio": 1.8051948051948052, "no_speech_prob": 0.02091887779533863}, {"id": 66, "seek": 25004, "start": 255.56, "end": 257.84, "text": " we can do?", "tokens": [50640, 321, 393, 360, 30, 50754], "temperature": 0.0, "avg_logprob": -0.13117788333703975, "compression_ratio": 1.8051948051948052, "no_speech_prob": 0.02091887779533863}, {"id": 67, "seek": 25004, "start": 257.84, "end": 260.76, "text": " Obviously it's not humor, maybe it's not reasoning.", "tokens": [50754, 7580, 309, 311, 406, 14318, 11, 1310, 309, 311, 406, 21577, 13, 50900], "temperature": 0.0, "avg_logprob": -0.13117788333703975, "compression_ratio": 1.8051948051948052, "no_speech_prob": 0.02091887779533863}, {"id": 68, "seek": 25004, "start": 260.76, "end": 265.56, "text": " Is there anything that we can do that a sufficiently well-trained large language model with a sufficient", "tokens": [50900, 1119, 456, 1340, 300, 321, 393, 360, 300, 257, 31868, 731, 12, 17227, 2001, 2416, 2856, 2316, 365, 257, 11563, 51140], "temperature": 0.0, "avg_logprob": -0.13117788333703975, "compression_ratio": 1.8051948051948052, "no_speech_prob": 0.02091887779533863}, {"id": 69, "seek": 25004, "start": 265.56, "end": 269.84, "text": " number of parameters and a sufficient amount of compute could not do in the future?", "tokens": [51140, 1230, 295, 9834, 293, 257, 11563, 2372, 295, 14722, 727, 406, 360, 294, 264, 2027, 30, 51354], "temperature": 0.0, "avg_logprob": -0.13117788333703975, "compression_ratio": 1.8051948051948052, "no_speech_prob": 0.02091887779533863}, {"id": 70, "seek": 25004, "start": 269.84, "end": 275.96, "text": " If the model is also trained on vision and picking things up and so on, then no.", "tokens": [51354, 759, 264, 2316, 307, 611, 8895, 322, 5201, 293, 8867, 721, 493, 293, 370, 322, 11, 550, 572, 13, 51660], "temperature": 0.0, "avg_logprob": -0.13117788333703975, "compression_ratio": 1.8051948051948052, "no_speech_prob": 0.02091887779533863}, {"id": 71, "seek": 27596, "start": 275.96, "end": 280.4, "text": " But is there anything that we can think of and any way we can think in any cognitive", "tokens": [50364, 583, 307, 456, 1340, 300, 321, 393, 519, 295, 293, 604, 636, 321, 393, 519, 294, 604, 15605, 50586], "temperature": 0.0, "avg_logprob": -0.10349169030653692, "compression_ratio": 1.8847736625514404, "no_speech_prob": 0.23823511600494385}, {"id": 72, "seek": 27596, "start": 280.4, "end": 284.08, "text": " process that the machines will not be able to replicate?", "tokens": [50586, 1399, 300, 264, 8379, 486, 406, 312, 1075, 281, 25356, 30, 50770], "temperature": 0.0, "avg_logprob": -0.10349169030653692, "compression_ratio": 1.8847736625514404, "no_speech_prob": 0.23823511600494385}, {"id": 73, "seek": 27596, "start": 284.08, "end": 288.44, "text": " We're just a machine, we're a wonderful, incredibly complicated machine, but we're", "tokens": [50770, 492, 434, 445, 257, 3479, 11, 321, 434, 257, 3715, 11, 6252, 6179, 3479, 11, 457, 321, 434, 50988], "temperature": 0.0, "avg_logprob": -0.10349169030653692, "compression_ratio": 1.8847736625514404, "no_speech_prob": 0.23823511600494385}, {"id": 74, "seek": 27596, "start": 288.44, "end": 292.67999999999995, "text": " just a big neural net and there's no reason why an artificial neural net shouldn't be", "tokens": [50988, 445, 257, 955, 18161, 2533, 293, 456, 311, 572, 1778, 983, 364, 11677, 18161, 2533, 4659, 380, 312, 51200], "temperature": 0.0, "avg_logprob": -0.10349169030653692, "compression_ratio": 1.8847736625514404, "no_speech_prob": 0.23823511600494385}, {"id": 75, "seek": 27596, "start": 292.67999999999995, "end": 294.47999999999996, "text": " able to do everything we can do.", "tokens": [51200, 1075, 281, 360, 1203, 321, 393, 360, 13, 51290], "temperature": 0.0, "avg_logprob": -0.10349169030653692, "compression_ratio": 1.8847736625514404, "no_speech_prob": 0.23823511600494385}, {"id": 76, "seek": 27596, "start": 294.47999999999996, "end": 299.28, "text": " Are we a big neural net that is more efficient than these new neural nets we're building", "tokens": [51290, 2014, 321, 257, 955, 18161, 2533, 300, 307, 544, 7148, 813, 613, 777, 18161, 36170, 321, 434, 2390, 51530], "temperature": 0.0, "avg_logprob": -0.10349169030653692, "compression_ratio": 1.8847736625514404, "no_speech_prob": 0.23823511600494385}, {"id": 77, "seek": 27596, "start": 299.28, "end": 301.47999999999996, "text": " or are we less efficient?", "tokens": [51530, 420, 366, 321, 1570, 7148, 30, 51640], "temperature": 0.0, "avg_logprob": -0.10349169030653692, "compression_ratio": 1.8847736625514404, "no_speech_prob": 0.23823511600494385}, {"id": 78, "seek": 30148, "start": 301.48, "end": 306.0, "text": " It depends whether you're talking about speed of acquiring knowledge and how much knowledge", "tokens": [50364, 467, 5946, 1968, 291, 434, 1417, 466, 3073, 295, 37374, 3601, 293, 577, 709, 3601, 50590], "temperature": 0.0, "avg_logprob": -0.12018960667407419, "compression_ratio": 1.970479704797048, "no_speech_prob": 0.002142375335097313}, {"id": 79, "seek": 30148, "start": 306.0, "end": 309.96000000000004, "text": " you can acquire or whether you're talking about energy consumption.", "tokens": [50590, 291, 393, 20001, 420, 1968, 291, 434, 1417, 466, 2281, 12126, 13, 50788], "temperature": 0.0, "avg_logprob": -0.12018960667407419, "compression_ratio": 1.970479704797048, "no_speech_prob": 0.002142375335097313}, {"id": 80, "seek": 30148, "start": 309.96000000000004, "end": 312.92, "text": " So in energy consumption, we're much more efficient.", "tokens": [50788, 407, 294, 2281, 12126, 11, 321, 434, 709, 544, 7148, 13, 50936], "temperature": 0.0, "avg_logprob": -0.12018960667407419, "compression_ratio": 1.970479704797048, "no_speech_prob": 0.002142375335097313}, {"id": 81, "seek": 30148, "start": 312.92, "end": 317.08000000000004, "text": " We're like 30 watts and one of these big language models, when you're training it, you train", "tokens": [50936, 492, 434, 411, 2217, 31247, 293, 472, 295, 613, 955, 2856, 5245, 11, 562, 291, 434, 3097, 309, 11, 291, 3847, 51144], "temperature": 0.0, "avg_logprob": -0.12018960667407419, "compression_ratio": 1.970479704797048, "no_speech_prob": 0.002142375335097313}, {"id": 82, "seek": 30148, "start": 317.08000000000004, "end": 320.76, "text": " many copies of it each looking at different parts of the data.", "tokens": [51144, 867, 14341, 295, 309, 1184, 1237, 412, 819, 3166, 295, 264, 1412, 13, 51328], "temperature": 0.0, "avg_logprob": -0.12018960667407419, "compression_ratio": 1.970479704797048, "no_speech_prob": 0.002142375335097313}, {"id": 83, "seek": 30148, "start": 320.76, "end": 322.92, "text": " So it's more like a megawatt.", "tokens": [51328, 407, 309, 311, 544, 411, 257, 10816, 1607, 1591, 13, 51436], "temperature": 0.0, "avg_logprob": -0.12018960667407419, "compression_ratio": 1.970479704797048, "no_speech_prob": 0.002142375335097313}, {"id": 84, "seek": 30148, "start": 322.92, "end": 327.52000000000004, "text": " So it's much more expensive in terms of energy, but all these copies can be learning different", "tokens": [51436, 407, 309, 311, 709, 544, 5124, 294, 2115, 295, 2281, 11, 457, 439, 613, 14341, 393, 312, 2539, 819, 51666], "temperature": 0.0, "avg_logprob": -0.12018960667407419, "compression_ratio": 1.970479704797048, "no_speech_prob": 0.002142375335097313}, {"id": 85, "seek": 30148, "start": 327.52000000000004, "end": 329.48, "text": " things from different parts of the data.", "tokens": [51666, 721, 490, 819, 3166, 295, 264, 1412, 13, 51764], "temperature": 0.0, "avg_logprob": -0.12018960667407419, "compression_ratio": 1.970479704797048, "no_speech_prob": 0.002142375335097313}, {"id": 86, "seek": 32948, "start": 329.48, "end": 333.36, "text": " So it's much more efficient in terms of acquiring knowledge from data.", "tokens": [50364, 407, 309, 311, 709, 544, 7148, 294, 2115, 295, 37374, 3601, 490, 1412, 13, 50558], "temperature": 0.0, "avg_logprob": -0.11711607570141817, "compression_ratio": 1.6496350364963503, "no_speech_prob": 0.006884269416332245}, {"id": 87, "seek": 32948, "start": 333.36, "end": 337.48, "text": " And it becomes only more efficient because each system can train each next system?", "tokens": [50558, 400, 309, 3643, 787, 544, 7148, 570, 1184, 1185, 393, 3847, 1184, 958, 1185, 30, 50764], "temperature": 0.0, "avg_logprob": -0.11711607570141817, "compression_ratio": 1.6496350364963503, "no_speech_prob": 0.006884269416332245}, {"id": 88, "seek": 32948, "start": 337.48, "end": 338.48, "text": " Yes.", "tokens": [50764, 1079, 13, 50814], "temperature": 0.0, "avg_logprob": -0.11711607570141817, "compression_ratio": 1.6496350364963503, "no_speech_prob": 0.006884269416332245}, {"id": 89, "seek": 32948, "start": 338.48, "end": 339.76, "text": " So let's get to your critique.", "tokens": [50814, 407, 718, 311, 483, 281, 428, 25673, 13, 50878], "temperature": 0.0, "avg_logprob": -0.11711607570141817, "compression_ratio": 1.6496350364963503, "no_speech_prob": 0.006884269416332245}, {"id": 90, "seek": 32948, "start": 339.76, "end": 345.36, "text": " So the best summarization of your critique came from a conference at the Milken Institute", "tokens": [50878, 407, 264, 1151, 14611, 2144, 295, 428, 25673, 1361, 490, 257, 7586, 412, 264, 7036, 2653, 9446, 51158], "temperature": 0.0, "avg_logprob": -0.11711607570141817, "compression_ratio": 1.6496350364963503, "no_speech_prob": 0.006884269416332245}, {"id": 91, "seek": 32948, "start": 345.36, "end": 351.96000000000004, "text": " about a month ago and it was Snoop Dogg and he said, I heard the old dude who created", "tokens": [51158, 466, 257, 1618, 2057, 293, 309, 390, 42902, 404, 13472, 70, 293, 415, 848, 11, 286, 2198, 264, 1331, 6449, 567, 2942, 51488], "temperature": 0.0, "avg_logprob": -0.11711607570141817, "compression_ratio": 1.6496350364963503, "no_speech_prob": 0.006884269416332245}, {"id": 92, "seek": 32948, "start": 351.96000000000004, "end": 357.16, "text": " AI saying this is not safe because the AI's got their own mind and those motherfuckers", "tokens": [51488, 7318, 1566, 341, 307, 406, 3273, 570, 264, 7318, 311, 658, 641, 1065, 1575, 293, 729, 29537, 1134, 433, 51748], "temperature": 0.0, "avg_logprob": -0.11711607570141817, "compression_ratio": 1.6496350364963503, "no_speech_prob": 0.006884269416332245}, {"id": 93, "seek": 35716, "start": 357.16, "end": 361.04, "text": " going to start doing their own shit.", "tokens": [50364, 516, 281, 722, 884, 641, 1065, 4611, 13, 50558], "temperature": 0.0, "avg_logprob": -0.14661079982541642, "compression_ratio": 1.6761904761904762, "no_speech_prob": 0.2901059687137604}, {"id": 94, "seek": 35716, "start": 361.04, "end": 362.04, "text": " Is that accurate?", "tokens": [50558, 1119, 300, 8559, 30, 50608], "temperature": 0.0, "avg_logprob": -0.14661079982541642, "compression_ratio": 1.6761904761904762, "no_speech_prob": 0.2901059687137604}, {"id": 95, "seek": 35716, "start": 362.04, "end": 365.28000000000003, "text": " Is that an accurate summarization?", "tokens": [50608, 1119, 300, 364, 8559, 14611, 2144, 30, 50770], "temperature": 0.0, "avg_logprob": -0.14661079982541642, "compression_ratio": 1.6761904761904762, "no_speech_prob": 0.2901059687137604}, {"id": 96, "seek": 35716, "start": 365.28000000000003, "end": 372.0, "text": " They probably didn't have mothers.", "tokens": [50770, 814, 1391, 994, 380, 362, 17941, 13, 51106], "temperature": 0.0, "avg_logprob": -0.14661079982541642, "compression_ratio": 1.6761904761904762, "no_speech_prob": 0.2901059687137604}, {"id": 97, "seek": 35716, "start": 372.0, "end": 374.76000000000005, "text": " But the rest of what Dr. Dogg said is correct.", "tokens": [51106, 583, 264, 1472, 295, 437, 2491, 13, 13472, 70, 848, 307, 3006, 13, 51244], "temperature": 0.0, "avg_logprob": -0.14661079982541642, "compression_ratio": 1.6761904761904762, "no_speech_prob": 0.2901059687137604}, {"id": 98, "seek": 35716, "start": 374.76000000000005, "end": 375.76000000000005, "text": " Hang on.", "tokens": [51244, 14070, 322, 13, 51294], "temperature": 0.0, "avg_logprob": -0.14661079982541642, "compression_ratio": 1.6761904761904762, "no_speech_prob": 0.2901059687137604}, {"id": 99, "seek": 35716, "start": 375.76000000000005, "end": 376.76000000000005, "text": " Yes.", "tokens": [51294, 1079, 13, 51344], "temperature": 0.0, "avg_logprob": -0.14661079982541642, "compression_ratio": 1.6761904761904762, "no_speech_prob": 0.2901059687137604}, {"id": 100, "seek": 35716, "start": 376.76000000000005, "end": 377.76000000000005, "text": " All right.", "tokens": [51344, 1057, 558, 13, 51394], "temperature": 0.0, "avg_logprob": -0.14661079982541642, "compression_ratio": 1.6761904761904762, "no_speech_prob": 0.2901059687137604}, {"id": 101, "seek": 35716, "start": 377.76000000000005, "end": 383.52000000000004, "text": " So explain what you mean or what he means and how it applies to what you mean when they're", "tokens": [51394, 407, 2903, 437, 291, 914, 420, 437, 415, 1355, 293, 577, 309, 13165, 281, 437, 291, 914, 562, 436, 434, 51682], "temperature": 0.0, "avg_logprob": -0.14661079982541642, "compression_ratio": 1.6761904761904762, "no_speech_prob": 0.2901059687137604}, {"id": 102, "seek": 35716, "start": 383.52000000000004, "end": 385.44000000000005, "text": " going to start doing their own shit.", "tokens": [51682, 516, 281, 722, 884, 641, 1065, 4611, 13, 51778], "temperature": 0.0, "avg_logprob": -0.14661079982541642, "compression_ratio": 1.6761904761904762, "no_speech_prob": 0.2901059687137604}, {"id": 103, "seek": 35716, "start": 385.44000000000005, "end": 386.44000000000005, "text": " What does that mean to you?", "tokens": [51778, 708, 775, 300, 914, 281, 291, 30, 51828], "temperature": 0.0, "avg_logprob": -0.14661079982541642, "compression_ratio": 1.6761904761904762, "no_speech_prob": 0.2901059687137604}, {"id": 104, "seek": 38644, "start": 386.56, "end": 387.56, "text": " Okay.", "tokens": [50370, 1033, 13, 50420], "temperature": 0.0, "avg_logprob": -0.18557999099510303, "compression_ratio": 1.70125786163522, "no_speech_prob": 0.03694983199238777}, {"id": 105, "seek": 38644, "start": 387.56, "end": 391.68, "text": " So first I have to emphasize we're entering a period of huge uncertainty.", "tokens": [50420, 407, 700, 286, 362, 281, 16078, 321, 434, 11104, 257, 2896, 295, 2603, 15697, 13, 50626], "temperature": 0.0, "avg_logprob": -0.18557999099510303, "compression_ratio": 1.70125786163522, "no_speech_prob": 0.03694983199238777}, {"id": 106, "seek": 38644, "start": 391.68, "end": 393.44, "text": " Nobody really knows what's going to happen.", "tokens": [50626, 9297, 534, 3255, 437, 311, 516, 281, 1051, 13, 50714], "temperature": 0.0, "avg_logprob": -0.18557999099510303, "compression_ratio": 1.70125786163522, "no_speech_prob": 0.03694983199238777}, {"id": 107, "seek": 38644, "start": 393.44, "end": 396.96, "text": " And people whose opinion I respect have very different beliefs from me.", "tokens": [50714, 400, 561, 6104, 4800, 286, 3104, 362, 588, 819, 13585, 490, 385, 13, 50890], "temperature": 0.0, "avg_logprob": -0.18557999099510303, "compression_ratio": 1.70125786163522, "no_speech_prob": 0.03694983199238777}, {"id": 108, "seek": 38644, "start": 396.96, "end": 399.36, "text": " Like Jan LeCun thinks everything's going to be fine.", "tokens": [50890, 1743, 4956, 1456, 34, 409, 7309, 1203, 311, 516, 281, 312, 2489, 13, 51010], "temperature": 0.0, "avg_logprob": -0.18557999099510303, "compression_ratio": 1.70125786163522, "no_speech_prob": 0.03694983199238777}, {"id": 109, "seek": 38644, "start": 399.36, "end": 400.36, "text": " They're just going to help us.", "tokens": [51010, 814, 434, 445, 516, 281, 854, 505, 13, 51060], "temperature": 0.0, "avg_logprob": -0.18557999099510303, "compression_ratio": 1.70125786163522, "no_speech_prob": 0.03694983199238777}, {"id": 110, "seek": 38644, "start": 400.36, "end": 401.96, "text": " It's all going to be wonderful.", "tokens": [51060, 467, 311, 439, 516, 281, 312, 3715, 13, 51140], "temperature": 0.0, "avg_logprob": -0.18557999099510303, "compression_ratio": 1.70125786163522, "no_speech_prob": 0.03694983199238777}, {"id": 111, "seek": 38644, "start": 401.96, "end": 406.15999999999997, "text": " But I think we have to take seriously the possibility that if they get to be smarter", "tokens": [51140, 583, 286, 519, 321, 362, 281, 747, 6638, 264, 7959, 300, 498, 436, 483, 281, 312, 20294, 51350], "temperature": 0.0, "avg_logprob": -0.18557999099510303, "compression_ratio": 1.70125786163522, "no_speech_prob": 0.03694983199238777}, {"id": 112, "seek": 38644, "start": 406.15999999999997, "end": 411.4, "text": " than us, which seems quite likely, and they have goals of their own, which seems quite", "tokens": [51350, 813, 505, 11, 597, 2544, 1596, 3700, 11, 293, 436, 362, 5493, 295, 641, 1065, 11, 597, 2544, 1596, 51612], "temperature": 0.0, "avg_logprob": -0.18557999099510303, "compression_ratio": 1.70125786163522, "no_speech_prob": 0.03694983199238777}, {"id": 113, "seek": 38644, "start": 411.4, "end": 415.12, "text": " likely, they may well develop the goal of taking control.", "tokens": [51612, 3700, 11, 436, 815, 731, 1499, 264, 3387, 295, 1940, 1969, 13, 51798], "temperature": 0.0, "avg_logprob": -0.18557999099510303, "compression_ratio": 1.70125786163522, "no_speech_prob": 0.03694983199238777}, {"id": 114, "seek": 41512, "start": 415.32, "end": 417.8, "text": " And if they do that, we're in trouble.", "tokens": [50374, 400, 498, 436, 360, 300, 11, 321, 434, 294, 5253, 13, 50498], "temperature": 0.0, "avg_logprob": -0.1676967704997343, "compression_ratio": 1.7163120567375887, "no_speech_prob": 0.022903162986040115}, {"id": 115, "seek": 41512, "start": 417.8, "end": 418.8, "text": " So okay.", "tokens": [50498, 407, 1392, 13, 50548], "temperature": 0.0, "avg_logprob": -0.1676967704997343, "compression_ratio": 1.7163120567375887, "no_speech_prob": 0.022903162986040115}, {"id": 116, "seek": 41512, "start": 418.8, "end": 422.4, "text": " So let's let's go back to that in a second, but let's take Jan's position.", "tokens": [50548, 407, 718, 311, 718, 311, 352, 646, 281, 300, 294, 257, 1150, 11, 457, 718, 311, 747, 4956, 311, 2535, 13, 50728], "temperature": 0.0, "avg_logprob": -0.1676967704997343, "compression_ratio": 1.7163120567375887, "no_speech_prob": 0.022903162986040115}, {"id": 117, "seek": 41512, "start": 422.4, "end": 426.04, "text": " So Jan LeCun was also one of the people who won the Turing Award and is also called the", "tokens": [50728, 407, 4956, 1456, 34, 409, 390, 611, 472, 295, 264, 561, 567, 1582, 264, 314, 1345, 13894, 293, 307, 611, 1219, 264, 50910], "temperature": 0.0, "avg_logprob": -0.1676967704997343, "compression_ratio": 1.7163120567375887, "no_speech_prob": 0.022903162986040115}, {"id": 118, "seek": 41512, "start": 426.04, "end": 427.56, "text": " Godfather of AI.", "tokens": [50910, 1265, 11541, 295, 7318, 13, 50986], "temperature": 0.0, "avg_logprob": -0.1676967704997343, "compression_ratio": 1.7163120567375887, "no_speech_prob": 0.022903162986040115}, {"id": 119, "seek": 41512, "start": 427.56, "end": 431.48, "text": " And I was recently interviewing him and he made the case.", "tokens": [50986, 400, 286, 390, 3938, 26524, 796, 293, 415, 1027, 264, 1389, 13, 51182], "temperature": 0.0, "avg_logprob": -0.1676967704997343, "compression_ratio": 1.7163120567375887, "no_speech_prob": 0.022903162986040115}, {"id": 120, "seek": 41512, "start": 431.48, "end": 436.2, "text": " He said, look, technologies, all technologies can be used for good or ill, but some technologies", "tokens": [51182, 634, 848, 11, 574, 11, 7943, 11, 439, 7943, 393, 312, 1143, 337, 665, 420, 3171, 11, 457, 512, 7943, 51418], "temperature": 0.0, "avg_logprob": -0.1676967704997343, "compression_ratio": 1.7163120567375887, "no_speech_prob": 0.022903162986040115}, {"id": 121, "seek": 41512, "start": 436.2, "end": 438.0, "text": " have more of an inherent goodness.", "tokens": [51418, 362, 544, 295, 364, 26387, 8387, 13, 51508], "temperature": 0.0, "avg_logprob": -0.1676967704997343, "compression_ratio": 1.7163120567375887, "no_speech_prob": 0.022903162986040115}, {"id": 122, "seek": 41512, "start": 438.0, "end": 443.76, "text": " And AI has been built by humans, by good humans for good purposes.", "tokens": [51508, 400, 7318, 575, 668, 3094, 538, 6255, 11, 538, 665, 6255, 337, 665, 9932, 13, 51796], "temperature": 0.0, "avg_logprob": -0.1676967704997343, "compression_ratio": 1.7163120567375887, "no_speech_prob": 0.022903162986040115}, {"id": 123, "seek": 44376, "start": 443.76, "end": 447.24, "text": " It's been trained on good books and good texts.", "tokens": [50364, 467, 311, 668, 8895, 322, 665, 3642, 293, 665, 15765, 13, 50538], "temperature": 0.0, "avg_logprob": -0.15616670055924176, "compression_ratio": 1.8636363636363635, "no_speech_prob": 0.167740598320961}, {"id": 124, "seek": 44376, "start": 447.24, "end": 450.68, "text": " It will have a bias towards good in the future.", "tokens": [50538, 467, 486, 362, 257, 12577, 3030, 665, 294, 264, 2027, 13, 50710], "temperature": 0.0, "avg_logprob": -0.15616670055924176, "compression_ratio": 1.8636363636363635, "no_speech_prob": 0.167740598320961}, {"id": 125, "seek": 44376, "start": 450.68, "end": 452.76, "text": " Do you believe that or not?", "tokens": [50710, 1144, 291, 1697, 300, 420, 406, 30, 50814], "temperature": 0.0, "avg_logprob": -0.15616670055924176, "compression_ratio": 1.8636363636363635, "no_speech_prob": 0.167740598320961}, {"id": 126, "seek": 44376, "start": 452.76, "end": 456.56, "text": " I think AI that's been trained by good people will have a bias towards good.", "tokens": [50814, 286, 519, 7318, 300, 311, 668, 8895, 538, 665, 561, 486, 362, 257, 12577, 3030, 665, 13, 51004], "temperature": 0.0, "avg_logprob": -0.15616670055924176, "compression_ratio": 1.8636363636363635, "no_speech_prob": 0.167740598320961}, {"id": 127, "seek": 44376, "start": 456.56, "end": 461.4, "text": " And AI that's been trained by bad people like Putin or somebody like that will have a bias", "tokens": [51004, 400, 7318, 300, 311, 668, 8895, 538, 1578, 561, 411, 19818, 420, 2618, 411, 300, 486, 362, 257, 12577, 51246], "temperature": 0.0, "avg_logprob": -0.15616670055924176, "compression_ratio": 1.8636363636363635, "no_speech_prob": 0.167740598320961}, {"id": 128, "seek": 44376, "start": 461.4, "end": 462.74, "text": " towards bad.", "tokens": [51246, 3030, 1578, 13, 51313], "temperature": 0.0, "avg_logprob": -0.15616670055924176, "compression_ratio": 1.8636363636363635, "no_speech_prob": 0.167740598320961}, {"id": 129, "seek": 44376, "start": 462.74, "end": 466.03999999999996, "text": " We know they're going to make battle robots.", "tokens": [51313, 492, 458, 436, 434, 516, 281, 652, 4635, 14733, 13, 51478], "temperature": 0.0, "avg_logprob": -0.15616670055924176, "compression_ratio": 1.8636363636363635, "no_speech_prob": 0.167740598320961}, {"id": 130, "seek": 44376, "start": 466.03999999999996, "end": 469.52, "text": " They're busy doing it in many different defense departments.", "tokens": [51478, 814, 434, 5856, 884, 309, 294, 867, 819, 7654, 15326, 13, 51652], "temperature": 0.0, "avg_logprob": -0.15616670055924176, "compression_ratio": 1.8636363636363635, "no_speech_prob": 0.167740598320961}, {"id": 131, "seek": 46952, "start": 469.52, "end": 474.12, "text": " So they're not going to necessarily be good since their primary purpose is going to be", "tokens": [50364, 407, 436, 434, 406, 516, 281, 4725, 312, 665, 1670, 641, 6194, 4334, 307, 516, 281, 312, 50594], "temperature": 0.0, "avg_logprob": -0.17469789270769087, "compression_ratio": 1.8237704918032787, "no_speech_prob": 0.10027649253606796}, {"id": 132, "seek": 46952, "start": 474.12, "end": 476.35999999999996, "text": " to kill people.", "tokens": [50594, 281, 1961, 561, 13, 50706], "temperature": 0.0, "avg_logprob": -0.17469789270769087, "compression_ratio": 1.8237704918032787, "no_speech_prob": 0.10027649253606796}, {"id": 133, "seek": 46952, "start": 476.35999999999996, "end": 483.64, "text": " So you believe that the risks of the bad uses of AI are whether they're more or less than", "tokens": [50706, 407, 291, 1697, 300, 264, 10888, 295, 264, 1578, 4960, 295, 7318, 366, 1968, 436, 434, 544, 420, 1570, 813, 51070], "temperature": 0.0, "avg_logprob": -0.17469789270769087, "compression_ratio": 1.8237704918032787, "no_speech_prob": 0.10027649253606796}, {"id": 134, "seek": 46952, "start": 483.64, "end": 488.24, "text": " the good uses of AI are so substantial, they deserve a lot of our thought right now.", "tokens": [51070, 264, 665, 4960, 295, 7318, 366, 370, 16726, 11, 436, 9948, 257, 688, 295, 527, 1194, 558, 586, 13, 51300], "temperature": 0.0, "avg_logprob": -0.17469789270769087, "compression_ratio": 1.8237704918032787, "no_speech_prob": 0.10027649253606796}, {"id": 135, "seek": 46952, "start": 488.24, "end": 489.24, "text": " Certainly.", "tokens": [51300, 16628, 13, 51350], "temperature": 0.0, "avg_logprob": -0.17469789270769087, "compression_ratio": 1.8237704918032787, "no_speech_prob": 0.10027649253606796}, {"id": 136, "seek": 46952, "start": 489.24, "end": 490.24, "text": " Yes.", "tokens": [51350, 1079, 13, 51400], "temperature": 0.0, "avg_logprob": -0.17469789270769087, "compression_ratio": 1.8237704918032787, "no_speech_prob": 0.10027649253606796}, {"id": 137, "seek": 46952, "start": 490.24, "end": 492.24, "text": " For lethal autonomous weapons, they deserve a lot of our thought.", "tokens": [51400, 1171, 34562, 23797, 7278, 11, 436, 9948, 257, 688, 295, 527, 1194, 13, 51500], "temperature": 0.0, "avg_logprob": -0.17469789270769087, "compression_ratio": 1.8237704918032787, "no_speech_prob": 0.10027649253606796}, {"id": 138, "seek": 46952, "start": 492.24, "end": 495.84, "text": " Well, let's, okay, let's stick on lethal autonomous weapons because one of the things", "tokens": [51500, 1042, 11, 718, 311, 11, 1392, 11, 718, 311, 2897, 322, 34562, 23797, 7278, 570, 472, 295, 264, 721, 51680], "temperature": 0.0, "avg_logprob": -0.17469789270769087, "compression_ratio": 1.8237704918032787, "no_speech_prob": 0.10027649253606796}, {"id": 139, "seek": 49584, "start": 495.84, "end": 501.47999999999996, "text": " in this argument is that you are one of the few people who is really speaking about this", "tokens": [50364, 294, 341, 6770, 307, 300, 291, 366, 472, 295, 264, 1326, 561, 567, 307, 534, 4124, 466, 341, 50646], "temperature": 0.0, "avg_logprob": -0.17306389043360582, "compression_ratio": 1.5336538461538463, "no_speech_prob": 0.18369001150131226}, {"id": 140, "seek": 49584, "start": 501.47999999999996, "end": 503.88, "text": " as a risk, a real risk.", "tokens": [50646, 382, 257, 3148, 11, 257, 957, 3148, 13, 50766], "temperature": 0.0, "avg_logprob": -0.17306389043360582, "compression_ratio": 1.5336538461538463, "no_speech_prob": 0.18369001150131226}, {"id": 141, "seek": 49584, "start": 503.88, "end": 512.4399999999999, "text": " Explain your hypothesis about why super powerful AI combined with the military could actually", "tokens": [50766, 39574, 428, 17291, 466, 983, 1687, 4005, 7318, 9354, 365, 264, 4632, 727, 767, 51194], "temperature": 0.0, "avg_logprob": -0.17306389043360582, "compression_ratio": 1.5336538461538463, "no_speech_prob": 0.18369001150131226}, {"id": 142, "seek": 49584, "start": 512.4399999999999, "end": 515.28, "text": " lead to more and more warfare.", "tokens": [51194, 1477, 281, 544, 293, 544, 24490, 13, 51336], "temperature": 0.0, "avg_logprob": -0.17306389043360582, "compression_ratio": 1.5336538461538463, "no_speech_prob": 0.18369001150131226}, {"id": 143, "seek": 49584, "start": 515.28, "end": 516.52, "text": " Okay.", "tokens": [51336, 1033, 13, 51398], "temperature": 0.0, "avg_logprob": -0.17306389043360582, "compression_ratio": 1.5336538461538463, "no_speech_prob": 0.18369001150131226}, {"id": 144, "seek": 49584, "start": 516.52, "end": 521.8, "text": " I don't actually want to answer that question.", "tokens": [51398, 286, 500, 380, 767, 528, 281, 1867, 300, 1168, 13, 51662], "temperature": 0.0, "avg_logprob": -0.17306389043360582, "compression_ratio": 1.5336538461538463, "no_speech_prob": 0.18369001150131226}, {"id": 145, "seek": 49584, "start": 521.8, "end": 523.12, "text": " There's a separate question.", "tokens": [51662, 821, 311, 257, 4994, 1168, 13, 51728], "temperature": 0.0, "avg_logprob": -0.17306389043360582, "compression_ratio": 1.5336538461538463, "no_speech_prob": 0.18369001150131226}, {"id": 146, "seek": 52312, "start": 523.12, "end": 528.32, "text": " Even if the AI isn't super intelligent, if defense departments use it for making battle", "tokens": [50364, 2754, 498, 264, 7318, 1943, 380, 1687, 13232, 11, 498, 7654, 15326, 764, 309, 337, 1455, 4635, 50624], "temperature": 0.0, "avg_logprob": -0.13857522557993404, "compression_ratio": 1.8132295719844358, "no_speech_prob": 0.4703597128391266}, {"id": 147, "seek": 52312, "start": 528.32, "end": 531.52, "text": " robots, it's going to be very nasty, scary stuff.", "tokens": [50624, 14733, 11, 309, 311, 516, 281, 312, 588, 17923, 11, 6958, 1507, 13, 50784], "temperature": 0.0, "avg_logprob": -0.13857522557993404, "compression_ratio": 1.8132295719844358, "no_speech_prob": 0.4703597128391266}, {"id": 148, "seek": 52312, "start": 531.52, "end": 535.4, "text": " And it's going to lead, even if it's not super intelligent, and even if it doesn't have its", "tokens": [50784, 400, 309, 311, 516, 281, 1477, 11, 754, 498, 309, 311, 406, 1687, 13232, 11, 293, 754, 498, 309, 1177, 380, 362, 1080, 50978], "temperature": 0.0, "avg_logprob": -0.13857522557993404, "compression_ratio": 1.8132295719844358, "no_speech_prob": 0.4703597128391266}, {"id": 149, "seek": 52312, "start": 535.4, "end": 540.64, "text": " own intentions, it just does what Putin tells it to.", "tokens": [50978, 1065, 19354, 11, 309, 445, 775, 437, 19818, 5112, 309, 281, 13, 51240], "temperature": 0.0, "avg_logprob": -0.13857522557993404, "compression_ratio": 1.8132295719844358, "no_speech_prob": 0.4703597128391266}, {"id": 150, "seek": 52312, "start": 540.64, "end": 546.0, "text": " It's going to make it much easier, for example, for rich countries to invade poor countries.", "tokens": [51240, 467, 311, 516, 281, 652, 309, 709, 3571, 11, 337, 1365, 11, 337, 4593, 3517, 281, 39171, 4716, 3517, 13, 51508], "temperature": 0.0, "avg_logprob": -0.13857522557993404, "compression_ratio": 1.8132295719844358, "no_speech_prob": 0.4703597128391266}, {"id": 151, "seek": 52312, "start": 546.0, "end": 551.24, "text": " A present, there's a barrier to invading poor countries willy-nilly, which is you get dead", "tokens": [51508, 316, 1974, 11, 456, 311, 257, 13357, 281, 1048, 8166, 4716, 3517, 486, 88, 12, 77, 6917, 11, 597, 307, 291, 483, 3116, 51770], "temperature": 0.0, "avg_logprob": -0.13857522557993404, "compression_ratio": 1.8132295719844358, "no_speech_prob": 0.4703597128391266}, {"id": 152, "seek": 55124, "start": 551.24, "end": 553.42, "text": " citizens coming home.", "tokens": [50364, 7180, 1348, 1280, 13, 50473], "temperature": 0.0, "avg_logprob": -0.1306103297642299, "compression_ratio": 1.7985611510791366, "no_speech_prob": 0.2438765913248062}, {"id": 153, "seek": 55124, "start": 553.42, "end": 555.72, "text": " If they just dead battle robots, that's just great.", "tokens": [50473, 759, 436, 445, 3116, 4635, 14733, 11, 300, 311, 445, 869, 13, 50588], "temperature": 0.0, "avg_logprob": -0.1306103297642299, "compression_ratio": 1.7985611510791366, "no_speech_prob": 0.2438765913248062}, {"id": 154, "seek": 55124, "start": 555.72, "end": 558.96, "text": " The military industrial complex would love that.", "tokens": [50588, 440, 4632, 9987, 3997, 576, 959, 300, 13, 50750], "temperature": 0.0, "avg_logprob": -0.1306103297642299, "compression_ratio": 1.7985611510791366, "no_speech_prob": 0.2438765913248062}, {"id": 155, "seek": 55124, "start": 558.96, "end": 563.32, "text": " So you think that because, I mean, it's sort of a similar argument that people make with", "tokens": [50750, 407, 291, 519, 300, 570, 11, 286, 914, 11, 309, 311, 1333, 295, 257, 2531, 6770, 300, 561, 652, 365, 50968], "temperature": 0.0, "avg_logprob": -0.1306103297642299, "compression_ratio": 1.7985611510791366, "no_speech_prob": 0.2438765913248062}, {"id": 156, "seek": 55124, "start": 563.32, "end": 564.32, "text": " drones.", "tokens": [50968, 23823, 13, 51018], "temperature": 0.0, "avg_logprob": -0.1306103297642299, "compression_ratio": 1.7985611510791366, "no_speech_prob": 0.2438765913248062}, {"id": 157, "seek": 55124, "start": 564.32, "end": 566.8, "text": " If you can send a drone and you don't have to send an airplane with a pilot, you're more", "tokens": [51018, 759, 291, 393, 2845, 257, 13852, 293, 291, 500, 380, 362, 281, 2845, 364, 17130, 365, 257, 9691, 11, 291, 434, 544, 51142], "temperature": 0.0, "avg_logprob": -0.1306103297642299, "compression_ratio": 1.7985611510791366, "no_speech_prob": 0.2438765913248062}, {"id": 158, "seek": 55124, "start": 566.8, "end": 570.08, "text": " likely to send the drone, therefore you're more likely to attack.", "tokens": [51142, 3700, 281, 2845, 264, 13852, 11, 4412, 291, 434, 544, 3700, 281, 2690, 13, 51306], "temperature": 0.0, "avg_logprob": -0.1306103297642299, "compression_ratio": 1.7985611510791366, "no_speech_prob": 0.2438765913248062}, {"id": 159, "seek": 55124, "start": 570.08, "end": 574.0, "text": " If you have a battle robot, it's that same thing squared.", "tokens": [51306, 759, 291, 362, 257, 4635, 7881, 11, 309, 311, 300, 912, 551, 8889, 13, 51502], "temperature": 0.0, "avg_logprob": -0.1306103297642299, "compression_ratio": 1.7985611510791366, "no_speech_prob": 0.2438765913248062}, {"id": 160, "seek": 55124, "start": 574.0, "end": 575.28, "text": " And that's your concern.", "tokens": [51502, 400, 300, 311, 428, 3136, 13, 51566], "temperature": 0.0, "avg_logprob": -0.1306103297642299, "compression_ratio": 1.7985611510791366, "no_speech_prob": 0.2438765913248062}, {"id": 161, "seek": 55124, "start": 575.28, "end": 577.12, "text": " That's my main concern with battle robots.", "tokens": [51566, 663, 311, 452, 2135, 3136, 365, 4635, 14733, 13, 51658], "temperature": 0.0, "avg_logprob": -0.1306103297642299, "compression_ratio": 1.7985611510791366, "no_speech_prob": 0.2438765913248062}, {"id": 162, "seek": 57712, "start": 577.12, "end": 582.04, "text": " It's a separate concern from what happens with super intelligent systems taking over", "tokens": [50364, 467, 311, 257, 4994, 3136, 490, 437, 2314, 365, 1687, 13232, 3652, 1940, 670, 50610], "temperature": 0.0, "avg_logprob": -0.1177383025487264, "compression_ratio": 1.7765957446808511, "no_speech_prob": 0.01704351231455803}, {"id": 163, "seek": 57712, "start": 582.04, "end": 584.36, "text": " for their own purposes.", "tokens": [50610, 337, 641, 1065, 9932, 13, 50726], "temperature": 0.0, "avg_logprob": -0.1177383025487264, "compression_ratio": 1.7765957446808511, "no_speech_prob": 0.01704351231455803}, {"id": 164, "seek": 57712, "start": 584.36, "end": 588.2, "text": " Before we get to super intelligent systems, let's talk about some of your other concerns.", "tokens": [50726, 4546, 321, 483, 281, 1687, 13232, 3652, 11, 718, 311, 751, 466, 512, 295, 428, 661, 7389, 13, 50918], "temperature": 0.0, "avg_logprob": -0.1177383025487264, "compression_ratio": 1.7765957446808511, "no_speech_prob": 0.01704351231455803}, {"id": 165, "seek": 57712, "start": 588.2, "end": 593.2, "text": " So in the litany of things that you're worried about, you obviously we have battle robots", "tokens": [50918, 407, 294, 264, 7997, 1325, 295, 721, 300, 291, 434, 5804, 466, 11, 291, 2745, 321, 362, 4635, 14733, 51168], "temperature": 0.0, "avg_logprob": -0.1177383025487264, "compression_ratio": 1.7765957446808511, "no_speech_prob": 0.01704351231455803}, {"id": 166, "seek": 57712, "start": 593.2, "end": 596.5600000000001, "text": " as one, you're also quite worried about inequality.", "tokens": [51168, 382, 472, 11, 291, 434, 611, 1596, 5804, 466, 16970, 13, 51336], "temperature": 0.0, "avg_logprob": -0.1177383025487264, "compression_ratio": 1.7765957446808511, "no_speech_prob": 0.01704351231455803}, {"id": 167, "seek": 57712, "start": 596.5600000000001, "end": 598.12, "text": " Tell me more about this.", "tokens": [51336, 5115, 385, 544, 466, 341, 13, 51414], "temperature": 0.0, "avg_logprob": -0.1177383025487264, "compression_ratio": 1.7765957446808511, "no_speech_prob": 0.01704351231455803}, {"id": 168, "seek": 57712, "start": 598.12, "end": 603.36, "text": " So it's fairly clear, it's not certain, but it's fairly clear that these big language", "tokens": [51414, 407, 309, 311, 6457, 1850, 11, 309, 311, 406, 1629, 11, 457, 309, 311, 6457, 1850, 300, 613, 955, 2856, 51676], "temperature": 0.0, "avg_logprob": -0.1177383025487264, "compression_ratio": 1.7765957446808511, "no_speech_prob": 0.01704351231455803}, {"id": 169, "seek": 57712, "start": 603.36, "end": 606.92, "text": " models will cause a big increase in productivity.", "tokens": [51676, 5245, 486, 3082, 257, 955, 3488, 294, 15604, 13, 51854], "temperature": 0.0, "avg_logprob": -0.1177383025487264, "compression_ratio": 1.7765957446808511, "no_speech_prob": 0.01704351231455803}, {"id": 170, "seek": 60692, "start": 606.92, "end": 611.24, "text": " So there's someone I know who answers letters of complaint for a health service.", "tokens": [50364, 407, 456, 311, 1580, 286, 458, 567, 6338, 7825, 295, 20100, 337, 257, 1585, 2643, 13, 50580], "temperature": 0.0, "avg_logprob": -0.1939592987951571, "compression_ratio": 1.8650519031141868, "no_speech_prob": 0.035044535994529724}, {"id": 171, "seek": 60692, "start": 611.24, "end": 616.1999999999999, "text": " And he used to write these letters himself and now he just gets chat GPT to write the", "tokens": [50580, 400, 415, 1143, 281, 2464, 613, 7825, 3647, 293, 586, 415, 445, 2170, 5081, 26039, 51, 281, 2464, 264, 50828], "temperature": 0.0, "avg_logprob": -0.1939592987951571, "compression_ratio": 1.8650519031141868, "no_speech_prob": 0.035044535994529724}, {"id": 172, "seek": 60692, "start": 616.1999999999999, "end": 620.64, "text": " letters and it takes one-fifth of the amount of time to answer a complaint.", "tokens": [50828, 7825, 293, 309, 2516, 472, 12, 69, 351, 392, 295, 264, 2372, 295, 565, 281, 1867, 257, 20100, 13, 51050], "temperature": 0.0, "avg_logprob": -0.1939592987951571, "compression_ratio": 1.8650519031141868, "no_speech_prob": 0.035044535994529724}, {"id": 173, "seek": 60692, "start": 620.64, "end": 626.8399999999999, "text": " So he can do five times as much work and so there are only five times fewer of him.", "tokens": [51050, 407, 415, 393, 360, 1732, 1413, 382, 709, 589, 293, 370, 456, 366, 787, 1732, 1413, 13366, 295, 796, 13, 51360], "temperature": 0.0, "avg_logprob": -0.1939592987951571, "compression_ratio": 1.8650519031141868, "no_speech_prob": 0.035044535994529724}, {"id": 174, "seek": 60692, "start": 626.8399999999999, "end": 628.7199999999999, "text": " Or maybe they'll just answer a lot more letters.", "tokens": [51360, 1610, 1310, 436, 603, 445, 1867, 257, 688, 544, 7825, 13, 51454], "temperature": 0.0, "avg_logprob": -0.1939592987951571, "compression_ratio": 1.8650519031141868, "no_speech_prob": 0.035044535994529724}, {"id": 175, "seek": 60692, "start": 628.7199999999999, "end": 629.9599999999999, "text": " Or they'll answer more letters, right?", "tokens": [51454, 1610, 436, 603, 1867, 544, 7825, 11, 558, 30, 51516], "temperature": 0.0, "avg_logprob": -0.1939592987951571, "compression_ratio": 1.8650519031141868, "no_speech_prob": 0.035044535994529724}, {"id": 176, "seek": 60692, "start": 629.9599999999999, "end": 633.48, "text": " Or maybe they'll have more people because they'll be so efficient, right?", "tokens": [51516, 1610, 1310, 436, 603, 362, 544, 561, 570, 436, 603, 312, 370, 7148, 11, 558, 30, 51692], "temperature": 0.0, "avg_logprob": -0.1939592987951571, "compression_ratio": 1.8650519031141868, "no_speech_prob": 0.035044535994529724}, {"id": 177, "seek": 60692, "start": 633.48, "end": 635.68, "text": " More productivity leads to more getting more done.", "tokens": [51692, 5048, 15604, 6689, 281, 544, 1242, 544, 1096, 13, 51802], "temperature": 0.0, "avg_logprob": -0.1939592987951571, "compression_ratio": 1.8650519031141868, "no_speech_prob": 0.035044535994529724}, {"id": 178, "seek": 63568, "start": 635.68, "end": 637.88, "text": " This is an unanswered question.", "tokens": [50364, 639, 307, 364, 517, 43904, 292, 1168, 13, 50474], "temperature": 0.0, "avg_logprob": -0.16429356892903646, "compression_ratio": 1.8107255520504733, "no_speech_prob": 0.04534529894590378}, {"id": 179, "seek": 63568, "start": 637.88, "end": 642.4399999999999, "text": " But what we expect in the kind of society we live in is that if you get a big increase", "tokens": [50474, 583, 437, 321, 2066, 294, 264, 733, 295, 4086, 321, 1621, 294, 307, 300, 498, 291, 483, 257, 955, 3488, 50702], "temperature": 0.0, "avg_logprob": -0.16429356892903646, "compression_ratio": 1.8107255520504733, "no_speech_prob": 0.04534529894590378}, {"id": 180, "seek": 63568, "start": 642.4399999999999, "end": 647.4399999999999, "text": " in productivity like that, the wealth isn't going to go to the people who are doing the", "tokens": [50702, 294, 15604, 411, 300, 11, 264, 7203, 1943, 380, 516, 281, 352, 281, 264, 561, 567, 366, 884, 264, 50952], "temperature": 0.0, "avg_logprob": -0.16429356892903646, "compression_ratio": 1.8107255520504733, "no_speech_prob": 0.04534529894590378}, {"id": 181, "seek": 63568, "start": 647.4399999999999, "end": 651.4399999999999, "text": " work or the people who get unemployed, it's going to go to making the rich richer and", "tokens": [50952, 589, 420, 264, 561, 567, 483, 34411, 11, 309, 311, 516, 281, 352, 281, 1455, 264, 4593, 29021, 293, 51152], "temperature": 0.0, "avg_logprob": -0.16429356892903646, "compression_ratio": 1.8107255520504733, "no_speech_prob": 0.04534529894590378}, {"id": 182, "seek": 63568, "start": 651.4399999999999, "end": 652.4399999999999, "text": " the poor poorer.", "tokens": [51152, 264, 4716, 49740, 13, 51202], "temperature": 0.0, "avg_logprob": -0.16429356892903646, "compression_ratio": 1.8107255520504733, "no_speech_prob": 0.04534529894590378}, {"id": 183, "seek": 63568, "start": 652.4399999999999, "end": 654.4399999999999, "text": " And that's very bad for society.", "tokens": [51202, 400, 300, 311, 588, 1578, 337, 4086, 13, 51302], "temperature": 0.0, "avg_logprob": -0.16429356892903646, "compression_ratio": 1.8107255520504733, "no_speech_prob": 0.04534529894590378}, {"id": 184, "seek": 63568, "start": 654.4399999999999, "end": 657.88, "text": " Definitionally, or you think there's some feature of AI that will lead to that?", "tokens": [51302, 46245, 15899, 11, 420, 291, 519, 456, 311, 512, 4111, 295, 7318, 300, 486, 1477, 281, 300, 30, 51474], "temperature": 0.0, "avg_logprob": -0.16429356892903646, "compression_ratio": 1.8107255520504733, "no_speech_prob": 0.04534529894590378}, {"id": 185, "seek": 63568, "start": 657.88, "end": 662.28, "text": " No, it's not to do with AI, it's just what happens when you get an increase in productivity,", "tokens": [51474, 883, 11, 309, 311, 406, 281, 360, 365, 7318, 11, 309, 311, 445, 437, 2314, 562, 291, 483, 364, 3488, 294, 15604, 11, 51694], "temperature": 0.0, "avg_logprob": -0.16429356892903646, "compression_ratio": 1.8107255520504733, "no_speech_prob": 0.04534529894590378}, {"id": 186, "seek": 63568, "start": 662.28, "end": 665.12, "text": " particularly in a society that doesn't have strong unions.", "tokens": [51694, 4098, 294, 257, 4086, 300, 1177, 380, 362, 2068, 24914, 13, 51836], "temperature": 0.0, "avg_logprob": -0.16429356892903646, "compression_ratio": 1.8107255520504733, "no_speech_prob": 0.04534529894590378}, {"id": 187, "seek": 66512, "start": 665.12, "end": 669.68, "text": " But now there are many economists who would take a different position and say that over", "tokens": [50364, 583, 586, 456, 366, 867, 32431, 567, 576, 747, 257, 819, 2535, 293, 584, 300, 670, 50592], "temperature": 0.0, "avg_logprob": -0.15294476826985678, "compression_ratio": 1.8987341772151898, "no_speech_prob": 0.09215030819177628}, {"id": 188, "seek": 66512, "start": 669.68, "end": 674.8, "text": " time, and if you were to look at technology, right, we went from horses and horses and", "tokens": [50592, 565, 11, 293, 498, 291, 645, 281, 574, 412, 2899, 11, 558, 11, 321, 1437, 490, 13112, 293, 13112, 293, 50848], "temperature": 0.0, "avg_logprob": -0.15294476826985678, "compression_ratio": 1.8987341772151898, "no_speech_prob": 0.09215030819177628}, {"id": 189, "seek": 66512, "start": 674.8, "end": 678.16, "text": " buggies and the horses and buggies went away and then we had cars and oh my gosh, the people", "tokens": [50848, 272, 3562, 530, 293, 264, 13112, 293, 272, 3562, 530, 1437, 1314, 293, 550, 321, 632, 5163, 293, 1954, 452, 6502, 11, 264, 561, 51016], "temperature": 0.0, "avg_logprob": -0.15294476826985678, "compression_ratio": 1.8987341772151898, "no_speech_prob": 0.09215030819177628}, {"id": 190, "seek": 66512, "start": 678.16, "end": 682.92, "text": " who drove the horses lost their jobs and ATMs came along and suddenly bank tellers no longer", "tokens": [51016, 567, 13226, 264, 13112, 2731, 641, 4782, 293, 8872, 26386, 1361, 2051, 293, 5800, 3765, 980, 433, 572, 2854, 51254], "temperature": 0.0, "avg_logprob": -0.15294476826985678, "compression_ratio": 1.8987341772151898, "no_speech_prob": 0.09215030819177628}, {"id": 191, "seek": 66512, "start": 682.92, "end": 683.92, "text": " need to do that.", "tokens": [51254, 643, 281, 360, 300, 13, 51304], "temperature": 0.0, "avg_logprob": -0.15294476826985678, "compression_ratio": 1.8987341772151898, "no_speech_prob": 0.09215030819177628}, {"id": 192, "seek": 66512, "start": 683.92, "end": 687.04, "text": " But we now employ many more bank tellers than we used to and we have many more people driving", "tokens": [51304, 583, 321, 586, 3188, 867, 544, 3765, 980, 433, 813, 321, 1143, 281, 293, 321, 362, 867, 544, 561, 4840, 51460], "temperature": 0.0, "avg_logprob": -0.15294476826985678, "compression_ratio": 1.8987341772151898, "no_speech_prob": 0.09215030819177628}, {"id": 193, "seek": 66512, "start": 687.04, "end": 689.2, "text": " Ubers than we had people driving horses.", "tokens": [51460, 624, 1616, 813, 321, 632, 561, 4840, 13112, 13, 51568], "temperature": 0.0, "avg_logprob": -0.15294476826985678, "compression_ratio": 1.8987341772151898, "no_speech_prob": 0.09215030819177628}, {"id": 194, "seek": 66512, "start": 689.2, "end": 695.08, "text": " So the argument what an economist would make to this would be, yes, there will be chair", "tokens": [51568, 407, 264, 6770, 437, 364, 36696, 576, 652, 281, 341, 576, 312, 11, 2086, 11, 456, 486, 312, 6090, 51862], "temperature": 0.0, "avg_logprob": -0.15294476826985678, "compression_ratio": 1.8987341772151898, "no_speech_prob": 0.09215030819177628}, {"id": 195, "seek": 69508, "start": 695.08, "end": 700.2, "text": " and there will be fewer people answering those letters, but there'll be many more higher", "tokens": [50364, 293, 456, 486, 312, 13366, 561, 13430, 729, 7825, 11, 457, 456, 603, 312, 867, 544, 2946, 50620], "temperature": 0.0, "avg_logprob": -0.15746643129459098, "compression_ratio": 1.7604166666666667, "no_speech_prob": 0.08335994929075241}, {"id": 196, "seek": 69508, "start": 700.2, "end": 701.64, "text": " cognitive things that will be done.", "tokens": [50620, 15605, 721, 300, 486, 312, 1096, 13, 50692], "temperature": 0.0, "avg_logprob": -0.15746643129459098, "compression_ratio": 1.7604166666666667, "no_speech_prob": 0.08335994929075241}, {"id": 197, "seek": 69508, "start": 701.64, "end": 703.9200000000001, "text": " How do you respond to that?", "tokens": [50692, 1012, 360, 291, 4196, 281, 300, 30, 50806], "temperature": 0.0, "avg_logprob": -0.15746643129459098, "compression_ratio": 1.7604166666666667, "no_speech_prob": 0.08335994929075241}, {"id": 198, "seek": 69508, "start": 703.9200000000001, "end": 708.64, "text": " I think the first thing I'd say is a loaf of bread used to cost a penny, then they invented", "tokens": [50806, 286, 519, 264, 700, 551, 286, 1116, 584, 307, 257, 40743, 295, 5961, 1143, 281, 2063, 257, 24178, 11, 550, 436, 14479, 51042], "temperature": 0.0, "avg_logprob": -0.15746643129459098, "compression_ratio": 1.7604166666666667, "no_speech_prob": 0.08335994929075241}, {"id": 199, "seek": 69508, "start": 708.64, "end": 712.6800000000001, "text": " economics and now it costs five dollars.", "tokens": [51042, 14564, 293, 586, 309, 5497, 1732, 3808, 13, 51244], "temperature": 0.0, "avg_logprob": -0.15746643129459098, "compression_ratio": 1.7604166666666667, "no_speech_prob": 0.08335994929075241}, {"id": 200, "seek": 69508, "start": 712.6800000000001, "end": 716.88, "text": " So I don't entirely trust what economists say, particularly when they're dealing with", "tokens": [51244, 407, 286, 500, 380, 7696, 3361, 437, 32431, 584, 11, 4098, 562, 436, 434, 6260, 365, 51454], "temperature": 0.0, "avg_logprob": -0.15746643129459098, "compression_ratio": 1.7604166666666667, "no_speech_prob": 0.08335994929075241}, {"id": 201, "seek": 69508, "start": 716.88, "end": 720.24, "text": " a new situation that's never happened before.", "tokens": [51454, 257, 777, 2590, 300, 311, 1128, 2011, 949, 13, 51622], "temperature": 0.0, "avg_logprob": -0.15746643129459098, "compression_ratio": 1.7604166666666667, "no_speech_prob": 0.08335994929075241}, {"id": 202, "seek": 69508, "start": 720.24, "end": 724.36, "text": " And superintelligence would be a new situation that never happened before, but even these", "tokens": [51622, 400, 1687, 20761, 17644, 576, 312, 257, 777, 2590, 300, 1128, 2011, 949, 11, 457, 754, 613, 51828], "temperature": 0.0, "avg_logprob": -0.15746643129459098, "compression_ratio": 1.7604166666666667, "no_speech_prob": 0.08335994929075241}, {"id": 203, "seek": 72436, "start": 724.36, "end": 730.4, "text": " big chatbots that are just replacing people whose job involves producing text, that's", "tokens": [50364, 955, 5081, 65, 1971, 300, 366, 445, 19139, 561, 6104, 1691, 11626, 10501, 2487, 11, 300, 311, 50666], "temperature": 0.0, "avg_logprob": -0.18512912163367637, "compression_ratio": 1.7310344827586206, "no_speech_prob": 0.022735677659511566}, {"id": 204, "seek": 72436, "start": 730.4, "end": 735.92, "text": " never happened before and I'm not sure how they can confidently predict that more jobs", "tokens": [50666, 1128, 2011, 949, 293, 286, 478, 406, 988, 577, 436, 393, 41956, 6069, 300, 544, 4782, 50942], "temperature": 0.0, "avg_logprob": -0.18512912163367637, "compression_ratio": 1.7310344827586206, "no_speech_prob": 0.022735677659511566}, {"id": 205, "seek": 72436, "start": 735.92, "end": 738.44, "text": " will be created than the number of jobs lost.", "tokens": [50942, 486, 312, 2942, 813, 264, 1230, 295, 4782, 2731, 13, 51068], "temperature": 0.0, "avg_logprob": -0.18512912163367637, "compression_ratio": 1.7310344827586206, "no_speech_prob": 0.022735677659511566}, {"id": 206, "seek": 72436, "start": 738.44, "end": 742.84, "text": " I just have a little side note that in the green room, I introduced Jeff to, I have two", "tokens": [51068, 286, 445, 362, 257, 707, 1252, 3637, 300, 294, 264, 3092, 1808, 11, 286, 7268, 7506, 281, 11, 286, 362, 732, 51288], "temperature": 0.0, "avg_logprob": -0.18512912163367637, "compression_ratio": 1.7310344827586206, "no_speech_prob": 0.022735677659511566}, {"id": 207, "seek": 72436, "start": 742.84, "end": 747.76, "text": " of my three children are here, Alice and Zachary, they're somewhere out here, and he said to", "tokens": [51288, 295, 452, 1045, 2227, 366, 510, 11, 16004, 293, 21028, 822, 11, 436, 434, 4079, 484, 510, 11, 293, 415, 848, 281, 51534], "temperature": 0.0, "avg_logprob": -0.18512912163367637, "compression_ratio": 1.7310344827586206, "no_speech_prob": 0.022735677659511566}, {"id": 208, "seek": 72436, "start": 747.76, "end": 750.24, "text": " Alice, he said, are you going to go into media?", "tokens": [51534, 16004, 11, 415, 848, 11, 366, 291, 516, 281, 352, 666, 3021, 30, 51658], "temperature": 0.0, "avg_logprob": -0.18512912163367637, "compression_ratio": 1.7310344827586206, "no_speech_prob": 0.022735677659511566}, {"id": 209, "seek": 72436, "start": 750.24, "end": 753.28, "text": " And then he said, well, I'm not sure media will exist.", "tokens": [51658, 400, 550, 415, 848, 11, 731, 11, 286, 478, 406, 988, 3021, 486, 2514, 13, 51810], "temperature": 0.0, "avg_logprob": -0.18512912163367637, "compression_ratio": 1.7310344827586206, "no_speech_prob": 0.022735677659511566}, {"id": 210, "seek": 75328, "start": 753.28, "end": 755.0, "text": " And then Alice was asking, what should I do?", "tokens": [50364, 400, 550, 16004, 390, 3365, 11, 437, 820, 286, 360, 30, 50450], "temperature": 0.0, "avg_logprob": -0.14869493426698627, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.01146999467164278}, {"id": 211, "seek": 75328, "start": 755.0, "end": 756.0, "text": " And you said?", "tokens": [50450, 400, 291, 848, 30, 50500], "temperature": 0.0, "avg_logprob": -0.14869493426698627, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.01146999467164278}, {"id": 212, "seek": 75328, "start": 756.0, "end": 757.0, "text": " Plumbing.", "tokens": [50500, 2149, 34236, 13, 50550], "temperature": 0.0, "avg_logprob": -0.14869493426698627, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.01146999467164278}, {"id": 213, "seek": 75328, "start": 757.0, "end": 758.0, "text": " Yes.", "tokens": [50550, 1079, 13, 50600], "temperature": 0.0, "avg_logprob": -0.14869493426698627, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.01146999467164278}, {"id": 214, "seek": 75328, "start": 758.0, "end": 759.0, "text": " Now explain.", "tokens": [50600, 823, 2903, 13, 50650], "temperature": 0.0, "avg_logprob": -0.14869493426698627, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.01146999467164278}, {"id": 215, "seek": 75328, "start": 759.0, "end": 763.4399999999999, "text": " I mean, we have a number of plumbing problems at our house, it'd be wonderful if they were", "tokens": [50650, 286, 914, 11, 321, 362, 257, 1230, 295, 39993, 2740, 412, 527, 1782, 11, 309, 1116, 312, 3715, 498, 436, 645, 50872], "temperature": 0.0, "avg_logprob": -0.14869493426698627, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.01146999467164278}, {"id": 216, "seek": 75328, "start": 763.4399999999999, "end": 765.72, "text": " able to put in a new sink.", "tokens": [50872, 1075, 281, 829, 294, 257, 777, 9500, 13, 50986], "temperature": 0.0, "avg_logprob": -0.14869493426698627, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.01146999467164278}, {"id": 217, "seek": 75328, "start": 765.72, "end": 770.12, "text": " Explain what jobs, a lot of young people out here, not just my children, but thinking about", "tokens": [50986, 39574, 437, 4782, 11, 257, 688, 295, 2037, 561, 484, 510, 11, 406, 445, 452, 2227, 11, 457, 1953, 466, 51206], "temperature": 0.0, "avg_logprob": -0.14869493426698627, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.01146999467164278}, {"id": 218, "seek": 75328, "start": 770.12, "end": 774.4399999999999, "text": " what careers to go into, what are the careers they should be looking at, what are the attributes", "tokens": [51206, 437, 16409, 281, 352, 666, 11, 437, 366, 264, 16409, 436, 820, 312, 1237, 412, 11, 437, 366, 264, 17212, 51422], "temperature": 0.0, "avg_logprob": -0.14869493426698627, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.01146999467164278}, {"id": 219, "seek": 75328, "start": 774.4399999999999, "end": 775.4399999999999, "text": " of them?", "tokens": [51422, 295, 552, 30, 51472], "temperature": 0.0, "avg_logprob": -0.14869493426698627, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.01146999467164278}, {"id": 220, "seek": 75328, "start": 775.4399999999999, "end": 778.9599999999999, "text": " I'll give you a little story about being a carpenter.", "tokens": [51472, 286, 603, 976, 291, 257, 707, 1657, 466, 885, 257, 26103, 14278, 13, 51648], "temperature": 0.0, "avg_logprob": -0.14869493426698627, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.01146999467164278}, {"id": 221, "seek": 77896, "start": 778.96, "end": 784.6, "text": " If you're a carpenter, it's fun making furniture, but it's a complete dead loss because machines", "tokens": [50364, 759, 291, 434, 257, 26103, 14278, 11, 309, 311, 1019, 1455, 15671, 11, 457, 309, 311, 257, 3566, 3116, 4470, 570, 8379, 50646], "temperature": 0.0, "avg_logprob": -0.08497675982388583, "compression_ratio": 1.763779527559055, "no_speech_prob": 0.28498730063438416}, {"id": 222, "seek": 77896, "start": 784.6, "end": 786.36, "text": " can make furniture.", "tokens": [50646, 393, 652, 15671, 13, 50734], "temperature": 0.0, "avg_logprob": -0.08497675982388583, "compression_ratio": 1.763779527559055, "no_speech_prob": 0.28498730063438416}, {"id": 223, "seek": 77896, "start": 786.36, "end": 791.76, "text": " If you're a carpenter, what you're good for is repairing furniture or fitting things into", "tokens": [50734, 759, 291, 434, 257, 26103, 14278, 11, 437, 291, 434, 665, 337, 307, 46158, 15671, 420, 15669, 721, 666, 51004], "temperature": 0.0, "avg_logprob": -0.08497675982388583, "compression_ratio": 1.763779527559055, "no_speech_prob": 0.28498730063438416}, {"id": 224, "seek": 77896, "start": 791.76, "end": 797.2800000000001, "text": " awkward spaces in old houses, making shelves in things that aren't quite square.", "tokens": [51004, 11411, 7673, 294, 1331, 8078, 11, 1455, 24349, 294, 721, 300, 3212, 380, 1596, 3732, 13, 51280], "temperature": 0.0, "avg_logprob": -0.08497675982388583, "compression_ratio": 1.763779527559055, "no_speech_prob": 0.28498730063438416}, {"id": 225, "seek": 77896, "start": 797.2800000000001, "end": 802.44, "text": " So the jobs that are going to survive AI for a long time are jobs where you have to be", "tokens": [51280, 407, 264, 4782, 300, 366, 516, 281, 7867, 7318, 337, 257, 938, 565, 366, 4782, 689, 291, 362, 281, 312, 51538], "temperature": 0.0, "avg_logprob": -0.08497675982388583, "compression_ratio": 1.763779527559055, "no_speech_prob": 0.28498730063438416}, {"id": 226, "seek": 77896, "start": 802.44, "end": 807.46, "text": " very adaptable and physically skilled and plumbing is that kind of a job.", "tokens": [51538, 588, 6231, 712, 293, 9762, 19690, 293, 39993, 307, 300, 733, 295, 257, 1691, 13, 51789], "temperature": 0.0, "avg_logprob": -0.08497675982388583, "compression_ratio": 1.763779527559055, "no_speech_prob": 0.28498730063438416}, {"id": 227, "seek": 80746, "start": 807.46, "end": 811.6600000000001, "text": " How does manual dexterity is hard for a machine to replicate?", "tokens": [50364, 1012, 775, 9688, 368, 36671, 507, 307, 1152, 337, 257, 3479, 281, 25356, 30, 50574], "temperature": 0.0, "avg_logprob": -0.1468258195250999, "compression_ratio": 1.6463022508038585, "no_speech_prob": 0.06261167675256729}, {"id": 228, "seek": 80746, "start": 811.6600000000001, "end": 817.02, "text": " It's still hard, and I think it's going to be longer before they can be really dexterous", "tokens": [50574, 467, 311, 920, 1152, 11, 293, 286, 519, 309, 311, 516, 281, 312, 2854, 949, 436, 393, 312, 534, 368, 36671, 563, 50842], "temperature": 0.0, "avg_logprob": -0.1468258195250999, "compression_ratio": 1.6463022508038585, "no_speech_prob": 0.06261167675256729}, {"id": 229, "seek": 80746, "start": 817.02, "end": 820.14, "text": " and get into awkward spaces.", "tokens": [50842, 293, 483, 666, 11411, 7673, 13, 50998], "temperature": 0.0, "avg_logprob": -0.1468258195250999, "compression_ratio": 1.6463022508038585, "no_speech_prob": 0.06261167675256729}, {"id": 230, "seek": 80746, "start": 820.14, "end": 824.02, "text": " That's going to take longer than being good at answering text questions.", "tokens": [50998, 663, 311, 516, 281, 747, 2854, 813, 885, 665, 412, 13430, 2487, 1651, 13, 51192], "temperature": 0.0, "avg_logprob": -0.1468258195250999, "compression_ratio": 1.6463022508038585, "no_speech_prob": 0.06261167675256729}, {"id": 231, "seek": 80746, "start": 824.02, "end": 825.02, "text": " Should I believe you?", "tokens": [51192, 6454, 286, 1697, 291, 30, 51242], "temperature": 0.0, "avg_logprob": -0.1468258195250999, "compression_ratio": 1.6463022508038585, "no_speech_prob": 0.06261167675256729}, {"id": 232, "seek": 80746, "start": 825.02, "end": 827.6600000000001, "text": " Because when we were on stage four years ago, you said reasoning.", "tokens": [51242, 1436, 562, 321, 645, 322, 3233, 1451, 924, 2057, 11, 291, 848, 21577, 13, 51374], "temperature": 0.0, "avg_logprob": -0.1468258195250999, "compression_ratio": 1.6463022508038585, "no_speech_prob": 0.06261167675256729}, {"id": 233, "seek": 80746, "start": 827.6600000000001, "end": 831.58, "text": " As long as somebody has a job that focuses on reasoning, they'll be able to last a dozen.", "tokens": [51374, 1018, 938, 382, 2618, 575, 257, 1691, 300, 16109, 322, 21577, 11, 436, 603, 312, 1075, 281, 1036, 257, 16654, 13, 51570], "temperature": 0.0, "avg_logprob": -0.1468258195250999, "compression_ratio": 1.6463022508038585, "no_speech_prob": 0.06261167675256729}, {"id": 234, "seek": 80746, "start": 831.58, "end": 837.38, "text": " Isn't the nature of AI such that we don't actually know where the next incredible", "tokens": [51570, 6998, 380, 264, 3687, 295, 7318, 1270, 300, 321, 500, 380, 767, 458, 689, 264, 958, 4651, 51860], "temperature": 0.0, "avg_logprob": -0.1468258195250999, "compression_ratio": 1.6463022508038585, "no_speech_prob": 0.06261167675256729}, {"id": 235, "seek": 83738, "start": 837.38, "end": 838.98, "text": " improvement in performance will come?", "tokens": [50364, 10444, 294, 3389, 486, 808, 30, 50444], "temperature": 0.0, "avg_logprob": -0.18569659480342157, "compression_ratio": 1.8028673835125448, "no_speech_prob": 0.017630212008953094}, {"id": 236, "seek": 83738, "start": 838.98, "end": 840.5, "text": " Maybe it will come in manual dexterity.", "tokens": [50444, 2704, 309, 486, 808, 294, 9688, 368, 36671, 507, 13, 50520], "temperature": 0.0, "avg_logprob": -0.18569659480342157, "compression_ratio": 1.8028673835125448, "no_speech_prob": 0.017630212008953094}, {"id": 237, "seek": 83738, "start": 840.5, "end": 842.5, "text": " Yeah, it's possible.", "tokens": [50520, 865, 11, 309, 311, 1944, 13, 50620], "temperature": 0.0, "avg_logprob": -0.18569659480342157, "compression_ratio": 1.8028673835125448, "no_speech_prob": 0.017630212008953094}, {"id": 238, "seek": 83738, "start": 842.5, "end": 845.34, "text": " So actually, let me ask you a question about that.", "tokens": [50620, 407, 767, 11, 718, 385, 1029, 291, 257, 1168, 466, 300, 13, 50762], "temperature": 0.0, "avg_logprob": -0.18569659480342157, "compression_ratio": 1.8028673835125448, "no_speech_prob": 0.017630212008953094}, {"id": 239, "seek": 83738, "start": 845.34, "end": 850.54, "text": " So do you think when we look at AI and we look at the next five years of AI, the most", "tokens": [50762, 407, 360, 291, 519, 562, 321, 574, 412, 7318, 293, 321, 574, 412, 264, 958, 1732, 924, 295, 7318, 11, 264, 881, 51022], "temperature": 0.0, "avg_logprob": -0.18569659480342157, "compression_ratio": 1.8028673835125448, "no_speech_prob": 0.017630212008953094}, {"id": 240, "seek": 83738, "start": 850.54, "end": 854.9399999999999, "text": " impactful improvements we'll see will be in large language models and related to large", "tokens": [51022, 30842, 13797, 321, 603, 536, 486, 312, 294, 2416, 2856, 5245, 293, 4077, 281, 2416, 51242], "temperature": 0.0, "avg_logprob": -0.18569659480342157, "compression_ratio": 1.8028673835125448, "no_speech_prob": 0.017630212008953094}, {"id": 241, "seek": 83738, "start": 854.9399999999999, "end": 856.14, "text": " language models?", "tokens": [51242, 2856, 5245, 30, 51302], "temperature": 0.0, "avg_logprob": -0.18569659480342157, "compression_ratio": 1.8028673835125448, "no_speech_prob": 0.017630212008953094}, {"id": 242, "seek": 83738, "start": 856.14, "end": 858.62, "text": " Or do you think it will be in something else?", "tokens": [51302, 1610, 360, 291, 519, 309, 486, 312, 294, 746, 1646, 30, 51426], "temperature": 0.0, "avg_logprob": -0.18569659480342157, "compression_ratio": 1.8028673835125448, "no_speech_prob": 0.017630212008953094}, {"id": 243, "seek": 83738, "start": 858.62, "end": 862.02, "text": " I think it'll probably be in multimodal large models.", "tokens": [51426, 286, 519, 309, 603, 1391, 312, 294, 32972, 378, 304, 2416, 5245, 13, 51596], "temperature": 0.0, "avg_logprob": -0.18569659480342157, "compression_ratio": 1.8028673835125448, "no_speech_prob": 0.017630212008953094}, {"id": 244, "seek": 83738, "start": 862.02, "end": 866.74, "text": " So they won't just be language models, they'll be doing vision.", "tokens": [51596, 407, 436, 1582, 380, 445, 312, 2856, 5245, 11, 436, 603, 312, 884, 5201, 13, 51832], "temperature": 0.0, "avg_logprob": -0.18569659480342157, "compression_ratio": 1.8028673835125448, "no_speech_prob": 0.017630212008953094}, {"id": 245, "seek": 86674, "start": 866.78, "end": 868.54, "text": " Actually, they'll be analyzing video.", "tokens": [50366, 5135, 11, 436, 603, 312, 23663, 960, 13, 50454], "temperature": 0.0, "avg_logprob": -0.20042142868041993, "compression_ratio": 1.765079365079365, "no_speech_prob": 0.07557346671819687}, {"id": 246, "seek": 86674, "start": 868.54, "end": 872.62, "text": " So they were able to train on all of the YouTube videos, for example.", "tokens": [50454, 407, 436, 645, 1075, 281, 3847, 322, 439, 295, 264, 3088, 2145, 11, 337, 1365, 13, 50658], "temperature": 0.0, "avg_logprob": -0.20042142868041993, "compression_ratio": 1.765079365079365, "no_speech_prob": 0.07557346671819687}, {"id": 247, "seek": 86674, "start": 872.62, "end": 878.1800000000001, "text": " And you can understand a lot from things other than language.", "tokens": [50658, 400, 291, 393, 1223, 257, 688, 490, 721, 661, 813, 2856, 13, 50936], "temperature": 0.0, "avg_logprob": -0.20042142868041993, "compression_ratio": 1.765079365079365, "no_speech_prob": 0.07557346671819687}, {"id": 248, "seek": 86674, "start": 878.1800000000001, "end": 882.26, "text": " And when you do that, you need less language to reach the same performance.", "tokens": [50936, 400, 562, 291, 360, 300, 11, 291, 643, 1570, 2856, 281, 2524, 264, 912, 3389, 13, 51140], "temperature": 0.0, "avg_logprob": -0.20042142868041993, "compression_ratio": 1.765079365079365, "no_speech_prob": 0.07557346671819687}, {"id": 249, "seek": 86674, "start": 882.26, "end": 885.54, "text": " So the idea that they're going to be saturated because they've already used all the language", "tokens": [51140, 407, 264, 1558, 300, 436, 434, 516, 281, 312, 25408, 570, 436, 600, 1217, 1143, 439, 264, 2856, 51304], "temperature": 0.0, "avg_logprob": -0.20042142868041993, "compression_ratio": 1.765079365079365, "no_speech_prob": 0.07557346671819687}, {"id": 250, "seek": 86674, "start": 885.54, "end": 889.1, "text": " there is, all the language is easy to get hold of.", "tokens": [51304, 456, 307, 11, 439, 264, 2856, 307, 1858, 281, 483, 1797, 295, 13, 51482], "temperature": 0.0, "avg_logprob": -0.20042142868041993, "compression_ratio": 1.765079365079365, "no_speech_prob": 0.07557346671819687}, {"id": 251, "seek": 86674, "start": 889.1, "end": 892.02, "text": " That's less of a concern if they're also using lots of other modalities.", "tokens": [51482, 663, 311, 1570, 295, 257, 3136, 498, 436, 434, 611, 1228, 3195, 295, 661, 1072, 16110, 13, 51628], "temperature": 0.0, "avg_logprob": -0.20042142868041993, "compression_ratio": 1.765079365079365, "no_speech_prob": 0.07557346671819687}, {"id": 252, "seek": 86674, "start": 892.02, "end": 896.5, "text": " I mean, this gets at one of the, another argument that Jan, your fellow Godfather of AI makes", "tokens": [51628, 286, 914, 11, 341, 2170, 412, 472, 295, 264, 11, 1071, 6770, 300, 4956, 11, 428, 7177, 1265, 11541, 295, 7318, 1669, 51852], "temperature": 0.0, "avg_logprob": -0.20042142868041993, "compression_ratio": 1.765079365079365, "no_speech_prob": 0.07557346671819687}, {"id": 253, "seek": 89650, "start": 896.54, "end": 898.62, "text": " is that language is so limited, right?", "tokens": [50366, 307, 300, 2856, 307, 370, 5567, 11, 558, 30, 50470], "temperature": 0.0, "avg_logprob": -0.13010519572666712, "compression_ratio": 1.7781456953642385, "no_speech_prob": 0.009778603911399841}, {"id": 254, "seek": 89650, "start": 898.62, "end": 900.94, "text": " There's so much information that we're conveying just beyond the word.", "tokens": [50470, 821, 311, 370, 709, 1589, 300, 321, 434, 18053, 1840, 445, 4399, 264, 1349, 13, 50586], "temperature": 0.0, "avg_logprob": -0.13010519572666712, "compression_ratio": 1.7781456953642385, "no_speech_prob": 0.009778603911399841}, {"id": 255, "seek": 89650, "start": 900.94, "end": 902.9, "text": " In fact, I'm gesturing like mad, right?", "tokens": [50586, 682, 1186, 11, 286, 478, 7219, 1345, 411, 5244, 11, 558, 30, 50684], "temperature": 0.0, "avg_logprob": -0.13010519572666712, "compression_ratio": 1.7781456953642385, "no_speech_prob": 0.009778603911399841}, {"id": 256, "seek": 89650, "start": 902.9, "end": 906.38, "text": " Which conveys some of the information as well as the lighting and all this.", "tokens": [50684, 3013, 18053, 749, 512, 295, 264, 1589, 382, 731, 382, 264, 9577, 293, 439, 341, 13, 50858], "temperature": 0.0, "avg_logprob": -0.13010519572666712, "compression_ratio": 1.7781456953642385, "no_speech_prob": 0.009778603911399841}, {"id": 257, "seek": 89650, "start": 906.38, "end": 908.9, "text": " So your view is that may be true.", "tokens": [50858, 407, 428, 1910, 307, 300, 815, 312, 2074, 13, 50984], "temperature": 0.0, "avg_logprob": -0.13010519572666712, "compression_ratio": 1.7781456953642385, "no_speech_prob": 0.009778603911399841}, {"id": 258, "seek": 89650, "start": 908.9, "end": 913.78, "text": " Language is a limited vector for information, but soon it will be combined with other vectors.", "tokens": [50984, 24445, 307, 257, 5567, 8062, 337, 1589, 11, 457, 2321, 309, 486, 312, 9354, 365, 661, 18875, 13, 51228], "temperature": 0.0, "avg_logprob": -0.13010519572666712, "compression_ratio": 1.7781456953642385, "no_speech_prob": 0.009778603911399841}, {"id": 259, "seek": 89650, "start": 913.78, "end": 915.3, "text": " Absolutely.", "tokens": [51228, 7021, 13, 51304], "temperature": 0.0, "avg_logprob": -0.13010519572666712, "compression_ratio": 1.7781456953642385, "no_speech_prob": 0.009778603911399841}, {"id": 260, "seek": 89650, "start": 915.3, "end": 919.9, "text": " It's amazing what you can learn from language alone, but you're much better off learning", "tokens": [51304, 467, 311, 2243, 437, 291, 393, 1466, 490, 2856, 3312, 11, 457, 291, 434, 709, 1101, 766, 2539, 51534], "temperature": 0.0, "avg_logprob": -0.13010519572666712, "compression_ratio": 1.7781456953642385, "no_speech_prob": 0.009778603911399841}, {"id": 261, "seek": 89650, "start": 919.9, "end": 921.02, "text": " from many modalities.", "tokens": [51534, 490, 867, 1072, 16110, 13, 51590], "temperature": 0.0, "avg_logprob": -0.13010519572666712, "compression_ratio": 1.7781456953642385, "no_speech_prob": 0.009778603911399841}, {"id": 262, "seek": 89650, "start": 921.02, "end": 923.78, "text": " Small children don't just learn from language alone.", "tokens": [51590, 15287, 2227, 500, 380, 445, 1466, 490, 2856, 3312, 13, 51728], "temperature": 0.0, "avg_logprob": -0.13010519572666712, "compression_ratio": 1.7781456953642385, "no_speech_prob": 0.009778603911399841}, {"id": 263, "seek": 89650, "start": 923.78, "end": 924.34, "text": " Right.", "tokens": [51728, 1779, 13, 51756], "temperature": 0.0, "avg_logprob": -0.13010519572666712, "compression_ratio": 1.7781456953642385, "no_speech_prob": 0.009778603911399841}, {"id": 264, "seek": 92434, "start": 924.38, "end": 931.1800000000001, "text": " So if you were, if your principal role right now was still researching AI, finding the", "tokens": [50366, 407, 498, 291, 645, 11, 498, 428, 9716, 3090, 558, 586, 390, 920, 24176, 7318, 11, 5006, 264, 50706], "temperature": 0.0, "avg_logprob": -0.2476935033445005, "compression_ratio": 1.606694560669456, "no_speech_prob": 0.02240540273487568}, {"id": 265, "seek": 92434, "start": 931.1800000000001, "end": 938.58, "text": " next big thing, you would be doing multi-modal AI and trying to attach, say, visual AI systems", "tokens": [50706, 958, 955, 551, 11, 291, 576, 312, 884, 4825, 12, 8014, 304, 7318, 293, 1382, 281, 5085, 11, 584, 11, 5056, 7318, 3652, 51076], "temperature": 0.0, "avg_logprob": -0.2476935033445005, "compression_ratio": 1.606694560669456, "no_speech_prob": 0.02240540273487568}, {"id": 266, "seek": 92434, "start": 938.58, "end": 940.62, "text": " to text-based AI systems?", "tokens": [51076, 281, 2487, 12, 6032, 7318, 3652, 30, 51178], "temperature": 0.0, "avg_logprob": -0.2476935033445005, "compression_ratio": 1.606694560669456, "no_speech_prob": 0.02240540273487568}, {"id": 267, "seek": 92434, "start": 940.62, "end": 943.38, "text": " Yes, which is what they're doing now at Google.", "tokens": [51178, 1079, 11, 597, 307, 437, 436, 434, 884, 586, 412, 3329, 13, 51316], "temperature": 0.0, "avg_logprob": -0.2476935033445005, "compression_ratio": 1.606694560669456, "no_speech_prob": 0.02240540273487568}, {"id": 268, "seek": 92434, "start": 943.38, "end": 949.1, "text": " Google is making a system called Gemini, but fortunately, Demisabis talked about it a few", "tokens": [51316, 3329, 307, 1455, 257, 1185, 1219, 22894, 3812, 11, 457, 25511, 11, 4686, 271, 455, 271, 2825, 466, 309, 257, 1326, 51602], "temperature": 0.0, "avg_logprob": -0.2476935033445005, "compression_ratio": 1.606694560669456, "no_speech_prob": 0.02240540273487568}, {"id": 269, "seek": 92434, "start": 949.1, "end": 953.22, "text": " days ago, and that's a multi-modal AI.", "tokens": [51602, 1708, 2057, 11, 293, 300, 311, 257, 4825, 12, 8014, 304, 7318, 13, 51808], "temperature": 0.0, "avg_logprob": -0.2476935033445005, "compression_ratio": 1.606694560669456, "no_speech_prob": 0.02240540273487568}, {"id": 270, "seek": 95322, "start": 953.26, "end": 955.34, "text": " Well, let me talk about actually something else at Google.", "tokens": [50366, 1042, 11, 718, 385, 751, 466, 767, 746, 1646, 412, 3329, 13, 50470], "temperature": 0.0, "avg_logprob": -0.14105456846731682, "compression_ratio": 1.6390977443609023, "no_speech_prob": 0.003479950362816453}, {"id": 271, "seek": 95322, "start": 955.34, "end": 961.5, "text": " So while you were there, Google invented the transformer network or invented the transformer", "tokens": [50470, 407, 1339, 291, 645, 456, 11, 3329, 14479, 264, 31782, 3209, 420, 14479, 264, 31782, 50778], "temperature": 0.0, "avg_logprob": -0.14105456846731682, "compression_ratio": 1.6390977443609023, "no_speech_prob": 0.003479950362816453}, {"id": 272, "seek": 95322, "start": 961.5, "end": 965.58, "text": " architecture, generative pre-trained transformers.", "tokens": [50778, 9482, 11, 1337, 1166, 659, 12, 17227, 2001, 4088, 433, 13, 50982], "temperature": 0.0, "avg_logprob": -0.14105456846731682, "compression_ratio": 1.6390977443609023, "no_speech_prob": 0.003479950362816453}, {"id": 273, "seek": 95322, "start": 965.58, "end": 972.4200000000001, "text": " When did you realize that that would be so central and so important?", "tokens": [50982, 1133, 630, 291, 4325, 300, 300, 576, 312, 370, 5777, 293, 370, 1021, 30, 51324], "temperature": 0.0, "avg_logprob": -0.14105456846731682, "compression_ratio": 1.6390977443609023, "no_speech_prob": 0.003479950362816453}, {"id": 274, "seek": 95322, "start": 972.4200000000001, "end": 977.78, "text": " It's interesting to me because it's this paper that comes out in 2017, and when it comes", "tokens": [51324, 467, 311, 1880, 281, 385, 570, 309, 311, 341, 3035, 300, 1487, 484, 294, 6591, 11, 293, 562, 309, 1487, 51592], "temperature": 0.0, "avg_logprob": -0.14105456846731682, "compression_ratio": 1.6390977443609023, "no_speech_prob": 0.003479950362816453}, {"id": 275, "seek": 95322, "start": 977.78, "end": 981.86, "text": " out, it's not as though firecrackers are left, you know, shot into the sky.", "tokens": [51592, 484, 11, 309, 311, 406, 382, 1673, 2610, 10757, 501, 433, 366, 1411, 11, 291, 458, 11, 3347, 666, 264, 5443, 13, 51796], "temperature": 0.0, "avg_logprob": -0.14105456846731682, "compression_ratio": 1.6390977443609023, "no_speech_prob": 0.003479950362816453}, {"id": 276, "seek": 98186, "start": 981.86, "end": 985.86, "text": " It's six years later, five years later, that we suddenly realized the consequences.", "tokens": [50364, 467, 311, 2309, 924, 1780, 11, 1732, 924, 1780, 11, 300, 321, 5800, 5334, 264, 10098, 13, 50564], "temperature": 0.0, "avg_logprob": -0.14455863069896854, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.008518991991877556}, {"id": 277, "seek": 98186, "start": 985.86, "end": 989.94, "text": " And it's interesting to think, what are the other papers out there that could be the same", "tokens": [50564, 400, 309, 311, 1880, 281, 519, 11, 437, 366, 264, 661, 10577, 484, 456, 300, 727, 312, 264, 912, 50768], "temperature": 0.0, "avg_logprob": -0.14455863069896854, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.008518991991877556}, {"id": 278, "seek": 98186, "start": 989.94, "end": 990.78, "text": " in five years?", "tokens": [50768, 294, 1732, 924, 30, 50810], "temperature": 0.0, "avg_logprob": -0.14455863069896854, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.008518991991877556}, {"id": 279, "seek": 98186, "start": 990.78, "end": 995.22, "text": " So with transformers, it was really only a couple of years later when Google developed", "tokens": [50810, 407, 365, 4088, 433, 11, 309, 390, 534, 787, 257, 1916, 295, 924, 1780, 562, 3329, 4743, 51032], "temperature": 0.0, "avg_logprob": -0.14455863069896854, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.008518991991877556}, {"id": 280, "seek": 98186, "start": 995.22, "end": 996.54, "text": " BERT.", "tokens": [51032, 363, 31479, 13, 51098], "temperature": 0.0, "avg_logprob": -0.14455863069896854, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.008518991991877556}, {"id": 281, "seek": 98186, "start": 996.54, "end": 1001.74, "text": " So BERT made it very clear transformers were a huge breakthrough.", "tokens": [51098, 407, 363, 31479, 1027, 309, 588, 1850, 4088, 433, 645, 257, 2603, 22397, 13, 51358], "temperature": 0.0, "avg_logprob": -0.14455863069896854, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.008518991991877556}, {"id": 282, "seek": 98186, "start": 1001.74, "end": 1008.86, "text": " I didn't immediately realize what a huge breakthrough they were, and I'm annoyed about that.", "tokens": [51358, 286, 994, 380, 4258, 4325, 437, 257, 2603, 22397, 436, 645, 11, 293, 286, 478, 25921, 466, 300, 13, 51714], "temperature": 0.0, "avg_logprob": -0.14455863069896854, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.008518991991877556}, {"id": 283, "seek": 98186, "start": 1008.86, "end": 1010.7, "text": " It took me a couple of years to realize.", "tokens": [51714, 467, 1890, 385, 257, 1916, 295, 924, 281, 4325, 13, 51806], "temperature": 0.0, "avg_logprob": -0.14455863069896854, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.008518991991877556}, {"id": 284, "seek": 101070, "start": 1010.7, "end": 1015.1, "text": " Well, you know, the first time I ever heard the word transformer was talking to you on", "tokens": [50364, 1042, 11, 291, 458, 11, 264, 700, 565, 286, 1562, 2198, 264, 1349, 31782, 390, 1417, 281, 291, 322, 50584], "temperature": 0.0, "avg_logprob": -0.15907320162145103, "compression_ratio": 1.7067137809187278, "no_speech_prob": 0.005812619347125292}, {"id": 285, "seek": 101070, "start": 1015.1, "end": 1020.5, "text": " stage, and you were talking about transformers versus capsules, and this was right after", "tokens": [50584, 3233, 11, 293, 291, 645, 1417, 466, 4088, 433, 5717, 13855, 3473, 11, 293, 341, 390, 558, 934, 50854], "temperature": 0.0, "avg_logprob": -0.15907320162145103, "compression_ratio": 1.7067137809187278, "no_speech_prob": 0.005812619347125292}, {"id": 286, "seek": 101070, "start": 1020.5, "end": 1021.5, "text": " it came out.", "tokens": [50854, 309, 1361, 484, 13, 50904], "temperature": 0.0, "avg_logprob": -0.15907320162145103, "compression_ratio": 1.7067137809187278, "no_speech_prob": 0.005812619347125292}, {"id": 287, "seek": 101070, "start": 1021.5, "end": 1025.46, "text": " Let's talk about one of the other critiques about language models and other models, which", "tokens": [50904, 961, 311, 751, 466, 472, 295, 264, 661, 3113, 4911, 466, 2856, 5245, 293, 661, 5245, 11, 597, 51102], "temperature": 0.0, "avg_logprob": -0.15907320162145103, "compression_ratio": 1.7067137809187278, "no_speech_prob": 0.005812619347125292}, {"id": 288, "seek": 101070, "start": 1025.46, "end": 1032.26, "text": " is soon, I mean, in fact, probably already they've absorbed all the organic data that", "tokens": [51102, 307, 2321, 11, 286, 914, 11, 294, 1186, 11, 1391, 1217, 436, 600, 20799, 439, 264, 10220, 1412, 300, 51442], "temperature": 0.0, "avg_logprob": -0.15907320162145103, "compression_ratio": 1.7067137809187278, "no_speech_prob": 0.005812619347125292}, {"id": 289, "seek": 101070, "start": 1032.26, "end": 1033.78, "text": " has been created by humans.", "tokens": [51442, 575, 668, 2942, 538, 6255, 13, 51518], "temperature": 0.0, "avg_logprob": -0.15907320162145103, "compression_ratio": 1.7067137809187278, "no_speech_prob": 0.005812619347125292}, {"id": 290, "seek": 101070, "start": 1033.78, "end": 1037.66, "text": " If I create an AI model right now, and I train it on the internet, it's trained on a bunch", "tokens": [51518, 759, 286, 1884, 364, 7318, 2316, 558, 586, 11, 293, 286, 3847, 309, 322, 264, 4705, 11, 309, 311, 8895, 322, 257, 3840, 51712], "temperature": 0.0, "avg_logprob": -0.15907320162145103, "compression_ratio": 1.7067137809187278, "no_speech_prob": 0.005812619347125292}, {"id": 291, "seek": 103766, "start": 1037.66, "end": 1041.94, "text": " of stuff, mostly stuff made by humans, but a bunch of stuff made by AI, right?", "tokens": [50364, 295, 1507, 11, 5240, 1507, 1027, 538, 6255, 11, 457, 257, 3840, 295, 1507, 1027, 538, 7318, 11, 558, 30, 50578], "temperature": 0.0, "avg_logprob": -0.1648812255859375, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.5099763870239258}, {"id": 292, "seek": 103766, "start": 1041.94, "end": 1042.94, "text": " Yeah.", "tokens": [50578, 865, 13, 50628], "temperature": 0.0, "avg_logprob": -0.1648812255859375, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.5099763870239258}, {"id": 293, "seek": 103766, "start": 1042.94, "end": 1047.74, "text": " And you're going to keep training AIs on stuff that has been created by AIs, whether it's", "tokens": [50628, 400, 291, 434, 516, 281, 1066, 3097, 316, 6802, 322, 1507, 300, 575, 668, 2942, 538, 316, 6802, 11, 1968, 309, 311, 50868], "temperature": 0.0, "avg_logprob": -0.1648812255859375, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.5099763870239258}, {"id": 294, "seek": 103766, "start": 1047.74, "end": 1051.78, "text": " text-based language model or whether it's a multimodal language model.", "tokens": [50868, 2487, 12, 6032, 2856, 2316, 420, 1968, 309, 311, 257, 32972, 378, 304, 2856, 2316, 13, 51070], "temperature": 0.0, "avg_logprob": -0.1648812255859375, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.5099763870239258}, {"id": 295, "seek": 103766, "start": 1051.78, "end": 1057.3000000000002, "text": " Will that lead to the inevitable decay and corruption, as some people argue?", "tokens": [51070, 3099, 300, 1477, 281, 264, 21451, 21039, 293, 17959, 11, 382, 512, 561, 9695, 30, 51346], "temperature": 0.0, "avg_logprob": -0.1648812255859375, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.5099763870239258}, {"id": 296, "seek": 103766, "start": 1057.3000000000002, "end": 1061.14, "text": " Or is that just a thing we have to deal with?", "tokens": [51346, 1610, 307, 300, 445, 257, 551, 321, 362, 281, 2028, 365, 30, 51538], "temperature": 0.0, "avg_logprob": -0.1648812255859375, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.5099763870239258}, {"id": 297, "seek": 103766, "start": 1061.14, "end": 1065.5800000000002, "text": " Or is it, as other people in the AI field, the greatest thing for training AIs, and we", "tokens": [51538, 1610, 307, 309, 11, 382, 661, 561, 294, 264, 7318, 2519, 11, 264, 6636, 551, 337, 3097, 316, 6802, 11, 293, 321, 51760], "temperature": 0.0, "avg_logprob": -0.1648812255859375, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.5099763870239258}, {"id": 298, "seek": 106558, "start": 1065.58, "end": 1068.1799999999998, "text": " should just use synthetic data in AI?", "tokens": [50364, 820, 445, 764, 23420, 1412, 294, 7318, 30, 50494], "temperature": 0.0, "avg_logprob": -0.15416382454537056, "compression_ratio": 1.7207547169811321, "no_speech_prob": 0.00589835224673152}, {"id": 299, "seek": 106558, "start": 1068.1799999999998, "end": 1069.1799999999998, "text": " Okay.", "tokens": [50494, 1033, 13, 50544], "temperature": 0.0, "avg_logprob": -0.15416382454537056, "compression_ratio": 1.7207547169811321, "no_speech_prob": 0.00589835224673152}, {"id": 300, "seek": 106558, "start": 1069.1799999999998, "end": 1071.8999999999999, "text": " I don't actually know the answer to this technically.", "tokens": [50544, 286, 500, 380, 767, 458, 264, 1867, 281, 341, 12120, 13, 50680], "temperature": 0.0, "avg_logprob": -0.15416382454537056, "compression_ratio": 1.7207547169811321, "no_speech_prob": 0.00589835224673152}, {"id": 301, "seek": 106558, "start": 1071.8999999999999, "end": 1076.06, "text": " I suspect you have to take precautions, so you're not just training on data that you yourself", "tokens": [50680, 286, 9091, 291, 362, 281, 747, 34684, 11, 370, 291, 434, 406, 445, 3097, 322, 1412, 300, 291, 1803, 50888], "temperature": 0.0, "avg_logprob": -0.15416382454537056, "compression_ratio": 1.7207547169811321, "no_speech_prob": 0.00589835224673152}, {"id": 302, "seek": 106558, "start": 1076.06, "end": 1080.54, "text": " generated or the some previous version of you generated.", "tokens": [50888, 10833, 420, 264, 512, 3894, 3037, 295, 291, 10833, 13, 51112], "temperature": 0.0, "avg_logprob": -0.15416382454537056, "compression_ratio": 1.7207547169811321, "no_speech_prob": 0.00589835224673152}, {"id": 303, "seek": 106558, "start": 1080.54, "end": 1084.74, "text": " I suspect it's going to be possible to take those precautions, although it would be much", "tokens": [51112, 286, 9091, 309, 311, 516, 281, 312, 1944, 281, 747, 729, 34684, 11, 4878, 309, 576, 312, 709, 51322], "temperature": 0.0, "avg_logprob": -0.15416382454537056, "compression_ratio": 1.7207547169811321, "no_speech_prob": 0.00589835224673152}, {"id": 304, "seek": 106558, "start": 1084.74, "end": 1088.3, "text": " easier if all fake data was marked fake.", "tokens": [51322, 3571, 498, 439, 7592, 1412, 390, 12658, 7592, 13, 51500], "temperature": 0.0, "avg_logprob": -0.15416382454537056, "compression_ratio": 1.7207547169811321, "no_speech_prob": 0.00589835224673152}, {"id": 305, "seek": 106558, "start": 1088.3, "end": 1093.9399999999998, "text": " There is one example in AI where training on stuff from yourself helps a lot.", "tokens": [51500, 821, 307, 472, 1365, 294, 7318, 689, 3097, 322, 1507, 490, 1803, 3665, 257, 688, 13, 51782], "temperature": 0.0, "avg_logprob": -0.15416382454537056, "compression_ratio": 1.7207547169811321, "no_speech_prob": 0.00589835224673152}, {"id": 306, "seek": 109394, "start": 1093.94, "end": 1099.18, "text": " So if you don't have much training data or rather you have a lot of unlabeled data and", "tokens": [50364, 407, 498, 291, 500, 380, 362, 709, 3097, 1412, 420, 2831, 291, 362, 257, 688, 295, 32118, 18657, 292, 1412, 293, 50626], "temperature": 0.0, "avg_logprob": -0.14913529040766696, "compression_ratio": 1.8504672897196262, "no_speech_prob": 0.005766513291746378}, {"id": 307, "seek": 109394, "start": 1099.18, "end": 1103.66, "text": " a small amount of labeled data, you can train a model to predict the labels on the labeled", "tokens": [50626, 257, 1359, 2372, 295, 21335, 1412, 11, 291, 393, 3847, 257, 2316, 281, 6069, 264, 16949, 322, 264, 21335, 50850], "temperature": 0.0, "avg_logprob": -0.14913529040766696, "compression_ratio": 1.8504672897196262, "no_speech_prob": 0.005766513291746378}, {"id": 308, "seek": 109394, "start": 1103.66, "end": 1113.02, "text": " data and then you take that same model and train it to predict labels for unlabeled data", "tokens": [50850, 1412, 293, 550, 291, 747, 300, 912, 2316, 293, 3847, 309, 281, 6069, 16949, 337, 32118, 18657, 292, 1412, 51318], "temperature": 0.0, "avg_logprob": -0.14913529040766696, "compression_ratio": 1.8504672897196262, "no_speech_prob": 0.005766513291746378}, {"id": 309, "seek": 109394, "start": 1113.02, "end": 1118.18, "text": " and whatever it predicts, you tell it you were right.", "tokens": [51318, 293, 2035, 309, 6069, 82, 11, 291, 980, 309, 291, 645, 558, 13, 51576], "temperature": 0.0, "avg_logprob": -0.14913529040766696, "compression_ratio": 1.8504672897196262, "no_speech_prob": 0.005766513291746378}, {"id": 310, "seek": 109394, "start": 1118.18, "end": 1120.5800000000002, "text": " And that actually makes the model work better.", "tokens": [51576, 400, 300, 767, 1669, 264, 2316, 589, 1101, 13, 51696], "temperature": 0.0, "avg_logprob": -0.14913529040766696, "compression_ratio": 1.8504672897196262, "no_speech_prob": 0.005766513291746378}, {"id": 311, "seek": 109394, "start": 1120.5800000000002, "end": 1122.8200000000002, "text": " How on earth does that work?", "tokens": [51696, 1012, 322, 4120, 775, 300, 589, 30, 51808], "temperature": 0.0, "avg_logprob": -0.14913529040766696, "compression_ratio": 1.8504672897196262, "no_speech_prob": 0.005766513291746378}, {"id": 312, "seek": 112282, "start": 1123.06, "end": 1127.86, "text": " Because on the whole it tends to be right.", "tokens": [50376, 1436, 322, 264, 1379, 309, 12258, 281, 312, 558, 13, 50616], "temperature": 0.0, "avg_logprob": -0.22806671290721708, "compression_ratio": 1.534412955465587, "no_speech_prob": 0.01765017956495285}, {"id": 313, "seek": 112282, "start": 1127.86, "end": 1128.86, "text": " It's complicated.", "tokens": [50616, 467, 311, 6179, 13, 50666], "temperature": 0.0, "avg_logprob": -0.22806671290721708, "compression_ratio": 1.534412955465587, "no_speech_prob": 0.01765017956495285}, {"id": 314, "seek": 112282, "start": 1128.86, "end": 1133.62, "text": " It's been analyzed much better in many years ago from acoustic modems.", "tokens": [50666, 467, 311, 668, 28181, 709, 1101, 294, 867, 924, 2057, 490, 26753, 1072, 9097, 13, 50904], "temperature": 0.0, "avg_logprob": -0.22806671290721708, "compression_ratio": 1.534412955465587, "no_speech_prob": 0.01765017956495285}, {"id": 315, "seek": 112282, "start": 1133.62, "end": 1135.78, "text": " They did the same trick.", "tokens": [50904, 814, 630, 264, 912, 4282, 13, 51012], "temperature": 0.0, "avg_logprob": -0.22806671290721708, "compression_ratio": 1.534412955465587, "no_speech_prob": 0.01765017956495285}, {"id": 316, "seek": 112282, "start": 1135.78, "end": 1141.74, "text": " So listening to this, I've had this realization on stage, you're a man who's very critical", "tokens": [51012, 407, 4764, 281, 341, 11, 286, 600, 632, 341, 25138, 322, 3233, 11, 291, 434, 257, 587, 567, 311, 588, 4924, 51310], "temperature": 0.0, "avg_logprob": -0.22806671290721708, "compression_ratio": 1.534412955465587, "no_speech_prob": 0.01765017956495285}, {"id": 317, "seek": 112282, "start": 1141.74, "end": 1145.78, "text": " of where we're going, killer robots, income inequality.", "tokens": [51310, 295, 689, 321, 434, 516, 11, 13364, 14733, 11, 5742, 16970, 13, 51512], "temperature": 0.0, "avg_logprob": -0.22806671290721708, "compression_ratio": 1.534412955465587, "no_speech_prob": 0.01765017956495285}, {"id": 318, "seek": 112282, "start": 1145.78, "end": 1147.9399999999998, "text": " You also sound like somebody who loves this stuff.", "tokens": [51512, 509, 611, 1626, 411, 2618, 567, 6752, 341, 1507, 13, 51620], "temperature": 0.0, "avg_logprob": -0.22806671290721708, "compression_ratio": 1.534412955465587, "no_speech_prob": 0.01765017956495285}, {"id": 319, "seek": 112282, "start": 1147.9399999999998, "end": 1150.02, "text": " Yeah, I love this stuff.", "tokens": [51620, 865, 11, 286, 959, 341, 1507, 13, 51724], "temperature": 0.0, "avg_logprob": -0.22806671290721708, "compression_ratio": 1.534412955465587, "no_speech_prob": 0.01765017956495285}, {"id": 320, "seek": 115002, "start": 1150.02, "end": 1153.1399999999999, "text": " How could you not love making intelligent things?", "tokens": [50364, 1012, 727, 291, 406, 959, 1455, 13232, 721, 30, 50520], "temperature": 0.0, "avg_logprob": -0.1314917108286982, "compression_ratio": 1.709090909090909, "no_speech_prob": 0.0068888673558831215}, {"id": 321, "seek": 115002, "start": 1153.1399999999999, "end": 1157.66, "text": " So let me get to maybe the most important question for the audience and for everyone", "tokens": [50520, 407, 718, 385, 483, 281, 1310, 264, 881, 1021, 1168, 337, 264, 4034, 293, 337, 1518, 50746], "temperature": 0.0, "avg_logprob": -0.1314917108286982, "compression_ratio": 1.709090909090909, "no_speech_prob": 0.0068888673558831215}, {"id": 322, "seek": 115002, "start": 1157.66, "end": 1159.58, "text": " here.", "tokens": [50746, 510, 13, 50842], "temperature": 0.0, "avg_logprob": -0.1314917108286982, "compression_ratio": 1.709090909090909, "no_speech_prob": 0.0068888673558831215}, {"id": 323, "seek": 115002, "start": 1159.58, "end": 1162.58, "text": " We're now at this moment where a lot of people here love this stuff and they want to build", "tokens": [50842, 492, 434, 586, 412, 341, 1623, 689, 257, 688, 295, 561, 510, 959, 341, 1507, 293, 436, 528, 281, 1322, 50992], "temperature": 0.0, "avg_logprob": -0.1314917108286982, "compression_ratio": 1.709090909090909, "no_speech_prob": 0.0068888673558831215}, {"id": 324, "seek": 115002, "start": 1162.58, "end": 1165.22, "text": " it and they want to experiment.", "tokens": [50992, 309, 293, 436, 528, 281, 5120, 13, 51124], "temperature": 0.0, "avg_logprob": -0.1314917108286982, "compression_ratio": 1.709090909090909, "no_speech_prob": 0.0068888673558831215}, {"id": 325, "seek": 115002, "start": 1165.22, "end": 1167.26, "text": " But we don't want negative consequences.", "tokens": [51124, 583, 321, 500, 380, 528, 3671, 10098, 13, 51226], "temperature": 0.0, "avg_logprob": -0.1314917108286982, "compression_ratio": 1.709090909090909, "no_speech_prob": 0.0068888673558831215}, {"id": 326, "seek": 115002, "start": 1167.26, "end": 1169.02, "text": " We don't want increased income inequality.", "tokens": [51226, 492, 500, 380, 528, 6505, 5742, 16970, 13, 51314], "temperature": 0.0, "avg_logprob": -0.1314917108286982, "compression_ratio": 1.709090909090909, "no_speech_prob": 0.0068888673558831215}, {"id": 327, "seek": 115002, "start": 1169.02, "end": 1171.3799999999999, "text": " I don't want media to disappear.", "tokens": [51314, 286, 500, 380, 528, 3021, 281, 11596, 13, 51432], "temperature": 0.0, "avg_logprob": -0.1314917108286982, "compression_ratio": 1.709090909090909, "no_speech_prob": 0.0068888673558831215}, {"id": 328, "seek": 115002, "start": 1171.3799999999999, "end": 1177.7, "text": " What are the choices and decisions and things we should be working on now to maximize the", "tokens": [51432, 708, 366, 264, 7994, 293, 5327, 293, 721, 321, 820, 312, 1364, 322, 586, 281, 19874, 264, 51748], "temperature": 0.0, "avg_logprob": -0.1314917108286982, "compression_ratio": 1.709090909090909, "no_speech_prob": 0.0068888673558831215}, {"id": 329, "seek": 117770, "start": 1177.7, "end": 1182.3400000000001, "text": " good, to maximize the creativity, but to limit the potential harms?", "tokens": [50364, 665, 11, 281, 19874, 264, 12915, 11, 457, 281, 4948, 264, 3995, 48505, 30, 50596], "temperature": 0.0, "avg_logprob": -0.13642242219713, "compression_ratio": 1.6614173228346456, "no_speech_prob": 0.045594703406095505}, {"id": 330, "seek": 117770, "start": 1182.3400000000001, "end": 1187.3400000000001, "text": " So I think to answer that you have to distinguish many kinds of potential harm.", "tokens": [50596, 407, 286, 519, 281, 1867, 300, 291, 362, 281, 20206, 867, 3685, 295, 3995, 6491, 13, 50846], "temperature": 0.0, "avg_logprob": -0.13642242219713, "compression_ratio": 1.6614173228346456, "no_speech_prob": 0.045594703406095505}, {"id": 331, "seek": 117770, "start": 1187.3400000000001, "end": 1190.74, "text": " So I'll distinguish like six of them for you.", "tokens": [50846, 407, 286, 603, 20206, 411, 2309, 295, 552, 337, 291, 13, 51016], "temperature": 0.0, "avg_logprob": -0.13642242219713, "compression_ratio": 1.6614173228346456, "no_speech_prob": 0.045594703406095505}, {"id": 332, "seek": 117770, "start": 1190.74, "end": 1193.94, "text": " There's bias and discrimination.", "tokens": [51016, 821, 311, 12577, 293, 15973, 13, 51176], "temperature": 0.0, "avg_logprob": -0.13642242219713, "compression_ratio": 1.6614173228346456, "no_speech_prob": 0.045594703406095505}, {"id": 333, "seek": 117770, "start": 1193.94, "end": 1197.8600000000001, "text": " That is present now.", "tokens": [51176, 663, 307, 1974, 586, 13, 51372], "temperature": 0.0, "avg_logprob": -0.13642242219713, "compression_ratio": 1.6614173228346456, "no_speech_prob": 0.045594703406095505}, {"id": 334, "seek": 117770, "start": 1197.8600000000001, "end": 1199.66, "text": " It's not one of these future things we need to worry about.", "tokens": [51372, 467, 311, 406, 472, 295, 613, 2027, 721, 321, 643, 281, 3292, 466, 13, 51462], "temperature": 0.0, "avg_logprob": -0.13642242219713, "compression_ratio": 1.6614173228346456, "no_speech_prob": 0.045594703406095505}, {"id": 335, "seek": 117770, "start": 1199.66, "end": 1201.3400000000001, "text": " It's happening now.", "tokens": [51462, 467, 311, 2737, 586, 13, 51546], "temperature": 0.0, "avg_logprob": -0.13642242219713, "compression_ratio": 1.6614173228346456, "no_speech_prob": 0.045594703406095505}, {"id": 336, "seek": 117770, "start": 1201.3400000000001, "end": 1206.14, "text": " But it is something that I think is relatively easy to fix compared with all the other things.", "tokens": [51546, 583, 309, 307, 746, 300, 286, 519, 307, 7226, 1858, 281, 3191, 5347, 365, 439, 264, 661, 721, 13, 51786], "temperature": 0.0, "avg_logprob": -0.13642242219713, "compression_ratio": 1.6614173228346456, "no_speech_prob": 0.045594703406095505}, {"id": 337, "seek": 120614, "start": 1206.14, "end": 1210.14, "text": " If you make your target, not be to have a completely unbiased system, but just to have", "tokens": [50364, 759, 291, 652, 428, 3779, 11, 406, 312, 281, 362, 257, 2584, 517, 5614, 1937, 1185, 11, 457, 445, 281, 362, 50564], "temperature": 0.0, "avg_logprob": -0.15561959478590223, "compression_ratio": 1.8084415584415585, "no_speech_prob": 0.04673655331134796}, {"id": 338, "seek": 120614, "start": 1210.14, "end": 1214.5800000000002, "text": " a system that's significantly less biased than what it's replacing.", "tokens": [50564, 257, 1185, 300, 311, 10591, 1570, 28035, 813, 437, 309, 311, 19139, 13, 50786], "temperature": 0.0, "avg_logprob": -0.15561959478590223, "compression_ratio": 1.8084415584415585, "no_speech_prob": 0.04673655331134796}, {"id": 339, "seek": 120614, "start": 1214.5800000000002, "end": 1218.5800000000002, "text": " So at present, you have old white men deciding whether the young black women should get mortgages.", "tokens": [50786, 407, 412, 1974, 11, 291, 362, 1331, 2418, 1706, 17990, 1968, 264, 2037, 2211, 2266, 820, 483, 6599, 70, 1660, 13, 50986], "temperature": 0.0, "avg_logprob": -0.15561959478590223, "compression_ratio": 1.8084415584415585, "no_speech_prob": 0.04673655331134796}, {"id": 340, "seek": 120614, "start": 1218.5800000000002, "end": 1223.3400000000001, "text": " And if you just train on that data, you get a system that's equally biased.", "tokens": [50986, 400, 498, 291, 445, 3847, 322, 300, 1412, 11, 291, 483, 257, 1185, 300, 311, 12309, 28035, 13, 51224], "temperature": 0.0, "avg_logprob": -0.15561959478590223, "compression_ratio": 1.8084415584415585, "no_speech_prob": 0.04673655331134796}, {"id": 341, "seek": 120614, "start": 1223.3400000000001, "end": 1225.7, "text": " But you can analyze the bias.", "tokens": [51224, 583, 291, 393, 12477, 264, 12577, 13, 51342], "temperature": 0.0, "avg_logprob": -0.15561959478590223, "compression_ratio": 1.8084415584415585, "no_speech_prob": 0.04673655331134796}, {"id": 342, "seek": 120614, "start": 1225.7, "end": 1227.98, "text": " You can see how it's biased because it won't change its behavior.", "tokens": [51342, 509, 393, 536, 577, 309, 311, 28035, 570, 309, 1582, 380, 1319, 1080, 5223, 13, 51456], "temperature": 0.0, "avg_logprob": -0.15561959478590223, "compression_ratio": 1.8084415584415585, "no_speech_prob": 0.04673655331134796}, {"id": 343, "seek": 120614, "start": 1227.98, "end": 1229.94, "text": " You can freeze it and then analyze it.", "tokens": [51456, 509, 393, 15959, 309, 293, 550, 12477, 309, 13, 51554], "temperature": 0.0, "avg_logprob": -0.15561959478590223, "compression_ratio": 1.8084415584415585, "no_speech_prob": 0.04673655331134796}, {"id": 344, "seek": 120614, "start": 1229.94, "end": 1232.74, "text": " And that should make it easier to correct for bias.", "tokens": [51554, 400, 300, 820, 652, 309, 3571, 281, 3006, 337, 12577, 13, 51694], "temperature": 0.0, "avg_logprob": -0.15561959478590223, "compression_ratio": 1.8084415584415585, "no_speech_prob": 0.04673655331134796}, {"id": 345, "seek": 120614, "start": 1232.74, "end": 1235.0200000000002, "text": " So okay, that's bias and discrimination.", "tokens": [51694, 407, 1392, 11, 300, 311, 12577, 293, 15973, 13, 51808], "temperature": 0.0, "avg_logprob": -0.15561959478590223, "compression_ratio": 1.8084415584415585, "no_speech_prob": 0.04673655331134796}, {"id": 346, "seek": 123502, "start": 1235.06, "end": 1236.54, "text": " I think we can do a lot about that.", "tokens": [50366, 286, 519, 321, 393, 360, 257, 688, 466, 300, 13, 50440], "temperature": 0.0, "avg_logprob": -0.1556492660005214, "compression_ratio": 1.6498194945848375, "no_speech_prob": 0.01063384860754013}, {"id": 347, "seek": 123502, "start": 1236.54, "end": 1240.42, "text": " And I think it's important we do a lot about that, but it's doable.", "tokens": [50440, 400, 286, 519, 309, 311, 1021, 321, 360, 257, 688, 466, 300, 11, 457, 309, 311, 41183, 13, 50634], "temperature": 0.0, "avg_logprob": -0.1556492660005214, "compression_ratio": 1.6498194945848375, "no_speech_prob": 0.01063384860754013}, {"id": 348, "seek": 123502, "start": 1240.42, "end": 1242.62, "text": " The next one is battle robots.", "tokens": [50634, 440, 958, 472, 307, 4635, 14733, 13, 50744], "temperature": 0.0, "avg_logprob": -0.1556492660005214, "compression_ratio": 1.6498194945848375, "no_speech_prob": 0.01063384860754013}, {"id": 349, "seek": 123502, "start": 1242.62, "end": 1248.3799999999999, "text": " That I'm really worried about because defense departments are going to build them.", "tokens": [50744, 663, 286, 478, 534, 5804, 466, 570, 7654, 15326, 366, 516, 281, 1322, 552, 13, 51032], "temperature": 0.0, "avg_logprob": -0.1556492660005214, "compression_ratio": 1.6498194945848375, "no_speech_prob": 0.01063384860754013}, {"id": 350, "seek": 123502, "start": 1248.3799999999999, "end": 1252.9, "text": " And I don't see how you could stop them doing it.", "tokens": [51032, 400, 286, 500, 380, 536, 577, 291, 727, 1590, 552, 884, 309, 13, 51258], "temperature": 0.0, "avg_logprob": -0.1556492660005214, "compression_ratio": 1.6498194945848375, "no_speech_prob": 0.01063384860754013}, {"id": 351, "seek": 123502, "start": 1252.9, "end": 1256.22, "text": " Something like a Geneva Convention would be great.", "tokens": [51258, 6595, 411, 257, 37285, 26793, 576, 312, 869, 13, 51424], "temperature": 0.0, "avg_logprob": -0.1556492660005214, "compression_ratio": 1.6498194945848375, "no_speech_prob": 0.01063384860754013}, {"id": 352, "seek": 123502, "start": 1256.22, "end": 1259.74, "text": " But those never happened until after they've been used with chemical weapons.", "tokens": [51424, 583, 729, 1128, 2011, 1826, 934, 436, 600, 668, 1143, 365, 7313, 7278, 13, 51600], "temperature": 0.0, "avg_logprob": -0.1556492660005214, "compression_ratio": 1.6498194945848375, "no_speech_prob": 0.01063384860754013}, {"id": 353, "seek": 123502, "start": 1259.74, "end": 1263.82, "text": " It didn't happen until after the First World War, I believe.", "tokens": [51600, 467, 994, 380, 1051, 1826, 934, 264, 2386, 3937, 3630, 11, 286, 1697, 13, 51804], "temperature": 0.0, "avg_logprob": -0.1556492660005214, "compression_ratio": 1.6498194945848375, "no_speech_prob": 0.01063384860754013}, {"id": 354, "seek": 126382, "start": 1263.82, "end": 1267.26, "text": " And so I think what may happen is people will use battle robots.", "tokens": [50364, 400, 370, 286, 519, 437, 815, 1051, 307, 561, 486, 764, 4635, 14733, 13, 50536], "temperature": 0.0, "avg_logprob": -0.1745617849784985, "compression_ratio": 1.6141732283464567, "no_speech_prob": 0.002557924948632717}, {"id": 355, "seek": 126382, "start": 1267.26, "end": 1269.74, "text": " We'll see just how absolutely awful they are.", "tokens": [50536, 492, 603, 536, 445, 577, 3122, 11232, 436, 366, 13, 50660], "temperature": 0.0, "avg_logprob": -0.1745617849784985, "compression_ratio": 1.6141732283464567, "no_speech_prob": 0.002557924948632717}, {"id": 356, "seek": 126382, "start": 1269.74, "end": 1273.6599999999999, "text": " And then maybe we can get an international convention to prohibit them.", "tokens": [50660, 400, 550, 1310, 321, 393, 483, 364, 5058, 10286, 281, 16015, 270, 552, 13, 50856], "temperature": 0.0, "avg_logprob": -0.1745617849784985, "compression_ratio": 1.6141732283464567, "no_speech_prob": 0.002557924948632717}, {"id": 357, "seek": 126382, "start": 1273.6599999999999, "end": 1274.6599999999999, "text": " So that's two.", "tokens": [50856, 407, 300, 311, 732, 13, 50906], "temperature": 0.0, "avg_logprob": -0.1745617849784985, "compression_ratio": 1.6141732283464567, "no_speech_prob": 0.002557924948632717}, {"id": 358, "seek": 126382, "start": 1274.6599999999999, "end": 1280.3799999999999, "text": " I mean, you could also tell the people building the AI to not sell their equipment to the military.", "tokens": [50906, 286, 914, 11, 291, 727, 611, 980, 264, 561, 2390, 264, 7318, 281, 406, 3607, 641, 5927, 281, 264, 4632, 13, 51192], "temperature": 0.0, "avg_logprob": -0.1745617849784985, "compression_ratio": 1.6141732283464567, "no_speech_prob": 0.002557924948632717}, {"id": 359, "seek": 126382, "start": 1280.3799999999999, "end": 1281.34, "text": " You could try.", "tokens": [51192, 509, 727, 853, 13, 51240], "temperature": 0.0, "avg_logprob": -0.1745617849784985, "compression_ratio": 1.6141732283464567, "no_speech_prob": 0.002557924948632717}, {"id": 360, "seek": 126382, "start": 1281.34, "end": 1281.74, "text": " Try.", "tokens": [51240, 6526, 13, 51260], "temperature": 0.0, "avg_logprob": -0.1745617849784985, "compression_ratio": 1.6141732283464567, "no_speech_prob": 0.002557924948632717}, {"id": 361, "seek": 126382, "start": 1281.74, "end": 1283.62, "text": " Okay, number three.", "tokens": [51260, 1033, 11, 1230, 1045, 13, 51354], "temperature": 0.0, "avg_logprob": -0.1745617849784985, "compression_ratio": 1.6141732283464567, "no_speech_prob": 0.002557924948632717}, {"id": 362, "seek": 126382, "start": 1283.62, "end": 1287.34, "text": " The military has lots of money.", "tokens": [51354, 440, 4632, 575, 3195, 295, 1460, 13, 51540], "temperature": 0.0, "avg_logprob": -0.1745617849784985, "compression_ratio": 1.6141732283464567, "no_speech_prob": 0.002557924948632717}, {"id": 363, "seek": 126382, "start": 1287.34, "end": 1291.4199999999998, "text": " Okay, number three, there's joblessness.", "tokens": [51540, 1033, 11, 1230, 1045, 11, 456, 311, 1691, 26663, 13, 51744], "temperature": 0.0, "avg_logprob": -0.1745617849784985, "compression_ratio": 1.6141732283464567, "no_speech_prob": 0.002557924948632717}, {"id": 364, "seek": 129142, "start": 1291.42, "end": 1296.8600000000001, "text": " You could try and do stuff to make sure the increase in productivity, some of that extra", "tokens": [50364, 509, 727, 853, 293, 360, 1507, 281, 652, 988, 264, 3488, 294, 15604, 11, 512, 295, 300, 2857, 50636], "temperature": 0.0, "avg_logprob": -0.15872847304052237, "compression_ratio": 1.6567796610169492, "no_speech_prob": 0.023507719859480858}, {"id": 365, "seek": 129142, "start": 1296.8600000000001, "end": 1301.26, "text": " revenue that comes from the increase in productivity is going goes to helping the people who make", "tokens": [50636, 9324, 300, 1487, 490, 264, 3488, 294, 15604, 307, 516, 1709, 281, 4315, 264, 561, 567, 652, 50856], "temperature": 0.0, "avg_logprob": -0.15872847304052237, "compression_ratio": 1.6567796610169492, "no_speech_prob": 0.023507719859480858}, {"id": 366, "seek": 129142, "start": 1301.26, "end": 1302.26, "text": " jobless.", "tokens": [50856, 1691, 1832, 13, 50906], "temperature": 0.0, "avg_logprob": -0.15872847304052237, "compression_ratio": 1.6567796610169492, "no_speech_prob": 0.023507719859480858}, {"id": 367, "seek": 129142, "start": 1302.26, "end": 1307.14, "text": " If it turns out that there aren't as many jobs created as destroyed.", "tokens": [50906, 759, 309, 4523, 484, 300, 456, 3212, 380, 382, 867, 4782, 2942, 382, 8937, 13, 51150], "temperature": 0.0, "avg_logprob": -0.15872847304052237, "compression_ratio": 1.6567796610169492, "no_speech_prob": 0.023507719859480858}, {"id": 368, "seek": 129142, "start": 1307.14, "end": 1309.02, "text": " That's a question of social policy.", "tokens": [51150, 663, 311, 257, 1168, 295, 2093, 3897, 13, 51244], "temperature": 0.0, "avg_logprob": -0.15872847304052237, "compression_ratio": 1.6567796610169492, "no_speech_prob": 0.023507719859480858}, {"id": 369, "seek": 129142, "start": 1309.02, "end": 1312.78, "text": " And what you really need for that is socialism.", "tokens": [51244, 400, 437, 291, 534, 643, 337, 300, 307, 36112, 13, 51432], "temperature": 0.0, "avg_logprob": -0.15872847304052237, "compression_ratio": 1.6567796610169492, "no_speech_prob": 0.023507719859480858}, {"id": 370, "seek": 129142, "start": 1312.78, "end": 1318.3400000000001, "text": " We're in Canada, so you can say socialism.", "tokens": [51432, 492, 434, 294, 6309, 11, 370, 291, 393, 584, 36112, 13, 51710], "temperature": 0.0, "avg_logprob": -0.15872847304052237, "compression_ratio": 1.6567796610169492, "no_speech_prob": 0.023507719859480858}, {"id": 371, "seek": 131834, "start": 1318.34, "end": 1325.5, "text": " Number four would be the warring echo chambers due to the big companies wanting you to click", "tokens": [50364, 5118, 1451, 576, 312, 264, 1516, 2937, 14300, 34513, 3462, 281, 264, 955, 3431, 7935, 291, 281, 2052, 50722], "temperature": 0.0, "avg_logprob": -0.13373666846233864, "compression_ratio": 1.8685258964143425, "no_speech_prob": 0.14562280476093292}, {"id": 372, "seek": 131834, "start": 1325.5, "end": 1327.3799999999999, "text": " on things that make you indignant.", "tokens": [50722, 322, 721, 300, 652, 291, 1016, 36818, 13, 50816], "temperature": 0.0, "avg_logprob": -0.13373666846233864, "compression_ratio": 1.8685258964143425, "no_speech_prob": 0.14562280476093292}, {"id": 373, "seek": 131834, "start": 1327.3799999999999, "end": 1330.4199999999998, "text": " And so giving you things that are more and more extreme.", "tokens": [50816, 400, 370, 2902, 291, 721, 300, 366, 544, 293, 544, 8084, 13, 50968], "temperature": 0.0, "avg_logprob": -0.13373666846233864, "compression_ratio": 1.8685258964143425, "no_speech_prob": 0.14562280476093292}, {"id": 374, "seek": 131834, "start": 1330.4199999999998, "end": 1335.22, "text": " And so you end up in this echo chamber where you believe these crazy conspiracy theorists,", "tokens": [50968, 400, 370, 291, 917, 493, 294, 341, 14300, 13610, 689, 291, 1697, 613, 3219, 20439, 27423, 1751, 11, 51208], "temperature": 0.0, "avg_logprob": -0.13373666846233864, "compression_ratio": 1.8685258964143425, "no_speech_prob": 0.14562280476093292}, {"id": 375, "seek": 131834, "start": 1335.22, "end": 1341.9399999999998, "text": " if you're in the other echo chamber, or you believe the truth, if you're in my echo chamber.", "tokens": [51208, 498, 291, 434, 294, 264, 661, 14300, 13610, 11, 420, 291, 1697, 264, 3494, 11, 498, 291, 434, 294, 452, 14300, 13610, 13, 51544], "temperature": 0.0, "avg_logprob": -0.13373666846233864, "compression_ratio": 1.8685258964143425, "no_speech_prob": 0.14562280476093292}, {"id": 376, "seek": 131834, "start": 1341.9399999999998, "end": 1345.6999999999998, "text": " That's partly to do with the policies of the companies and maybe something could be done", "tokens": [51544, 663, 311, 17031, 281, 360, 365, 264, 7657, 295, 264, 3431, 293, 1310, 746, 727, 312, 1096, 51732], "temperature": 0.0, "avg_logprob": -0.13373666846233864, "compression_ratio": 1.8685258964143425, "no_speech_prob": 0.14562280476093292}, {"id": 377, "seek": 131834, "start": 1345.6999999999998, "end": 1346.6999999999998, "text": " about that.", "tokens": [51732, 466, 300, 13, 51782], "temperature": 0.0, "avg_logprob": -0.13373666846233864, "compression_ratio": 1.8685258964143425, "no_speech_prob": 0.14562280476093292}, {"id": 378, "seek": 134670, "start": 1347.06, "end": 1351.82, "text": " But that would mean that is a problem that exists if it existed prior to large language", "tokens": [50382, 583, 300, 576, 914, 300, 307, 257, 1154, 300, 8198, 498, 309, 13135, 4059, 281, 2416, 2856, 50620], "temperature": 0.0, "avg_logprob": -0.1915231148401896, "compression_ratio": 1.9057971014492754, "no_speech_prob": 0.018163839355111122}, {"id": 379, "seek": 134670, "start": 1351.82, "end": 1352.82, "text": " models.", "tokens": [50620, 5245, 13, 50670], "temperature": 0.0, "avg_logprob": -0.1915231148401896, "compression_ratio": 1.9057971014492754, "no_speech_prob": 0.018163839355111122}, {"id": 380, "seek": 134670, "start": 1352.82, "end": 1355.98, "text": " And in fact, large language models could reverse it.", "tokens": [50670, 400, 294, 1186, 11, 2416, 2856, 5245, 727, 9943, 309, 13, 50828], "temperature": 0.0, "avg_logprob": -0.1915231148401896, "compression_ratio": 1.9057971014492754, "no_speech_prob": 0.018163839355111122}, {"id": 381, "seek": 134670, "start": 1355.98, "end": 1356.98, "text": " Maybe.", "tokens": [50828, 2704, 13, 50878], "temperature": 0.0, "avg_logprob": -0.1915231148401896, "compression_ratio": 1.9057971014492754, "no_speech_prob": 0.018163839355111122}, {"id": 382, "seek": 134670, "start": 1356.98, "end": 1360.78, "text": " I mean, it's an open question of whether they can make it better or whether they make that", "tokens": [50878, 286, 914, 11, 309, 311, 364, 1269, 1168, 295, 1968, 436, 393, 652, 309, 1101, 420, 1968, 436, 652, 300, 51068], "temperature": 0.0, "avg_logprob": -0.1915231148401896, "compression_ratio": 1.9057971014492754, "no_speech_prob": 0.018163839355111122}, {"id": 383, "seek": 134670, "start": 1360.78, "end": 1361.78, "text": " problem worse.", "tokens": [51068, 1154, 5324, 13, 51118], "temperature": 0.0, "avg_logprob": -0.1915231148401896, "compression_ratio": 1.9057971014492754, "no_speech_prob": 0.018163839355111122}, {"id": 384, "seek": 134670, "start": 1361.78, "end": 1366.82, "text": " Yeah, it's a problem to do with AI, but it's not to do with large language models.", "tokens": [51118, 865, 11, 309, 311, 257, 1154, 281, 360, 365, 7318, 11, 457, 309, 311, 406, 281, 360, 365, 2416, 2856, 5245, 13, 51370], "temperature": 0.0, "avg_logprob": -0.1915231148401896, "compression_ratio": 1.9057971014492754, "no_speech_prob": 0.018163839355111122}, {"id": 385, "seek": 134670, "start": 1366.82, "end": 1369.94, "text": " It's a problem to do with AI in the sense that there's an algorithm using AI trained", "tokens": [51370, 467, 311, 257, 1154, 281, 360, 365, 7318, 294, 264, 2020, 300, 456, 311, 364, 9284, 1228, 7318, 8895, 51526], "temperature": 0.0, "avg_logprob": -0.1915231148401896, "compression_ratio": 1.9057971014492754, "no_speech_prob": 0.018163839355111122}, {"id": 386, "seek": 134670, "start": 1369.94, "end": 1372.42, "text": " on our emotions that then pushes us in those directions.", "tokens": [51526, 322, 527, 8462, 300, 550, 21020, 505, 294, 729, 11095, 13, 51650], "temperature": 0.0, "avg_logprob": -0.1915231148401896, "compression_ratio": 1.9057971014492754, "no_speech_prob": 0.018163839355111122}, {"id": 387, "seek": 134670, "start": 1372.42, "end": 1373.42, "text": " Okay.", "tokens": [51650, 1033, 13, 51700], "temperature": 0.0, "avg_logprob": -0.1915231148401896, "compression_ratio": 1.9057971014492754, "no_speech_prob": 0.018163839355111122}, {"id": 388, "seek": 134670, "start": 1373.42, "end": 1374.42, "text": " All right.", "tokens": [51700, 1057, 558, 13, 51750], "temperature": 0.0, "avg_logprob": -0.1915231148401896, "compression_ratio": 1.9057971014492754, "no_speech_prob": 0.018163839355111122}, {"id": 389, "seek": 134670, "start": 1374.42, "end": 1375.42, "text": " So that's number four.", "tokens": [51750, 407, 300, 311, 1230, 1451, 13, 51800], "temperature": 0.0, "avg_logprob": -0.1915231148401896, "compression_ratio": 1.9057971014492754, "no_speech_prob": 0.018163839355111122}, {"id": 390, "seek": 137542, "start": 1375.42, "end": 1380.26, "text": " Because the existential risk, which is the one I decided to talk about because a lot", "tokens": [50364, 1436, 264, 37133, 3148, 11, 597, 307, 264, 472, 286, 3047, 281, 751, 466, 570, 257, 688, 50606], "temperature": 0.0, "avg_logprob": -0.17586844558015877, "compression_ratio": 1.8326693227091633, "no_speech_prob": 0.04805607721209526}, {"id": 391, "seek": 137542, "start": 1380.26, "end": 1381.8200000000002, "text": " of people think is a joke.", "tokens": [50606, 295, 561, 519, 307, 257, 7647, 13, 50684], "temperature": 0.0, "avg_logprob": -0.17586844558015877, "compression_ratio": 1.8326693227091633, "no_speech_prob": 0.04805607721209526}, {"id": 392, "seek": 137542, "start": 1381.8200000000002, "end": 1382.8200000000002, "text": " Right.", "tokens": [50684, 1779, 13, 50734], "temperature": 0.0, "avg_logprob": -0.17586844558015877, "compression_ratio": 1.8326693227091633, "no_speech_prob": 0.04805607721209526}, {"id": 393, "seek": 137542, "start": 1382.8200000000002, "end": 1388.8600000000001, "text": " So there was an editorial in Nature yesterday where they basically said, I'm fear-mongering", "tokens": [50734, 407, 456, 390, 364, 33412, 294, 20159, 5186, 689, 436, 1936, 848, 11, 286, 478, 4240, 12, 76, 556, 1794, 51036], "temperature": 0.0, "avg_logprob": -0.17586844558015877, "compression_ratio": 1.8326693227091633, "no_speech_prob": 0.04805607721209526}, {"id": 394, "seek": 137542, "start": 1388.8600000000001, "end": 1394.1000000000001, "text": " about the existential risk is distracting attention from the actual risks.", "tokens": [51036, 466, 264, 37133, 3148, 307, 36689, 3202, 490, 264, 3539, 10888, 13, 51298], "temperature": 0.0, "avg_logprob": -0.17586844558015877, "compression_ratio": 1.8326693227091633, "no_speech_prob": 0.04805607721209526}, {"id": 395, "seek": 137542, "start": 1394.1000000000001, "end": 1398.38, "text": " So they compared existential risk with actual risks, implying the existential risk wasn't", "tokens": [51298, 407, 436, 5347, 37133, 3148, 365, 3539, 10888, 11, 704, 7310, 264, 37133, 3148, 2067, 380, 51512], "temperature": 0.0, "avg_logprob": -0.17586844558015877, "compression_ratio": 1.8326693227091633, "no_speech_prob": 0.04805607721209526}, {"id": 396, "seek": 137542, "start": 1398.38, "end": 1401.26, "text": " actual.", "tokens": [51512, 3539, 13, 51656], "temperature": 0.0, "avg_logprob": -0.17586844558015877, "compression_ratio": 1.8326693227091633, "no_speech_prob": 0.04805607721209526}, {"id": 397, "seek": 137542, "start": 1401.26, "end": 1405.18, "text": " I think it's important that people understand it's not just science fiction.", "tokens": [51656, 286, 519, 309, 311, 1021, 300, 561, 1223, 309, 311, 406, 445, 3497, 13266, 13, 51852], "temperature": 0.0, "avg_logprob": -0.17586844558015877, "compression_ratio": 1.8326693227091633, "no_speech_prob": 0.04805607721209526}, {"id": 398, "seek": 140518, "start": 1405.18, "end": 1407.3, "text": " It's not just fear-mongering.", "tokens": [50364, 467, 311, 406, 445, 4240, 12, 76, 556, 1794, 13, 50470], "temperature": 0.0, "avg_logprob": -0.1702608315341444, "compression_ratio": 1.8493589743589745, "no_speech_prob": 0.10325833410024643}, {"id": 399, "seek": 140518, "start": 1407.3, "end": 1411.78, "text": " It is a real risk that we need to think about, and we need to figure out in advance how to", "tokens": [50470, 467, 307, 257, 957, 3148, 300, 321, 643, 281, 519, 466, 11, 293, 321, 643, 281, 2573, 484, 294, 7295, 577, 281, 50694], "temperature": 0.0, "avg_logprob": -0.1702608315341444, "compression_ratio": 1.8493589743589745, "no_speech_prob": 0.10325833410024643}, {"id": 400, "seek": 140518, "start": 1411.78, "end": 1412.94, "text": " deal with it.", "tokens": [50694, 2028, 365, 309, 13, 50752], "temperature": 0.0, "avg_logprob": -0.1702608315341444, "compression_ratio": 1.8493589743589745, "no_speech_prob": 0.10325833410024643}, {"id": 401, "seek": 140518, "start": 1412.94, "end": 1418.0600000000002, "text": " So that's five, and there's one more, and I can't think what it is.", "tokens": [50752, 407, 300, 311, 1732, 11, 293, 456, 311, 472, 544, 11, 293, 286, 393, 380, 519, 437, 309, 307, 13, 51008], "temperature": 0.0, "avg_logprob": -0.1702608315341444, "compression_ratio": 1.8493589743589745, "no_speech_prob": 0.10325833410024643}, {"id": 402, "seek": 140518, "start": 1418.0600000000002, "end": 1420.38, "text": " How do you have a list that doesn't end on existential risk?", "tokens": [51008, 1012, 360, 291, 362, 257, 1329, 300, 1177, 380, 917, 322, 37133, 3148, 30, 51124], "temperature": 0.0, "avg_logprob": -0.1702608315341444, "compression_ratio": 1.8493589743589745, "no_speech_prob": 0.10325833410024643}, {"id": 403, "seek": 140518, "start": 1420.38, "end": 1421.98, "text": " I feel like that should be the end of the list.", "tokens": [51124, 286, 841, 411, 300, 820, 312, 264, 917, 295, 264, 1329, 13, 51204], "temperature": 0.0, "avg_logprob": -0.1702608315341444, "compression_ratio": 1.8493589743589745, "no_speech_prob": 0.10325833410024643}, {"id": 404, "seek": 140518, "start": 1421.98, "end": 1425.8600000000001, "text": " No, that was the end, but I thought if I talked about existential risk, I'd be able to remember", "tokens": [51204, 883, 11, 300, 390, 264, 917, 11, 457, 286, 1194, 498, 286, 2825, 466, 37133, 3148, 11, 286, 1116, 312, 1075, 281, 1604, 51398], "temperature": 0.0, "avg_logprob": -0.1702608315341444, "compression_ratio": 1.8493589743589745, "no_speech_prob": 0.10325833410024643}, {"id": 405, "seek": 140518, "start": 1425.8600000000001, "end": 1428.26, "text": " the missing one while I talk about it, but I couldn't.", "tokens": [51398, 264, 5361, 472, 1339, 286, 751, 466, 309, 11, 457, 286, 2809, 380, 13, 51518], "temperature": 0.0, "avg_logprob": -0.1702608315341444, "compression_ratio": 1.8493589743589745, "no_speech_prob": 0.10325833410024643}, {"id": 406, "seek": 140518, "start": 1428.26, "end": 1429.26, "text": " All right.", "tokens": [51518, 1057, 558, 13, 51568], "temperature": 0.0, "avg_logprob": -0.1702608315341444, "compression_ratio": 1.8493589743589745, "no_speech_prob": 0.10325833410024643}, {"id": 407, "seek": 140518, "start": 1429.26, "end": 1430.46, "text": " Well, let's talk about existential risk.", "tokens": [51568, 1042, 11, 718, 311, 751, 466, 37133, 3148, 13, 51628], "temperature": 0.0, "avg_logprob": -0.1702608315341444, "compression_ratio": 1.8493589743589745, "no_speech_prob": 0.10325833410024643}, {"id": 408, "seek": 140518, "start": 1430.46, "end": 1434.94, "text": " What exactly explain exactly existential risk, how it happens?", "tokens": [51628, 708, 2293, 2903, 2293, 37133, 3148, 11, 577, 309, 2314, 30, 51852], "temperature": 0.0, "avg_logprob": -0.1702608315341444, "compression_ratio": 1.8493589743589745, "no_speech_prob": 0.10325833410024643}, {"id": 409, "seek": 143494, "start": 1434.94, "end": 1440.98, "text": " Or explain, as best you can imagine it, what it is that goes wrong that leads us to extinction", "tokens": [50364, 1610, 2903, 11, 382, 1151, 291, 393, 3811, 309, 11, 437, 309, 307, 300, 1709, 2085, 300, 6689, 505, 281, 33163, 50666], "temperature": 0.0, "avg_logprob": -0.1374646700345553, "compression_ratio": 1.6653543307086613, "no_speech_prob": 0.06200103461742401}, {"id": 410, "seek": 143494, "start": 1440.98, "end": 1443.18, "text": " or disappearance of humanity as a species?", "tokens": [50666, 420, 37049, 295, 10243, 382, 257, 6172, 30, 50776], "temperature": 0.0, "avg_logprob": -0.1374646700345553, "compression_ratio": 1.6653543307086613, "no_speech_prob": 0.06200103461742401}, {"id": 411, "seek": 143494, "start": 1443.18, "end": 1444.18, "text": " Okay.", "tokens": [50776, 1033, 13, 50826], "temperature": 0.0, "avg_logprob": -0.1374646700345553, "compression_ratio": 1.6653543307086613, "no_speech_prob": 0.06200103461742401}, {"id": 412, "seek": 143494, "start": 1444.18, "end": 1449.5, "text": " At a very general level, if you've got something a lot smarter than you that's very good at", "tokens": [50826, 1711, 257, 588, 2674, 1496, 11, 498, 291, 600, 658, 746, 257, 688, 20294, 813, 291, 300, 311, 588, 665, 412, 51092], "temperature": 0.0, "avg_logprob": -0.1374646700345553, "compression_ratio": 1.6653543307086613, "no_speech_prob": 0.06200103461742401}, {"id": 413, "seek": 143494, "start": 1449.5, "end": 1454.3400000000001, "text": " manipulating people, just at a very general level, are you confident people will stay", "tokens": [51092, 40805, 561, 11, 445, 412, 257, 588, 2674, 1496, 11, 366, 291, 6679, 561, 486, 1754, 51334], "temperature": 0.0, "avg_logprob": -0.1374646700345553, "compression_ratio": 1.6653543307086613, "no_speech_prob": 0.06200103461742401}, {"id": 414, "seek": 143494, "start": 1454.3400000000001, "end": 1456.3400000000001, "text": " in charge?", "tokens": [51334, 294, 4602, 30, 51434], "temperature": 0.0, "avg_logprob": -0.1374646700345553, "compression_ratio": 1.6653543307086613, "no_speech_prob": 0.06200103461742401}, {"id": 415, "seek": 143494, "start": 1456.3400000000001, "end": 1460.98, "text": " And then you can go into specific scenarios for how people might lose control, even though", "tokens": [51434, 400, 550, 291, 393, 352, 666, 2685, 15077, 337, 577, 561, 1062, 3624, 1969, 11, 754, 1673, 51666], "temperature": 0.0, "avg_logprob": -0.1374646700345553, "compression_ratio": 1.6653543307086613, "no_speech_prob": 0.06200103461742401}, {"id": 416, "seek": 146098, "start": 1460.98, "end": 1464.34, "text": " they're the people creating this and giving it its goals.", "tokens": [50364, 436, 434, 264, 561, 4084, 341, 293, 2902, 309, 1080, 5493, 13, 50532], "temperature": 0.0, "avg_logprob": -0.1503812634215063, "compression_ratio": 1.6196581196581197, "no_speech_prob": 0.10743258148431778}, {"id": 417, "seek": 146098, "start": 1464.34, "end": 1469.66, "text": " And one very obvious scenario is if you're given a goal and you want to be good at achieving", "tokens": [50532, 400, 472, 588, 6322, 9005, 307, 498, 291, 434, 2212, 257, 3387, 293, 291, 528, 281, 312, 665, 412, 19626, 50798], "temperature": 0.0, "avg_logprob": -0.1503812634215063, "compression_ratio": 1.6196581196581197, "no_speech_prob": 0.10743258148431778}, {"id": 418, "seek": 146098, "start": 1469.66, "end": 1474.78, "text": " it, what you need is as much control as possible.", "tokens": [50798, 309, 11, 437, 291, 643, 307, 382, 709, 1969, 382, 1944, 13, 51054], "temperature": 0.0, "avg_logprob": -0.1503812634215063, "compression_ratio": 1.6196581196581197, "no_speech_prob": 0.10743258148431778}, {"id": 419, "seek": 146098, "start": 1474.78, "end": 1480.74, "text": " So for example, if I'm sitting in a boring seminar and I see a little dot of light on", "tokens": [51054, 407, 337, 1365, 11, 498, 286, 478, 3798, 294, 257, 9989, 29235, 293, 286, 536, 257, 707, 5893, 295, 1442, 322, 51352], "temperature": 0.0, "avg_logprob": -0.1503812634215063, "compression_ratio": 1.6196581196581197, "no_speech_prob": 0.10743258148431778}, {"id": 420, "seek": 146098, "start": 1480.74, "end": 1487.42, "text": " the ceiling, and then suddenly I notice that when I move, that dot of light moves, I realize", "tokens": [51352, 264, 13655, 11, 293, 550, 5800, 286, 3449, 300, 562, 286, 1286, 11, 300, 5893, 295, 1442, 6067, 11, 286, 4325, 51686], "temperature": 0.0, "avg_logprob": -0.1503812634215063, "compression_ratio": 1.6196581196581197, "no_speech_prob": 0.10743258148431778}, {"id": 421, "seek": 148742, "start": 1487.42, "end": 1491.7, "text": " this is the reflection from my watch, the sun is bouncing off my watch.", "tokens": [50364, 341, 307, 264, 12914, 490, 452, 1159, 11, 264, 3295, 307, 27380, 766, 452, 1159, 13, 50578], "temperature": 0.0, "avg_logprob": -0.1504972723146148, "compression_ratio": 1.8874172185430464, "no_speech_prob": 0.8575709462165833}, {"id": 422, "seek": 148742, "start": 1491.7, "end": 1495.3400000000001, "text": " And so the next thing I do is I don't start listening to the boring seminar again.", "tokens": [50578, 400, 370, 264, 958, 551, 286, 360, 307, 286, 500, 380, 722, 4764, 281, 264, 9989, 29235, 797, 13, 50760], "temperature": 0.0, "avg_logprob": -0.1504972723146148, "compression_ratio": 1.8874172185430464, "no_speech_prob": 0.8575709462165833}, {"id": 423, "seek": 148742, "start": 1495.3400000000001, "end": 1498.78, "text": " I immediately try and figure out how to make it go this way and how to make it go that", "tokens": [50760, 286, 4258, 853, 293, 2573, 484, 577, 281, 652, 309, 352, 341, 636, 293, 577, 281, 652, 309, 352, 300, 50932], "temperature": 0.0, "avg_logprob": -0.1504972723146148, "compression_ratio": 1.8874172185430464, "no_speech_prob": 0.8575709462165833}, {"id": 424, "seek": 148742, "start": 1498.78, "end": 1499.78, "text": " way.", "tokens": [50932, 636, 13, 50982], "temperature": 0.0, "avg_logprob": -0.1504972723146148, "compression_ratio": 1.8874172185430464, "no_speech_prob": 0.8575709462165833}, {"id": 425, "seek": 148742, "start": 1499.78, "end": 1502.6200000000001, "text": " And once I got control of it, then maybe I'll listen to the seminar again.", "tokens": [50982, 400, 1564, 286, 658, 1969, 295, 309, 11, 550, 1310, 286, 603, 2140, 281, 264, 29235, 797, 13, 51124], "temperature": 0.0, "avg_logprob": -0.1504972723146148, "compression_ratio": 1.8874172185430464, "no_speech_prob": 0.8575709462165833}, {"id": 426, "seek": 148742, "start": 1502.6200000000001, "end": 1507.14, "text": " We have a very strong built in urge to get control and it's very sensible because the", "tokens": [51124, 492, 362, 257, 588, 2068, 3094, 294, 19029, 281, 483, 1969, 293, 309, 311, 588, 25380, 570, 264, 51350], "temperature": 0.0, "avg_logprob": -0.1504972723146148, "compression_ratio": 1.8874172185430464, "no_speech_prob": 0.8575709462165833}, {"id": 427, "seek": 148742, "start": 1507.14, "end": 1510.74, "text": " more control you get, the easier it is to achieve things.", "tokens": [51350, 544, 1969, 291, 483, 11, 264, 3571, 309, 307, 281, 4584, 721, 13, 51530], "temperature": 0.0, "avg_logprob": -0.1504972723146148, "compression_ratio": 1.8874172185430464, "no_speech_prob": 0.8575709462165833}, {"id": 428, "seek": 148742, "start": 1510.74, "end": 1513.5, "text": " And I think AI will be able to derive that too.", "tokens": [51530, 400, 286, 519, 7318, 486, 312, 1075, 281, 28446, 300, 886, 13, 51668], "temperature": 0.0, "avg_logprob": -0.1504972723146148, "compression_ratio": 1.8874172185430464, "no_speech_prob": 0.8575709462165833}, {"id": 429, "seek": 148742, "start": 1513.5, "end": 1516.38, "text": " It's good to get control so you can achieve other goals.", "tokens": [51668, 467, 311, 665, 281, 483, 1969, 370, 291, 393, 4584, 661, 5493, 13, 51812], "temperature": 0.0, "avg_logprob": -0.1504972723146148, "compression_ratio": 1.8874172185430464, "no_speech_prob": 0.8575709462165833}, {"id": 430, "seek": 151638, "start": 1516.5800000000002, "end": 1524.14, "text": " Wait, so you actually believe that getting control will be an innate feature of something", "tokens": [50374, 3802, 11, 370, 291, 767, 1697, 300, 1242, 1969, 486, 312, 364, 41766, 4111, 295, 746, 50752], "temperature": 0.0, "avg_logprob": -0.1580794910052875, "compression_ratio": 1.836734693877551, "no_speech_prob": 0.02816447988152504}, {"id": 431, "seek": 151638, "start": 1524.14, "end": 1526.1000000000001, "text": " that the AIs are trained on us, right?", "tokens": [50752, 300, 264, 316, 6802, 366, 8895, 322, 505, 11, 558, 30, 50850], "temperature": 0.0, "avg_logprob": -0.1580794910052875, "compression_ratio": 1.836734693877551, "no_speech_prob": 0.02816447988152504}, {"id": 432, "seek": 151638, "start": 1526.1000000000001, "end": 1527.1000000000001, "text": " They act like us.", "tokens": [50850, 814, 605, 411, 505, 13, 50900], "temperature": 0.0, "avg_logprob": -0.1580794910052875, "compression_ratio": 1.836734693877551, "no_speech_prob": 0.02816447988152504}, {"id": 433, "seek": 151638, "start": 1527.1000000000001, "end": 1531.5, "text": " They think like us because the neural architecture makes them like our human brains and because", "tokens": [50900, 814, 519, 411, 505, 570, 264, 18161, 9482, 1669, 552, 411, 527, 1952, 15442, 293, 570, 51120], "temperature": 0.0, "avg_logprob": -0.1580794910052875, "compression_ratio": 1.836734693877551, "no_speech_prob": 0.02816447988152504}, {"id": 434, "seek": 151638, "start": 1531.5, "end": 1533.1000000000001, "text": " they're trained on all of our outputs.", "tokens": [51120, 436, 434, 8895, 322, 439, 295, 527, 23930, 13, 51200], "temperature": 0.0, "avg_logprob": -0.1580794910052875, "compression_ratio": 1.836734693877551, "no_speech_prob": 0.02816447988152504}, {"id": 435, "seek": 151638, "start": 1533.1000000000001, "end": 1537.7800000000002, "text": " So you actually think that getting control of humans will be something that the AI is", "tokens": [51200, 407, 291, 767, 519, 300, 1242, 1969, 295, 6255, 486, 312, 746, 300, 264, 7318, 307, 51434], "temperature": 0.0, "avg_logprob": -0.1580794910052875, "compression_ratio": 1.836734693877551, "no_speech_prob": 0.02816447988152504}, {"id": 436, "seek": 151638, "start": 1537.7800000000002, "end": 1539.5, "text": " almost aspire to?", "tokens": [51434, 1920, 41224, 281, 30, 51520], "temperature": 0.0, "avg_logprob": -0.1580794910052875, "compression_ratio": 1.836734693877551, "no_speech_prob": 0.02816447988152504}, {"id": 437, "seek": 151638, "start": 1539.5, "end": 1544.94, "text": " No, I think they'll derive it as a way of achieving other goals.", "tokens": [51520, 883, 11, 286, 519, 436, 603, 28446, 309, 382, 257, 636, 295, 19626, 661, 5493, 13, 51792], "temperature": 0.0, "avg_logprob": -0.1580794910052875, "compression_ratio": 1.836734693877551, "no_speech_prob": 0.02816447988152504}, {"id": 438, "seek": 154494, "start": 1544.94, "end": 1546.3, "text": " I think in us it's innate.", "tokens": [50364, 286, 519, 294, 505, 309, 311, 41766, 13, 50432], "temperature": 0.0, "avg_logprob": -0.14632874948007088, "compression_ratio": 1.7113821138211383, "no_speech_prob": 0.0012789617758244276}, {"id": 439, "seek": 154494, "start": 1546.3, "end": 1552.6200000000001, "text": " I think I'm very dubious about saying things are really innate, but I think the desire", "tokens": [50432, 286, 519, 286, 478, 588, 18540, 851, 466, 1566, 721, 366, 534, 41766, 11, 457, 286, 519, 264, 7516, 50748], "temperature": 0.0, "avg_logprob": -0.14632874948007088, "compression_ratio": 1.7113821138211383, "no_speech_prob": 0.0012789617758244276}, {"id": 440, "seek": 154494, "start": 1552.6200000000001, "end": 1558.74, "text": " to understand how things work is a very sensible desire to have and I think we have that.", "tokens": [50748, 281, 1223, 577, 721, 589, 307, 257, 588, 25380, 7516, 281, 362, 293, 286, 519, 321, 362, 300, 13, 51054], "temperature": 0.0, "avg_logprob": -0.14632874948007088, "compression_ratio": 1.7113821138211383, "no_speech_prob": 0.0012789617758244276}, {"id": 441, "seek": 154494, "start": 1558.74, "end": 1564.02, "text": " So we have that and then AIs will develop an ability to manipulate us and control us", "tokens": [51054, 407, 321, 362, 300, 293, 550, 316, 6802, 486, 1499, 364, 3485, 281, 20459, 505, 293, 1969, 505, 51318], "temperature": 0.0, "avg_logprob": -0.14632874948007088, "compression_ratio": 1.7113821138211383, "no_speech_prob": 0.0012789617758244276}, {"id": 442, "seek": 154494, "start": 1564.02, "end": 1568.46, "text": " in a way that we can't respond to, right?", "tokens": [51318, 294, 257, 636, 300, 321, 393, 380, 4196, 281, 11, 558, 30, 51540], "temperature": 0.0, "avg_logprob": -0.14632874948007088, "compression_ratio": 1.7113821138211383, "no_speech_prob": 0.0012789617758244276}, {"id": 443, "seek": 154494, "start": 1568.46, "end": 1574.3400000000001, "text": " That the manipulative AIs and even though good people will be able to use equally powerful", "tokens": [51540, 663, 264, 9258, 22678, 316, 6802, 293, 754, 1673, 665, 561, 486, 312, 1075, 281, 764, 12309, 4005, 51834], "temperature": 0.0, "avg_logprob": -0.14632874948007088, "compression_ratio": 1.7113821138211383, "no_speech_prob": 0.0012789617758244276}, {"id": 444, "seek": 157434, "start": 1574.3799999999999, "end": 1578.54, "text": " AIs to counter these bad ones, you believe that we still could have an existential crisis?", "tokens": [50366, 316, 6802, 281, 5682, 613, 1578, 2306, 11, 291, 1697, 300, 321, 920, 727, 362, 364, 37133, 5869, 30, 50574], "temperature": 0.0, "avg_logprob": -0.19693543807319971, "compression_ratio": 1.7723577235772359, "no_speech_prob": 0.018973639234900475}, {"id": 445, "seek": 157434, "start": 1578.54, "end": 1579.74, "text": " Yes.", "tokens": [50574, 1079, 13, 50634], "temperature": 0.0, "avg_logprob": -0.19693543807319971, "compression_ratio": 1.7723577235772359, "no_speech_prob": 0.018973639234900475}, {"id": 446, "seek": 157434, "start": 1579.74, "end": 1580.74, "text": " It's not clear to me.", "tokens": [50634, 467, 311, 406, 1850, 281, 385, 13, 50684], "temperature": 0.0, "avg_logprob": -0.19693543807319971, "compression_ratio": 1.7723577235772359, "no_speech_prob": 0.018973639234900475}, {"id": 447, "seek": 157434, "start": 1580.74, "end": 1585.3799999999999, "text": " I mean, that makes the argument that the good people will have more resources than the", "tokens": [50684, 286, 914, 11, 300, 1669, 264, 6770, 300, 264, 665, 561, 486, 362, 544, 3593, 813, 264, 50916], "temperature": 0.0, "avg_logprob": -0.19693543807319971, "compression_ratio": 1.7723577235772359, "no_speech_prob": 0.018973639234900475}, {"id": 448, "seek": 157434, "start": 1585.3799999999999, "end": 1587.3799999999999, "text": " bad people.", "tokens": [50916, 1578, 561, 13, 51016], "temperature": 0.0, "avg_logprob": -0.19693543807319971, "compression_ratio": 1.7723577235772359, "no_speech_prob": 0.018973639234900475}, {"id": 449, "seek": 157434, "start": 1587.3799999999999, "end": 1593.3, "text": " I'm not sure about that and that good AI is going to be more powerful than bad AI and", "tokens": [51016, 286, 478, 406, 988, 466, 300, 293, 300, 665, 7318, 307, 516, 281, 312, 544, 4005, 813, 1578, 7318, 293, 51312], "temperature": 0.0, "avg_logprob": -0.19693543807319971, "compression_ratio": 1.7723577235772359, "no_speech_prob": 0.018973639234900475}, {"id": 450, "seek": 157434, "start": 1593.3, "end": 1595.86, "text": " good AI is going to be able to regulate bad AI.", "tokens": [51312, 665, 7318, 307, 516, 281, 312, 1075, 281, 24475, 1578, 7318, 13, 51440], "temperature": 0.0, "avg_logprob": -0.19693543807319971, "compression_ratio": 1.7723577235772359, "no_speech_prob": 0.018973639234900475}, {"id": 451, "seek": 157434, "start": 1595.86, "end": 1600.6599999999999, "text": " And we have a situation like that at present where you have people using AI to create", "tokens": [51440, 400, 321, 362, 257, 2590, 411, 300, 412, 1974, 689, 291, 362, 561, 1228, 7318, 281, 1884, 51680], "temperature": 0.0, "avg_logprob": -0.19693543807319971, "compression_ratio": 1.7723577235772359, "no_speech_prob": 0.018973639234900475}, {"id": 452, "seek": 160066, "start": 1600.7, "end": 1606.46, "text": " spam and you have people like Google using AI to filter out the spam and at present Google", "tokens": [50366, 24028, 293, 291, 362, 561, 411, 3329, 1228, 7318, 281, 6608, 484, 264, 24028, 293, 412, 1974, 3329, 50654], "temperature": 0.0, "avg_logprob": -0.16403441361978022, "compression_ratio": 1.8421052631578947, "no_speech_prob": 0.1325717270374298}, {"id": 453, "seek": 160066, "start": 1606.46, "end": 1611.26, "text": " has more resources than the defenders of beating the attackers, but I don't see that it'll", "tokens": [50654, 575, 544, 3593, 813, 264, 36063, 295, 13497, 264, 45129, 11, 457, 286, 500, 380, 536, 300, 309, 603, 50894], "temperature": 0.0, "avg_logprob": -0.16403441361978022, "compression_ratio": 1.8421052631578947, "no_speech_prob": 0.1325717270374298}, {"id": 454, "seek": 160066, "start": 1611.26, "end": 1612.26, "text": " always be like that.", "tokens": [50894, 1009, 312, 411, 300, 13, 50944], "temperature": 0.0, "avg_logprob": -0.16403441361978022, "compression_ratio": 1.8421052631578947, "no_speech_prob": 0.1325717270374298}, {"id": 455, "seek": 160066, "start": 1612.26, "end": 1615.0600000000002, "text": " I mean, even in cyber warfare where you have moments where it seems like the criminals", "tokens": [50944, 286, 914, 11, 754, 294, 13411, 24490, 689, 291, 362, 6065, 689, 309, 2544, 411, 264, 23474, 51084], "temperature": 0.0, "avg_logprob": -0.16403441361978022, "compression_ratio": 1.8421052631578947, "no_speech_prob": 0.1325717270374298}, {"id": 456, "seek": 160066, "start": 1615.0600000000002, "end": 1618.0600000000002, "text": " are winning and sometimes where it seems like the defenders are winning.", "tokens": [51084, 366, 8224, 293, 2171, 689, 309, 2544, 411, 264, 36063, 366, 8224, 13, 51234], "temperature": 0.0, "avg_logprob": -0.16403441361978022, "compression_ratio": 1.8421052631578947, "no_speech_prob": 0.1325717270374298}, {"id": 457, "seek": 160066, "start": 1618.0600000000002, "end": 1622.1000000000001, "text": " So you believe that there will be a battle like that over control of humans by super", "tokens": [51234, 407, 291, 1697, 300, 456, 486, 312, 257, 4635, 411, 300, 670, 1969, 295, 6255, 538, 1687, 51436], "temperature": 0.0, "avg_logprob": -0.16403441361978022, "compression_ratio": 1.8421052631578947, "no_speech_prob": 0.1325717270374298}, {"id": 458, "seek": 160066, "start": 1622.1000000000001, "end": 1623.38, "text": " intelligent artificial intelligence?", "tokens": [51436, 13232, 11677, 7599, 30, 51500], "temperature": 0.0, "avg_logprob": -0.16403441361978022, "compression_ratio": 1.8421052631578947, "no_speech_prob": 0.1325717270374298}, {"id": 459, "seek": 160066, "start": 1623.38, "end": 1624.38, "text": " It may well be, yes.", "tokens": [51500, 467, 815, 731, 312, 11, 2086, 13, 51550], "temperature": 0.0, "avg_logprob": -0.16403441361978022, "compression_ratio": 1.8421052631578947, "no_speech_prob": 0.1325717270374298}, {"id": 460, "seek": 160066, "start": 1624.38, "end": 1629.38, "text": " And I'm not convinced that good AI that's trying to stop bad AI getting control will", "tokens": [51550, 400, 286, 478, 406, 12561, 300, 665, 7318, 300, 311, 1382, 281, 1590, 1578, 7318, 1242, 1969, 486, 51800], "temperature": 0.0, "avg_logprob": -0.16403441361978022, "compression_ratio": 1.8421052631578947, "no_speech_prob": 0.1325717270374298}, {"id": 461, "seek": 160066, "start": 1629.38, "end": 1630.38, "text": " win.", "tokens": [51800, 1942, 13, 51850], "temperature": 0.0, "avg_logprob": -0.16403441361978022, "compression_ratio": 1.8421052631578947, "no_speech_prob": 0.1325717270374298}, {"id": 462, "seek": 163038, "start": 1630.42, "end": 1631.42, "text": " Okay.", "tokens": [50366, 1033, 13, 50416], "temperature": 0.0, "avg_logprob": -0.13277224198128412, "compression_ratio": 1.7307692307692308, "no_speech_prob": 0.014203774742782116}, {"id": 463, "seek": 163038, "start": 1631.42, "end": 1633.3400000000001, "text": " So, all right.", "tokens": [50416, 407, 11, 439, 558, 13, 50512], "temperature": 0.0, "avg_logprob": -0.13277224198128412, "compression_ratio": 1.7307692307692308, "no_speech_prob": 0.014203774742782116}, {"id": 464, "seek": 163038, "start": 1633.3400000000001, "end": 1638.98, "text": " So before this existential risk happened, before bad AI does this, we have a lot of extremely", "tokens": [50512, 407, 949, 341, 37133, 3148, 2011, 11, 949, 1578, 7318, 775, 341, 11, 321, 362, 257, 688, 295, 4664, 50794], "temperature": 0.0, "avg_logprob": -0.13277224198128412, "compression_ratio": 1.7307692307692308, "no_speech_prob": 0.014203774742782116}, {"id": 465, "seek": 163038, "start": 1638.98, "end": 1642.1000000000001, "text": " smart people building a lot of extremely important things.", "tokens": [50794, 4069, 561, 2390, 257, 688, 295, 4664, 1021, 721, 13, 50950], "temperature": 0.0, "avg_logprob": -0.13277224198128412, "compression_ratio": 1.7307692307692308, "no_speech_prob": 0.014203774742782116}, {"id": 466, "seek": 163038, "start": 1642.1000000000001, "end": 1647.3400000000001, "text": " What exactly can they do to most help limit this risk?", "tokens": [50950, 708, 2293, 393, 436, 360, 281, 881, 854, 4948, 341, 3148, 30, 51212], "temperature": 0.0, "avg_logprob": -0.13277224198128412, "compression_ratio": 1.7307692307692308, "no_speech_prob": 0.014203774742782116}, {"id": 467, "seek": 163038, "start": 1647.3400000000001, "end": 1654.5800000000002, "text": " So one thing you can do is before the AI gets super intelligent, you can do empirical work", "tokens": [51212, 407, 472, 551, 291, 393, 360, 307, 949, 264, 7318, 2170, 1687, 13232, 11, 291, 393, 360, 31886, 589, 51574], "temperature": 0.0, "avg_logprob": -0.13277224198128412, "compression_ratio": 1.7307692307692308, "no_speech_prob": 0.014203774742782116}, {"id": 468, "seek": 163038, "start": 1654.5800000000002, "end": 1659.66, "text": " into how it goes wrong, how it tries to get control, whether it tries to get control.", "tokens": [51574, 666, 577, 309, 1709, 2085, 11, 577, 309, 9898, 281, 483, 1969, 11, 1968, 309, 9898, 281, 483, 1969, 13, 51828], "temperature": 0.0, "avg_logprob": -0.13277224198128412, "compression_ratio": 1.7307692307692308, "no_speech_prob": 0.014203774742782116}, {"id": 469, "seek": 165966, "start": 1659.66, "end": 1661.42, "text": " You don't know whether it would.", "tokens": [50364, 509, 500, 380, 458, 1968, 309, 576, 13, 50452], "temperature": 0.0, "avg_logprob": -0.1236356209064352, "compression_ratio": 1.8411552346570397, "no_speech_prob": 0.027216719463467598}, {"id": 470, "seek": 165966, "start": 1661.42, "end": 1666.14, "text": " But before it's smarter than us, I think the people developing it should be encouraged", "tokens": [50452, 583, 949, 309, 311, 20294, 813, 505, 11, 286, 519, 264, 561, 6416, 309, 820, 312, 14658, 50688], "temperature": 0.0, "avg_logprob": -0.1236356209064352, "compression_ratio": 1.8411552346570397, "no_speech_prob": 0.027216719463467598}, {"id": 471, "seek": 165966, "start": 1666.14, "end": 1671.98, "text": " to put a lot of work into understanding how it might go wrong, understanding how it might", "tokens": [50688, 281, 829, 257, 688, 295, 589, 666, 3701, 577, 309, 1062, 352, 2085, 11, 3701, 577, 309, 1062, 50980], "temperature": 0.0, "avg_logprob": -0.1236356209064352, "compression_ratio": 1.8411552346570397, "no_speech_prob": 0.027216719463467598}, {"id": 472, "seek": 165966, "start": 1671.98, "end": 1674.0800000000002, "text": " try and take control away.", "tokens": [50980, 853, 293, 747, 1969, 1314, 13, 51085], "temperature": 0.0, "avg_logprob": -0.1236356209064352, "compression_ratio": 1.8411552346570397, "no_speech_prob": 0.027216719463467598}, {"id": 473, "seek": 165966, "start": 1674.0800000000002, "end": 1679.26, "text": " And I think the government could maybe encourage the big companies developing it to put comparable", "tokens": [51085, 400, 286, 519, 264, 2463, 727, 1310, 5373, 264, 955, 3431, 6416, 309, 281, 829, 25323, 51344], "temperature": 0.0, "avg_logprob": -0.1236356209064352, "compression_ratio": 1.8411552346570397, "no_speech_prob": 0.027216719463467598}, {"id": 474, "seek": 165966, "start": 1679.26, "end": 1684.38, "text": " resources, maybe not equal resources, but right now there's 99 very smart people trying", "tokens": [51344, 3593, 11, 1310, 406, 2681, 3593, 11, 457, 558, 586, 456, 311, 11803, 588, 4069, 561, 1382, 51600], "temperature": 0.0, "avg_logprob": -0.1236356209064352, "compression_ratio": 1.8411552346570397, "no_speech_prob": 0.027216719463467598}, {"id": 475, "seek": 165966, "start": 1684.38, "end": 1688.3400000000001, "text": " to make it better and one very smart person trying to figure out how to stop it taking", "tokens": [51600, 281, 652, 309, 1101, 293, 472, 588, 4069, 954, 1382, 281, 2573, 484, 577, 281, 1590, 309, 1940, 51798], "temperature": 0.0, "avg_logprob": -0.1236356209064352, "compression_ratio": 1.8411552346570397, "no_speech_prob": 0.027216719463467598}, {"id": 476, "seek": 168834, "start": 1688.3799999999999, "end": 1689.3799999999999, "text": " over.", "tokens": [50366, 670, 13, 50416], "temperature": 0.0, "avg_logprob": -0.15289706718630908, "compression_ratio": 1.6853932584269662, "no_speech_prob": 0.3050392270088196}, {"id": 477, "seek": 168834, "start": 1689.3799999999999, "end": 1692.06, "text": " And maybe you want it more balanced.", "tokens": [50416, 400, 1310, 291, 528, 309, 544, 13902, 13, 50550], "temperature": 0.0, "avg_logprob": -0.15289706718630908, "compression_ratio": 1.6853932584269662, "no_speech_prob": 0.3050392270088196}, {"id": 478, "seek": 168834, "start": 1692.06, "end": 1697.1399999999999, "text": " And so this is in some ways your role right now, the reason why you've left Google on", "tokens": [50550, 400, 370, 341, 307, 294, 512, 2098, 428, 3090, 558, 586, 11, 264, 1778, 983, 291, 600, 1411, 3329, 322, 50804], "temperature": 0.0, "avg_logprob": -0.15289706718630908, "compression_ratio": 1.6853932584269662, "no_speech_prob": 0.3050392270088196}, {"id": 479, "seek": 168834, "start": 1697.1399999999999, "end": 1701.98, "text": " good terms, but you want to be able to speak out and help participate in this conversation", "tokens": [50804, 665, 2115, 11, 457, 291, 528, 281, 312, 1075, 281, 1710, 484, 293, 854, 8197, 294, 341, 3761, 51046], "temperature": 0.0, "avg_logprob": -0.15289706718630908, "compression_ratio": 1.6853932584269662, "no_speech_prob": 0.3050392270088196}, {"id": 480, "seek": 168834, "start": 1701.98, "end": 1704.6999999999998, "text": " so more people can join that one and not the 99.", "tokens": [51046, 370, 544, 561, 393, 3917, 300, 472, 293, 406, 264, 11803, 13, 51182], "temperature": 0.0, "avg_logprob": -0.15289706718630908, "compression_ratio": 1.6853932584269662, "no_speech_prob": 0.3050392270088196}, {"id": 481, "seek": 168834, "start": 1704.6999999999998, "end": 1705.6999999999998, "text": " Yeah.", "tokens": [51182, 865, 13, 51232], "temperature": 0.0, "avg_logprob": -0.15289706718630908, "compression_ratio": 1.6853932584269662, "no_speech_prob": 0.3050392270088196}, {"id": 482, "seek": 168834, "start": 1705.6999999999998, "end": 1708.6999999999998, "text": " I would say it's very important for smart people to be working on that.", "tokens": [51232, 286, 576, 584, 309, 311, 588, 1021, 337, 4069, 561, 281, 312, 1364, 322, 300, 13, 51382], "temperature": 0.0, "avg_logprob": -0.15289706718630908, "compression_ratio": 1.6853932584269662, "no_speech_prob": 0.3050392270088196}, {"id": 483, "seek": 168834, "start": 1708.6999999999998, "end": 1712.74, "text": " But I'd also say it's very important not to think this is the only risk.", "tokens": [51382, 583, 286, 1116, 611, 584, 309, 311, 588, 1021, 406, 281, 519, 341, 307, 264, 787, 3148, 13, 51584], "temperature": 0.0, "avg_logprob": -0.15289706718630908, "compression_ratio": 1.6853932584269662, "no_speech_prob": 0.3050392270088196}, {"id": 484, "seek": 168834, "start": 1712.74, "end": 1714.4199999999998, "text": " There's all these other risks.", "tokens": [51584, 821, 311, 439, 613, 661, 10888, 13, 51668], "temperature": 0.0, "avg_logprob": -0.15289706718630908, "compression_ratio": 1.6853932584269662, "no_speech_prob": 0.3050392270088196}, {"id": 485, "seek": 171442, "start": 1714.42, "end": 1718.7, "text": " And I've remembered the last one, which is fake news.", "tokens": [50364, 400, 286, 600, 13745, 264, 1036, 472, 11, 597, 307, 7592, 2583, 13, 50578], "temperature": 0.0, "avg_logprob": -0.16711826813526642, "compression_ratio": 1.6756756756756757, "no_speech_prob": 0.19523885846138}, {"id": 486, "seek": 171442, "start": 1718.7, "end": 1723.66, "text": " So it's very important to try, for example, to mark everything that's fake as fake, whether", "tokens": [50578, 407, 309, 311, 588, 1021, 281, 853, 11, 337, 1365, 11, 281, 1491, 1203, 300, 311, 7592, 382, 7592, 11, 1968, 50826], "temperature": 0.0, "avg_logprob": -0.16711826813526642, "compression_ratio": 1.6756756756756757, "no_speech_prob": 0.19523885846138}, {"id": 487, "seek": 171442, "start": 1723.66, "end": 1727.18, "text": " we can do that technically, I don't know, but it'd be great if we could.", "tokens": [50826, 321, 393, 360, 300, 12120, 11, 286, 500, 380, 458, 11, 457, 309, 1116, 312, 869, 498, 321, 727, 13, 51002], "temperature": 0.0, "avg_logprob": -0.16711826813526642, "compression_ratio": 1.6756756756756757, "no_speech_prob": 0.19523885846138}, {"id": 488, "seek": 171442, "start": 1727.18, "end": 1728.74, "text": " Governments do it with counterfeit money.", "tokens": [51002, 5515, 1117, 360, 309, 365, 5682, 37434, 1460, 13, 51080], "temperature": 0.0, "avg_logprob": -0.16711826813526642, "compression_ratio": 1.6756756756756757, "no_speech_prob": 0.19523885846138}, {"id": 489, "seek": 171442, "start": 1728.74, "end": 1734.8600000000001, "text": " They won't allow counterfeit money because that reflects on their sort of central interest.", "tokens": [51080, 814, 1582, 380, 2089, 5682, 37434, 1460, 570, 300, 18926, 322, 641, 1333, 295, 5777, 1179, 13, 51386], "temperature": 0.0, "avg_logprob": -0.16711826813526642, "compression_ratio": 1.6756756756756757, "no_speech_prob": 0.19523885846138}, {"id": 490, "seek": 171442, "start": 1734.8600000000001, "end": 1738.46, "text": " They should try and do it with AI-generated stuff.", "tokens": [51386, 814, 820, 853, 293, 360, 309, 365, 7318, 12, 21848, 770, 1507, 13, 51566], "temperature": 0.0, "avg_logprob": -0.16711826813526642, "compression_ratio": 1.6756756756756757, "no_speech_prob": 0.19523885846138}, {"id": 491, "seek": 171442, "start": 1738.46, "end": 1739.94, "text": " I don't know whether they can.", "tokens": [51566, 286, 500, 380, 458, 1968, 436, 393, 13, 51640], "temperature": 0.0, "avg_logprob": -0.16711826813526642, "compression_ratio": 1.6756756756756757, "no_speech_prob": 0.19523885846138}, {"id": 492, "seek": 173994, "start": 1739.94, "end": 1740.94, "text": " All right.", "tokens": [50364, 1057, 558, 13, 50414], "temperature": 0.0, "avg_logprob": -0.16619576348198783, "compression_ratio": 1.72992700729927, "no_speech_prob": 0.01682627573609352}, {"id": 493, "seek": 173994, "start": 1740.94, "end": 1741.94, "text": " So we're out of time.", "tokens": [50414, 407, 321, 434, 484, 295, 565, 13, 50464], "temperature": 0.0, "avg_logprob": -0.16619576348198783, "compression_ratio": 1.72992700729927, "no_speech_prob": 0.01682627573609352}, {"id": 494, "seek": 173994, "start": 1741.94, "end": 1746.5, "text": " Give one specific to-do, something to read, a thought experiment, one thing to leave", "tokens": [50464, 5303, 472, 2685, 281, 12, 2595, 11, 746, 281, 1401, 11, 257, 1194, 5120, 11, 472, 551, 281, 1856, 50692], "temperature": 0.0, "avg_logprob": -0.16619576348198783, "compression_ratio": 1.72992700729927, "no_speech_prob": 0.01682627573609352}, {"id": 495, "seek": 173994, "start": 1746.5, "end": 1750.3400000000001, "text": " the audience with so they can go out here and think, OK, I'm going to do this.", "tokens": [50692, 264, 4034, 365, 370, 436, 393, 352, 484, 510, 293, 519, 11, 2264, 11, 286, 478, 516, 281, 360, 341, 13, 50884], "temperature": 0.0, "avg_logprob": -0.16619576348198783, "compression_ratio": 1.72992700729927, "no_speech_prob": 0.01682627573609352}, {"id": 496, "seek": 173994, "start": 1750.3400000000001, "end": 1755.14, "text": " AI is the most powerful thing we've invented, and perhaps in our lifetimes, and I'm going", "tokens": [50884, 7318, 307, 264, 881, 4005, 551, 321, 600, 14479, 11, 293, 4317, 294, 527, 4545, 302, 1532, 11, 293, 286, 478, 516, 51124], "temperature": 0.0, "avg_logprob": -0.16619576348198783, "compression_ratio": 1.72992700729927, "no_speech_prob": 0.01682627573609352}, {"id": 497, "seek": 173994, "start": 1755.14, "end": 1760.18, "text": " to make it better to make it more likely it's a force for good in the next generation.", "tokens": [51124, 281, 652, 309, 1101, 281, 652, 309, 544, 3700, 309, 311, 257, 3464, 337, 665, 294, 264, 958, 5125, 13, 51376], "temperature": 0.0, "avg_logprob": -0.16619576348198783, "compression_ratio": 1.72992700729927, "no_speech_prob": 0.01682627573609352}, {"id": 498, "seek": 173994, "start": 1760.18, "end": 1762.46, "text": " So how could they make it more likely be a force for good?", "tokens": [51376, 407, 577, 727, 436, 652, 309, 544, 3700, 312, 257, 3464, 337, 665, 30, 51490], "temperature": 0.0, "avg_logprob": -0.16619576348198783, "compression_ratio": 1.72992700729927, "no_speech_prob": 0.01682627573609352}, {"id": 499, "seek": 173994, "start": 1762.46, "end": 1763.46, "text": " Yes.", "tokens": [51490, 1079, 13, 51540], "temperature": 0.0, "avg_logprob": -0.16619576348198783, "compression_ratio": 1.72992700729927, "no_speech_prob": 0.01682627573609352}, {"id": 500, "seek": 173994, "start": 1763.46, "end": 1766.8200000000002, "text": " One final thought for everyone here.", "tokens": [51540, 1485, 2572, 1194, 337, 1518, 510, 13, 51708], "temperature": 0.0, "avg_logprob": -0.16619576348198783, "compression_ratio": 1.72992700729927, "no_speech_prob": 0.01682627573609352}, {"id": 501, "seek": 176682, "start": 1766.82, "end": 1772.34, "text": " I actually don't have a plan for how to make it more likely to be good than bad, sorry.", "tokens": [50364, 286, 767, 500, 380, 362, 257, 1393, 337, 577, 281, 652, 309, 544, 3700, 281, 312, 665, 813, 1578, 11, 2597, 13, 50640], "temperature": 0.0, "avg_logprob": -0.10102236681971057, "compression_ratio": 1.679245283018868, "no_speech_prob": 0.035135168582201004}, {"id": 502, "seek": 176682, "start": 1772.34, "end": 1777.1399999999999, "text": " I think it's great that it's being developed because we didn't get to mention the huge", "tokens": [50640, 286, 519, 309, 311, 869, 300, 309, 311, 885, 4743, 570, 321, 994, 380, 483, 281, 2152, 264, 2603, 50880], "temperature": 0.0, "avg_logprob": -0.10102236681971057, "compression_ratio": 1.679245283018868, "no_speech_prob": 0.035135168582201004}, {"id": 503, "seek": 176682, "start": 1777.1399999999999, "end": 1782.1, "text": " numbers of good uses of it, like in medicine, in climate change, and so on.", "tokens": [50880, 3547, 295, 665, 4960, 295, 309, 11, 411, 294, 7195, 11, 294, 5659, 1319, 11, 293, 370, 322, 13, 51128], "temperature": 0.0, "avg_logprob": -0.10102236681971057, "compression_ratio": 1.679245283018868, "no_speech_prob": 0.035135168582201004}, {"id": 504, "seek": 176682, "start": 1782.1, "end": 1788.1799999999998, "text": " So I think progress in AI is inevitable and it's probably good, but we seriously ought", "tokens": [51128, 407, 286, 519, 4205, 294, 7318, 307, 21451, 293, 309, 311, 1391, 665, 11, 457, 321, 6638, 13416, 51432], "temperature": 0.0, "avg_logprob": -0.10102236681971057, "compression_ratio": 1.679245283018868, "no_speech_prob": 0.035135168582201004}, {"id": 505, "seek": 176682, "start": 1788.1799999999998, "end": 1792.3799999999999, "text": " to worry about mitigating all the bad side effects of it and worry about the existential", "tokens": [51432, 281, 3292, 466, 15699, 990, 439, 264, 1578, 1252, 5065, 295, 309, 293, 3292, 466, 264, 37133, 51642], "temperature": 0.0, "avg_logprob": -0.10102236681971057, "compression_ratio": 1.679245283018868, "no_speech_prob": 0.035135168582201004}, {"id": 506, "seek": 176682, "start": 1792.3799999999999, "end": 1793.3799999999999, "text": " threat.", "tokens": [51642, 4734, 13, 51692], "temperature": 0.0, "avg_logprob": -0.10102236681971057, "compression_ratio": 1.679245283018868, "no_speech_prob": 0.035135168582201004}, {"id": 507, "seek": 176682, "start": 1793.3799999999999, "end": 1794.3799999999999, "text": " All right.", "tokens": [51692, 1057, 558, 13, 51742], "temperature": 0.0, "avg_logprob": -0.10102236681971057, "compression_ratio": 1.679245283018868, "no_speech_prob": 0.035135168582201004}, {"id": 508, "seek": 179438, "start": 1794.38, "end": 1797.98, "text": " Thank you everyone, an incredibly thoughtful, inspiring, interesting, phenomenally smart.", "tokens": [50364, 1044, 291, 1518, 11, 364, 6252, 21566, 11, 15883, 11, 1880, 11, 9388, 379, 4069, 13, 50544], "temperature": 0.0, "avg_logprob": -0.3432999504937066, "compression_ratio": 1.368421052631579, "no_speech_prob": 0.8231546878814697}, {"id": 509, "seek": 179438, "start": 1797.98, "end": 1798.98, "text": " Thank you to Jeffrey Hinton.", "tokens": [50544, 1044, 291, 281, 28721, 389, 12442, 13, 50594], "temperature": 0.0, "avg_logprob": -0.3432999504937066, "compression_ratio": 1.368421052631579, "no_speech_prob": 0.8231546878814697}, {"id": 510, "seek": 179438, "start": 1798.98, "end": 1799.98, "text": " Thank you.", "tokens": [50594, 1044, 291, 13, 50644], "temperature": 0.0, "avg_logprob": -0.3432999504937066, "compression_ratio": 1.368421052631579, "no_speech_prob": 0.8231546878814697}, {"id": 511, "seek": 179438, "start": 1799.98, "end": 1800.98, "text": " Thank you, Jeff.", "tokens": [50644, 1044, 291, 11, 7506, 13, 50694], "temperature": 0.0, "avg_logprob": -0.3432999504937066, "compression_ratio": 1.368421052631579, "no_speech_prob": 0.8231546878814697}, {"id": 512, "seek": 179438, "start": 1800.98, "end": 1801.48, "text": " So great.", "tokens": [50694, 407, 869, 13, 50719], "temperature": 0.0, "avg_logprob": -0.3432999504937066, "compression_ratio": 1.368421052631579, "no_speech_prob": 0.8231546878814697}], "language": "en"}