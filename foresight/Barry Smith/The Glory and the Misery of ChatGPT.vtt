WEBVTT

00:00.000 --> 00:07.680
So I'm going to be talking about the book indeed, but I guess the most interesting part

00:07.680 --> 00:12.800
of what I have to say is about chat GPT, and so I changed the title.

00:12.800 --> 00:14.840
This is the book.

00:14.840 --> 00:18.520
The subtitle is Artificial Intelligence Without Fear.

00:18.520 --> 00:23.640
So we certainly don't need to be worried about the supposed fact that machines will one day

00:23.640 --> 00:25.320
rule the world.

00:25.720 --> 00:33.920
AI is a set of algorithms, of algorithms which belong to a certain kind of applied mathematics.

00:33.920 --> 00:36.000
And these algorithms are very good.

00:36.000 --> 00:37.520
They can do wonderful things.

00:37.520 --> 00:42.800
And the fear that people have, and we are aiming in the book to set aside this fear,

00:42.800 --> 00:48.800
is that one day there will be an algorithm of this sort which is able to provide an

00:48.800 --> 00:53.480
intelligence which surpasses the intelligence of human beings.

00:53.480 --> 01:00.520
And then once we have an AI algorithm like that, it would be able to write a new AI algorithm

01:00.520 --> 01:06.000
which would be even more intelligent, and then we have an explosion of ever more intelligent

01:06.000 --> 01:12.960
AIs, and eventually they would be able to use their intelligence to replace human beings

01:12.960 --> 01:17.320
and to rule the world or the galaxy or the whole universe in principle.

01:17.320 --> 01:18.720
This is nonsense.

01:18.720 --> 01:20.200
This will never happen.

01:20.280 --> 01:25.920
AI algorithms will be always much lower in intelligence than human beings.

01:25.920 --> 01:31.560
Indeed, they will never have intelligence like the intelligence of human beings, because

01:31.560 --> 01:37.600
they will always be what is called narrow AI, which means that they are intelligent only

01:37.600 --> 01:43.200
in relation to one specific activity, for instance, playing the game of Go, and they

01:43.200 --> 01:48.200
will never have the kind of general intelligence which we have and which would be needed to

01:48.200 --> 01:49.760
take over the world.

01:49.760 --> 01:53.240
So that's what we mean by artificial intelligence without fear.

01:53.240 --> 01:59.800
There will never be the singularity when AI explodes and becomes more intelligent and

01:59.800 --> 02:02.080
more powerful than we are.

02:02.080 --> 02:06.440
So this is another way of formulating the main theses of the book, which rests upon

02:06.440 --> 02:09.680
the mathematics of complex systems.

02:09.680 --> 02:15.720
Complex systems, and that means all systems involving organisms, your brain, your digestive

02:15.720 --> 02:20.360
system, you yourself, the system formed now by the people in this room.

02:20.360 --> 02:23.480
All of these complex systems have evolutionary properties.

02:23.480 --> 02:25.960
What that means is that they can change.

02:25.960 --> 02:32.120
They can acquire new elements, new types of elements, new types of interactions.

02:32.120 --> 02:38.480
And any model which can predict the behavior of a system breaks when you have new types

02:38.480 --> 02:41.320
of phase space, they say, in physics.

02:41.320 --> 02:45.000
We can't model complex systems mathematically.

02:45.000 --> 02:51.680
Therefore, we can't emulate such systems inside a computer that follows trivially.

02:51.680 --> 02:53.920
So this is the main thesis of the book.

02:53.920 --> 02:57.240
The main chapter is about the mathematics of complex systems.

02:57.240 --> 03:00.120
The rest of the book is about many things.

03:00.120 --> 03:03.180
It's about intelligence, which I'm going to talk about next.

03:03.180 --> 03:05.760
Human intelligence, what makes it special?

03:05.760 --> 03:11.840
It's about attempts to emulate human intelligence by means of modeling in some sense biologically

03:11.840 --> 03:12.840
the human brain.

03:12.840 --> 03:14.960
I'm going to talk about that.

03:15.680 --> 03:21.840
And then I'm going to focus my energies on chat GPT, which is, as I say, something glorious,

03:21.840 --> 03:25.800
but it's also really, really, really bad.

03:25.800 --> 03:28.640
And I'll try and prove that with some examples.

03:28.640 --> 03:35.280
So an example of a system which is changing its phase space is the system of creating

03:35.280 --> 03:43.120
spam, which is a system run by evil people whose life is devoted to creating these horrible

03:43.160 --> 03:45.280
things called spam.

03:45.280 --> 03:47.480
We can stop the spam using AI.

03:47.480 --> 03:51.720
We can build spam filters, which are narrow AI in two senses.

03:51.720 --> 03:58.320
One, they only filter out spam, but two, they only filter out spam of a sort and sort.

03:58.320 --> 04:03.280
And as soon as new types of spam come down the pipeline, then the spam filters won't

04:03.280 --> 04:04.280
work.

04:04.280 --> 04:09.560
And this is what I mean by the impossibility of predicting the future, predicting future

04:09.560 --> 04:11.240
behavior of a complex system.

04:11.240 --> 04:15.880
Even a complex system as familiar as the system of spam creation.

04:15.880 --> 04:17.080
All right.

04:17.080 --> 04:23.240
So AI is always limited to simple systems in a technical sense.

04:23.240 --> 04:31.000
So an AI algorithm like chat GPT is a huge mathematical polynomial function with billions

04:31.000 --> 04:32.320
of parameters.

04:32.320 --> 04:40.920
Google Translate is not based upon those complex systems which are human languages.

04:40.920 --> 04:48.720
It's based on a frozen set of data, a corpus taken from the 96 or so human languages which

04:48.720 --> 04:51.160
Google Translate translates.

04:51.160 --> 04:55.720
And that corpus is then turned into a simple system.

04:55.720 --> 05:03.040
And then Google Translate uses very large algorithms to create polynomial functions

05:03.040 --> 05:08.240
which can take an input in German and yield an output in English.

05:08.240 --> 05:14.200
And that's a mathematical application to binary vectors made up of zeros and ones which can

05:14.200 --> 05:19.360
be translated as English sentences and binary vectors made up of zeros and ones which can

05:19.360 --> 05:22.320
be translated as German sentences.

05:22.320 --> 05:24.120
Google Translate is dumb.

05:24.120 --> 05:27.480
It doesn't know anything about meaning or semantics.

05:27.480 --> 05:29.560
It doesn't know what it's talking about.

05:29.560 --> 05:34.080
It just performs a certain mathematical calculation.

05:34.080 --> 05:39.200
Simply rather simple because it has to compute inside a Turing machine which is a relatively

05:39.200 --> 05:45.040
simple kind of environment but incredibly long as an algorithm which explains why it's

05:45.040 --> 05:47.520
able to perform such impressive feat.

05:47.520 --> 05:49.960
So there is glory to Google Translate.

05:49.960 --> 05:54.680
I think Google Translate is fantastic but it's not going to take over the world or anything

05:54.680 --> 05:55.680
like that.

05:55.680 --> 05:56.680
All right.

05:56.680 --> 05:57.680
Now how does this work?

05:57.680 --> 06:02.040
How does an algorithm like Google Translate work?

06:02.040 --> 06:07.680
Well many people think that all you need is enough training data and then these things

06:07.680 --> 06:17.280
called deep neural networks can be trained to use statistics in order to predict patterns

06:17.280 --> 06:20.000
in those large bodies of data.

06:20.000 --> 06:25.520
But this isn't quite right and even a lot of people in the AI world don't appreciate

06:25.520 --> 06:31.920
this shortfall in the idea that all we need is mere quantity of data.

06:31.920 --> 06:38.880
What we need is to be able to sample data which has a variance which is the same as

06:38.880 --> 06:40.400
the target data.

06:40.400 --> 06:46.000
So if we're going to take the sample data and use it to predict patterns in the target

06:46.000 --> 06:53.040
data then the sample data has to be statistically like, it has to be a typical sample in other

06:53.040 --> 06:55.400
words, like the target data.

06:55.400 --> 06:58.880
It must be representative of the target data.

06:58.880 --> 07:03.200
So what that means is that it has to have the same distribution of the target data and

07:03.200 --> 07:06.600
this is the bell curve which is the simplest kind of distribution.

07:06.600 --> 07:12.600
There are other kinds of distribution but the data you have has to have the same distribution

07:12.600 --> 07:16.600
as the target data you're applying to and that's what Google Translate does.

07:16.600 --> 07:23.200
It takes samples from all the world's languages and it is able to take them as representative

07:23.200 --> 07:28.120
of the patterns in this frozen corpus that they use as a starting point.

07:28.120 --> 07:32.360
Now there are target domains where there is no distribution and so there is no way in

07:32.360 --> 07:35.160
which we can get representative sample data.

07:35.160 --> 07:41.160
So this is true in an emergency room in a hospital in a big city.

07:41.160 --> 07:45.320
You just can't predict how much blood will be needed or how many beds will be needed

07:45.320 --> 07:49.360
or how many doctors will be needed even an hour ahead.

07:49.360 --> 07:51.960
But it's true also of any conversation.

07:51.960 --> 07:56.320
You can't predict what your conversation partner will say next.

07:56.360 --> 07:59.200
Alright so this is an overview of what I'm going to talk about.

07:59.200 --> 08:04.760
First of all I'm going to talk about human intelligence, actually animal and human intelligence.

08:04.760 --> 08:10.520
Then I'm going to talk about the real reason why computers will never take over the world

08:10.520 --> 08:16.560
which is the fact that they will never want to take over the world because algorithms can't

08:16.560 --> 08:17.560
want.

08:17.560 --> 08:20.040
They can only do what you tell them to do.

08:20.040 --> 08:26.200
Then I'll talk a little bit about Nick Bostrom and his idea that we can build a super-intelligent

08:26.200 --> 08:31.480
AI algorithm by emulating the whole brain of the human being.

08:31.480 --> 08:38.320
And then finally I'll talk about the really funny story of chat GPT.

08:38.320 --> 08:46.680
Alright so the big difference between organisms and simple systems is in one word it's thermodynamics.

08:46.680 --> 08:52.760
So in other words it's a matter of physics which involves energy and we and all animals

08:52.760 --> 08:58.200
survive because we have the drive to acquire energy from the environment.

08:58.200 --> 09:02.600
Now we humans do this in a very complicated way involving things like supermarkets and

09:02.600 --> 09:08.120
farms but every animal has a way of sucking energy out of the environment.

09:08.120 --> 09:10.480
Every plant does this with the sun.

09:10.480 --> 09:12.480
Even computers are driven in a certain sense.

09:12.480 --> 09:18.080
They take energy from the environment but only because we give it to them and no one

09:18.080 --> 09:19.520
gives us energy.

09:19.520 --> 09:22.600
No one gives animals energy we have to go and find it ourselves.

09:22.600 --> 09:30.120
If there is a surface of energy in our environment, in the ancestral environment of human beings

09:30.120 --> 09:36.760
then we become obese because we like eating and so we keep eating and this eventually

09:36.760 --> 09:41.240
will mean that we will eat so much that we use up all the energy in the environment and

09:41.240 --> 09:43.240
then we die.

09:43.240 --> 09:51.360
So gradually we moved out of the areas of the world where there was lots of food into

09:51.360 --> 09:57.040
areas of the world which were cold and barren and so we had to find ways of surviving in

09:57.040 --> 09:59.720
much harsher environments.

09:59.720 --> 10:08.200
That's why through a long series of faltering steps we created civilization, police, armies

10:08.200 --> 10:13.560
all the other things which make it possible for us to survive in a world where we are

10:13.560 --> 10:20.880
competing with other groups for limited food supplies.

10:20.880 --> 10:26.480
What civilization does, what social norms do is channel the excess dry which human beings

10:26.480 --> 10:27.480
have.

10:27.480 --> 10:34.320
In other words we become more rational and less instinctive.

10:34.320 --> 10:43.200
But we are still always seeking for energy but now because we have found ways of solving

10:43.200 --> 10:47.160
the energy problem through supermarkets and farms and so on.

10:47.160 --> 10:53.920
We can do other things, we can build orchestras, we can go to talks about chat GPT, we can

10:53.920 --> 10:59.360
play with chat GPT, we can watch the traffic through the window, we're always doing something.

10:59.360 --> 11:03.880
We're doing one damn thing after another and that's the same with animals too.

11:03.880 --> 11:09.760
We never stop, there's no tendency towards equilibrium.

11:09.760 --> 11:18.640
As long as we're alive we are doing one damn thing after another so no convergence on equilibrium.

11:18.640 --> 11:25.160
This is thermodynamically remarkable that there are entities on the planet which are

11:25.160 --> 11:33.440
decreasing entropy by taking energy out of the environment and replacing it with cathedrals

11:33.480 --> 11:37.800
or with airplanes or supermarkets.

11:37.800 --> 11:46.880
Now so as we go through life not approaching any equilibrium we are constantly changing

11:46.880 --> 11:51.480
our state, changing the phase space.

11:51.480 --> 11:56.120
So if we're in an orchestra and we're under the command of the conductor we have one phase

11:56.120 --> 12:03.400
space but then suddenly we have a pain in our arm and we run outside and go to the doctor

12:03.400 --> 12:08.000
because we think there's something wrong with our arm and we're in another phase space.

12:08.000 --> 12:13.560
Any kind of change like that and such changes happen all the time would break any kind of

12:13.560 --> 12:22.400
predictive machine because predictive machines have to use mathematical equations of a mathematically

12:22.400 --> 12:28.480
rather simple sort and they can't cope with multiple ever-changing phase spaces.

12:28.480 --> 12:34.440
This is if you want to predict the behavior of an entity where you have a Cartesian coordinate

12:34.440 --> 12:40.320
system telling you what its behavior is but then suddenly it changes the behavior so that

12:40.320 --> 12:44.200
you need a further dimension and a different coordinate system.

12:44.200 --> 12:50.600
Your predictive attempt would fail because you've changed the phase space.

12:50.600 --> 12:54.440
Alright now there are in fact three kinds of drivenness.

12:54.440 --> 13:01.040
There's animate drivenness which is organisms, animals and humans particularly.

13:01.040 --> 13:09.200
There is inanimate drivenness so the tides take energy from the moon I guess and the

13:09.200 --> 13:12.720
whole earth takes energy from the sun.

13:12.720 --> 13:18.080
Machines get energy given to them so we give coal to the steam engine, we give electricity

13:18.080 --> 13:19.920
to the computer.

13:19.920 --> 13:25.760
This is external drivenness and external drivenness means that the external supplier of energy

13:25.760 --> 13:29.840
which is typically a human being is in control of the machine.

13:29.840 --> 13:34.320
That's another reason why machines will never rule the world.

13:34.320 --> 13:41.360
Alright so we have natural drivenness and artificial drivenness and artificial drivenness

13:41.360 --> 13:45.240
means steam engines, laptops, tanks and so on.

13:45.240 --> 13:47.760
Ice drivenness depends on human drivenness.

13:47.760 --> 13:50.960
We want to have the steam engine do something for us.

13:50.960 --> 13:56.280
If it's not doing anything for us we're not going to feed it energy anymore and that's

13:56.280 --> 13:58.400
what happens.

13:58.400 --> 14:05.120
So somebody forgot to maintain this entity and so we don't need to supply it with energy

14:05.120 --> 14:08.960
anymore.

14:08.960 --> 14:14.120
And this is how Schrodinger expresses this matter.

14:14.120 --> 14:18.840
Now of course eventually we do not escape the decay to equilibrium, there comes a point

14:18.840 --> 14:23.480
where we go over the cliff and then we're dead jack.

14:23.480 --> 14:28.360
But until then it's one damn thing after another.

14:28.360 --> 14:34.440
Alright now so machines need energy from the environment and they create energy.

14:34.440 --> 14:40.120
So a computer if it's switched on but not being used is a heater, it's giving off heat

14:40.120 --> 14:45.360
and this is another reason why what we're talking about now is thermodynamics.

14:45.360 --> 14:52.000
And this aspect of computers is often neglected but it's another factor in the question whether

14:52.000 --> 14:54.400
computers would ever take over the world.

14:54.400 --> 15:01.480
So we already know that the crypto coin industry is using significant amounts of energy, significant

15:01.480 --> 15:04.800
fractions of the energy which humans need to live.

15:04.800 --> 15:10.680
If we have computers of anything like the power that people conceive then there would

15:10.680 --> 15:17.560
be an energy problem and that would mean that this power would be reduced one way or another.

15:17.560 --> 15:22.480
But of course we'll never get even near there.

15:22.480 --> 15:26.640
We will never see even the attempt to take over the world by machines because they cannot

15:26.640 --> 15:28.480
want anything.

15:28.480 --> 15:35.560
Alright so we produce energy storing molecules called ATP from the sun and from food and

15:35.560 --> 15:40.880
so forth and then we use that energy to survive and reproduce and to do all the things that

15:40.880 --> 15:46.160
we do such as wave our arms when we're speaking and things like that.

15:46.160 --> 15:48.920
Now we come to intelligence.

15:48.920 --> 15:59.040
So primal intelligence we find in both animals and humans.

15:59.040 --> 16:04.560
And then there is a kind of intelligence that we call objectifying which is exclusive to

16:04.560 --> 16:10.440
humans and which is the reason why we're able to build supermarkets and farms and airports

16:10.440 --> 16:17.760
and all of those other things that enable us to do more than survive.

16:17.760 --> 16:24.800
So primal intelligence is what animals do when they're in their ancestral environments

16:24.800 --> 16:27.920
and they're acquiring food.

16:27.920 --> 16:30.600
If there is food around then they just use it.

16:30.600 --> 16:35.360
If they have to go chasing food, finding food because their available resources have been

16:35.360 --> 16:41.680
used up then they have to still use their primal intelligence but they have to use their

16:41.680 --> 16:46.960
primal intelligence in order to find new food which means they need at least two aspects

16:46.960 --> 16:50.280
of intelligence which plants don't have.

16:50.280 --> 16:56.160
One is they need to have conscious perception because they need to be able to identify new

16:56.160 --> 17:03.880
food as food rather than as something which looks like food but which is in fact poison

17:03.880 --> 17:08.400
or are just an accident of similarity of shape.

17:08.400 --> 17:16.920
And so they display ever more powerful versions of primal intelligence as they become more

17:17.920 --> 17:23.720
complicated, more ambitious in their attempts to find new food and eventually they go hunting

17:23.720 --> 17:30.600
in teams and then they develop a crude or language, a proto language to organize the

17:30.600 --> 17:34.240
other members of the team so that they know what's going on when they're hunting large

17:34.240 --> 17:36.680
animals for instance.

17:36.680 --> 17:42.560
And so they become to some degree adaptive but always within the ancestral environment.

17:42.560 --> 17:47.280
The adaptiveness is their ability to find new food and of course if they fail to find

17:47.280 --> 17:54.960
new food then they're dead and this applies to all kinds of animals from parrots to humans

17:54.960 --> 18:00.320
in the ancestral state.

18:00.320 --> 18:06.240
So we don't learn primal intelligence, it's innate, it's instinct and the characteristic

18:06.240 --> 18:12.400
of human beings is that they have abandoned, they've lost most of their instincts and instead

18:12.400 --> 18:17.280
we have civilization, we have social norms, social control and so on.

18:17.280 --> 18:26.360
And it's a marker for intelligence in the sense that it doesn't act by trial and error

18:26.360 --> 18:35.240
or by, I don't know, some alternative to trial and error which would involve checking samples,

18:35.240 --> 18:36.760
it's immediate.

18:36.760 --> 18:40.600
As soon as they see something which looks like food immediately they know that that could

18:40.600 --> 18:46.720
be food and the typical characteristic feature of something's being intelligent is that it's

18:46.720 --> 18:50.640
a response which happens immediately.

18:50.640 --> 18:57.640
Alright so these are the features of primal intelligence and so you can't train anything

18:57.640 --> 19:01.880
to have it, either it has it or doesn't or it doesn't.

19:01.880 --> 19:07.000
And non-human animals have just the goals of their ancestral environment to find food

19:07.000 --> 19:13.640
in that environment, to survive when competitors try and steal the food so they have the ability

19:13.640 --> 19:20.440
to fight or the ability to flee and they ignore everything which is not responding to their

19:20.440 --> 19:23.120
biological needs.

19:23.120 --> 19:30.880
Their world is just that which is relevant to eating, fighting, fleeing and so forth.

19:30.880 --> 19:35.760
Now higher animals, as I've already said, can develop something like a proto-language

19:35.800 --> 19:41.840
so birds have elaborate signalling systems for instance.

19:41.840 --> 19:46.840
Many animals have developed elaborate tracking skills for seeking the food which they need

19:46.840 --> 19:55.320
in order to survive and they've even developed something like wanting so they want to find

19:55.320 --> 19:57.960
food when they're hungry.

19:57.960 --> 20:03.640
But it's always within the ancestral environment so they don't build new kinds of buildings

20:03.640 --> 20:12.600
because they don't build buildings really and that's the big difference of course when

20:12.600 --> 20:17.560
we move to the case of humans.

20:17.560 --> 20:22.360
So we had to survive in tough environments that meant that we had to go outside our ancestral

20:22.360 --> 20:27.880
environment which means that we had to abandon practically all of the instincts that kept

20:27.880 --> 20:32.920
us alive in the ancestral environment and work out new ways of living.

20:32.920 --> 20:38.000
And that meant that we had to develop things like curiosity but we had to develop other

20:38.000 --> 20:49.720
kinds of capabilities and one way of grouping these capabilities so everything I've said

20:49.720 --> 20:57.400
so far is pretty standard but the term objectifying intelligence is a new term which we formulated

20:57.400 --> 21:03.560
in response to Husserl's way, I'm switching suddenly to philosophy, of understanding the

21:03.560 --> 21:06.560
way language and the mind works.

21:06.560 --> 21:13.760
So he talks about objectifying acts and what he means by is acts directed towards objects

21:13.760 --> 21:18.640
typically other people but it might also be things like tables chairs or it might be things

21:18.640 --> 21:25.120
in the future or in the past things which are distant in each case we have this objectifying

21:25.120 --> 21:33.640
intelligence and for humans this goes beyond any biological need, it can extend towards

21:33.640 --> 21:40.480
the future, it can extend towards the opera, it can extend towards the planet Mars independently

21:40.480 --> 21:46.760
of any biological need which is the reverse situation from what we find among animals.

21:46.760 --> 21:51.560
So we're moving into new kinds of contexts all the time, we're able to keep track of

21:51.560 --> 21:56.840
objects as we move from one context to another or we're able to switch targeting completely

21:56.840 --> 22:04.440
to a new set of objects and a new set of norms and so forth and this happens sometimes in

22:04.440 --> 22:11.600
a given in a single conversation so that reminds me of what we were talking about last Christmas

22:11.600 --> 22:17.040
about the rotten cheese that had made me so sick just before the Covid panic started.

22:17.040 --> 22:23.560
We jumped around in just one longish part sentence between multiple context you all

22:23.560 --> 22:29.400
follow what I was referring to even though you've never heard this I'm not sure now

22:29.400 --> 22:33.760
what would happen if I fed this into chat GPT.

22:33.760 --> 22:41.400
So there's no Markov property here one of the reasons why computers are not able to predict

22:41.400 --> 22:46.800
the future in a realm like human conversation is because human conversations don't have

22:46.800 --> 22:53.440
the Markov property and our mathematical resources to model processes nearly always

22:53.440 --> 22:59.120
rely on the Markov property that's missing.

22:59.120 --> 23:04.720
Alright so how did objectifying intelligence evolve the answer is over millions of years

23:04.720 --> 23:13.960
and certain parts of it I can talk about here so one important part I've already mentioned

23:14.320 --> 23:18.520
because we have these proto languages and eventually have language in its fully formed

23:18.520 --> 23:25.160
state we can engage in all kinds of shared agency so we can plan on going to the moon

23:25.160 --> 23:31.800
or we can build a cathedral or we can well we started by building walls to keep us safe

23:31.800 --> 23:38.040
against our enemies building a wall like that involved some considerable shared agency at

23:38.080 --> 23:44.720
that time and this is one of the oldest five walls on earth on top by Google I guess I

23:44.720 --> 23:51.040
could chat chat GPT to alright so these are some of the marks of objectifying intelligence

23:51.040 --> 23:57.320
and I'll go through this quite quickly so as I say it doesn't depend upon our biological

23:57.320 --> 24:01.520
state you can move in any cultural world you can move in the world of mathematics you can

24:01.520 --> 24:09.480
move in the world of plant biology it's completely open and it involves categorical thinking

24:09.480 --> 24:16.640
already from infancy so children can recognize categories they have an infant metaphysics

24:16.640 --> 24:22.360
and we have a world model which is built out of these categories and the relations between

24:22.360 --> 24:28.760
objects in different categories for instance the causal relations but then also the relations

24:28.760 --> 24:33.240
having to do with ethics for instance that if you bump into a chair you don't need to

24:33.240 --> 24:38.680
apologize to the chair but if you bump into a human being you probably need to apologize

24:38.680 --> 24:46.640
and we have a theory of mind or inter subjectivity so you are all objects I am an object for you

24:46.640 --> 24:55.120
I can also be an object for myself in being an object for me under the category of person I

24:55.360 --> 25:01.360
appreciate automatically without reasoning about it that you have beliefs and desires and so

25:01.360 --> 25:10.400
forth we can plan so objectifying intelligence allows us to plan for the future and we can

25:10.400 --> 25:21.200
plan together to build an airport or a moon landing or whatever it might be and then finally a

25:21.360 --> 25:27.840
feature of objectifying intelligence is that while we typically target objects that we believe to

25:27.840 --> 25:35.120
exist we can cancel belief and we can imagine and we do that when we plan when we have ambitious

25:35.120 --> 25:39.760
plans we plan going beyond the planet earth but we can also do it when we're writing fiction

25:40.560 --> 25:46.400
and this is this is an ability way way beyond anything which animals have chat gpt has this

25:46.960 --> 25:53.760
ability it but it doesn't need to suspend belief because it doesn't have any belief in the in

25:53.760 --> 26:02.800
the beginning it can mimic writing imaginative texts and then we once we build these new environments

26:02.800 --> 26:10.240
we can live in them culturally including in scientific environments so we can build an

26:10.240 --> 26:15.600
environment to serve a certain purpose for instance studying disease or whatever it might be

26:16.640 --> 26:23.120
all right now we come to the missing a i will and we'll talk a little bit about my hero nick

26:23.120 --> 26:30.160
bostrom who wrote a book called superintelligence in this book he says all philosophers should

26:30.160 --> 26:40.320
give up their job and work with him to prevent the singularity and this we this is a rational act

26:40.320 --> 26:47.760
because once a i become superintelligent it will be able to do better philosophy than we can do now

26:47.760 --> 26:56.320
anyway so preventing the intelligence well anyway you get the idea so now he thinks that

26:56.320 --> 27:04.080
this singularity could exist and that there is a ticking time bomb which is the a i this chat gpt

27:04.080 --> 27:09.920
plotting to take over the world it's already ticking and we don't know how far away we are from

27:09.920 --> 27:17.840
the great cataclysmic events when a i will machines will join together and and take over

27:17.840 --> 27:25.360
the universe but he worries a lot about it and the problem is as i say that computers can't want

27:26.080 --> 27:31.760
and so they can't want to take over the world they do not have a will now bostrom talks quite a

27:31.760 --> 27:38.160
bit about goals of machines in his book but he never explains how computers can have goals

27:39.040 --> 27:47.840
what he does is refer to this man yudkowski who i understand does good work in a i ethics

27:49.280 --> 27:57.120
and so and he apologizes he refers to yudkowski's work on the machine will but he wants to distance

27:57.120 --> 28:01.680
himself because he appreciates that it's not really quite clear what yudkowski is trying to say

28:02.480 --> 28:08.800
and you can decide for yourself so this is what he says it you will notice that he doesn't tell us

28:08.800 --> 28:15.440
how a goal system will come into existence he just tells us about what a goal system is like

28:16.080 --> 28:20.560
and he tells us only about the goal system goal system that he himself would like

28:21.520 --> 28:27.040
not about the goal system which a machine if it could have goals which of course it can't

28:27.120 --> 28:33.680
so it's a goal system containing only decisions super goals in and beliefs with all sub goal

28:33.680 --> 28:38.960
content being identical with beliefs about which events are predicted to lead to other events

28:38.960 --> 28:46.000
and all desirability being identical with with leads to supergoldness if you can understand that

28:46.000 --> 28:52.640
then you're a better man or woman than i i have no idea what he's talking about and that's why

28:52.640 --> 28:58.960
bostrom apologized because he didn't have any idea and he goes on like this so the content of this

28:58.960 --> 29:06.800
goal system is our wish if we knew more thought faster were more people we wished we were had

29:06.800 --> 29:13.600
drawn up further together where the extrapolation converges and so on it's complete i don't understand

29:13.680 --> 29:22.560
what it is and it goes on so now why is a machine will and bostrom did not find a

29:22.560 --> 29:26.560
count of a machine well i don't believe that there is a good account of how a machine could have a

29:26.560 --> 29:33.600
will outside the cases i'm going to talk about in in talking about charting pt later on there is

29:33.600 --> 29:41.840
something like a will that i will explain in a minute so without a will the machine could never

29:41.840 --> 29:48.000
become an autonomous agent and if it can never become an autonomous agent then it can never

29:48.000 --> 29:54.720
pursue goals and if it's not autonomous it can never be either moral or immoral you can only

29:54.720 --> 29:59.600
be moral if you can take responsibility for your actions and you can only take responsibility if you

29:59.600 --> 30:05.360
will them if we will them which is what we would do in writing the software they're not your goals

30:05.360 --> 30:13.200
and you look you do not have a will you're just following our will so how do we understand the

30:13.200 --> 30:18.880
human will now here i'm going to do some more philosophy this is a man called max sheila who

30:18.880 --> 30:25.360
was a very influential philosopher the turn of the last century and one of his students with

30:25.360 --> 30:31.920
edith stein who is one of the i wanted to say father figures but i guess i should say mother

30:31.920 --> 30:40.080
figures of feminine of female philosophy who was also a saint so she died in auschwitz and

30:41.120 --> 30:48.960
was canonized and he was a saint too oh he's a saint both of them were very

30:48.960 --> 30:55.040
influent very much influenced by max sheila he whitey was habity tats jaunschlift is about

30:55.040 --> 31:01.280
max sheila's word it's also about thomas equinas of course but it's about sheila primarily and

31:01.280 --> 31:07.680
this is rather an amazing feat for a teacher to have two of his students become canonized

31:09.200 --> 31:15.920
and but so but sheila is interesting for other reasons so this is his big book about ethics

31:16.560 --> 31:22.160
and basically he distinguishes ethics into two categories first of all there's formal ethics

31:22.160 --> 31:28.400
which is cant and the like where you have imperatives that you have to follow and they are

31:28.400 --> 31:34.640
to be followed on the basis of rational arguments and then you have sheila's own version of ethics

31:34.640 --> 31:42.000
which he calls material ethics which is based on feelings value feelings every normal person

31:42.000 --> 31:46.000
experiences value feelings all the time even if it's just thirst

31:46.000 --> 31:59.840
but there are some people psychopaths who are value blind and so sheila on this basis

31:59.840 --> 32:07.280
tries to give an account of the will and his example is a rescue scenario where a man sees

32:07.280 --> 32:14.080
a drowning child and jumps in to rescue the child so it's a perfectly general account of the will

32:14.080 --> 32:20.000
and it could be applied also if you're playing chess the decision to move your night in a certain

32:20.000 --> 32:27.360
direction would fit his schema for what the will is like and so this is the chess scenario

32:28.080 --> 32:33.760
i'm going to talk about the jumping in scenario it consists of four stages but we're only going

32:33.760 --> 32:39.040
to talk about two of them there's a fifth stage where you do actually jump in but this is what

32:39.040 --> 32:46.880
is involved in the will to jump in and more precisely the act of will takes place at the end

32:46.880 --> 32:52.560
here and that there is uh i'll give you a picture in a minute so you see the drowning child it's not

32:52.560 --> 32:58.240
just perception you also begin to have value feelings you feel that there is something which

32:58.240 --> 33:06.880
needs to be done here you might call that a moral affordance and then you draw the value consequence

33:07.600 --> 33:13.360
in the sense that you you you watch the child you realize that she's going to drown and you

33:13.360 --> 33:20.720
realize that this would be a bad thing and then you decide to act now this is this is a complex

33:20.720 --> 33:28.720
phenomenon making a decision so you decide to jump in to save the child and this decision is

33:28.720 --> 33:35.040
based on knowing that you can swim that you can swim well enough in the current to save the child

33:35.120 --> 33:39.200
you have enough time to save the child so this part of the deciding is kind of

33:39.200 --> 33:48.000
rational part combined with value feelings but there are other parts so 3a is forming an intention

33:48.640 --> 33:55.520
to save the child and to view the child as worth saving something that ought to be preserved

33:57.040 --> 34:03.040
and then part of the decision making process is delivering how to how to perform the rescue

34:03.680 --> 34:11.520
but then the important part is resolving to take that course of action and here we're dealing with

34:11.520 --> 34:18.880
something which is a physiological change in the brain and that physiological change in the brain

34:19.840 --> 34:25.600
is it starts you off it starts you moving so it's an act of will which has a real consequence

34:25.600 --> 34:31.440
or rather it's one side of an act of will because you have to have a physiological change also which

34:31.440 --> 34:43.280
triggers the bodily movement so 3c the final very very tiny sliver of your deciding process when you

34:43.280 --> 34:50.320
actually resolve to take the course of action in the full sense that your body starts moving

34:50.320 --> 34:56.240
is practically just the other side of the coin from your body sending signals to your feet

34:56.240 --> 35:03.280
that they need to start running and so we can see this roughly as taking this shape you have something

35:03.280 --> 35:12.480
going on in the brain up here and you have something going on in the arm down here as your you move

35:12.480 --> 35:21.600
out towards a swim I guess I should have taken feet here and that whole thing then is the is the

35:21.600 --> 35:29.520
act of will it's a combination of a very very rapid triggering event in the brain and a very

35:29.520 --> 35:34.240
very rapid signaling event to the relevant part of the body where the triggering event still has

35:34.240 --> 35:40.720
something rational about it now we know very little about the brain and we can't predict any

35:40.720 --> 35:46.320
practically speaking we can't predict any of this and so we can't emulate it in a machine or in an

35:46.320 --> 35:54.480
algorithm and so we can't describe it mathematically and you can check by looking in textbooks of

35:54.480 --> 36:00.640
neurophysiology there's very little in the way of mathematics all right now why is human well

36:00.640 --> 36:05.360
so important well because of hunting and all of those important things which kept us alive during

36:05.360 --> 36:10.240
the eight million years when we were involving ourselves evolving ourselves to a present to

36:10.240 --> 36:16.480
present state now hunting involves tracking and tracking is really difficult and that's because

36:16.480 --> 36:23.040
as you hunt the tiger the tiger is responding to you changing your environment as you change

36:23.040 --> 36:30.320
his environment hiding behind trees performing tricks I don't know what tigers do but all the time

36:30.320 --> 36:37.200
that you're moving around targeting the the tiger you're changing your face space and if you try to

36:37.200 --> 36:44.320
do that with stationary sensors sending one-dimensional signals to a machine you'll get nowhere you will

36:44.320 --> 36:50.640
never be able to hunt a lion a tiger and and we have a section of the book which describes

36:50.640 --> 36:56.080
mathematically why something like tracking an animal or tracking a human being in a forest

36:56.080 --> 37:01.280
or something is going to be way beyond the power of a computer so you have to spot the man with the

37:01.280 --> 37:11.600
gun say he's well he's here and he has to spot the the bird that he's going to shoot and keep track

37:11.600 --> 37:17.200
of the bird all right now the other reason why human well is so important there are many reasons

37:17.200 --> 37:23.760
i'm just going to talk about two of them this is the second one conversation human conversation as

37:23.760 --> 37:32.720
we saw is unpredictable how do we manage human conversation chat box created for bank telephone

37:32.720 --> 37:39.280
conversation with customers after 50 years are still now i want to say crap but i wouldn't say

37:39.280 --> 37:47.920
crap in it polite audience they're not not good 50 years why because conversation is really hard

37:47.920 --> 37:54.800
it's harder than tracking a lion and the the the reason why it's hard is because conversations

37:54.800 --> 38:00.080
rely on context so much and there are many different kinds of contexts including multiple

38:00.080 --> 38:07.040
contexts in a single conversation as you talk about oh how bad it was in the covid era and so

38:07.040 --> 38:14.080
you can shift the the context i just did now i've shifted the context to be about this particular

38:14.800 --> 38:21.680
it's not really a conversation it's a one-sided harangue but um i'm now making what i'm saying

38:22.240 --> 38:30.400
the context for what i'm saying and i just made the that context the context anyway um so our

38:30.400 --> 38:37.360
goals will change but we always have goals it's the goals which keep the conversation alive my

38:37.360 --> 38:43.280
goal is to convince you of certain things that's why i'm becoming so involved and that's some of

38:43.360 --> 38:49.040
you may be becoming involved and we'll respond later i hope so that's what keeps conversation

38:49.040 --> 38:53.520
alive everybody has goals their goals evolve through the conversation but without goals there

38:53.520 --> 39:00.880
would be no conversation chat gpt has no goals well actually that's not quite true i will explain

39:00.880 --> 39:08.240
in what sense chat gpt has a goal in a minute so how can you build a general intelligence a

39:08.240 --> 39:14.880
machine intelligence that can do any of this um so the will will not arise by itself some people

39:14.880 --> 39:20.240
claim that if you put all the computers together in a big internet system it will somehow evolve a

39:20.240 --> 39:27.520
will that's just it's happy talk and you can't program a goal system not even you kowski can

39:27.520 --> 39:33.680
program a goal system we can in some cases if you want to win at the game of go you can program a

39:33.680 --> 39:40.160
goal system you can't program a goal system to win a conversation and if you don't believe me try it

39:40.160 --> 39:47.760
with your spouse makes heaps core of each step in a conversation see who wins it will not work

39:49.280 --> 39:58.400
all right so what are the proposed methods uh to i think i'm near 45 minutes is that correct

39:58.400 --> 40:05.280
but that's fine just it's interesting okay um well that's good to hear all right so the old way of

40:05.280 --> 40:10.880
doing ai was expert systems based on logic then came stochastic systems which are based on statistics

40:10.880 --> 40:16.800
which we've been talking about that's chat gpt boss room have this idea of whole brain emulation

40:16.800 --> 40:24.240
i think i'm going to skip that um because it's full of nonsense uh that is the the the the funny

40:24.240 --> 40:31.360
chapter in the book and i'll give you just one joke um which is not me it's boston and he didn't

40:31.360 --> 40:36.560
realize it was funny and then we will have we won't talk about artificial life at all we'll go

40:36.560 --> 40:41.920
straight to chat gpt so this is the most boston's book and he thought that you could scan the brain

40:43.360 --> 40:47.680
the problem with that is that to scan the brain you need to kill the patient and so that you're

40:47.680 --> 40:52.480
scanning something which is static so you can never find the dynamic patterns in the brain and

40:52.480 --> 40:58.400
that's just one of the problems so and um we don't know anything about the molecular

40:58.960 --> 41:08.800
configuration of cells and um and some people think that we can do ai in in the general genuinely

41:08.800 --> 41:14.080
intelligent sense if we use quantum computers but quantum computers are turing machines too

41:14.720 --> 41:19.440
they're just a lot quicker and we we haven't built one yet practically speaking it's a dead end

41:20.080 --> 41:26.240
maybe a dead end uh he also talks about biological enhancement of existing brains so you can maybe

41:26.240 --> 41:36.320
make superintelligence by selective breeding uh you get i don't know um so you you get a lot of

41:36.320 --> 41:43.120
people to breed and then you select only a small number of embryos that the clever ones so you have

41:43.120 --> 41:49.840
a really clever way selecting intelligent embryos which i don't know about and then he says if we do

41:49.840 --> 42:00.000
that we can raise the iq level by 24.3 iq points that is the silliest thing that was ever said

42:00.000 --> 42:07.120
by anybody working in biology or in any anything near biology it's um anyway it's it's not good now

42:08.080 --> 42:19.440
uh so that basically his whole thing doesn't work um so let's talk about chat gp t and um

42:19.440 --> 42:25.440
i i really mean it when i say it's glorious and it's really a fantastic thing and i like ai

42:25.440 --> 42:32.640
generally i just i'm aware that it's always going to be narrow ai now chat gp t is narrow ai too

42:32.640 --> 42:43.120
can only do one thing um so let's talk about the misery and i imagine all of you have played

42:43.120 --> 42:49.600
with chat gp t if not you should certainly play with chat gp t for a bit and you will find that it

42:49.600 --> 42:57.760
does odd things so that it makes stuff up for instance and now this is an example where it

42:57.760 --> 43:03.440
realizes that it's not really intelligent you can't do something which even a not very intelligent

43:03.440 --> 43:12.320
human being can do so i asked it to send me five a list of five single authored papers on medical ai

43:13.840 --> 43:21.120
and it said no he can't do that but then he gave me a list or sorry it gave me a whole paragraph

43:21.120 --> 43:26.640
of stuff that i didn't want to know so telling me about ai applications in medicine and so on which

43:26.640 --> 43:33.680
i knew anyway it it wants to be nice as it were gets anyway you'll see why it wants to be nice in

43:33.680 --> 43:38.960
a minute and it couldn't give me an answer so to the question i wanted which is an easy question

43:39.520 --> 43:44.880
so it gave me an answer to a different question but then i asked it again a few seconds later the

43:44.880 --> 43:52.880
very same question and it gave me five single authored papers on medical ai sure here are five

43:52.880 --> 44:00.240
single authored papers on medical ai ai so the first problem is that two of them have et al in the

44:00.240 --> 44:08.480
author list now even an ignorant person who understands the request will know that this is a bad

44:09.600 --> 44:15.120
first step in answering that request but it got three right out of five which is a good score

44:16.000 --> 44:23.840
for these difficult questions so and as i say any human intelligence would find this

44:23.840 --> 44:28.960
request is a trivial and it failed but the the next problem is that none of the five papers that

44:28.960 --> 44:38.720
it requested exists it made them up so it can't even make up a single authored paper at random

44:38.720 --> 44:49.360
it it failed on two of them and i'll try another one so i um in that this way i i this was a serious

44:49.360 --> 44:55.440
question i wanted to know the answer uh so i have an iphone 11 and i thinking about buying an iphone

44:55.440 --> 45:03.280
14 so i asked it and it said sorry the iphone 14 is not yet released this was on 17th of march

45:03.280 --> 45:10.960
2023 and then it gave me all sorts of information that i didn't ask for about iphone 13 and so

45:10.960 --> 45:17.840
but two minutes later i tell it but the iphone 14 was released four months ago

45:18.960 --> 45:24.000
and so it says i apologize for the confusion you're right and so so that's not a good sign either

45:24.880 --> 45:33.760
now i i've done a lot of work i know a lot about barry smith and so i can ask you all

45:33.760 --> 45:38.640
such sorts of questions and work out the score of how often you get things right and it's it's

45:38.640 --> 45:46.000
less than 50 so here we have the question who wrote that which i wrote i wrote this phd thesis so i

45:46.000 --> 45:52.160
want the i want the answer barry smith so it gives me the answer kevin molligan who is a close friend

45:52.160 --> 45:59.120
we've written things together but he did not write my phd dissertation so i tell it to try again

45:59.840 --> 46:06.400
and then it says that my phd dissertation was written by a famous philosopher from the 1950s

46:06.400 --> 46:13.760
1960s which was when i was a boy a little boy uh so he didn't write it and so i tell it to try again

46:13.760 --> 46:19.120
it goes back to kevin molligan and i say are you sure yes i'm sure that kevin molligan wrote

46:19.680 --> 46:24.880
are you sure you're sure and then he apologizes again and he says that it was actually written

46:24.880 --> 46:32.960
by john michael croiss who i'd never heard of from that moment but it turns out that as

46:32.960 --> 46:37.600
chat gpt says he was a philosopher which is correct he was a professor of philosophy at the

46:37.600 --> 46:43.600
university of frankfurt which is incorrect he was born in 1943 which is correct in boston which is

46:43.600 --> 46:52.240
incorrect and so so he gets a little bit of truth about the non-author of my phd dissertation which

46:52.240 --> 47:00.000
is worth less than zero to me except that i can prove that there are things going on here that

47:00.000 --> 47:06.480
shouldn't be going on now let's try this one all the swiss people in this room will know that there

47:06.480 --> 47:16.000
is the orna loch and it's an old tongue basically an interesting old tongue so i asked it what is

47:16.000 --> 47:23.600
the orna loch and it said i'm sorry but i'm not sure which specific orna loch you are referring to

47:23.600 --> 47:30.880
as there may be different places or things with this name however one possible reference is to the

47:30.880 --> 47:39.280
orna lochschaft so it changed the subject it says it's in switzerland in a district in the canton

47:39.280 --> 47:46.480
of ori that encompasses the valleys of schekenthal and oeseren do those valleys exist anybody know

47:48.560 --> 47:55.040
the valleys exist good the name orna lochschaft literally means the district of the ori valley

47:55.760 --> 48:03.600
that is not true i'm assuming you can correct me here another reference is the orna loch cave

48:03.600 --> 48:10.240
in austria there is no such cave now if you could provide more information on the specific orna

48:10.240 --> 48:16.080
loch you are referring to i'd be happy to provide more information so i said could you provide me

48:16.080 --> 48:23.280
with more information about the orna lochschaft in switzerland which doesn't exist and it gave me

48:23.280 --> 48:30.960
two whole pages of tourism information other notable attractions include the historic town of

48:30.960 --> 48:36.880
aldorf and the aldermat i have no idea whether any of these things exist either but the orna loch

48:36.880 --> 48:44.240
shaft does not exist and you can check by asking google there is nothing there isn't a single entry

48:44.240 --> 48:49.600
which is a kind of miracle for any strings that you might give to google it can usually think of

48:49.600 --> 48:57.280
something but here there's nothing so is there an orna loch shaft i think no it made it up all

48:57.280 --> 49:05.200
right now there is a a very nice um slide deck by yang luqun who is one of the real experts in

49:07.360 --> 49:13.840
the sarcastic ai he's also one of the people who we cite in our book as also believing that

49:13.840 --> 49:18.880
there is a lot of nonsense being talked about the singularity machines taking over the world

49:20.080 --> 49:28.080
here he he gives a mathematical argument why these hallucinations they're called

49:28.080 --> 49:37.920
non-nonsense that uh genomes that the chat gpt throws up um the the reason is a mathematical one

49:38.480 --> 49:45.200
and it's so the mathematics we think is not quite right the formula needs to take account of

49:45.200 --> 49:51.600
length of input and length of output because the likelihood of error goes up for longer inputs

49:51.600 --> 49:58.320
and longer outputs which seems reasonable but this is a first step the probability of a of a

49:58.320 --> 50:07.040
chat gpt output being correct is one minus e raised to the power n and that means it's this red

50:07.040 --> 50:15.600
area here they are the correct answers and he thinks that this exponential divergence is not

50:15.600 --> 50:25.280
fixable so chat gpt is dead jack because if they can't fix this nonsense no one will trust chat gpt

50:25.280 --> 50:29.760
and it will be replaced by something quite different and no one knows what that is because the

50:29.760 --> 50:37.920
four large language models which is what chat gpt is the google one the the bing one uh i've

50:37.920 --> 50:42.800
forgotten the facebook one i guess they all use the same principles and they all have the same

50:42.800 --> 50:52.320
error code they all generate stuff uh that they make up all right now that's the misery of chat

50:52.320 --> 50:59.120
gpt and it should feel miserable now because i just declared it dead and i should really be investing

50:59.120 --> 51:06.320
i should be shorting stock which relies on chat gpt being alive in say six months but i'm not doing

51:06.320 --> 51:12.400
that all right so let's see how it works and why it is fantastic why it's a really a miracle which

51:12.400 --> 51:20.560
surprised me so i'm not pleased with it at all but it it did something which is important so

51:21.360 --> 51:27.360
how did we go the answer is through an ai method called reinforcement learning which is a method

51:27.360 --> 51:34.560
which works well for games like go and the way it works is that for a game like you know you can

51:34.560 --> 51:40.880
go you can define a reward system for each move and it can be a reward system which

51:40.880 --> 51:48.560
whether rewards can be assigned by the computer now if you can do that you can play the game

51:51.440 --> 51:56.320
over and over again billions of times inside the computer you don't need human beings so

51:56.320 --> 52:02.560
they're still trying to crack the game of dota 2 which is apparently a leading esport game i've

52:02.560 --> 52:09.040
no idea what esport means but dota 2 exists they still haven't cracked it but they're trying to

52:09.040 --> 52:17.120
crack it with a software algorithm called open ai 5 which usually wins against humans and this can

52:17.120 --> 52:25.920
play 180 years worth of dota 2 games in a single day if you can do that you can do you can perform

52:26.000 --> 52:37.040
miracles in principles such as beating dota 2 so can you do it for conversation three months ago i

52:37.040 --> 52:44.800
would have said no impossible and i just said it 10 minutes ago chat gpt showed how you can apply

52:44.800 --> 52:52.800
reinforcement learning to what looks like conversations now how did it do that so what that

52:52.800 --> 52:59.920
means is that we are doing a little bit like emulating human will because the alpha go has to

52:59.920 --> 53:05.600
want to win the game of go in some sense of want it has to emulate the kind of want that you have

53:05.600 --> 53:13.840
when you play a game and want to win so how does it work well you need a reward system and i i put

53:13.840 --> 53:20.160
this in that's what i used to believe i still believe it really but um chat gp has unsettled my

53:20.160 --> 53:27.920
conviction so chat gp found a chat gpt found a way to use reinforcement learning to emulate two

53:27.920 --> 53:34.000
persons human conversation inside a computer and it says to here this is a big deal and i mean that

53:34.000 --> 53:43.360
in a positive way now how does chat gpt work you give it any string and it will work out from its

53:43.360 --> 53:50.560
really powerful knowledge of language what the next lightliest next syllable is

53:51.440 --> 53:56.960
that's why it sometimes takes time when it's chatting as it were so if you say the best thing

53:56.960 --> 54:02.320
about ai is its ability to then it will say learn because that's the next most probable

54:04.400 --> 54:09.600
output and now it doesn't always take the most probable because if it did it would go around

54:09.680 --> 54:18.000
circles so sometimes it has a random kick down the hierarchy all right now notice that it doesn't

54:18.000 --> 54:22.960
understand anything it just has an incredibly powerful knowledge of the patterns of language

54:22.960 --> 54:28.960
which enables it to know what the next syllable will be will be most likely after any given string

54:30.800 --> 54:36.720
and so this is how it was built so the first part is creating this wonderful

54:37.440 --> 54:43.200
patterned model of language not just english but other languages too and i won't talk about that

54:43.200 --> 54:49.360
that's that that's the same kind of training that you find in google translate and and there are

54:49.360 --> 54:55.360
then three steps which i'll go through one by one so we have prompts and these come from being

54:56.560 --> 55:00.320
so they're being questions we don't know what they are and that's a little bit fishy

55:01.040 --> 55:06.720
so some people would like to see the prompts because chat gpt4 is claiming that it can beat

55:06.720 --> 55:12.720
humans in medical exams and some people think that the answers to the medical exam questions were in

55:12.720 --> 55:20.400
the prompt database that was used to train chat gpt in which case the being able to beat humans

55:20.480 --> 55:30.560
would be worth nothing um so and then you have people i some people say it was 40 contractors

55:30.560 --> 55:34.640
but again that's a secret it may have been many more they were all in india so they didn't cost

55:34.640 --> 55:41.120
as much as if they've been in theory for instance and they were hired to write responses to those

55:41.120 --> 55:52.240
prompts now so the when was michael jackson born that kind of prompt and and many other prompts but

55:52.240 --> 55:57.280
only a limited number and we don't know what they are but some people say 13 000 prompts

55:58.640 --> 56:05.120
so that's the first step now the second step so you've you've you've got the prompts from being

56:05.120 --> 56:10.080
and you've got the outputs from the people in india who are paid to respond to these prompts

56:10.160 --> 56:19.840
producing text then the next stage is that you pay a labeler it's called but it means an evaluator

56:20.560 --> 56:29.600
to rank the outputs created in the first stage now you can't rank outputs when you're talking to your

56:29.600 --> 56:37.280
spouse in a conversation but you and that's why we can't create a reward system for conversation

56:37.280 --> 56:45.280
because you can't rank outputs in conversations but the chat gpt found a way to rank outputs by

56:45.280 --> 56:52.720
paying somebody to label them with a score of one two three or four points so four points means it's

56:52.720 --> 57:01.920
a good output and one point means it's a bad output and i believe that the reason why chat gpt very

57:01.920 --> 57:09.600
often says honestly i don't know the answer to your question so it didn't say i have no idea what

57:09.600 --> 57:16.000
the orna lock is it told me to think about the orna lock shaft which has all kinds of rivers running

57:16.000 --> 57:21.920
through and doesn't exist why did it go to that trouble of giving me all this tourist information

57:21.920 --> 57:31.040
because the labelers poor things think that a response who says i don't know what you want

57:32.080 --> 57:39.680
i'm sorry is less reward worthy than a long list of tourism information about a non-existing

57:39.680 --> 57:44.000
village because it's a long list of tourist information that must be worth four points

57:44.000 --> 57:53.200
and so chat gpt basically is being bribed by the labelers to reward long outputs which are

57:54.000 --> 58:00.320
kind and gentle and so this is why it throws up so much rubbish the machine will always try to

58:00.320 --> 58:05.280
have nice friendly output but the machine can play response prompt response prompt response

58:05.280 --> 58:10.160
prompt response games with itself billions of times every day for weeks and that that is what

58:10.160 --> 58:15.760
it did and it cost a lot of money to do all that training and then it can give answers that's how

58:15.760 --> 58:18.720
it does it and so the lesson

