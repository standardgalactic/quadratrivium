WEBVTT

00:00.000 --> 00:03.200
Hi, Vern. Welcome to FOSAT's Intelligent Cooperation Group.

00:03.200 --> 00:05.080
We're really excited about this seminar.

00:05.080 --> 00:07.560
We have DC here from Welkheim.

00:07.560 --> 00:11.160
Thank you so much for joining us to give an overview of ZKML,

00:11.160 --> 00:13.560
which is a topic that has come up so much,

00:13.560 --> 00:16.920
especially, I guess, data coming up already a few years ago

00:16.920 --> 00:18.560
in this group, and then much, much more

00:18.560 --> 00:20.640
to have really ramping up in the last year.

00:20.640 --> 00:22.720
And so I'm really excited for you to share a little bit more

00:22.720 --> 00:24.840
about it because we have not had a dedicated seminar

00:24.840 --> 00:25.600
to this topic yet.

00:25.600 --> 00:26.960
So thanks a lot for joining.

00:26.960 --> 00:28.640
We're really excited about you guys' work.

00:28.720 --> 00:30.120
Without further ado, please take it away.

00:30.120 --> 00:31.760
I'll be in the chat monitoring questions,

00:31.760 --> 00:33.760
and we're off to the races.

00:33.760 --> 00:35.600
Awesome. Thank you for having me.

00:35.600 --> 00:38.640
So today, I'll be talking about the zero-knowledge machine

00:38.640 --> 00:39.120
learning.

00:39.120 --> 00:41.600
I'll be giving a very brief introduction.

00:41.600 --> 00:45.120
But first, maybe let me start by saying a little bit about myself.

00:45.120 --> 00:48.200
I'm a research engineer at the World Coin Foundation,

00:48.200 --> 00:49.640
and World Coin is this project that

00:49.640 --> 00:53.640
is trying to build the largest identity and financial network.

00:53.640 --> 00:56.720
And there is an interplay of various technologies

00:56.720 --> 00:59.600
in the products and things that we're building at World Coin,

00:59.600 --> 01:03.040
and some of which are AI, and some of which are cryptography.

01:03.040 --> 01:05.160
So we've had expertise in both realms

01:05.160 --> 01:06.840
from different teams internally.

01:06.840 --> 01:09.840
And there have been some essentially experimentation

01:09.840 --> 01:10.960
that naturally occurred.

01:10.960 --> 01:12.840
We have some AI parts of the stack,

01:12.840 --> 01:15.200
and there are some reasons why cryptography might

01:15.200 --> 01:17.560
be useful in the AI sector of the stack.

01:17.560 --> 01:21.200
And so this prompted us to think about this topic

01:21.200 --> 01:23.000
about two years ago in August.

01:23.000 --> 01:25.280
Almost two years ago, August of 2022.

01:25.760 --> 01:28.240
One of my teammates was just playing around with cryptography

01:28.240 --> 01:30.160
and trying to prove machine learning models.

01:30.160 --> 01:32.640
But so this is a little bit of a background.

01:32.640 --> 01:34.920
I mostly run our grants program, where

01:34.920 --> 01:36.920
we give grants to people to help decentralize World

01:36.920 --> 01:38.400
Coin and solve some more problems,

01:38.400 --> 01:41.040
and also help with a bunch of different R&D efforts

01:41.040 --> 01:43.080
as an individual contribute.

01:43.080 --> 01:46.240
So without further ado, let me start with the presentation.

01:46.240 --> 01:48.720
Usually, the way that I like to start with this presentation

01:48.720 --> 01:52.400
is that I like to decompose the statement into its constituents

01:52.400 --> 01:55.560
so that people have an understanding of which elements

01:55.560 --> 01:57.040
or what is zero-knowledge machine learning?

01:57.040 --> 01:58.280
What is the zero-knowledge part?

01:58.280 --> 02:00.040
What is the machine learning part?

02:00.040 --> 02:03.000
I like to decompose it into its fundamental compositions,

02:03.000 --> 02:04.240
so competition.

02:04.240 --> 02:06.280
And the first one that I want to talk about

02:06.280 --> 02:10.280
is zero-knowledge cryptography, or called zero-knowledge.

02:10.280 --> 02:12.720
I don't know if many of you understand the reference that

02:12.720 --> 02:15.320
or get the reference that I put here, which is Waldo,

02:15.320 --> 02:16.320
finding Waldo.

02:16.320 --> 02:20.160
Waldo essentially is a character or one specific analogy,

02:20.200 --> 02:22.320
which is very simple, very easy, very friendly

02:22.320 --> 02:24.280
to explain what zero-knowledge cryptography is

02:24.280 --> 02:26.320
to people who have never heard about it.

02:26.320 --> 02:28.760
Because there is this essentially like poster

02:28.760 --> 02:31.080
that many people know where there's just lots of characters

02:31.080 --> 02:33.960
which are in the city, and there's one Waldo.

02:33.960 --> 02:36.960
And it takes some amount of time to essentially find the Waldo,

02:36.960 --> 02:39.720
and that's like the challenge of these specific games.

02:39.720 --> 02:41.840
And so there is one specific analogy

02:41.840 --> 02:44.360
which allows people to explain what zero-knowledge is,

02:44.360 --> 02:50.120
which is that if I put a bigger like white paper

02:50.240 --> 02:53.400
on top of the poster, defining Waldo game,

02:53.400 --> 02:56.120
and if I create a little tiny cutout for the head of Waldo,

02:56.120 --> 02:59.520
and I place the cutout just on top of Waldo's head,

02:59.520 --> 03:03.960
but covering the entire game itself, or the poster itself,

03:03.960 --> 03:06.960
then I'm able to prove to anyone that I know where Waldo is

03:06.960 --> 03:09.400
without revealing his location within the poster.

03:09.400 --> 03:10.680
So this is like the good analogy

03:10.680 --> 03:12.640
for explaining what zero-knowledge cryptography is,

03:12.640 --> 03:15.600
because I'm able to prove things that I know

03:15.600 --> 03:17.880
to someone else, to an outside observer,

03:17.880 --> 03:20.360
without them learning everything

03:20.360 --> 03:21.800
about the things I'm making a proof of.

03:21.800 --> 03:24.440
I can selectively prove specific statements

03:24.440 --> 03:25.960
because I have information,

03:25.960 --> 03:27.880
but I don't have to reveal everything

03:27.880 --> 03:29.360
in order to be able to prove that statement.

03:29.360 --> 03:32.240
So this is like a good analogy to explain DK.

03:32.240 --> 03:35.520
So some of the properties that zero-knowledge cryptography has.

03:35.520 --> 03:37.600
So the first one, which I think is the most important one,

03:37.600 --> 03:39.200
especially in the context of blockchain,

03:39.200 --> 03:42.800
I saw that many of you were like in previous presentations

03:42.800 --> 03:44.720
of this specific group.

03:44.720 --> 03:46.120
I saw that there's a few crypto people

03:46.120 --> 03:47.240
that were talking about different things.

03:47.240 --> 03:49.920
I'm sure that came along a few times.

03:49.920 --> 03:51.960
So succinct list essentially just means

03:51.960 --> 03:55.320
that in order to verify a proof of a statement,

03:55.320 --> 03:57.680
it's a lot less computationally expensive

03:57.680 --> 03:59.160
or a lot less expensive

03:59.160 --> 04:02.160
than to actually prove the computation

04:02.160 --> 04:04.520
or to just perform the computation yourself, right?

04:04.520 --> 04:07.600
So essentially verifying that I know where Waldo is,

04:07.600 --> 04:08.680
as an outside observer,

04:08.680 --> 04:11.320
it's a lot easier than me finding Waldo myself.

04:11.320 --> 04:13.280
So this is really important in the context of blockchains

04:13.280 --> 04:15.160
because for example, for scalability solutions,

04:15.160 --> 04:17.080
instead of everyone having to re-execute

04:17.080 --> 04:18.720
the same transactions in a block,

04:18.720 --> 04:20.000
I can just verify a proof

04:20.000 --> 04:21.280
and I can just update my state

04:21.280 --> 04:23.760
without having to secure it myself, for example.

04:23.760 --> 04:25.640
So this property is important for the kid

04:25.640 --> 04:27.720
because it allows us to very easily,

04:27.720 --> 04:30.440
computationally easily verify things

04:30.440 --> 04:32.000
without having to do computation ourselves.

04:32.000 --> 04:33.600
This is a really important property.

04:33.600 --> 04:37.240
The second one, arguably the one that is most known for,

04:37.240 --> 04:38.200
is correctness.

04:38.200 --> 04:39.640
So correctness essentially means

04:39.640 --> 04:42.960
that I can have almost 100% certainty

04:42.960 --> 04:46.400
that this statement that I'm proving is correct, right?

04:46.440 --> 04:47.680
That I cannot lie.

04:47.680 --> 04:49.840
There is no way that I as a prover

04:49.840 --> 04:52.000
can lie to a verifier

04:52.000 --> 04:55.000
unless if the cryptography is sound in this case.

04:55.000 --> 04:56.520
There's two specific properties

04:56.520 --> 04:58.040
that constitute correctness.

04:58.040 --> 04:59.440
One is soundness.

04:59.440 --> 05:01.760
So soundness means that I, if I'm a prover,

05:01.760 --> 05:04.560
someone making this claim, someone making a statement,

05:04.560 --> 05:08.720
I'm not able to fool a verifier with invalid proof

05:08.720 --> 05:11.040
and completeness is another property

05:11.040 --> 05:14.280
where I'm not essentially able to create a valid proof

05:14.280 --> 05:15.220
unless I know the truth.

05:15.220 --> 05:16.180
If I don't know the truth,

05:16.180 --> 05:20.380
I cannot make a valid proof as a prover.

05:20.380 --> 05:23.460
And the third one, which is name after, zero knowledge,

05:23.460 --> 05:26.860
is this property where I can hide parts of the statement.

05:26.860 --> 05:28.660
For example, let's say that I have,

05:28.660 --> 05:29.820
I don't know, this is a good example.

05:29.820 --> 05:31.260
Let's say I have my passport.

05:31.260 --> 05:34.380
So I have my name, my nationality, my date of birth,

05:34.380 --> 05:36.980
where I'm from, which country I was born in,

05:36.980 --> 05:39.100
for example, the place of birth.

05:39.100 --> 05:40.460
So something that would be useful

05:40.460 --> 05:43.220
or like something that would constitute a zero knowledge proof

05:43.220 --> 05:44.500
is that I can make the statement

05:44.500 --> 05:47.500
that my age is over 18 years old

05:47.500 --> 05:49.460
without revealing to anyone my age,

05:49.460 --> 05:53.060
but anyone can just verify that I'm actually over 18.

05:53.060 --> 05:54.540
The way that this is actually implemented

05:54.540 --> 05:55.820
is that within a zero knowledge proof,

05:55.820 --> 05:59.100
I can verify a signature from some issuing body

05:59.100 --> 06:00.160
like the government.

06:00.160 --> 06:02.020
And then I can make a statement that like A,

06:02.020 --> 06:03.820
this age, which was attested to

06:03.820 --> 06:07.420
or essentially committed to by a government is over 18

06:07.420 --> 06:08.780
and you don't learn my age.

06:08.780 --> 06:10.100
So this is the zero knowledge part

06:10.100 --> 06:11.940
where I'm able to hide parts of the state

06:11.940 --> 06:14.740
that I'm making a statement about or proof about

06:14.740 --> 06:17.780
according to some constraint or some statement, right?

06:17.780 --> 06:19.580
Like I can say greater than, less than,

06:19.580 --> 06:23.020
equal to a bunch of other properties

06:23.020 --> 06:24.540
that I think can put.

06:24.540 --> 06:27.020
So the second part of the statement

06:27.020 --> 06:28.340
of zero knowledge machine learning,

06:28.340 --> 06:29.420
this machine learning, right?

06:29.420 --> 06:32.020
I think that one is much more familiar to most of you

06:32.020 --> 06:35.100
since it's been generating such a buzz everywhere,

06:35.100 --> 06:36.860
like machine learning through a generative AI,

06:36.860 --> 06:39.060
like in things like ChagYPT or Dali

06:39.060 --> 06:41.300
or a lot of generative AI models

06:41.340 --> 06:43.940
or natural language processing, categorizing models

06:43.940 --> 06:46.180
like robots, the machine learning essentially,

06:46.180 --> 06:49.540
the way that I think about it is that it's a tool

06:49.540 --> 06:53.340
that allows us to give us not the non-deterministic solutions

06:53.340 --> 06:56.220
or just estimates for short for problems

06:56.220 --> 06:58.940
that don't really have a concrete solution, right?

06:58.940 --> 07:00.860
There's usually there's some problems

07:00.860 --> 07:02.820
which we can solve algorithmically

07:02.820 --> 07:04.180
and we can just have a set of steps

07:04.180 --> 07:07.140
that we can just execute in order to solve it

07:07.140 --> 07:09.620
and we will have a perfect solution every time.

07:09.620 --> 07:11.900
In the case of machine learning, however,

07:11.900 --> 07:13.420
most of the problems that are being solved

07:13.420 --> 07:15.340
by machine learning are not such problems.

07:15.340 --> 07:16.820
Therefore, we need to,

07:16.820 --> 07:19.500
because maybe like the space of solutions is too big

07:19.500 --> 07:22.420
or the space of the steps that we can take is too big,

07:22.420 --> 07:24.940
so it's really hard to navigate deterministically,

07:24.940 --> 07:27.060
then we just have this sort of juristic.

07:27.060 --> 07:30.620
A juristic essentially is a good enough approximation

07:30.620 --> 07:33.460
to the real solution which we can work with

07:33.460 --> 07:35.820
and which has some form of accuracy, right?

07:35.820 --> 07:37.540
So in the context of machine learning,

07:37.540 --> 07:40.300
we have some sort of juristic for some problem.

07:40.300 --> 07:42.540
So let's say I want to categorize

07:42.540 --> 07:46.060
whether an image that I see is the image of a dog or a cat.

07:46.060 --> 07:48.340
This I can train a machine learning model

07:48.340 --> 07:49.980
to essentially solve this task,

07:49.980 --> 07:52.300
but the machine learning model will never be 100% correct.

07:52.300 --> 07:54.460
It will have some accuracy, right?

07:54.460 --> 07:55.780
It will have some that will fail on,

07:55.780 --> 07:58.940
it will have, most of them it will get correct.

07:58.940 --> 08:01.860
But essentially the way that the machine learning model works

08:01.860 --> 08:04.380
is that it trains on some data.

08:04.380 --> 08:06.620
So I feed some data to some model

08:06.740 --> 08:09.340
or to some machine learning algorithm and it gets better.

08:09.340 --> 08:11.940
And this juristic keep getting better and better

08:11.940 --> 08:14.060
for things that it hasn't seen before.

08:14.060 --> 08:15.820
It generalizes over the data

08:15.820 --> 08:18.540
and it's able to make essentially like predictions

08:18.540 --> 08:21.060
or classifications or all sorts of things.

08:21.060 --> 08:22.300
So in the case, for example,

08:22.300 --> 08:25.220
of foundational models for large language models,

08:25.220 --> 08:28.620
they get better at creating like cohesive explanations

08:28.620 --> 08:30.620
or at reasoning or at mathematics

08:30.620 --> 08:32.620
or at all sorts of different things.

08:32.620 --> 08:34.380
And we can have these benchmarks

08:34.380 --> 08:36.860
and with more data, they get better at these benchmarks,

08:36.860 --> 08:39.540
which essentially provide better juristic problems

08:39.540 --> 08:41.060
that we're grading them on.

08:41.060 --> 08:44.180
So another concept that I want to explain here

08:44.180 --> 08:47.140
is that there's two specific parts within machine learning

08:47.140 --> 08:50.580
or two specific things you can do usually,

08:50.580 --> 08:53.380
is that when you have a model, you can train a model.

08:53.380 --> 08:56.540
The act of training a model is the act of creating a function

08:56.540 --> 08:58.860
which gets actually better and better

08:58.860 --> 09:00.820
at giving you the juristics,

09:00.820 --> 09:02.700
the more data you feed into it, right?

09:02.700 --> 09:04.780
So I'm able to update the parameters of this function

09:04.780 --> 09:07.820
by learning, this is what learning is, right?

09:07.820 --> 09:09.340
I'm updating parameters of a function

09:09.340 --> 09:10.980
in order to get a better jurist.

09:10.980 --> 09:12.900
And this process is really expensive, right?

09:12.900 --> 09:15.820
It's really hard, you have to co-locate a data center,

09:15.820 --> 09:19.340
it's running lots of graphics cards in a big place

09:19.340 --> 09:21.460
and consuming lots of electricity for months on end

09:21.460 --> 09:23.500
in order to be able to create something useful

09:23.500 --> 09:25.540
or meaningful, this is really expensive.

09:25.540 --> 09:27.580
But the end product is very easy to run.

09:27.580 --> 09:29.020
So once I've trained this function,

09:29.020 --> 09:30.700
once I have my set of parameters,

09:30.700 --> 09:32.620
evaluating this function at some input,

09:32.620 --> 09:35.340
is usually inexpensive or very inexpensive

09:35.340 --> 09:37.300
compared to actually training it,

09:37.300 --> 09:39.500
several orders of magnitude less.

09:39.500 --> 09:41.220
So these are like the,

09:41.220 --> 09:44.300
how I usually explain machine learning just very briefly.

09:44.300 --> 09:45.700
And so now I want to get,

09:45.700 --> 09:47.660
what is zero knowledge machine learning, right?

09:47.660 --> 09:49.620
We have some intuitions from the ZK side,

09:49.620 --> 09:51.740
some intuitions from the machine learning side.

09:51.740 --> 09:55.700
Now we can discuss what ZK machine learning can be

09:55.700 --> 09:58.780
or is within the modern understanding of it.

09:58.780 --> 10:00.780
So essentially what ZKML is,

10:00.780 --> 10:04.060
is the creation of zero knowledge proofs

10:04.060 --> 10:05.980
of machine learning algorithms, right?

10:05.980 --> 10:08.460
So zero knowledge cryptography allows you

10:08.460 --> 10:11.420
to create proofs of arbitrary computations.

10:11.420 --> 10:14.620
It can be a proof that I've computed some specific thing.

10:14.620 --> 10:17.500
It can be a proof that some variable is bigger than another.

10:17.500 --> 10:19.300
Essentially it's making proofs about computation

10:19.300 --> 10:22.140
and you know the person who's verifying that proof

10:22.140 --> 10:24.540
knows that someone has executed that computation

10:24.540 --> 10:27.860
on some inputs and has produced some output.

10:27.860 --> 10:29.100
So in the context of machine learning,

10:29.100 --> 10:32.260
usually you have some input, a function or a model,

10:32.260 --> 10:33.500
and then some output, right?

10:33.500 --> 10:35.460
So if it's let's say like charge EPT,

10:35.460 --> 10:37.700
I have a prompt which I feed into the model.

10:37.700 --> 10:41.380
The model just takes that prompt and evaluates its model

10:41.380 --> 10:42.700
and it gives you an output,

10:42.700 --> 10:44.660
which is the thing that you then read in the end,

10:44.660 --> 10:46.060
which is the result, right?

10:46.060 --> 10:48.780
So zero knowledge machine learning would be the art

10:48.780 --> 10:53.060
or act of creating a proof that I have fed an input

10:53.060 --> 10:54.940
to a model and I've produced some output.

10:54.940 --> 10:58.060
And I can verify that this output came from a model

10:58.100 --> 11:01.700
without essentially having to evaluate this myself personally.

11:01.700 --> 11:03.900
I just know that this comes from a model

11:03.900 --> 11:07.100
because I have a cryptographic proof that this indeed happened.

11:07.100 --> 11:09.300
So something that many people in the space

11:09.300 --> 11:13.140
actually use as a good analogy that accountable AI, right?

11:13.140 --> 11:15.380
Usually AI or machine learning models,

11:15.380 --> 11:17.540
you don't know that they're actually correct

11:17.540 --> 11:20.180
unless you run them yourself, right?

11:20.180 --> 11:22.260
If you run it yourself on your own local machine

11:22.260 --> 11:24.940
or your own data center which you have privileged access to,

11:24.940 --> 11:27.580
then you know that you've run the right thing.

11:27.580 --> 11:30.660
But let's say that you're using some form of server or API, right?

11:30.660 --> 11:33.860
If I go to chat GPT, like the website,

11:33.860 --> 11:36.940
how do I know that OpenAI is actually serving me

11:36.940 --> 11:37.860
the right model?

11:37.860 --> 11:40.940
They claim, like in the UI, in the front end,

11:40.940 --> 11:43.740
they claim that I am using GPT-4, but how do I know that?

11:43.740 --> 11:46.540
There's no way of me of actually verifying that this is GPT-4.

11:46.540 --> 11:48.180
They might be serving me a worse model,

11:48.180 --> 11:49.540
which is cheaper to run

11:49.540 --> 11:52.020
and just pocketing the difference, for example, right?

11:52.020 --> 11:52.900
I don't know.

11:52.900 --> 11:55.460
So one good thing that ZKML provides

11:55.460 --> 11:56.780
is this form of accountability

11:56.780 --> 12:00.660
where I, as the consumer of some API or some model,

12:00.660 --> 12:02.900
I know that this actually came from something

12:02.900 --> 12:05.100
because I can verify a cryptographic proof

12:05.100 --> 12:06.020
that this indeed happened.

12:06.020 --> 12:07.740
So we can make AIs accountable.

12:07.740 --> 12:09.780
We can make anyone using AI accountable

12:09.780 --> 12:12.620
because we can make proofs of computation.

12:12.620 --> 12:17.020
Many of the framing for ZKML in the modern way

12:17.020 --> 12:20.340
is that they want to essentially bring machine learning on-chain

12:20.340 --> 12:22.220
or onto the blockchain in this case, right?

12:22.220 --> 12:24.860
Like we have the blockchains where we have

12:24.860 --> 12:29.100
very interconnected networks of low-end hardware, mostly.

12:29.100 --> 12:32.220
It's like consumer hardware, which is available everywhere,

12:32.220 --> 12:34.460
to run these decentralized networks.

12:34.460 --> 12:36.700
And the problem with this is that every single computer

12:36.700 --> 12:39.420
on this network needs to re-execute everything

12:39.420 --> 12:41.620
that the network sees in order to validate

12:41.620 --> 12:43.860
that the network is progressing correctly.

12:43.860 --> 12:45.100
And this is a big problem

12:45.100 --> 12:47.060
because now everything is really expensive.

12:47.060 --> 12:49.940
If it's already expensive running it on your own machine,

12:49.940 --> 12:52.100
if you have to run it on 1,000 machines

12:52.100 --> 12:53.900
or 10,000 or 100,000 machines,

12:53.940 --> 12:56.620
it's as many times more expensive.

12:56.620 --> 13:00.300
So it's unfeasible to essentially do machine learning

13:00.300 --> 13:03.500
on-chain right now because it's just too expensive.

13:03.500 --> 13:05.140
And the computational environment

13:05.140 --> 13:07.300
that these usually like blockchains have,

13:07.300 --> 13:09.900
like virtual machines, let's say if they're about the EVM,

13:09.900 --> 13:12.900
Solana has SVM, the Solana virtual machine,

13:12.900 --> 13:15.060
that every single blockchain or most blockchains

13:15.060 --> 13:17.460
do have some form of execution capabilities

13:17.460 --> 13:18.740
or computing capabilities.

13:18.740 --> 13:20.420
And these are very constrained.

13:20.460 --> 13:23.940
So some of the things that blockchains are good at

13:23.940 --> 13:26.580
is cryptography because they're usually subsidized

13:26.580 --> 13:30.100
within the cost of execution in blockchain.

13:30.100 --> 13:33.700
So I can verify a zero-knowledge proof on a blockchain

13:33.700 --> 13:36.540
and I can bring something that I run off-chain

13:36.540 --> 13:38.060
on-chain by providing a proof, right?

13:38.060 --> 13:41.300
So for example, if I'm evaluating a model locally,

13:41.300 --> 13:42.820
I'm able to create a zero-knowledge proof

13:42.820 --> 13:44.900
that I've evaluated a model on some input

13:44.900 --> 13:47.460
and I can just send the output to the chain

13:47.460 --> 13:48.660
and verify a proof.

13:48.660 --> 13:50.820
And then the chain or the smart contract

13:50.820 --> 13:53.860
can know that I've actually run a model on some inputs

13:53.860 --> 13:57.060
and I don't have to run that within the environment,

13:57.060 --> 13:58.180
the computing environment, the blockchain,

13:58.180 --> 13:59.660
so I can save a lot of cost.

13:59.660 --> 14:02.340
And if I make ML more accessible on-chain,

14:02.340 --> 14:04.820
I can actually bring it and I can build application

14:04.820 --> 14:07.420
that leverage machine learning for lots of different things

14:07.420 --> 14:09.820
which I'll get into a little bit later.

14:09.820 --> 14:12.660
And the last one is the zero-knowledge part of things

14:12.660 --> 14:15.660
where I'm able to hide specific parts of the computation

14:15.660 --> 14:18.420
or specific parts of the data that I'm making proofs about

14:18.420 --> 14:21.340
and therefore I can make machine learning private.

14:21.340 --> 14:22.660
In order to make machine learning private,

14:22.660 --> 14:24.540
there's other techniques as well

14:24.540 --> 14:26.260
which is like fully homomorphic encryption

14:26.260 --> 14:27.860
and multi-party computation.

14:27.860 --> 14:30.340
Each of these other types of cryptography

14:30.340 --> 14:33.700
or types of distributed systems engineering and compute it

14:33.700 --> 14:35.460
usually have different trade-offs.

14:35.460 --> 14:37.580
So for example, fully homomorphic encryption

14:37.580 --> 14:40.140
does not give you this correctness assumption

14:40.140 --> 14:41.500
or like probability.

14:41.500 --> 14:43.620
I cannot verify that something happened correctly,

14:43.620 --> 14:47.020
but I can, for example, make computations on Cyphertex.

14:47.020 --> 14:48.500
So if I encrypt some data,

14:48.500 --> 14:51.220
I'm able to perform computations on encrypted data.

14:51.220 --> 14:54.380
And when I decrypt, I have the computation performed

14:54.380 --> 14:57.020
on the original input, on the original plaintext

14:57.020 --> 14:59.180
which is something that is quite fascinating.

14:59.180 --> 15:01.140
However, I do lose this property of ZK

15:01.140 --> 15:04.220
where I cannot verify that something happened correctly.

15:04.220 --> 15:07.060
Multi-party computation is like the better of both worlds

15:07.060 --> 15:10.380
but for example, these protocols require multiple parties

15:10.380 --> 15:12.140
to work in unison

15:12.140 --> 15:14.740
and this is really hard to manage, for example.

15:14.740 --> 15:17.060
So yeah, so I want to talk a bit

15:17.060 --> 15:18.620
about who is actually building

15:18.620 --> 15:21.380
Zeronautic Machine Learning nowadays.

15:21.380 --> 15:23.260
Like which startups, which teams,

15:23.260 --> 15:24.700
what are they're focusing on?

15:25.700 --> 15:28.500
So full disclosure, I am an investor in Giza and Modulus

15:28.500 --> 15:31.980
so I don't want to put that out there, just so you know.

15:31.980 --> 15:35.180
So essentially there's different avenues

15:35.180 --> 15:38.980
on what is there to build on within the ZKML domain

15:38.980 --> 15:40.820
in order to make these systems better

15:40.820 --> 15:42.540
or to make this more interesting

15:42.540 --> 15:45.140
or faster and all sorts of different things.

15:45.140 --> 15:48.220
So the three main companies that usually go around

15:48.220 --> 15:50.740
are Giza, Modulus and Ezekio.

15:50.740 --> 15:53.300
On Giza, for example, they're building

15:53.300 --> 15:54.860
on top of the StarkNet ecosystem

15:54.860 --> 15:57.060
which is like one specific scalability solution

15:57.060 --> 15:58.780
in the Ethereum space

15:58.780 --> 16:02.420
and they're implemented a bunch of machine learning models

16:02.420 --> 16:04.580
within this computational environment

16:04.580 --> 16:06.740
that this blockchain had, which is called Cairo.

16:06.740 --> 16:08.220
The computational environment is called Cairo,

16:08.220 --> 16:09.940
the blockchain is called Tarkin

16:09.940 --> 16:11.900
and they're building products, right?

16:11.900 --> 16:13.300
So they're building, for example,

16:13.300 --> 16:14.980
tooling so that financial products

16:14.980 --> 16:16.540
that are deployed on StarkNet

16:16.540 --> 16:19.220
can leverage machine learning within their,

16:19.220 --> 16:21.780
for example, prediction models for financial services

16:21.780 --> 16:25.020
so they can predict where the highest yield is

16:25.020 --> 16:26.740
to routes my money into

16:26.740 --> 16:28.940
so I can get the highest yield on my collateral

16:28.940 --> 16:31.540
or my assets so I can use machine learning off-chain

16:31.540 --> 16:32.580
or machine learning on-chain

16:32.580 --> 16:34.060
within this computational environment,

16:34.060 --> 16:35.780
I can prove it, et cetera, et cetera.

16:35.780 --> 16:36.820
So essentially Giza is building

16:36.820 --> 16:38.180
a lot of the product side of things,

16:38.180 --> 16:40.540
like different abstraction, different SDKs,

16:40.540 --> 16:43.620
different representations of models, on-chain, et cetera.

16:43.620 --> 16:48.260
Modulus is mostly working on the foundational side of things

16:48.260 --> 16:51.420
and by foundation, I mean the primordial science

16:51.420 --> 16:55.140
of doing cryptography and doing engineering.

16:55.140 --> 16:57.580
So they're essentially building their own,

16:57.580 --> 16:59.660
the thing so-called like approving system

16:59.660 --> 17:02.740
which is how do you implement a zero-knowledge scheme?

17:02.740 --> 17:05.020
Like zero-knowledge, it boiled down to mathematics

17:05.020 --> 17:07.940
and working with polynomials and finite fields

17:07.940 --> 17:12.260
and mostly like linear algebra and abstract algebra

17:12.260 --> 17:14.940
and modular arithmetic and bunch of things of this sort.

17:14.940 --> 17:17.020
So essentially they're trying to build

17:17.020 --> 17:19.980
better cryptographic models and better cryptographic systems

17:19.980 --> 17:22.020
in order for zero-knowledge machine learning

17:22.020 --> 17:25.460
to be more efficient within the actual representation of it

17:25.460 --> 17:27.460
in the computing sense, right?

17:27.460 --> 17:29.580
So this is what they're working on.

17:29.580 --> 17:31.580
I'm happy to then after this presentation

17:31.580 --> 17:34.140
or in the FAQ, I'm happy to share more if anyone wants.

17:34.140 --> 17:37.020
Like there's plenty of resources to learn more

17:37.020 --> 17:38.940
and Ithiko is mostly building, tooling

17:38.940 --> 17:41.180
and also some of the products type of things

17:41.180 --> 17:43.580
and infrastructure, a lot of infrastructure as well.

17:43.580 --> 17:46.140
So Ithiko, for example, is building an abstraction layer

17:46.140 --> 17:47.980
that allows developers that are,

17:47.980 --> 17:49.740
they come from the machine learning world.

17:49.740 --> 17:51.620
So people who usually know Python

17:51.620 --> 17:54.180
or right now in this context is just Python.

17:54.180 --> 17:57.020
So people who know Python and know the standard tools

17:57.020 --> 17:58.300
for building machine learning models,

17:58.300 --> 18:00.220
whether it's TensorFlow or Pycorg

18:00.220 --> 18:03.580
or I could learn or any other library for machine learning,

18:03.580 --> 18:05.700
they even have a standardized representation

18:05.700 --> 18:08.260
of a model which can be exported

18:08.260 --> 18:11.340
to this model representation called ONIX, ONIX,

18:11.340 --> 18:13.540
open your network exchange format.

18:13.540 --> 18:15.780
And this format essentially is something

18:15.780 --> 18:18.460
that represents what the model looks like

18:18.460 --> 18:19.700
in the computational sense.

18:19.700 --> 18:21.660
It's a computational graph of different operations

18:21.660 --> 18:23.060
that you need to perform.

18:23.060 --> 18:26.980
And Ithiko allows you to convert whatever you are building

18:26.980 --> 18:30.300
within Python to something that can be ZK proven,

18:30.300 --> 18:33.300
that you can make a proof of in a very easy way.

18:33.300 --> 18:35.740
So you just import a Python library,

18:35.740 --> 18:36.780
you will create your model

18:36.780 --> 18:39.500
and then you just do model that ZK proved

18:39.500 --> 18:41.300
and you are able to ZK prove that

18:41.300 --> 18:43.060
without you as a Python engineer,

18:43.060 --> 18:44.380
as a machine learning engineer,

18:44.380 --> 18:46.500
you don't need to know how ZK works.

18:46.500 --> 18:47.620
You just create a proof of it

18:47.620 --> 18:50.980
because Ithiko has built a tool that helped convert

18:50.980 --> 18:52.660
the way that you work with ML

18:52.660 --> 18:54.620
to something that cryptography can,

18:54.620 --> 18:57.060
the cryptography tooling can create proofs of.

18:57.060 --> 18:58.820
And of course, academia, academia

18:58.820 --> 19:01.100
has been a crucial element of all of this.

19:01.140 --> 19:02.700
There's lots of cryptography,

19:02.700 --> 19:05.860
new cryptography coming out every week almost.

19:05.860 --> 19:07.580
There's new proving systems,

19:07.580 --> 19:09.860
there's new types of final field arithmetic,

19:09.860 --> 19:12.540
there's new discoveries in different field.

19:12.540 --> 19:13.740
There's different optimizations

19:13.740 --> 19:16.500
like computing optimization from representation,

19:16.500 --> 19:18.500
better models on the machine learning side.

19:18.500 --> 19:19.740
There's also improvements

19:19.740 --> 19:22.020
and since usually ZK ML,

19:22.020 --> 19:24.540
you need both things to become more performant.

19:24.540 --> 19:26.460
If academia comes up with better models

19:26.460 --> 19:28.820
and better quantization schemes and whatnot,

19:28.820 --> 19:31.540
all of these improvements, compounds, right?

19:31.540 --> 19:33.180
It's usually the worst of both,

19:33.180 --> 19:36.300
the thing that becomes the worst for the aggregate.

19:36.300 --> 19:38.300
So the worst of KML, or sorry,

19:38.300 --> 19:39.940
the worst of ZK and the worst of ML

19:39.940 --> 19:43.060
become the worst of ZK ML, like the bottlenecks.

19:43.060 --> 19:45.860
So academia is working a lot of the foundational bottlenecks

19:45.860 --> 19:47.740
when it comes to cryptography

19:47.740 --> 19:49.860
and all these other things that I mentioned.

19:51.060 --> 19:52.940
So some of the use cases,

19:52.940 --> 19:54.500
I do wanna talk about use cases

19:54.500 --> 19:55.940
because I've seen a lot of people

19:55.940 --> 19:59.020
who are really deeply interested in the technology,

19:59.020 --> 20:01.060
but the only way that I've seen technology

20:01.060 --> 20:04.580
actually progress forward is if there's funding

20:04.580 --> 20:07.180
and people actually are interested and excited about it.

20:07.180 --> 20:09.180
For example, in the case of zero knowledge cryptography,

20:09.180 --> 20:10.660
because I mostly spend most of my time

20:10.660 --> 20:12.100
in the blockchain space,

20:12.100 --> 20:15.020
zero knowledge cryptography has become really popular

20:15.020 --> 20:16.380
in the last two to three years,

20:16.380 --> 20:19.220
mostly because there's been products that actually use it,

20:19.220 --> 20:20.740
whether it's scalability solutions,

20:20.740 --> 20:22.660
whether it's privacy solutions,

20:22.660 --> 20:24.700
whether it's digital identity solutions,

20:24.740 --> 20:26.900
there's been product market fit for this technology

20:26.900 --> 20:28.820
and so new companies have been created

20:28.820 --> 20:31.100
and a lot of capital has been poured in

20:31.100 --> 20:33.780
and this capital was reinvested

20:33.780 --> 20:35.940
into the actual development of better cryptography,

20:35.940 --> 20:38.300
better tooling, better hardware,

20:38.300 --> 20:41.100
and also there's a lot of network effects, right?

20:41.100 --> 20:43.300
So if there's lots of people using something,

20:43.300 --> 20:45.100
other vendors like hardware vendors

20:45.100 --> 20:47.300
might want to create hardware for these people,

20:47.300 --> 20:49.620
so it will even speed it up even further.

20:49.620 --> 20:51.900
So I do believe that, for example,

20:51.900 --> 20:54.060
ZKML needs a lot of product market fit

20:54.060 --> 20:56.860
or products or catalysts and use cases,

20:56.860 --> 20:59.340
which would improve the state of the art

20:59.340 --> 21:01.460
just by the fact that there's many people looking at it,

21:01.460 --> 21:04.380
there's a lot of mind share, there's high excitement.

21:04.380 --> 21:06.420
So of course there's negative parts to this as well,

21:06.420 --> 21:08.620
but mostly I think it's good.

21:08.620 --> 21:11.500
So some of the use cases that I've seen around,

21:11.500 --> 21:12.860
so I personally work at WorldQuake

21:12.860 --> 21:16.220
and that's like the way that I got exposed to it.

21:16.220 --> 21:19.660
I'll explain our specific youth case towards the end.

21:19.660 --> 21:21.420
So provable inference is one,

21:21.420 --> 21:25.580
so I mentioned earlier on that I do not know

21:25.580 --> 21:26.780
if I'm using chat GPT,

21:26.780 --> 21:29.060
that someone is actually serving me

21:29.060 --> 21:30.900
the model that they claim they are.

21:30.900 --> 21:32.780
So provable inference is just this concept

21:32.780 --> 21:36.340
where I can know that whomever who used a model

21:36.340 --> 21:38.900
to infer some output, I know where it came from.

21:38.900 --> 21:40.100
I know which model it came from.

21:40.100 --> 21:41.300
If it's public, of course,

21:41.300 --> 21:44.300
the APIs can choose to keep the model private,

21:44.300 --> 21:46.460
but at least they can, for example, commit to it.

21:46.460 --> 21:47.940
Something that I can do if, let's say,

21:47.940 --> 21:49.260
GPT-Force Quilt Force, right?

21:49.260 --> 21:50.700
Open source is not open source.

21:50.740 --> 21:53.860
OpenAI did not open source GPT-Force, as of now.

21:53.860 --> 21:56.380
And so if, for example,

21:56.380 --> 21:59.380
I cannot know that someone used GPT-Force

21:59.380 --> 22:01.060
because I don't have the weights, right?

22:01.060 --> 22:03.380
It's not a public thing.

22:03.380 --> 22:06.020
But something that OpenAI could do or anyone else

22:06.020 --> 22:07.700
with a private model could do

22:07.700 --> 22:11.140
is that they can commit to a specific model,

22:11.140 --> 22:12.380
let's say a hash.

22:12.380 --> 22:15.100
And for example, I know that for the entire user base,

22:15.100 --> 22:16.660
they're using the same model.

22:16.660 --> 22:18.220
So they cannot fool any single user

22:18.220 --> 22:20.300
that they're using specific different models

22:20.300 --> 22:21.460
for anyone else.

22:21.460 --> 22:23.180
At least they can commit to it

22:23.180 --> 22:25.620
with a cryptographic hash, so I can just hash.

22:25.620 --> 22:27.420
I know that there is one deterministic output

22:27.420 --> 22:28.260
for this model.

22:28.260 --> 22:30.460
And I know every single user knows

22:30.460 --> 22:31.580
that they're using the same model

22:31.580 --> 22:33.340
because within the zero-knowledge group,

22:33.340 --> 22:36.700
they have a commitment to some specific set of weights,

22:36.700 --> 22:38.020
but they do not reveal the weight.

22:38.020 --> 22:39.060
They're just committed.

22:39.060 --> 22:41.820
And maybe later, they open source the model,

22:41.820 --> 22:43.020
they can reveal the weights,

22:43.020 --> 22:44.300
and you can see that the commitment

22:44.300 --> 22:45.460
does indeed match the weight.

22:45.460 --> 22:49.500
So you actually learn that you did indeed learn about that.

22:49.500 --> 22:52.460
That they did actually use the model they claimed they were.

22:52.460 --> 22:53.540
In this case, GPT-4,

22:53.540 --> 22:55.900
they managed to open source the weights.

22:55.900 --> 22:57.300
So that's provable inference.

22:57.300 --> 22:58.580
It can be used for APIs.

22:58.580 --> 22:59.780
So I mentioned like chat GPT,

22:59.780 --> 23:01.700
but there's many others, like video games.

23:01.700 --> 23:03.340
If I'm playing an on-chain game

23:03.340 --> 23:04.820
and there's some form of ML,

23:04.820 --> 23:06.540
how do I know that the game is not cheating?

23:06.540 --> 23:09.300
How do I know that I have fair rules on there?

23:09.300 --> 23:11.220
The second one is bringing AI on chain.

23:11.220 --> 23:13.180
So there's lots of smart contracts,

23:13.180 --> 23:15.380
lots of applications that people are building

23:15.380 --> 23:16.940
within the blockchain domain.

23:16.940 --> 23:18.820
And within the blockchain domain right now,

23:18.820 --> 23:21.020
it's very limited in terms of things it can do.

23:21.020 --> 23:23.860
And machine learning can provide lots of cool solutions

23:23.860 --> 23:25.860
to a lot of different problems, right?

23:25.860 --> 23:27.980
At the end of the day, machine learning is able to provide

23:27.980 --> 23:30.980
good enough approximations to problems that people have.

23:30.980 --> 23:32.860
And so if we're able to bring that on chain,

23:32.860 --> 23:35.220
we might be able to bring some interesting

23:35.220 --> 23:36.620
opportunity to the table.

23:36.620 --> 23:38.340
I mentioned the financial ones,

23:38.340 --> 23:41.540
where for example, I have a yield protocol on chain

23:41.540 --> 23:44.340
where I deposit assets to this protocol

23:44.340 --> 23:46.660
and it tries to optimize the yield

23:46.660 --> 23:48.140
that I get on those assets.

23:48.140 --> 23:50.300
But it can, it has to use a strategy.

23:50.300 --> 23:53.220
Usually these strategies are called source and hidden,

23:53.220 --> 23:55.700
but at least I can commit to a strategy.

23:55.700 --> 23:57.700
And this strategy can now leverage machine learning

23:57.700 --> 23:59.500
and I can take proof to the protocol

23:59.500 --> 24:02.420
that we're using a machine learning strategy fairly

24:02.420 --> 24:04.300
and we're not updating the weights.

24:04.300 --> 24:05.500
And we can also, for example,

24:05.500 --> 24:07.380
prove that it was trained on some historical data

24:07.380 --> 24:08.780
with some accuracy, right?

24:08.780 --> 24:11.380
I can make a proof that my model is accurate

24:11.380 --> 24:13.860
on some historical data in terms of yield routing

24:13.860 --> 24:15.660
with some accuracy and it's routed

24:15.660 --> 24:19.180
the most performant way, for example.

24:19.180 --> 24:22.020
There's also another one which is agents or intents

24:22.020 --> 24:23.060
in the context of blockchain.

24:23.060 --> 24:26.580
So agents is a word that comes from the ML lingo,

24:26.580 --> 24:29.380
which is like a program that has the ability

24:29.380 --> 24:30.860
to do actions on their own, right?

24:30.860 --> 24:32.700
They're a player, some system,

24:32.700 --> 24:34.740
like game theoretical system in this case.

24:34.740 --> 24:37.580
So if we have some system, let's say that, I don't know,

24:37.580 --> 24:39.660
like we have a program and we allow

24:39.660 --> 24:41.980
this machine learning algorithm, let's say robotics.

24:41.980 --> 24:45.300
Robotic agents are, is a good analogy, right?

24:45.340 --> 24:47.820
So I have a robot and the robot is able

24:47.820 --> 24:49.100
to interact with the real world

24:49.100 --> 24:51.860
because it has limbs, it has different tools

24:51.860 --> 24:53.180
like cameras, et cetera.

24:53.180 --> 24:54.700
And it's able to interact with the real world.

24:54.700 --> 24:56.420
The robot in this case is an agent, right?

24:56.420 --> 24:58.700
It's a program which is able to perform actions

24:58.700 --> 24:59.540
in the real world.

24:59.540 --> 25:01.140
It doesn't have to be a real world agent.

25:01.140 --> 25:02.220
It can be a digital agent.

25:02.220 --> 25:03.500
It can interact with a website.

25:03.500 --> 25:04.660
It can browse the web.

25:04.660 --> 25:08.180
It can watch a video and give me some information about it.

25:08.180 --> 25:10.700
But essentially on-chain agent could, for example,

25:10.700 --> 25:12.340
interact with a blockchain

25:12.340 --> 25:13.980
if they have maybe some knowledge, right?

25:13.980 --> 25:16.020
So if it's a smart agent, it sees that,

25:16.020 --> 25:17.460
okay, something happened here.

25:17.460 --> 25:19.860
So maybe I see that there's a liquidation happening.

25:19.860 --> 25:22.380
So let me do this, let me buy this, let me sell that.

25:22.380 --> 25:24.860
There's different agents that can learn based on information

25:24.860 --> 25:27.540
and if they have a set of steps that they can do,

25:27.540 --> 25:29.860
they can maybe try and optimize for some goal

25:29.860 --> 25:31.860
and then they become agents in the system.

25:31.860 --> 25:34.740
Blockchain people like to call this intense, yeah?

25:34.740 --> 25:37.820
And another one is attestations, for example.

25:37.820 --> 25:40.660
So I can make attestations about things, right?

25:40.660 --> 25:43.340
I can prove to a smart contract that I'm over 18.

25:43.380 --> 25:47.140
I can prove that all sorts of different things, right?

25:47.140 --> 25:49.540
Essentially, I'm just able to use machine learning off-chain

25:49.540 --> 25:51.900
and I can prove that and bring it on-chain.

25:51.900 --> 25:53.420
Private and machine learning cruise.

25:53.420 --> 25:55.460
So this one is a cool one.

25:55.460 --> 25:57.300
So for example, in the context of medicine,

25:57.300 --> 26:01.060
let's say that there's a cancer diagnosis model

26:01.060 --> 26:04.620
and I as the patient, I do not wanna reveal to anyone

26:04.620 --> 26:07.580
like my personal health records.

26:07.580 --> 26:08.980
But for example, there's a doctor

26:08.980 --> 26:10.660
or some health institution

26:10.660 --> 26:14.100
which signs some form of report

26:14.100 --> 26:15.500
or some form of certificates

26:15.500 --> 26:18.420
to some personal health records or data.

26:18.420 --> 26:20.580
And then there's a machine learning model

26:20.580 --> 26:23.420
which uses this data to essentially evaluate it

26:23.420 --> 26:25.940
and tells you whether you're likely to have cancer

26:25.940 --> 26:29.100
or whether you have cancer and with what's uncertainty.

26:29.100 --> 26:30.940
So something that you can hear

26:30.940 --> 26:32.660
is that if you want to prove to, for example,

26:32.660 --> 26:36.100
let's say that an insurance or a payout

26:36.100 --> 26:38.300
had a condition that you've been insured against

26:38.300 --> 26:39.980
or something like that,

26:39.980 --> 26:41.420
you'd be able to prove to them

26:41.420 --> 26:44.060
that there's some health institution

26:44.060 --> 26:46.900
or a specific health institution if you want

26:46.900 --> 26:50.340
that has concluded that I am indeed this

26:50.340 --> 26:52.620
or have been diagnosed with a specific thing

26:52.620 --> 26:56.180
without revealing the model, without revealing the weight,

26:56.180 --> 26:58.300
but you at least know that there's some specific thing

26:58.300 --> 27:00.180
that you can make a proof about.

27:00.180 --> 27:02.500
The possibilities here are early big

27:02.500 --> 27:05.620
in the sense that there is generally programmable.

27:05.620 --> 27:07.900
So this is like just one concrete example,

27:07.900 --> 27:11.500
but people can essentially make proofs about anything,

27:11.500 --> 27:14.060
any data that they have and computations that they did

27:14.060 --> 27:16.580
when they're machine learning base or not

27:16.580 --> 27:18.540
without revealing the data itself, right?

27:18.540 --> 27:20.260
The only person who learns about the data

27:20.260 --> 27:23.340
in the context of ZK is the person making the proof.

27:23.340 --> 27:26.420
I mentioned earlier that this property called completeness.

27:26.420 --> 27:28.260
So in order to make a valid proof,

27:28.260 --> 27:29.660
I do need to have the data.

27:29.660 --> 27:32.580
So the problem is that there's always a prover,

27:32.580 --> 27:33.660
always learns the data,

27:33.660 --> 27:35.940
but if the prover is controlled by myself,

27:35.940 --> 27:38.660
then only it's the same thing as me learning data.

27:38.660 --> 27:40.620
So it's something that is a worthy trade-off.

27:40.620 --> 27:42.700
So if I'm making a proof on my own computer,

27:42.700 --> 27:43.540
that makes sense.

27:43.540 --> 27:45.220
And I can prove to anyone else anything

27:45.220 --> 27:46.420
without revealing my data.

27:46.420 --> 27:48.780
But if I am, for example, delegating it to a server,

27:48.780 --> 27:50.620
the server doesn't need to learn my information,

27:50.620 --> 27:52.500
so I need to be careful.

27:52.500 --> 27:54.180
And digital identity.

27:54.180 --> 27:56.140
So I do want to explain very briefly,

27:56.140 --> 27:58.860
like how did we come to this at WorldCoding?

27:58.860 --> 28:01.540
So we have this hardware device, it's called an org.

28:01.540 --> 28:02.940
I do have it with me.

28:02.940 --> 28:06.060
Maybe if you guys want, I can just go grab it.

28:06.060 --> 28:08.620
And one second in the FAQs, I can show it.

28:08.620 --> 28:12.140
But essentially the WorldCoding org is a piece of hardware

28:12.140 --> 28:13.820
that verifies two things.

28:13.820 --> 28:16.460
It proves that there's a real person

28:16.460 --> 28:18.260
in front of this hardware device.

28:18.260 --> 28:22.980
It does this bunch of phenomenally detection like methods,

28:22.980 --> 28:26.900
and some other like statistical-based methods,

28:26.900 --> 28:29.580
some sensors that it has like infrared sensors,

28:29.580 --> 28:31.300
and it has like field of depth sensors,

28:31.340 --> 28:33.820
it has high-resolution cameras, et cetera.

28:33.820 --> 28:35.660
And it's able to determine that there's a real person

28:35.660 --> 28:37.500
in front of the hardware device, the org,

28:37.500 --> 28:39.940
with like a shiny ball, I'll show it in a bit.

28:39.940 --> 28:43.380
And it can also prove the person in front of it is unique.

28:43.380 --> 28:45.740
And the way that it does that is that it takes

28:45.740 --> 28:48.580
a high-resolution image of the person's IRC's,

28:48.580 --> 28:51.620
and it's able to compute a unique representation of them

28:51.620 --> 28:53.020
called an IRS code.

28:53.020 --> 28:55.060
And this IRS code, the good thing about it,

28:55.060 --> 28:56.500
is that it's not deemed personally

28:56.500 --> 28:59.380
that if I put information, it's just the representation

28:59.380 --> 29:03.500
of the uniqueness or of the randomness of a person's IRS,

29:03.500 --> 29:06.180
and I can use that to measure how unique they are.

29:06.180 --> 29:08.580
And if the distance between two different IRS codes

29:08.580 --> 29:11.780
is big enough, I can prove that this user is unique.

29:11.780 --> 29:13.860
And then once I prove that the person is unique,

29:13.860 --> 29:17.100
I'm able to essentially put them in a set of verified users.

29:17.100 --> 29:20.180
And then what we do is we have a protocol called WorldID,

29:20.180 --> 29:22.660
which allows you to prove that you're a member

29:22.660 --> 29:24.700
of this set of verified users

29:24.700 --> 29:26.660
without revealing which member you are,

29:26.660 --> 29:28.180
using zoological photography as well,

29:28.180 --> 29:31.700
but not ZKML, just traditional zero-knowledge cryptography.

29:31.700 --> 29:34.340
You're able to prove that I am a unique verified human being

29:34.340 --> 29:35.980
without revealing who you are,

29:35.980 --> 29:38.460
and the data that we collect, which is just this IRS code,

29:38.460 --> 29:40.220
is not personally data-fibre information.

29:40.220 --> 29:43.780
We don't collect the raw biometric images, which is cool,

29:43.780 --> 29:46.460
because you're able to essentially leverage modern cryptography,

29:46.460 --> 29:49.900
modern biometric literature, and the modern tools,

29:49.900 --> 29:52.220
like modern hardware like GPUs and everything.

29:52.220 --> 29:53.540
Everything happens client-side,

29:53.540 --> 29:56.060
like within this actual hardware device, right?

29:56.060 --> 29:58.660
So the hardware device does this computation,

29:58.660 --> 30:00.580
nothing leaves the actual orb,

30:00.580 --> 30:04.380
and then the orb deletes everything within its secure enclave

30:04.380 --> 30:06.540
and computational environment.

30:06.540 --> 30:09.060
Within this model of how work can work,

30:09.060 --> 30:12.260
very simplistic model, there's one specific problem,

30:12.260 --> 30:14.460
which in our biometrics pipeline,

30:14.460 --> 30:18.620
if you change the pipeline in any significant way,

30:18.620 --> 30:21.540
you change the outputs of this uniqueness representation,

30:21.540 --> 30:24.500
you change the output space of the IRS codes,

30:24.500 --> 30:26.100
you can think of them as vectors, right?

30:26.100 --> 30:28.700
So you essentially take this vector space,

30:28.700 --> 30:30.380
and you convert it to a different one.

30:30.380 --> 30:33.660
So the same user will have a different representation

30:33.660 --> 30:34.940
in this new space,

30:34.940 --> 30:38.260
therefore you will not be able to measure uniqueness anymore.

30:38.260 --> 30:39.980
So if you ever update the model,

30:39.980 --> 30:42.020
you have to re-sign up all users.

30:42.020 --> 30:44.100
And since you have this physical hardware device

30:44.100 --> 30:45.380
that people have to go to,

30:45.380 --> 30:47.660
it means that all the users that have signed up to date

30:47.660 --> 30:51.660
to WorldID have to go in person again to this hardware device

30:51.660 --> 30:52.940
and get re-signed up.

30:52.940 --> 30:54.140
And this is terrible,

30:54.140 --> 30:56.660
because it's already been really hard enough

30:56.660 --> 30:59.060
for us to get 5 million plus users

30:59.060 --> 31:01.980
and to have to force our users to re-sign up

31:01.980 --> 31:04.380
every single time that we update the biometrics pipeline,

31:04.380 --> 31:06.220
it would be really bad.

31:06.220 --> 31:08.420
And it has like really terrible user experience.

31:08.420 --> 31:10.660
And so this is where one of my coworkers,

31:10.660 --> 31:13.300
his name is Remco, at the WorldCon Foundation,

31:13.300 --> 31:17.740
he came across with a solution or an idea,

31:17.740 --> 31:22.140
which was what if users self-custody their own biometrics,

31:22.140 --> 31:23.660
meaning that the orb,

31:23.660 --> 31:26.020
which has essentially a secure enclave

31:26.020 --> 31:28.020
and a trusted execution environment.

31:28.020 --> 31:30.740
So essentially these two pieces of chips

31:30.740 --> 31:33.540
or these two chips allow you to sign things.

31:33.540 --> 31:35.300
So I'm able to cryptograph a big sign,

31:35.300 --> 31:37.380
something that the orb sees.

31:37.380 --> 31:39.020
So whenever the user gets verified

31:39.020 --> 31:41.340
that they're a real and unique person,

31:41.340 --> 31:43.260
the orb can sign their raw biometric,

31:43.260 --> 31:46.420
which it has in its memory for a given lifetime,

31:46.420 --> 31:48.460
and it can give it to the user,

31:48.460 --> 31:51.660
and the user can store their own biometrics

31:51.660 --> 31:54.780
in their phone and they can encrypt them, of course,

31:54.780 --> 31:56.460
store them safely in an encrypted fashion

31:56.460 --> 31:59.580
on their own phone or cloud or whatever they prefer.

31:59.580 --> 32:02.540
And they would be able to then have a signature

32:02.540 --> 32:04.900
from the orb on the actual biometric, right?

32:04.900 --> 32:08.620
You know that this image was seen at one point by the orb

32:08.620 --> 32:10.860
and it said that this is a unique human being

32:10.860 --> 32:12.180
and this is a real human being,

32:12.180 --> 32:14.100
most importantly is the real part.

32:14.100 --> 32:17.220
Whenever we want to update the model,

32:17.220 --> 32:19.380
what the user could do is they would be able

32:19.420 --> 32:22.140
to download the new model, the weights of the model,

32:22.140 --> 32:25.100
and they seek the approving library for that specific model

32:25.100 --> 32:26.500
and they would be able to create a group

32:26.500 --> 32:31.060
that created this iris code within a zero-knowledge environment.

32:31.060 --> 32:33.140
So they would be able to create a zero-knowledge proof

32:33.140 --> 32:35.100
that they've created a valid iris code

32:35.100 --> 32:38.220
from an input image, which was attested to by the orb.

32:38.220 --> 32:41.820
So essentially the pipeline of trust here is not broke, right?

32:41.820 --> 32:44.020
I know that I've created an iris code

32:44.020 --> 32:45.100
from an original biometric,

32:45.100 --> 32:47.180
which was verified by the orb to be unique.

32:47.220 --> 32:50.740
And with this, I'm able to permissionlessly

32:50.740 --> 32:52.420
or out of my own accord,

32:52.420 --> 32:55.020
I'm able to permissionlessly insert myself

32:55.020 --> 32:56.900
into the set of verified users

32:56.900 --> 32:58.660
without having to go to the orb again

32:58.660 --> 33:01.100
because I have the entire set of steps that I need

33:01.100 --> 33:03.740
in order to prove to the world ID protocol

33:03.740 --> 33:06.260
that I'm a unique user without revealing who I am again.

33:06.260 --> 33:09.300
I just proved to you that, hey, the orb saw me at one point in time,

33:09.300 --> 33:12.820
the orb did indeed sign this my image, I store my images,

33:12.820 --> 33:13.660
and then I make a proof

33:13.660 --> 33:16.180
that I've created this derived representation of uniqueness

33:16.180 --> 33:18.020
for my biometrics,

33:18.020 --> 33:19.660
and I can prove to them I'm a unique human

33:19.660 --> 33:21.940
in this new representation and this new model

33:21.940 --> 33:24.020
without revealing who I am again, right?

33:24.020 --> 33:26.060
So this is like perfect things,

33:26.060 --> 33:27.500
like a perfect solution for us.

33:27.500 --> 33:32.500
It's actually quite crazy that this problem didn't exist,

33:33.500 --> 33:37.260
at least that's what I felt when I first covered it through Remco.

33:37.260 --> 33:38.900
And so right now, for example,

33:38.900 --> 33:40.300
we're working with one of the companies

33:40.300 --> 33:41.380
which I mentioned earlier,

33:41.380 --> 33:44.940
Modulus to essentially do this client-side

33:44.940 --> 33:46.860
zero-knowledge machine learning proving

33:46.860 --> 33:48.580
inside of a user's phone, right?

33:48.580 --> 33:50.580
So that people can self-cassellate the biometrics

33:50.580 --> 33:52.460
and permissionlessly insert themselves.

33:52.460 --> 33:53.660
It's like very early stages,

33:53.660 --> 33:55.140
R&D is not yet in production,

33:55.140 --> 33:57.260
but there's been a lot of good progress here.

33:57.260 --> 33:59.500
And two years ago, it seemed like sci-fi,

33:59.500 --> 34:02.020
now there's already like concrete proof concepts

34:02.020 --> 34:04.860
and implementation and there's benchmarks

34:04.860 --> 34:06.620
and things that are improving.

34:06.620 --> 34:09.500
But yeah, this is like one of the things that I saw.

34:10.980 --> 34:12.580
One last thing that I do want to mention

34:12.580 --> 34:15.380
before I leave you to ask me questions

34:15.380 --> 34:17.940
and for me to go grab my orb as well

34:17.940 --> 34:19.580
is technical bottlenecks.

34:19.580 --> 34:20.980
Zero-knowledge machine learning, right?

34:20.980 --> 34:22.180
We've seen some use cases,

34:22.180 --> 34:24.220
we've seen what people are working on,

34:24.220 --> 34:25.580
what people are doing, what it is,

34:25.580 --> 34:27.380
some of the things that we are doing,

34:27.380 --> 34:28.860
but where do we go now, right?

34:28.860 --> 34:30.860
If you're someone who is interested in this topic,

34:30.860 --> 34:32.660
where could you contribute if you want to,

34:32.660 --> 34:34.020
if you end up learning more?

34:34.020 --> 34:35.660
How do you contribute to these?

34:36.540 --> 34:38.380
Or what are the problems that are hard

34:38.380 --> 34:40.940
and that would help us improve in the front?

34:40.940 --> 34:44.060
So one is better cryptography, right?

34:44.060 --> 34:45.980
Because it's better ZK.

34:45.980 --> 34:48.620
As I mentioned, the worst in ZK and the worst of ML

34:48.620 --> 34:49.980
create a joint bottleneck.

34:49.980 --> 34:52.420
So if you improve ZK or if you improve ML,

34:52.420 --> 34:53.900
you improve the KML.

34:53.900 --> 34:55.980
But there is also an intersection

34:55.980 --> 34:58.380
where if you just focus on the ZK parts

34:58.380 --> 34:59.420
that would make ML better

34:59.420 --> 35:01.700
and on the ML parts that would make ZK better

35:01.700 --> 35:05.100
or simpler, that's the most focused effort

35:05.100 --> 35:08.260
that you can make to essentially improve everything.

35:08.260 --> 35:09.860
The one is better cryptography.

35:09.860 --> 35:11.340
So remainder, for example,

35:11.340 --> 35:12.700
the thing that I mentioned here,

35:12.700 --> 35:14.220
remainder is a proving library

35:14.220 --> 35:17.620
that is built by modulus labs or modulus,

35:17.620 --> 35:20.740
which essentially uses a type of cryptography

35:20.740 --> 35:22.980
which better models the structured nature

35:22.980 --> 35:24.300
of machine learning computing.

35:24.300 --> 35:25.660
Where like machine learning usually have

35:25.660 --> 35:27.340
matrix multiplication.

35:27.340 --> 35:29.220
They have some non-linearities.

35:29.220 --> 35:32.060
So like functions that are non-linear, in this case,

35:32.060 --> 35:33.620
there's like activation functions

35:33.620 --> 35:35.060
or like a good example of this.

35:35.060 --> 35:37.300
So there's things like ReLU,

35:37.300 --> 35:38.860
which is one of the most popular ones,

35:39.420 --> 35:41.820
defined linear unit, something like that.

35:41.820 --> 35:43.740
Like tanh, there's a bunch of activation functions,

35:43.740 --> 35:44.980
non-linear function.

35:44.980 --> 35:47.980
So they built a cryptographic system

35:47.980 --> 35:52.060
which is able to represent the structured computation

35:52.060 --> 35:54.420
in a much more efficient way.

35:54.420 --> 35:58.220
So when it comes to proving these structured computations,

35:58.220 --> 36:00.420
it takes a lot less computational power to do so

36:00.420 --> 36:03.260
because the representation is much more succinct

36:03.260 --> 36:04.620
and much more efficient.

36:04.620 --> 36:06.300
And so it makes it a lot faster

36:06.300 --> 36:07.660
and a lot more performant

36:07.660 --> 36:09.700
and less computationally intensive.

36:09.700 --> 36:12.260
So this would potentially make it feasible

36:12.260 --> 36:14.620
to run a DK machine learning prover

36:14.620 --> 36:17.380
on a personal phone, for example.

36:17.380 --> 36:18.860
Another one is better hardware.

36:18.860 --> 36:21.420
So hardware and specialized hardware

36:21.420 --> 36:24.260
is one of the things that modern science

36:24.260 --> 36:25.860
has benefited from most.

36:25.860 --> 36:28.100
We've seen the transistor consistently shrinking

36:28.100 --> 36:28.940
and shrinking.

36:28.940 --> 36:30.620
We fit more transistors on a chip,

36:30.620 --> 36:32.580
almost like 2X every 18 months, right?

36:32.580 --> 36:35.180
There's Moore's Law, which goes exponentially.

36:35.180 --> 36:37.300
And now we're at like the two nanometer scale

36:37.300 --> 36:39.660
where we have transistors that are two nanometers wide

36:39.660 --> 36:42.460
and we're able to pack trillions of them on modern GPUs.

36:42.460 --> 36:44.860
And for example, in the context of machine learning,

36:44.860 --> 36:46.780
machine learning was really terrible

36:46.780 --> 36:49.580
on traditional computers like CPUs back in the day,

36:49.580 --> 36:51.580
like in the 60s and 70s and 90s.

36:51.580 --> 36:53.820
So no one actually did machine learning back then.

36:53.820 --> 36:57.180
But when these people were playing video game for some reason,

36:57.180 --> 36:58.940
people started building chips

36:58.940 --> 37:02.820
that represent graphical interfaces a lot better.

37:02.820 --> 37:06.780
And it happens that there's an overlap of the mathematics

37:06.780 --> 37:10.300
that are used to represent graphics and graphics card

37:10.300 --> 37:12.540
and the machine learning, right?

37:12.540 --> 37:14.660
Machine learning is the matrix multiplication

37:14.660 --> 37:17.500
and the way that you represent pictures is matrices, right?

37:17.500 --> 37:20.580
It's just zeros and one that represent the RGB values

37:20.580 --> 37:22.660
of every single pixel on the screen

37:22.660 --> 37:24.220
and transformations between them.

37:24.220 --> 37:25.660
And so you have to do these operations

37:25.660 --> 37:26.860
between pixels really fast.

37:26.860 --> 37:28.300
And it just happened that it's the same thing

37:28.300 --> 37:30.820
as doing machine learning like neural network

37:30.820 --> 37:33.900
fast multiplication across multiple connected layers.

37:33.900 --> 37:35.420
It's like very similar structure.

37:35.420 --> 37:38.980
And so people start using GPUs to speed up machine learning

37:38.980 --> 37:41.780
and machine learning became feasible all of a sudden in 2012

37:41.780 --> 37:43.180
with convolutional neural networks

37:43.180 --> 37:46.260
and all these new like booms that we've been writing

37:46.260 --> 37:47.900
until now with modern LLMs.

37:47.900 --> 37:50.380
Like LLMs and all these new generative AI models

37:50.380 --> 37:52.580
are only possible because of this specialized hardware

37:52.580 --> 37:56.540
that come from NVIDIA, DCMC, AMD, ASML,

37:56.540 --> 37:58.780
like all these like transistor manufacturers,

37:58.780 --> 38:01.860
graphic car manufacturers, specialized hardware manufacturers.

38:01.860 --> 38:02.980
These ones are for machine learning,

38:02.980 --> 38:04.940
GPUs and tensor processing unit,

38:04.940 --> 38:07.540
GPUs, cryptography on the other hand,

38:07.540 --> 38:09.340
they work with a different type of math.

38:09.340 --> 38:11.780
Instead of working with floating points or arithmetic,

38:11.780 --> 38:15.340
they work with finite fields and sixth point arithmetic.

38:15.340 --> 38:17.820
And so you need to design fundamentally different hardware.

38:17.820 --> 38:19.380
And so we need to build better hardware

38:19.380 --> 38:22.340
to improve the computational capabilities

38:22.340 --> 38:24.100
of zero knowledge machine learning

38:24.100 --> 38:26.700
or just zero knowledge cryptography in this then.

38:26.700 --> 38:28.300
So there's lots of things to be done here.

38:28.300 --> 38:30.580
So I'm, for example, I'm also an investor in Fabric,

38:30.580 --> 38:31.420
I'm sorry for that,

38:31.420 --> 38:34.700
but Fabric is one of the ZK hardware company.

38:34.700 --> 38:37.020
In GoNyama, not size thick, it's size thick,

38:37.020 --> 38:39.460
sorry about that, some misspelling without the T.

38:39.460 --> 38:40.380
And irreducible,

38:40.380 --> 38:43.260
there's some of the biggest ZK hardware companies.

38:43.260 --> 38:45.740
And yeah, so these are trying to essentially model

38:45.740 --> 38:48.140
the software in hardware so that it's faster

38:48.140 --> 38:49.740
and there's less overhead.

38:49.740 --> 38:51.100
Another one is better tooling.

38:51.100 --> 38:52.540
So I mentioned Ezekiel and Giza.

38:52.540 --> 38:54.180
They're building tooling that makes it easier

38:54.180 --> 38:56.820
for developers to use ZK.

38:56.820 --> 38:58.260
And if I'm a machine learning engineer,

38:58.260 --> 39:00.940
there's no way in hell I'm gonna spend six years

39:00.940 --> 39:03.860
learning cryptography and learning the state of the art

39:03.860 --> 39:05.020
and trying to contribute there

39:05.020 --> 39:06.980
so that I can prove my machine learning model.

39:06.980 --> 39:08.100
As a machine learning engineer,

39:08.100 --> 39:11.340
I just care about something that ZK can bring to me.

39:11.340 --> 39:12.980
And vice versa, if I'm a ZK guy,

39:12.980 --> 39:15.220
I just care about something that ML can bring to me

39:15.220 --> 39:18.440
to get better or like somehow make it on chain.

39:18.440 --> 39:21.180
So whenever we've brought down the cost of barriers,

39:21.180 --> 39:24.140
like barriers that the cost barriers

39:24.140 --> 39:26.380
that prevent us from doing something,

39:26.380 --> 39:27.660
people start experimenting, right?

39:27.660 --> 39:30.500
Like same thing happened with the web.

39:30.500 --> 39:32.260
Like anyone can build a website nowadays

39:32.260 --> 39:33.180
and you can build a business,

39:33.180 --> 39:34.260
you can just be Shopify.

39:34.260 --> 39:35.420
And if I'm a business guy,

39:35.420 --> 39:36.780
I don't need to know web development.

39:36.780 --> 39:38.060
Shopify and I have my store

39:38.060 --> 39:40.020
and I can process millions of dollars of payment.

39:40.020 --> 39:42.860
I can have a truly user and everything.

39:42.860 --> 39:44.900
And otherwise I would have to learn web development,

39:44.900 --> 39:45.980
servers, everything.

39:45.980 --> 39:46.940
I don't have to care about that.

39:46.940 --> 39:47.780
I just do my business

39:47.780 --> 39:50.340
and I use web technology without having to know how it works.

39:50.340 --> 39:52.980
So the same thing applies to KML of course.

39:52.980 --> 39:55.020
More robust than secure implementation.

39:55.020 --> 39:57.060
That one is a bit like self-explanatory

39:57.060 --> 39:58.980
but essentially like the more security

39:58.980 --> 40:02.380
the less prevent like if we can prevent hacks and exploit

40:02.380 --> 40:03.980
then if it's more robust,

40:03.980 --> 40:06.460
it can sustain more users, et cetera.

40:06.460 --> 40:08.340
And the other one is like what I mentioned before

40:08.340 --> 40:09.420
pretty much at the same point,

40:09.420 --> 40:11.620
like better tooling and easier interfaces

40:11.620 --> 40:12.660
is pretty much the same thing

40:12.660 --> 40:14.260
because the easier it is to use,

40:14.260 --> 40:16.460
the more experimentation there for the more products,

40:16.460 --> 40:17.660
the more product market fits,

40:17.660 --> 40:18.940
the more businesses can build

40:18.940 --> 40:21.220
and the more technology can accelerate

40:21.220 --> 40:24.180
towards the direction of growth.

40:24.180 --> 40:27.020
So yeah, that's everything about my presentation

40:27.020 --> 40:31.540
and I would love to answer any of your questions.

40:31.540 --> 40:33.060
I don't know how long we have.

40:33.060 --> 40:35.260
I think it's 14 minutes for FAQ.

40:35.260 --> 40:38.260
I can also go run, get the orb if you guys wanna see it.

40:38.260 --> 40:40.540
And thank you for having me.

40:40.540 --> 40:41.380
This was fantastic.

40:41.380 --> 40:42.380
Thank you so much.

40:42.380 --> 40:43.220
What a world.

40:43.220 --> 40:45.100
And we have a few questions already here

40:45.100 --> 40:46.260
from people in the chat

40:46.260 --> 40:48.500
and then maybe after a few we give you some time to breathe

40:48.500 --> 40:50.620
and get the orb, that would be great.

40:50.620 --> 40:52.100
Okay, so first one, Shadi,

40:52.100 --> 40:54.420
if you wanna unmute your first.

40:54.420 --> 40:56.300
Hi, yeah, thanks for the great presentation.

40:56.380 --> 40:57.580
Very informative.

40:57.580 --> 41:00.740
I had a question about the personally identifying information

41:00.740 --> 41:04.420
from the hash from the iris biometrics.

41:04.420 --> 41:07.820
Isn't a hash or iris still uniquely identifying

41:07.820 --> 41:11.500
if you know the hashing function to produce that digest?

41:11.500 --> 41:14.700
Or did you mean that make the function is kept secret

41:14.700 --> 41:18.860
and nobody can easily take like a photograph of someone

41:18.860 --> 41:22.100
and then produce the same hash and that look on chain,

41:22.100 --> 41:23.460
for example, I don't think you posted on chain

41:23.460 --> 41:26.220
but look on chain, for example, to try to match that.

41:26.940 --> 41:30.380
Yeah, there's one unfortunate naming collision here.

41:30.380 --> 41:31.740
So in biometric literature,

41:31.740 --> 41:34.780
people use a hash in a non-urgorous way.

41:34.780 --> 41:36.180
And so what we mean here,

41:36.180 --> 41:37.260
or what we used to mean,

41:37.260 --> 41:39.900
we've changed the way that we explain these things.

41:39.900 --> 41:41.700
We no longer use the terminology of hash

41:41.700 --> 41:45.500
because we work in the intersection of AI and cryptography

41:45.500 --> 41:47.900
and if you use a term that means a different thing in both,

41:47.900 --> 41:51.420
it's like ambiguous and it can cause problems

41:51.420 --> 41:53.100
like this one right now.

41:53.100 --> 41:56.780
Actually, the way the biometrics pipeline works

41:56.780 --> 42:00.020
is that there's this essentially convolution-like algorithm.

42:00.020 --> 42:03.020
It's called the GABER wavelet or GABER filter,

42:03.020 --> 42:04.660
which essentially applies convolutions

42:04.660 --> 42:06.660
into original biometrics many times over

42:06.660 --> 42:10.500
and it's able to compute like a randomness representation.

42:10.500 --> 42:14.460
And this one essentially compresses the image so much,

42:14.460 --> 42:16.300
like after performing all these operations,

42:16.300 --> 42:20.820
you end up with a pretty much a small representation

42:20.820 --> 42:22.660
of a few bits, like I think it's 200,

42:22.660 --> 42:24.860
something that, so the vector in the end,

42:24.860 --> 42:26.660
like the embedding in the end is like a few bit.

42:26.660 --> 42:29.980
And this one is not able to be reconstructed

42:30.980 --> 42:33.660
to its original, at least like a lossy function, right?

42:33.660 --> 42:36.140
If I go from a compressed representation

42:36.140 --> 42:38.580
to a fully, try to expand it back,

42:38.580 --> 42:39.900
I lose information in the process

42:39.900 --> 42:41.940
of converting it to this compressed representation.

42:41.940 --> 42:43.980
Therefore, I'm not able to reconstruct the same one.

42:43.980 --> 42:47.060
And the good part of this is that I'm able to,

42:47.060 --> 42:48.860
I'm able to reconstruct something similar,

42:48.860 --> 42:51.300
but it's not personalized identifiable,

42:51.300 --> 42:54.340
at least not considered so in modern literature, right?

42:54.340 --> 42:56.860
This may change and this is why we've been working

42:56.860 --> 42:58.580
on a lot of other things within world economy,

42:58.580 --> 43:01.380
like more of the party computation solutions and whatnot.

43:01.380 --> 43:03.180
We're gonna be publishing a lot about this

43:03.180 --> 43:05.180
in the coming month, but if you're interested

43:05.180 --> 43:08.060
in like follow this, the biometrics pipeline works

43:08.060 --> 43:10.140
and have the definition of it and how it works

43:10.140 --> 43:11.500
and what is actually going on,

43:11.500 --> 43:13.740
I recommend going to the link I just said in the chat,

43:13.740 --> 43:15.300
my paper that work in the org.

43:15.300 --> 43:17.260
Also, one of my teammates is in the,

43:17.260 --> 43:19.460
actually one of the former teammates,

43:19.460 --> 43:20.820
he's at Tool for Humanity,

43:20.820 --> 43:22.220
which is the labs entity.

43:22.220 --> 43:24.620
I'm at the foundation of different legal entities,

43:24.620 --> 43:26.740
but they're both contributing to the world team project.

43:26.740 --> 43:28.380
His name is Daniel Gershiewicz.

43:28.380 --> 43:29.660
He is in the cause law.

43:29.660 --> 43:31.700
So he's also able to explain a bit more.

43:31.700 --> 43:32.860
He's on the org software team.

43:32.860 --> 43:36.140
So he works a lot more with the biometrics pipeline than I do.

43:36.140 --> 43:37.740
I'm more still in the cryptography

43:37.740 --> 43:38.980
protocol side of thing.

43:38.980 --> 43:40.460
But yeah, within the white paper,

43:40.460 --> 43:41.900
white paper.worldcoin.org,

43:41.900 --> 43:43.300
you have a biometric action

43:43.300 --> 43:44.380
and you have the third definition

43:44.380 --> 43:45.660
of what it is that we're doing

43:45.660 --> 43:47.260
and how we preserve privacy.

43:47.260 --> 43:49.900
So to answer your question in a specific way,

43:49.900 --> 43:51.620
it's not a hash, it's not a cryptographic hash.

43:51.620 --> 43:53.060
There's no digest, there's no plaintext.

43:53.060 --> 43:55.660
It's essentially a convolutional like operation

43:55.660 --> 43:56.700
which happens many times

43:56.700 --> 43:58.300
and it leaves the input unrecognizable

43:58.300 --> 43:59.380
and you compress certain information

43:59.380 --> 44:01.100
of the randomness that you get.

44:01.100 --> 44:03.340
You cannot use that to reconstruct the original thing

44:03.340 --> 44:04.380
that you put into this function

44:04.380 --> 44:05.980
because it's a very lofty function.

44:05.980 --> 44:08.780
And this is good enough to prevent

44:08.780 --> 44:12.060
like getting the raw biometric out again.

44:13.180 --> 44:14.020
Got it.

44:14.020 --> 44:16.420
So the idea is even if I had access

44:16.420 --> 44:19.060
to the kernels that you used to train,

44:19.220 --> 44:24.220
then I wouldn't be able to deconvolute the output.

44:25.740 --> 44:26.580
I see.

44:26.580 --> 44:30.500
Ideally to try and break our own assumptions

44:30.500 --> 44:31.700
and try to reverse engineer

44:31.700 --> 44:33.220
and actually get the original image.

44:33.220 --> 44:35.420
And now we've gone ahead a step further

44:35.420 --> 44:37.100
because if it was possible,

44:37.100 --> 44:38.100
we've gone a step further

44:38.100 --> 44:39.940
and we're now storing everything in ciphertext

44:39.940 --> 44:41.300
and the uniqueness check,

44:41.300 --> 44:44.060
it's happening on ciphertext with multi-party computation.

44:44.060 --> 44:46.860
So yeah, that's like cool, cool new research stuff.

44:47.820 --> 44:48.660
Love it.

44:48.660 --> 44:50.100
Dan also shared, I think the white paper

44:50.100 --> 44:51.700
that you referenced directly here in the chat

44:51.700 --> 44:53.340
already a little further up.

44:53.340 --> 44:54.420
Thanks for that, Dan.

44:54.420 --> 44:57.380
Next one up we have Richard and then we have Micah.

44:58.540 --> 45:00.620
Yeah, I think the previous discussion

45:00.620 --> 45:01.780
answered my question there.

45:01.780 --> 45:03.020
Thank you.

45:03.020 --> 45:04.060
Awesome.

45:04.060 --> 45:04.900
Wonderful.

45:04.900 --> 45:06.340
Micah, you go.

45:06.340 --> 45:07.540
Micah, we can't hear you.

45:07.540 --> 45:09.740
Feel free if you can't unmute to put your chat,

45:09.740 --> 45:11.700
your question in the chat.

45:11.700 --> 45:13.420
Okay, he's going to rejoin.

45:13.420 --> 45:15.860
This could be a great opportunity for you to get the orb.

45:15.860 --> 45:19.780
I also have a few questions, but God, you go.

45:20.620 --> 45:21.460
Can you hear me?

45:22.580 --> 45:24.020
Yes, Dan, we can hear you.

45:25.300 --> 45:27.180
I want to go back, there was this question about

45:27.180 --> 45:29.740
and things being personally identifiable

45:29.740 --> 45:31.820
or uniquely identifying information.

45:31.820 --> 45:34.540
And then the question turned into ashes

45:34.540 --> 45:37.420
versus wavelet encodings.

45:38.500 --> 45:39.340
I don't know.

45:39.340 --> 45:41.820
I think the question actually got lots of discussions.

45:41.820 --> 45:44.740
And the interesting thing is that even if you've had

45:44.740 --> 45:46.220
either a hash or an encoding,

45:46.220 --> 45:49.580
and you somehow broke this and could reverse that image,

45:50.580 --> 45:52.940
actually the privacy comes from

45:52.940 --> 45:54.340
what was briefly mentioned in the talk,

45:54.340 --> 45:58.900
which is that when you prove your ownership of such,

45:58.900 --> 46:01.140
you're proving ownership of a key

46:01.140 --> 46:05.780
that was linked to this biometric encoding.

46:05.780 --> 46:07.260
So when you prove ownership of that key,

46:07.260 --> 46:09.500
you're not pointing to which encoding is yours.

46:09.500 --> 46:10.420
So you're a member of the set

46:10.420 --> 46:12.220
without revealing which member.

46:12.220 --> 46:13.420
And that means that these encodings

46:13.420 --> 46:15.540
are cryptographically delinked from anything else,

46:15.540 --> 46:17.580
your transactions, your accounts.

46:17.580 --> 46:18.540
Nothing can be linked back.

46:18.540 --> 46:23.180
So if you did reverse those codes, you wouldn't know.

46:23.180 --> 46:25.260
Also, one additional thing is that

46:25.260 --> 46:27.500
these encodings are not public.

46:27.500 --> 46:30.340
They're hidden in a database that we have.

46:30.340 --> 46:33.020
The thing that is public is the public key

46:33.020 --> 46:36.220
associated with the user that has undergone a unique question.

46:36.220 --> 46:38.380
So if I have this unique coding,

46:38.380 --> 46:41.460
and I prove that I'm a unique within the coding set,

46:41.500 --> 46:44.500
which is kept not on any public sphere,

46:44.500 --> 46:46.980
it's now kept in this multi-party computation

46:46.980 --> 46:48.500
encrypted environment in a database

46:48.500 --> 46:51.380
that is run by three different parties

46:51.380 --> 46:54.340
in an MPC setting, again, multi-party.

46:54.340 --> 46:56.660
And when the user is verified to be unique,

46:56.660 --> 46:58.060
we take the user's public key,

46:58.060 --> 46:59.660
which was generated by the World app,

46:59.660 --> 47:01.620
which is the way that you interface with World ID

47:01.620 --> 47:03.980
and the wallet and a bunch of other things that we're building.

47:03.980 --> 47:05.460
Essentially, the public key that was generated

47:05.460 --> 47:07.300
by the World app, by the user,

47:07.300 --> 47:09.100
which is a unique person that's been just verified

47:09.100 --> 47:12.780
by the World, gets inserted into the set of verified users,

47:12.780 --> 47:14.860
and then I'm able to make a knowledge proof

47:14.860 --> 47:17.820
that I own a private key to a public key

47:17.820 --> 47:19.420
and the set of verified users.

47:19.420 --> 47:21.220
So even then, there's one more step

47:21.220 --> 47:24.100
that removed from your biometric completely,

47:24.100 --> 47:26.300
because a public key is just random,

47:26.300 --> 47:29.420
cryptographical, gibberish that I can make proofs about,

47:29.420 --> 47:31.420
and I'm able to prove to you that I'm a unique member

47:31.420 --> 47:32.500
of the set because I own a private key

47:32.500 --> 47:35.020
to a public key in the set, but I don't know which one.

47:35.020 --> 47:36.540
And there's another cool part,

47:36.540 --> 47:38.660
which is the nullifier scheme that we have,

47:38.660 --> 47:41.100
which allows you to represent unique actions.

47:41.100 --> 47:43.700
For example, one is like unique governance,

47:43.700 --> 47:46.220
like one person, one vote, digital governance,

47:46.220 --> 47:47.820
or voting protocol.

47:47.820 --> 47:48.980
Currently, there's no way to prove

47:48.980 --> 47:50.580
that you're not a bot online.

47:50.580 --> 47:52.620
So if you, for example, let's say, I don't know,

47:52.620 --> 47:55.780
Elon Musk puts a poll on Twitter or on X

47:55.780 --> 47:58.380
that, hey, is this doc cute or no?

47:58.380 --> 48:03.100
I can create a bajillion X accounts and vote for no, right?

48:03.100 --> 48:04.300
There's no way for me to prove

48:04.300 --> 48:05.940
that this is a one person, one vote.

48:05.940 --> 48:08.420
So whomever who posts a poll on whatever thing

48:08.460 --> 48:10.220
doesn't matter, like the opinion doesn't matter,

48:10.220 --> 48:11.820
the result of the poll doesn't matter.

48:11.820 --> 48:13.580
There's million bots that have incentives

48:13.580 --> 48:15.740
and both, like presidential elections,

48:15.740 --> 48:18.140
if Elon says, is this candidate a good guy?

48:19.100 --> 48:21.100
People can vote yes, but it can be like a third,

48:21.100 --> 48:24.380
like external nation state actor trying to just

48:24.380 --> 48:26.740
civil attack, which means like attack a protocol

48:26.740 --> 48:29.100
where you need unique members in a way

48:29.100 --> 48:31.340
that just make the protocol broken

48:31.340 --> 48:32.940
completely beyond repair.

48:32.940 --> 48:34.140
So this is where we step in,

48:34.140 --> 48:36.780
where we create a unit of account of uniqueness

48:36.780 --> 48:39.140
for humans in a digital environment,

48:39.140 --> 48:41.620
whether it's on chain or it's off chain doesn't matter.

48:41.620 --> 48:43.300
As long as you're able to make these cryptographic

48:43.300 --> 48:44.980
at the station that I am a unique person

48:44.980 --> 48:46.820
and I've not done an action before,

48:46.820 --> 48:49.260
so I'm able to prove that I'm a unique actor.

48:49.260 --> 48:51.420
I'm a unique member of this protocol

48:51.420 --> 48:53.020
and I only voted once.

48:53.020 --> 48:56.420
So I can say that this dog was cute only once.

48:56.420 --> 48:57.940
And if I want to weigh the outcome,

48:57.940 --> 48:59.660
the only way to weigh the outcome is that I need

48:59.660 --> 49:01.340
to convince a thousand other members

49:01.340 --> 49:02.460
to vote for the same thing,

49:02.460 --> 49:04.660
but I'm not able to just create a million accounts

49:04.660 --> 49:07.620
and vote for a same thing to weigh the outcome.

49:07.620 --> 49:08.460
Yeah.

49:08.460 --> 49:09.300
Awesome.

49:09.300 --> 49:10.340
Yeah, I think Bramco talked a little bit about that,

49:10.340 --> 49:12.340
especially like with possible future applications

49:12.340 --> 49:14.380
also that you also listed very briefly,

49:14.380 --> 49:16.580
including in medicine and so forth

49:16.580 --> 49:19.020
that I think these groups are just like really incredible for

49:19.020 --> 49:21.260
because it can't for medicine, for financial risk,

49:21.260 --> 49:22.100
for insurance and stuff,

49:22.100 --> 49:25.220
you just can't really access the data any other way.

49:25.220 --> 49:28.020
Or you just can't do too much anyways with the information.

49:28.020 --> 49:29.140
Okay, we have another question,

49:29.140 --> 49:31.540
but you also have the orb now or?

49:31.540 --> 49:32.780
It's right here, my lap.

49:34.740 --> 49:36.140
Wonderful.

49:36.140 --> 49:38.100
By the call, the battery,

49:39.500 --> 49:40.340
at least.

49:41.500 --> 49:42.540
All right, sorry.

49:42.540 --> 49:44.700
I'm gonna unbler my background.

49:44.700 --> 49:46.660
I do have a, I just moved into a new apartment,

49:46.660 --> 49:48.300
so forgive me for,

49:50.060 --> 49:55.060
but yeah, the battery right here.

49:55.300 --> 49:57.940
Yeah, that is able to say a lot more about the orb than I can.

49:57.940 --> 49:59.900
If you work on the orb software team,

49:59.900 --> 50:03.300
you've been working on this for three years plus.

50:03.300 --> 50:04.140
Yeah.

50:04.940 --> 50:08.300
Yeah, I've come in multiple close contacts with the orb already

50:08.300 --> 50:11.020
and I think in 50 years you even have it like taken apart,

50:11.020 --> 50:12.180
you know, and it's different components,

50:12.180 --> 50:13.620
which is really fun to see.

50:13.620 --> 50:15.340
So yeah, thanks.

50:15.340 --> 50:17.740
The orb hardware specs are publicly available

50:17.740 --> 50:18.940
on GitHub as well.

50:18.940 --> 50:20.700
So people can see the PCB design,

50:20.700 --> 50:22.700
they can see like what components it's made out of.

50:22.700 --> 50:23.900
There's also an hour paper,

50:23.900 --> 50:26.980
there's like an annotated set of every single component

50:26.980 --> 50:29.940
and like what it does, how it works, et cetera.

50:29.940 --> 50:31.140
Yeah, I've been following like

50:31.140 --> 50:32.380
just how many people are signing up

50:32.380 --> 50:34.580
and like the very, very long lines.

50:35.340 --> 50:38.060
Sign up stations, which has been really interesting.

50:38.060 --> 50:40.700
Okay, Micah, you rejoined and you raised your hand.

50:40.700 --> 50:42.940
Do you want to ask you a final question?

50:42.940 --> 50:44.140
Testing, can you hear me?

50:45.540 --> 50:46.580
Yep.

50:46.580 --> 50:48.780
Quick comment and then a question after that.

50:48.780 --> 50:51.700
The, I believe that while the transactions,

50:51.700 --> 50:54.660
your transactions made using your unique ID

50:54.660 --> 50:55.820
can't be linked back to you.

50:55.820 --> 50:57.580
You can be linked back to your transaction.

50:57.580 --> 51:00.060
Someone has an orb or the algorithm in the orb

51:00.060 --> 51:01.940
and they can get a picture of you, so to speak.

51:01.940 --> 51:04.500
They can then regenerate your unique ID

51:04.500 --> 51:07.180
and this is an unnecessary piece.

51:07.180 --> 51:09.420
You can't get rid of it because in order to have

51:09.420 --> 51:11.820
a unique human, you need to be able to verify.

51:11.820 --> 51:13.620
There needs to be only one outcome.

51:13.620 --> 51:15.380
You can't introduce randomness here, right?

51:15.380 --> 51:19.740
And so if your goal is to not have someone be able

51:19.740 --> 51:21.700
to tell which transactions you did,

51:21.700 --> 51:22.660
that is not possible here.

51:22.660 --> 51:25.980
But someone can't tell just by looking at the transactions

51:25.980 --> 51:26.820
that they were yours.

51:26.820 --> 51:28.220
It's a one-way thing.

51:28.220 --> 51:29.980
This one held you down and put an orb in front of your eye,

51:29.980 --> 51:31.600
they can then figure out all your transactions,

51:31.600 --> 51:33.260
but they couldn't look at your transaction

51:33.260 --> 51:36.620
and figure out which eye they belong to, so to speak.

51:36.620 --> 51:40.260
Yes and no, there's one step that helps us mitigate this,

51:40.260 --> 51:42.180
which is the separation of the public key, right?

51:42.180 --> 51:43.900
Like your transactions are not being done

51:43.900 --> 51:45.860
by your iris code or whatever.

51:45.860 --> 51:47.940
The transactions are being done by a public key

51:47.940 --> 51:49.220
which was owned by a user,

51:49.220 --> 51:51.900
which just happened to verify at the orb, right?

51:51.900 --> 51:54.580
You would have to get the user's private key

51:54.580 --> 51:56.500
to learn what they did on the game.

51:56.500 --> 51:58.460
And then you would also have to get their bandwidth forked

51:58.460 --> 52:00.820
to try and interlink too, right?

52:00.820 --> 52:02.060
You'd have to get their bandwidth forked,

52:02.060 --> 52:03.220
you'd generate the iris code,

52:03.220 --> 52:05.780
and then get somehow steal from them their private key.

52:05.780 --> 52:06.980
And then with a private key,

52:06.980 --> 52:10.100
you're able to de-anonymize the on-chain state

52:10.100 --> 52:11.700
that they performed in a DK way

52:11.700 --> 52:14.340
because you're not able to just get the live iris.

52:14.340 --> 52:15.960
You know you can generate them.

52:15.960 --> 52:19.780
And so there's two things that you need to compromise there.

52:19.780 --> 52:20.980
I'll just, my actual question,

52:20.980 --> 52:21.820
I'll try to keep it,

52:21.820 --> 52:23.460
I know I've got one minute left.

52:23.460 --> 52:26.180
Last I checked, DK proof of an execution takes

52:26.180 --> 52:28.740
on the order of a thousand times or so,

52:28.740 --> 52:31.580
executing the same thing without a DK proof.

52:31.580 --> 52:33.740
Even though inference is significantly cheaper

52:33.740 --> 52:36.700
than training, execution costs is still very non-trivial.

52:36.700 --> 52:39.340
That's why you need giant GPUs and whatnot,

52:39.340 --> 52:41.220
just to do inference.

52:41.220 --> 52:42.620
The use cases you're thinking of,

52:42.620 --> 52:45.580
are they all things that are like become useful

52:45.580 --> 52:49.180
once we can get the DK proofing costs down by a hundred times?

52:49.180 --> 52:51.460
Or do you think there's some things that are usable

52:51.460 --> 52:54.460
even with that thousand increase in execution costs?

52:54.460 --> 52:57.300
Right now there's already like DK use cases on-chain, right?

52:57.300 --> 53:00.460
And there's equally expensive in the ML lens,

53:00.460 --> 53:04.020
like already proved a hundred million like parameter models

53:04.020 --> 53:05.700
in an inexpensive way, right?

53:05.700 --> 53:07.100
In a usable way, right?

53:07.100 --> 53:09.220
Let's say you have a small convolutional neural network

53:09.220 --> 53:12.500
classifier with 200 million like weights,

53:12.500 --> 53:13.580
like flowing point,

53:13.580 --> 53:16.340
or in this case for a ZKML with field elements,

53:16.340 --> 53:18.820
but you're able to make proofs in reasonable time,

53:18.820 --> 53:21.020
one to two minutes for inference, right?

53:21.020 --> 53:24.540
Where the evaluation of it in the normal world

53:24.540 --> 53:25.700
is a thousand nights less,

53:25.700 --> 53:28.740
two millisecond, 20 millisecond, like point two second,

53:28.740 --> 53:30.340
or 200 million, my bad.

53:30.340 --> 53:32.780
So yeah, like this is like the costly incur,

53:32.780 --> 53:34.740
but it makes sense for some things.

53:34.740 --> 53:36.820
And right now, as I mentioned,

53:36.820 --> 53:38.300
like the things that we're doing could prove the thing,

53:38.300 --> 53:40.140
like cryptography, better implementation,

53:40.140 --> 53:41.900
better hardware, specialized hardware, et cetera,

53:41.900 --> 53:43.620
they're gonna bring down this cost significantly,

53:43.620 --> 53:45.460
it's gonna make more things feasible.

53:45.460 --> 53:47.220
Like now we can maybe prove an LLM,

53:47.220 --> 53:49.140
it may take 10 minutes,

53:49.140 --> 53:51.100
but maybe proving that LLM once

53:51.100 --> 53:54.700
for something that's really important enables a new thing.

53:54.700 --> 53:55.900
And it's always happened like this,

53:55.900 --> 53:57.620
that like the use case and the demand for it

53:57.660 --> 53:59.060
and bring the proving time down,

53:59.060 --> 54:00.580
the overhead down, the performance up,

54:00.580 --> 54:03.060
and we're still like have a bunch of things to do.

54:03.060 --> 54:05.260
So it should work out eventually.

54:06.340 --> 54:07.180
Love it.

54:07.180 --> 54:08.020
Any final words?

54:08.020 --> 54:08.980
How can people find out more?

54:08.980 --> 54:10.300
I know that you said, for example,

54:10.300 --> 54:11.700
there's an announcement coming on soon,

54:11.700 --> 54:13.100
but if people are really excited about this

54:13.100 --> 54:14.300
or they just wanna learn more,

54:14.300 --> 54:17.060
what are any possible action items that people can take?

54:17.060 --> 54:18.220
So action items.

54:18.220 --> 54:20.500
So if you have a specific question about this presentation,

54:20.500 --> 54:22.980
you wanna ask me, I think my Twitter or my Telegram,

54:22.980 --> 54:24.940
or like my ex and my Telegram are the best.

54:24.940 --> 54:27.500
So my handle is DC build 3R.

54:27.540 --> 54:31.820
So DC builder, but with the 3 instead of an E at the end.

54:31.820 --> 54:33.500
So that is for asking me questions.

54:33.500 --> 54:36.660
If you were interested in ZKML itself,

54:36.660 --> 54:40.940
I do have a resource aggregator for ZKML things.

54:40.940 --> 54:43.540
It's on my, or one of my GitHub's,

54:43.540 --> 54:48.540
which is github.com slash ZKML dash community slash

54:48.860 --> 54:50.860
awesome dash ZKML.

54:50.860 --> 54:53.940
I'm able to leave the link in the chat real quick,

54:53.940 --> 54:56.380
but I think like the spelling makes sense.

54:56.420 --> 54:59.380
Besides that, there's a bunch of startups working in ZKML,

54:59.380 --> 55:03.820
mostly like what I mentioned, like Modulus, Giza, and Ezekio.

55:03.820 --> 55:06.940
And these three keep coming out with new developments,

55:06.940 --> 55:08.900
new things, new announcements, et cetera.

55:08.900 --> 55:11.300
There's cryptographic papers coming out on ZKML,

55:11.300 --> 55:13.820
which I also try and keep up to date on my resource.

55:13.820 --> 55:16.900
So yeah, those are like the best ones, I think.

55:17.740 --> 55:18.580
Love it.

55:18.580 --> 55:19.580
And I just saw from Dan that he's bringing

55:19.580 --> 55:21.580
up to our upcoming May workshop though.

55:21.580 --> 55:24.020
If you're going to that one, you may be able to try it.

55:24.020 --> 55:24.980
Hey, thank you so much.

55:24.980 --> 55:26.220
This was really fantastic.

55:26.260 --> 55:27.820
Thanks for staying on three minutes longer.

55:27.820 --> 55:28.740
I really appreciated it.

55:28.740 --> 55:30.380
Thanks for all of your great questions, everyone,

55:30.380 --> 55:31.860
and I hope to see you guys soon.

55:31.860 --> 55:32.700
Bye-bye.

