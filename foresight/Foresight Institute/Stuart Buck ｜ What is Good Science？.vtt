WEBVTT

00:00.000 --> 00:04.800
Hi, everyone. Welcome to Foresight's existential podcast. We're really delighted to have Stuart

00:04.800 --> 00:11.440
Buck here today. We actually met in person at a recent EAG before. I've had heard of you research

00:11.440 --> 00:16.560
before and just booked a call with you or an in-person meeting there. We stumbled over a bunch

00:16.560 --> 00:21.600
of really interesting metascience projects and problems, challenges, and possible solutions,

00:21.600 --> 00:26.320
and then dove into a little bit of perhaps the new emerging landscapes of interesting orgs.

00:26.960 --> 00:30.560
I'll talk to you a little bit about that in the introduction. I'd love to hear from you on

00:30.560 --> 00:34.800
that. I guess we were just ships passing the night itself by Southwest too bad,

00:34.800 --> 00:39.920
but I decided to hopefully next time in person connect you. All right, so maybe just to get

00:39.920 --> 00:44.720
us started, would you want to share a little bit more about good sciences really up to and if you

00:44.720 --> 00:49.920
can also get your journey into the organization? I think that usually helps people like map the

00:49.920 --> 00:55.200
genealogy of your work a bit. Sure. I should start by reminding about 12 years or so.

00:56.080 --> 01:00.080
Around 2012, I went to go work for a place called the Laura and John Arnold Foundation.

01:00.080 --> 01:05.520
It's this major billion-dollar plus philanthropy that focuses a lot on evidence-based policy,

01:05.520 --> 01:08.960
and it's grown a lot since I joined. When I joined, it was pretty new. There were like

01:08.960 --> 01:13.680
eight or 10 people. There are now it's over 100. The scope and the scale of it is really

01:13.680 --> 01:18.000
growing, but right from the start, the Arnold's, who themselves are around 50 years old,

01:18.000 --> 01:23.040
they had retired at 38 and were devoting their wealth to philanthropy. They were mostly interested

01:23.040 --> 01:27.840
in just evidence-based policy across lots of areas like education and criminal justice and health.

01:29.200 --> 01:34.080
One thing that we initially started noticing was the what you call the reproducibility crisis,

01:34.080 --> 01:38.800
the problem of trying to replicate research. We first noticed it in psychology, but I started

01:38.800 --> 01:43.120
digging into it as director of research there. It's a problem in a lot of fields,

01:43.120 --> 01:48.160
including medicine and cancer biology and economics. Pretty much any field you dig into

01:48.160 --> 01:52.000
that turns out there are some issues with replication, sometimes outright fraud.

01:52.960 --> 01:58.320
Just the publication process is often biased towards exciting positive results, which is

01:58.320 --> 02:03.520
natural. We all want to have exciting positive results come out of the scientific world, but

02:03.520 --> 02:08.080
when there's a bias towards that, then people feel compelled to sometimes stretch the truth,

02:08.080 --> 02:12.400
push the boundaries of acceptable practices. The Arnold's decided that if you want to pursue

02:12.400 --> 02:16.320
evidence-based policy, it's really difficult to do that if you're not sure how much you can trust

02:16.320 --> 02:20.800
the evidence, or if you think the evidence has been biased in a positive direction.

02:21.760 --> 02:27.200
Their initial vision of philanthropy had been that they would look to education, for example,

02:27.200 --> 02:32.320
and it would be fairly simple just to find what are the best ideas supported by the best evidence,

02:32.320 --> 02:36.240
and then just write a big check to the best idea, and then it's very simple.

02:36.240 --> 02:39.760
But it turns out it's much more complicated than that if you really start digging into the evidence

02:39.760 --> 02:45.920
as to what works. I started a grant-making program there with the Arnold's money, of

02:45.920 --> 02:52.960
course, focused on open science and reproducibility and trying to improve science. I handed out

02:52.960 --> 02:59.280
probably $60-plus million over several years, and then in the process of that endeavor,

02:59.280 --> 03:03.920
I ran across a guy named Patrick Collison who runs a company called Stripe. I ran into him

03:03.920 --> 03:08.240
several years ago at a conference, and he was very interested in trying to improve science,

03:08.240 --> 03:12.640
but not just reproducibility, but improving innovation, improving the pace of innovation,

03:12.640 --> 03:17.200
the freedom that the best scientists have to explore the universe and explore their best

03:17.200 --> 03:23.440
ideas without having to cater to what funders most desire. So anyway, I introduced him to John

03:23.440 --> 03:29.600
Earl, and we continued conversations, and then a couple of years ago, actually, time has flown.

03:29.600 --> 03:33.920
Actually, it's going on two and a half, almost three years ago. I had some further conversations

03:33.920 --> 03:38.480
with Patrick Collison that led to him being the initial funder for what I'm doing on my own now,

03:38.480 --> 03:42.960
which is a good science project. It's a small, I guess you could say, think tank focused on

03:42.960 --> 03:48.080
trying to improve federal science funding and policy so that we have faster innovation and,

03:48.080 --> 03:53.600
hopefully, more breakthroughs and clean up reproducibility as well. So that's the journey

03:53.600 --> 03:58.320
as to how I got to where I am now. Robert, I think it's always really interesting to hear,

03:58.320 --> 04:02.480
and the individuals involved and so forth, and somewhat of the serendipity in it. Okay,

04:02.480 --> 04:07.120
that's wonderful. Maybe let's dive into a few of the topics that you actually focus on to give

04:07.120 --> 04:11.520
people a little bit of a taste of what you guys are working on. I know that you've published a

04:11.520 --> 04:15.920
lot on Substack, but in other outlets, too, and you sent me a few really interesting docs,

04:15.920 --> 04:20.560
so I just want to jump around here a bit, if you don't mind. And one that I thought was really

04:20.560 --> 04:24.480
interesting and is, of course, has become, I think, a pretty prominent field recently,

04:24.480 --> 04:28.880
is the field of meta science progress, and it's not really necessarily involved with individual

04:28.880 --> 04:33.200
scientific fields. For example, Forsyte was a part specific researchers working on one technology,

04:33.200 --> 04:36.480
but it's really also looking at a broader, with a broader lens of what could be improved

04:36.480 --> 04:40.080
in the ecosystem. And you've written some really interesting stuff there. And so I'd just love

04:40.080 --> 04:44.080
to know, including, for example, how much progress we've made in meta science, but where we could

04:44.080 --> 04:49.600
still speed up progress. And I'd love to get your thoughts on the broader, if you think about

04:49.600 --> 04:53.520
science from this meta lens, like you mentioned reproducibility as one, but what are a few of

04:53.520 --> 04:57.200
the different areas that you think are really holding scientists back right now at producing

04:57.200 --> 05:00.720
the research that we would all want from them? And then perhaps a few recommendations that you

05:00.720 --> 05:05.920
have here. Sure, that's really broad. So I'll just pick one issue that I care about a lot. And

05:06.000 --> 05:10.720
a lot of folks have focused on, and it's really tough to crack down. It's the issue of bureaucracy.

05:10.720 --> 05:15.440
Everyone hates bureaucracy in the abstract. But the problem is that everyone loves bureaucracy

05:15.440 --> 05:21.120
when you point to any particular feature of it. So to take us back, there have been multiple

05:21.120 --> 05:26.560
surveys of federally funded scientists over the past couple of decades. And the most recent survey

05:26.560 --> 05:31.600
surveyed thousands of federally funded scientists. And they said, on average, that they were spending

05:31.600 --> 05:38.480
44% of their time on bureaucracy, basically filing reports and budgets and proposals and

05:38.480 --> 05:44.080
just all the machinery that comes with getting a federal grant. And so everyone points to that

05:44.080 --> 05:48.480
and says, that's a huge problem. We're scientists spending nearly half their time on bureaucracy.

05:48.480 --> 05:54.480
That seems like we're paying people to dig a hole and fill it back in. And as you say,

05:54.480 --> 05:59.200
that's an average. There are some scientists who are fortunate enough to have great administrative

05:59.200 --> 06:04.240
help. And so they don't have personally have to spend as much on the other extreme. I talked to

06:04.240 --> 06:09.920
one scientist at the University of North Carolina, who said that he's probably spent 70% of his time

06:09.920 --> 06:14.960
on bureaucracy, because he said he does animal experiments. And he said that quite frankly,

06:14.960 --> 06:20.080
his administrative help in the department wasn't very good. And so he had to do all the ethics

06:20.080 --> 06:25.360
paperwork himself. And so he felt like his direct quote from him was, I just don't feel like there's

06:25.360 --> 06:29.200
time to do science anymore. And so that seems quite paradoxical. What are we paying people to do

06:29.200 --> 06:33.920
just to fill out reports about the money that we handed them? It just makes no sense. And it's

06:33.920 --> 06:38.400
depressing. No one goes into science thinking they're going to spend 70% of their time filling out

06:38.400 --> 06:43.680
reports and filling out paperwork and et cetera, right? They go into science because they love

06:43.680 --> 06:48.160
a particular field and they want to learn more and they want to make discoveries and so forth.

06:48.160 --> 06:53.120
And it just drains all the excitement out of science. But here's the problem. Every bureaucratic

06:53.200 --> 06:58.480
requirement has some justification for it. There are ethics requirements as to animal

06:58.480 --> 07:01.920
experiments. And those are there for good reasons, because animals can be abused and

07:01.920 --> 07:07.600
can suffer horrifically in experimentation. We've developed a whole set of procedures to protect

07:07.600 --> 07:14.160
animal safety and to protect against unnecessary deaths of animals and so forth.

07:14.160 --> 07:19.920
The same goes for experiments involving human beings. And that's again, thanks to a kind of

07:19.920 --> 07:26.640
horrific history of experimentation done in the 20th century on unsuspecting human subjects that

07:26.640 --> 07:30.880
were mistreated. And so there's a whole set of ethical requirements there so that nobody wants

07:30.880 --> 07:35.920
to get rid of that. It is federal money that's being spent. And so there's going to be some oversight

07:35.920 --> 07:40.560
like the budget and how the money is spent and so forth. Right now, there's a lot of focus on

07:40.560 --> 07:47.920
international security and focus on our researchers unwittingly passing the top technological secrets

07:47.920 --> 07:52.320
to researchers in China. And there's probably that new focus on China and maybe some discrimination

07:52.320 --> 07:57.680
involved. But yeah, it's still a fair consideration. But how much should we fund research that might

07:57.680 --> 08:02.800
unwittingly be used to support a foreign adversary, let's say. So anyway, like any bureaucratic

08:02.800 --> 08:06.480
requirement you point to, someone somewhere is going to say, there's a good reason for that,

08:06.480 --> 08:10.720
right? We need to keep that one. So it's really hard. And the whole is like, that's

08:10.720 --> 08:15.360
by a thousand cuts. But if you point to any one specific bureaucratic requirement, again,

08:16.000 --> 08:18.960
there was a good reason for it. There was some scandal. There was some

08:18.960 --> 08:22.480
problem that someone was trying to solve with this rule, with this procedure.

08:23.200 --> 08:28.320
And so that's why there have been many efforts to get rid of or to try to limit bureaucracy,

08:28.320 --> 08:32.480
but they haven't really gone anywhere. Because what you really need is to have some person,

08:33.040 --> 08:38.880
like with almost, I hate to use this word, but almost dictatorial authority over an agency like

08:38.960 --> 08:45.280
NIH or over an agency like NSF, to just go through the entire bureaucracy and take a red

08:45.280 --> 08:49.840
pen and slash through the stuff that isn't necessary or that isn't the top priority.

08:49.840 --> 08:54.560
And with the objective of, let's say, reducing the burden on scientists time to 20%, let's say,

08:54.560 --> 09:00.000
rather than 44%. And you'd have to have someone who is willing to make some really difficult

09:00.000 --> 09:05.120
tradeoffs and difficult choices and prioritize. We have a thousand things that everyone wants

09:05.120 --> 09:08.720
researchers to do. They'd take up too much of their time. So you're going to have to slash

09:08.720 --> 09:12.400
through some of them that even though they individually, they might sound like a good idea

09:12.400 --> 09:18.880
because you just have to prioritize. So you need someone or some committee that has the power and

09:18.880 --> 09:26.160
the will to actually get rid of some rules and regulations that maybe seem like a good idea.

09:26.160 --> 09:29.520
And that's politically difficult. But I think it's still worth trying because otherwise we're

09:29.520 --> 09:34.880
in a trajectory where ultimately we'll just be paying for 50%, 60% of science at this time.

09:36.160 --> 09:40.240
And it's insanity. Scientists need to have more time to focus on their science.

09:40.800 --> 09:44.320
So that's one of the issues that I've written. But I could dive into many more.

09:45.040 --> 09:48.960
Just to attach on this for a little bit longer, who would be an org that could do this?

09:48.960 --> 09:52.320
Or do you think it would be an individual at each scientific organization? Or could that be

09:52.320 --> 09:56.960
something for the GOA? Or would that be something like scientists writing an open letter about

09:56.960 --> 10:01.280
specific things that they get particularly up about in their research? In terms of thinking about

10:01.280 --> 10:07.680
solutions, if it's not as easy as a science gone coming in and doing it, are there any

10:07.680 --> 10:14.000
pathways that you think are worthwhile exploring? Another challenge is that these rules and regulations

10:14.000 --> 10:19.200
arise from different places. They arise from to dig into the weeds of the American government,

10:19.200 --> 10:26.000
like the Office of Management and Budget, or OMB, that has federal-wide authority to regulate how

10:26.000 --> 10:30.160
federal monies are spent and accounted for. And so they have a lot of budgetary requirements

10:30.160 --> 10:34.400
amongst others. So that's one source. But that's under the control of the White House.

10:34.400 --> 10:38.320
And so the White House could do something about that. Some of the requirements come from agencies

10:38.320 --> 10:44.240
like NIH or NSF themselves. Some requirements come directly from Congress. So Congress mandates

10:44.240 --> 10:49.520
particular practices and says that agencies need to look into X, Y, or Z. Some requirements

10:49.840 --> 10:55.680
honestly come from universities that want to behave conservatively, so to speak. They're

10:55.680 --> 11:00.640
risk averse and they want to make sure that they cross every T and dot every I. And some universities

11:00.640 --> 11:05.920
perhaps over-regulate their own researchers or over-stats their own departments that are in

11:05.920 --> 11:11.920
charge of monitoring and evaluating and submitting budgets and all of that. So yeah, it comes from

11:11.920 --> 11:16.640
many different places. So that's one challenge. I do think the White House could, in theory,

11:16.640 --> 11:21.920
issue an executive order that asked the Office of Management and Budget to review all of its

11:21.920 --> 11:27.520
practices and its rules with the guide towards slashing stuff that hasn't a time requirement

11:27.520 --> 11:32.640
on researchers or the impact on researchers directly. The White House could also review

11:32.640 --> 11:36.960
its past executive orders because some executive... So here's an example. Some of these requirements

11:36.960 --> 11:40.480
come from the White House itself, from prior executive orders. So there was an executive order

11:40.480 --> 11:45.680
in the 1990s signed by President Clinton that says that if you get federal money, you need to

11:45.680 --> 11:51.280
certify that you make people wear seatbelts. And again, it's well-motivated. There was nobody's

11:51.280 --> 11:56.480
really against seatbelts and it's a good idea to probably save some lives perhaps. But some 20,

11:57.120 --> 12:03.120
30, almost 30 years later, with their seatbelt laws in various states and probably anyone who

12:03.120 --> 12:07.200
wears it wants to wear a seatbelt or he does wear a seatbelt. And it's done clear that making

12:07.200 --> 12:13.040
people check that box and on federal applications really does need good. And so you could go back

12:13.040 --> 12:16.800
and look at it through prior executive orders like that and say, look, here's some executive orders

12:16.800 --> 12:22.560
that may have been a nice idea at the time, but we don't need to make everybody at every university

12:22.560 --> 12:26.240
certify that they do everything with a good idea in the world. We can prioritize and say, look,

12:26.240 --> 12:30.880
the time that passed when we needed to investigate whether people use seatbelts. And so there are

12:30.880 --> 12:35.280
probably any number of requirements like that that again, individually, sure, that's fine to make

12:35.280 --> 12:40.400
people wear seatbelts and it's not that much time to check a box. But just in terms of priorities,

12:40.400 --> 12:43.600
we should be able to streamline that. So the White House could, as I say,

12:43.600 --> 12:48.080
go back and look at the requirements that it has come up with over decades and see where it does

12:48.080 --> 12:52.000
streamline. So yeah, I think there are some opportunities that the White House could take

12:52.000 --> 12:56.400
advantage of if they want to. Okay, if anyone relevant is hearing, that feels a little bit

12:56.400 --> 13:00.880
about the action. I also guess like the problem here is almost just getting worse over time just

13:00.880 --> 13:05.040
because like people rarely ever take things out, but they just add to the pile. Like you never

13:05.040 --> 13:10.000
really know how large the pile in total becomes once you start adding stuff to it.

13:10.000 --> 13:13.040
But your individual thing that you want to add to it is really important right now

13:13.040 --> 13:17.360
without considering the entirety of it. So it's definitely, hopefully it's not getting much worse

13:17.360 --> 13:22.880
on the long run. But yeah, okay, that's definitely really important one that I couldn't agree more.

13:22.880 --> 13:27.120
Like riding grants is already complicated enough. And if that is a big one, that's that that could

13:27.120 --> 13:31.040
be an easy one to perhaps cut down on. The other thing that you've also written about really

13:31.040 --> 13:35.840
interestingly is I think on like patents in general. And I think the sub seg post was actually

13:35.840 --> 13:39.680
titled like how we screwing over researchers or something like that. And it had a lead at least

13:39.680 --> 13:43.840
a bit like patent component in there. And that's I guess university targeted to some extent also.

13:43.840 --> 13:47.280
So perhaps you could share a little bit more about what you were addressing there and perhaps even

13:47.280 --> 13:52.640
tell the quick story of Catalina Carrico, if you feel like it. Sure. Yeah. Yeah. I admittedly

13:52.640 --> 13:57.360
chose a kind of provocative title for that article set to hopefully get people to read at least a

13:57.360 --> 14:03.360
little bit to rewind a little bit. There was this famous act in 1980, the Bidol Act that was passed

14:03.360 --> 14:09.440
in the United States. Prior to that, it's complicated. But basically, when NIH NSF, when the federal

14:09.440 --> 14:14.800
government funded research, it would often end up taking control the government itself would end

14:14.800 --> 14:19.440
up taking control of patents arising from that research. And there was this perception that

14:19.440 --> 14:24.320
the government is not the most efficient user of patents. It doesn't know what to do with them.

14:24.400 --> 14:28.720
They weren't being actually used very well or commercialized or turned into

14:28.720 --> 14:33.440
something that was useful for the market, useful for medical patients and so forth.

14:34.080 --> 14:37.680
There's this idea that instead of having the government take control of patents,

14:37.680 --> 14:41.440
let's shift that and have universities take control of patents because universities

14:41.440 --> 14:46.880
are technically the recipients of all the federal grants that come from NIH and NSF, etc.

14:46.880 --> 14:50.640
So the money doesn't go straight to it. We talk about a researcher getting grant, but it doesn't.

14:51.280 --> 14:55.040
The money goes straight to the researcher's pocket, right? It goes to the university. They're

14:55.040 --> 14:59.040
the ones who handle the money, and they pay the researcher, right? So universities are the...

14:59.040 --> 15:06.320
They have a lot of indirect costs. That's a whole separate issue. But yeah, the indirect costs at

15:06.320 --> 15:12.080
top universities are often between 60 and 70%. So what that... And just to clarify what that means,

15:12.080 --> 15:16.320
so if you get a... If you as a researcher get a grant and let's say it's $100 to be simple,

15:17.280 --> 15:21.920
like NIH would give $100 designated for you, the researcher, and they would add

15:21.920 --> 15:26.800
60% on top of that, $60, let's say, as indirect costs to the university. So the total grant would

15:26.800 --> 15:33.360
have to be 160. So the 60% is on top of rather than taken out of. So it's not like... So anyways,

15:33.360 --> 15:37.360
that's just how that works. And by the way, indirect costs are also supporting a lot of

15:37.360 --> 15:42.880
bureaucracy that universities administer. So the bureaucracy issue is tied in to indirect costs.

15:42.880 --> 15:48.560
So anyways, university started patenting. And the story since then has been like, this is a great

15:48.560 --> 15:53.680
success. So until 1980, you had all these patents that were either didn't exist or went unused.

15:53.680 --> 15:58.000
And then afterwards, you have this huge flourishing university-based patents.

15:58.560 --> 16:02.640
And so around 20 years ago, there were a bunch of European countries that also started moving

16:02.640 --> 16:08.000
in that direction and trying to give universities more control over patents. But here's the thing,

16:08.160 --> 16:14.080
in some of those universities, in some of those European countries, the prior rule had not been

16:14.080 --> 16:17.520
that the government controlled the patents. The prior rule had been that the professor or the

16:17.520 --> 16:21.520
researcher controlled the patent. And in fact, they call it professor's privilege in some of

16:21.520 --> 16:26.960
those countries. And so they were switching from in a different direction, right? They were switching

16:26.960 --> 16:32.880
to the US regime that was perceived as successful. But they were switching from completely different

16:32.960 --> 16:38.080
place where the professor or the researcher had more control. And so there's been some empirical

16:38.080 --> 16:43.440
research on that that has shown that when European countries moved in that direction,

16:43.440 --> 16:48.720
the rate of patenting actually went down, which actually doesn't seem too surprising because

16:48.720 --> 16:55.280
universities often are very diffused. They encompass many departments. They may not have

16:55.280 --> 17:00.160
anyone who's a specialist in what one professor is doing and the commercialization of that

17:00.160 --> 17:06.480
research. And so maybe they put less priority overall on trying to commercialize anyone given

17:06.480 --> 17:11.600
discovery or possible patent than the researcher themselves who has more skin in the game, so

17:11.600 --> 17:15.760
to speak. So that's where the empirical evidence seems to lie so far is that it would be better

17:15.760 --> 17:19.600
to give better for innovation, better for patenting, better for commercialization,

17:19.600 --> 17:23.920
to get professors more of a say and perhaps to control over the patents rather than the

17:23.920 --> 17:27.920
universities themselves. Now, this came to a head with Katalin Kiriko, which is the story that I

17:27.920 --> 17:33.200
talked about quite a bit. So she was a Hungarian researcher who came over to the U.S. and worked

17:33.200 --> 17:39.840
at the University of Pennsylvania and got demoted repeatedly at Pennsylvania because she couldn't

17:39.840 --> 17:46.320
get NIH grants to support the work that she was doing on early mRNA research, which at the time

17:46.320 --> 17:50.720
it was not very popular. They weren't further of it now because it turned out to be the basis

17:50.720 --> 17:55.760
of some COVID vaccines. But in the 90s, it wasn't very popular at all. And it was seen as the dead

17:55.760 --> 17:59.840
end for whatever or something that's extremely difficult. It would never work. So she couldn't

17:59.840 --> 18:04.800
get grants to support the work. And the NAS, by the way, opens up a whole other huge topic,

18:04.800 --> 18:10.720
which is the role of NIH money and so-called soft money in universities, soft money, meaning

18:10.720 --> 18:14.560
researchers like Kiriko who were expected to pay for their own salary. It's like they're

18:15.680 --> 18:20.000
they're not given a salary directly by the university or not 100% of their salary. They're

18:20.000 --> 18:24.640
expected to raise their own salary for themselves to their grants. And so that makes them very

18:24.640 --> 18:29.680
dependent on appealing to whatever NIH wants to fund at any given point in time.

18:29.680 --> 18:34.080
So Karen Kiriko was repeatedly demoted and eventually basically pushed out of academia

18:34.080 --> 18:40.880
even after what became a paper that later won her and her co-author the Nobel Prize.

18:40.880 --> 18:44.880
Now, of course, no one knew that at the time. Like Ben, the University of Pennsylvania couldn't

18:44.880 --> 18:49.520
foresee the future. But the University of Pennsylvania did, as I found from reading some

18:49.520 --> 18:54.640
student newspapers from Pennsylvania, they kept the patents on for work, even after pushing her

18:54.640 --> 19:00.880
out of academia. And the student newspaper produced a chart like the universities across

19:00.880 --> 19:04.960
the country and how much money they're making royalties from patents. And the University of

19:04.960 --> 19:10.960
Pennsylvania was far and away, making many times more money than Stanford or other universities

19:10.960 --> 19:16.160
that you might think of as hotbeds of discovery and technological advancement.

19:16.160 --> 19:21.440
And so Pennsylvania made something like over a billion dollars in one recent year from the

19:21.440 --> 19:25.920
Fed with vaccines and from the patents on apparently from the patents on Kiriko's research,

19:25.920 --> 19:29.840
even though she's long gone from Penn and they not only didn't help with her research,

19:29.840 --> 19:33.120
they drove her out of academia. So things like this kind of glaring

19:33.760 --> 19:39.200
unfairness and on top of the inefficiency process. So yeah, I think that's an area that yeah, I

19:39.200 --> 19:43.760
think definitely deserves some reform or at least some really detailed, I think Congress

19:43.760 --> 19:48.720
definitely should fund or require some really detailed investigations of what is even happening

19:48.720 --> 19:52.800
at these university offices that are supposed to be patenting, researching, commercializing it.

19:52.800 --> 19:58.640
How many patents go unrealized or uncommercialized? How many take too long? There are lots of

19:58.640 --> 20:03.120
anecdotal complaints at certain universities that the process takes too long and the university

20:03.120 --> 20:09.680
demands too much of a cut. I think it'd be better to have a more systematic kind of investigation

20:09.680 --> 20:14.400
to add to the anecdotal stories. But in any event, I think I do think that the story from

20:14.400 --> 20:18.720
Europe or the empirical evidence from Europe shows that it might be better to move back in the

20:18.720 --> 20:23.360
direction of giving the professor or the researcher more of a say in what happens to their own

20:23.360 --> 20:26.720
discoveries. Yeah, it's crazy when you think about it, it's almost like all the incentives

20:26.720 --> 20:32.640
that are wrong. It's a few, right? But like, why even, how to come up with that type of system

20:32.640 --> 20:37.920
in the first place, I think. But yeah, I think I love that there is this almost not really an

20:37.920 --> 20:42.640
A-B testing, but at least some precedent of how it used to possibly work better and that that was

20:42.640 --> 20:47.760
useful to go back into that. You already mentioned one of the bits on funding and with the kind of

20:47.760 --> 20:53.120
like soft support from the NIH. And so I think another really interesting, super detailed analysis

20:53.120 --> 20:58.560
that you've done is specifically on NIH reform. You list a full laundry list there of things

20:58.560 --> 21:02.880
that could be improved with the NIH. And I don't think we get through all of them. I think accounting

21:03.840 --> 21:08.640
is almost 10. And we already touched on them individually. But when you think about the

21:08.640 --> 21:13.920
the NIH, what are like a few kind of crucial areas that you yourself are perhaps really excited about

21:13.920 --> 21:18.480
and promoting that there could be possibly a good reform applied to the NIH?

21:19.680 --> 21:24.480
Sure. I think there are any number of ideas, as you say. I think one thing the NIH should

21:24.480 --> 21:30.160
consider using more is an approach called basically fund the person, not the project.

21:30.800 --> 21:35.840
Now, it's interesting. There is a program at one of the NIH institutes called the National

21:35.840 --> 21:40.560
Institute for General Medical Sciences, NIGMS. And if you're wondering what that is,

21:40.560 --> 21:44.400
because many folks might, I did when I first started it. It's basically the NIH Institute

21:44.400 --> 21:50.880
that funds basic research as opposed to National Cancer Institute, focuses on cancer, the National

21:50.880 --> 21:56.400
Heart, Lung and Blood Institute that focuses on the cardiovascular disease, etc. NIGMS is focused

21:56.400 --> 22:03.280
on truly basic science that's not necessarily connected to any one specific disease like some

22:03.280 --> 22:09.680
of the other NIH institutes are. So NIGMS has this program called Maximizing Investigators

22:09.680 --> 22:17.280
Research Awards, M-I-R-A, and they pronounce it Mira. And this program is really intended to give

22:17.280 --> 22:21.920
researchers more flexibility and freedom to give them funding for several years where they don't

22:21.920 --> 22:27.360
have to spend as much time trying to pre-specify everything that they're going to do and then

22:27.360 --> 22:31.360
report back on what they said they were going to do three years ago or four years ago,

22:31.360 --> 22:37.040
instead it's intended to give them more freedom to follow the science and to follow their nose,

22:37.040 --> 22:43.280
so to speak, as to what the best ideas are at any given point. And I think that there's some

22:43.280 --> 22:49.840
evidence that the papers produced by that are performing equally as well or better in terms

22:49.840 --> 22:55.040
of citations. That's only one very limited metric, I think longer term you would want to see a rate of

22:55.680 --> 22:59.920
breakthrough discoveries. And that's hard to see because you can't expect a breakthrough every

22:59.920 --> 23:06.000
day from everyone. That's impossible. And as the director of NIGMS, John Lorsch has said,

23:06.000 --> 23:09.600
if I knew where the next breakthrough was going to come from, I would have already made that

23:09.600 --> 23:15.040
discovery myself. So part of his idea of funding is that you want to spread the money widely

23:15.040 --> 23:19.280
amongst talented scientists and give them the freedom and who knows where the next breakthrough

23:19.360 --> 23:24.000
will come from. Especially with basic science, often there's any number of stories from basic

23:24.000 --> 23:28.560
science where a discovery will be made in one decade and then three decades later it turns out

23:28.560 --> 23:34.240
that it's amazingly useful or influential. But yeah, I think that's a good example of a program

23:34.240 --> 23:38.720
that's experimental at NIH in the sense that it's a new thing. It's still fairly new. It's been

23:38.720 --> 23:44.800
around for a few years. I think that program could be expanded to other institutes at NIH like

23:44.800 --> 23:48.960
National Cancer Institute. And there are other institutes that have a version of this, but it's

23:48.960 --> 23:55.840
much smaller. NIGMS funds this type of grant four times as much when I last reviewed the numbers.

23:55.840 --> 24:00.720
Four times as much as the rest of NIH put together. Huge imbalance. NIGMS is very much focused on

24:00.720 --> 24:06.320
this for basic science, but I think you could try that approach elsewhere at NIH. And again,

24:06.320 --> 24:11.040
with the idea of giving scientists more flexibility and freedom. And here's another key idea that

24:11.040 --> 24:16.080
was in the document I sent you, which is NIH should take a more deliberate approach to

24:16.080 --> 24:21.040
experimenting and learning from what it does. Take a very meta science approach instead of just

24:21.040 --> 24:24.800
starting up new programs and saying, all right, everybody's going to do this. Then you don't

24:24.800 --> 24:30.160
have as much of a chance to learn and to iterate and to introduce deliberate experimentation.

24:30.160 --> 24:35.680
NIH is big enough that you could do like the literal randomized experiments and how you hand

24:35.680 --> 24:42.560
out money. They'd fund something like 90,000 grants at any given point in time. There's 90,000

24:42.560 --> 24:48.000
grants and each grant often supports multiple researchers. So I'm not sure the exact total,

24:48.640 --> 24:53.680
but it's hundreds of thousands of researchers that are supported by NIH. That's plenty of

24:53.680 --> 24:58.160
opportunity. So you could do a randomized trial that involved a thousand researchers,

24:58.160 --> 25:04.000
and that would be a drop in the bucket from what NIH supports. And you could randomize 500 to be

25:04.080 --> 25:10.400
funded in one way, 500 to be funded in a different way, and they just fold over time and see what

25:10.400 --> 25:15.840
happens. See what are the results from funding that offers more flexibility and freedom versus the

25:15.840 --> 25:20.240
more usual way that NIH does things. And I think that kind of deliberate experimentation

25:20.240 --> 25:25.280
is something that NIH should do at all. They've really ripped on that.

25:25.280 --> 25:29.440
Yeah, I think on your last point, it's really interesting just to hop back on the kind of

25:29.440 --> 25:33.920
funding people, not projects that is somewhat also pretty present right now, I guess in the

25:33.920 --> 25:37.520
private space where I think, for example, the Lieberman Brothers, they're now launching a new

25:37.520 --> 25:41.840
effort to actually fund individuals early on before basically making bets early on and almost

25:41.840 --> 25:46.080
invest into individuals like you invest in companies. And I think that kind of at least that

25:46.080 --> 25:52.400
meme or that new approach should also hopefully extrapolate outward through different and perhaps

25:52.400 --> 25:55.680
even scientific funding organizations. I think that would be wonderful. I think.

25:56.240 --> 25:59.840
I'd like the parallel to venture capital because I mean, I think there are a lot of,

25:59.840 --> 26:05.360
any number of, again, statements or examples of venture capitalists who say, yeah, you're making

26:05.360 --> 26:11.200
a bet on the person. There are many examples where a founder of a company ends up pivoting and doing

26:11.200 --> 26:16.400
something slightly different or a lot different. And venture capitalists often are happy with that

26:16.400 --> 26:19.920
because you're trying something and you realize it didn't work and now you found something that

26:19.920 --> 26:26.480
did work. And if you would be unthinkable to go to, I don't know, to go to Mark Zuckerberg and say,

26:26.480 --> 26:30.240
wait a minute, like your original proposal said that you were going to do X, Y, and Z and said

26:30.240 --> 26:35.920
that you were going to spend $5,000 in year three on this line item and where it shows that you

26:35.920 --> 26:40.560
spent the money that way. You would never want that level of micro management of a talented

26:40.560 --> 26:45.200
entrepreneur. Okay, students want to give them a little more freedom and flexibility to adapt to

26:45.200 --> 26:50.320
the market in which we should treat a lot more scientists the same way that you should give

26:50.320 --> 26:56.800
them the same respect and autonomy that entrepreneurs routinely have and give them the freedom of

26:56.800 --> 27:02.400
flexibility to say, wait a minute, I said I was going to do X, Y, and Z, but I tried it and it

27:02.400 --> 27:07.440
didn't work and I came up with a better idea the next year and now I'm going to want to do the better

27:07.440 --> 27:12.080
idea. Of course, we should all follow the better idea when that comes up. Yeah, I guess. Otherwise,

27:12.160 --> 27:15.280
you just assume that people aren't learning as they're actually in the field and then

27:15.280 --> 27:19.200
fermenting and dropping things. It's a crazy assumption to make in the first place, I think.

27:20.560 --> 27:25.520
The process should be about learning and changing and adapting to new ideas of the MLA. That's

27:25.520 --> 27:29.200
a bold point. If you already knew what you were going to do five years from now,

27:29.680 --> 27:35.280
I think it's, I'm paraphrasing, but well, one scientist that I know at Pennsylvania as well,

27:35.280 --> 27:39.040
he said, if I'm doing what I said I was going to do five years ago, I should be fired because I

27:39.040 --> 27:44.000
should have warranted and adapted in that book. Yeah, I love it. We only got to a small part of

27:44.000 --> 27:47.600
the laundry list that you have for the NIH, including other misopryptonies and stuff, but I

27:47.600 --> 27:51.760
think I want to close at least my part of the podcast with a question perhaps a little bit on

27:51.760 --> 27:57.040
a hopeful note to already lean into the extension whole part of the podcast after, but we have

27:57.040 --> 28:01.520
briefly touched on when we met and you've also pointed out again afterwards that there's actually

28:01.520 --> 28:08.160
now a really cool new landscape emerging of these alternative possible homes for researchers and

28:08.160 --> 28:13.360
scientists. I think there's FROs, there's Future House, Park Institute, Astera, Spectac, there's

28:13.360 --> 28:18.160
a few really interesting new orgs that have been popping up and we certainly had a few founders

28:18.160 --> 28:22.240
and executive directors of these orgs already on here for podcasts and for individual topics,

28:22.240 --> 28:26.240
but could you share a little bit of how you see that landscape changing and what these new organizations

28:26.240 --> 28:30.160
are setting out to do and perhaps what we can hope for in the minutes? We don't have to cover all

28:30.160 --> 28:35.040
of them, but just the general spirit, a great idea. And you could add to that some, there's

28:35.040 --> 28:40.640
some government agency, surprisingly enough. There's a health version of DARPA, so it's called

28:40.640 --> 28:45.280
ARPA-H, which I'm sure any listeners are familiar with, but yeah, it's intended to be like a

28:46.160 --> 28:51.120
government agency that has the innovative approach that DARPA and it's taken for decades.

28:51.120 --> 28:55.360
And there's a version of that in the UK as well called ARIA, also trying to be like the

28:56.320 --> 28:59.920
imitator of DARPA in a way. I think that's all tremendously hopeful. I do think it's

28:59.920 --> 29:04.640
hardly borne out of discontent with the current system, but as I say, it tends to be

29:05.520 --> 29:10.720
very bureaucratic and very top-heavy and a system in which it's hard to get a

29:10.720 --> 29:16.480
foothold, the average age for NIH, the first major NIH grant is so we're making people like

29:16.480 --> 29:22.960
slave away in other people's labs for 15 years before they finally get a foothold as a researcher.

29:22.960 --> 29:26.880
And so they're long past the age, which a lot of people in previous generations did some of

29:26.880 --> 29:30.720
their best scientific work. Einstein made some of his greatest discoveries at age 25, and so

29:30.720 --> 29:34.480
I think Newton, James Watson, there's any number of examples of that kind of thing.

29:35.600 --> 29:40.000
So there's a lot of discontent with that system. And so there are people within government and

29:40.000 --> 29:44.960
private philanthropists who say this is an opportunity to diversify the landscape,

29:44.960 --> 29:50.080
to come up with new ways, hopefully better ways of doing science and of funding science and of

29:50.080 --> 29:56.640
organizing science, all very important meta science issues. And so one thing that I really

29:56.640 --> 30:02.480
hope we're able to do, we being just collective meta science community and policymakers over the

30:02.480 --> 30:09.120
next five to 10 years, is just really deliberately learn from what all these new organizations

30:09.120 --> 30:15.680
have produced and do it in a systematic way. I do think possibly one risk, like any new

30:15.680 --> 30:21.120
organizations, like just the same as universities, their temptation is going to be to send out

30:21.120 --> 30:26.240
press releases about all the amazing things they've done and brag about that. And that's fine,

30:26.240 --> 30:30.880
that's to be expected, and often that's even true. But there will be cases in which they fail,

30:30.880 --> 30:35.360
and I think it's important to learn from failure, and it's important to be public about that.

30:35.360 --> 30:40.880
And so I think hopefully over time, we can have a meta science discussion that's able to have

30:40.880 --> 30:46.800
just a truly honest appraisal of what's working, what has failed, and failure isn't a bad thing.

30:46.800 --> 30:50.160
We should learn from not everything that's going to work for the first try. Let's learn

30:50.160 --> 30:55.760
about how to design organizations more efficiently or with more perfectly going forwards.

30:55.840 --> 30:59.680
And so I think that's where I hope the conversation goes for the next five to 10 years.

30:59.680 --> 31:05.440
Yeah, thank you for that. So yeah, so this part is more like the philosophical part. We've been

31:05.440 --> 31:10.640
talking about the meta science and everything, but it's diving into the sort of existential hope

31:10.640 --> 31:15.200
aspects of where science and the progress of it can take us. You touched on it now,

31:15.200 --> 31:18.800
but I would be really curious to hear, do you feel like things are changing? Are you gaining

31:18.800 --> 31:24.400
traction with this? Yeah, I do think things are changing. Again, we just touched on that with all

31:24.400 --> 31:31.200
the proliferation of new organizations, both inside government and outside government. I think

31:31.200 --> 31:40.000
that's a really helpful sign. And again, my hope is that over time, there should really be a diversity

31:40.000 --> 31:45.520
of approaches and organizations that probably something that will be bad for science is to

31:45.520 --> 31:53.360
say everybody has to fit in the exact same box. That probably isn't good, even if the box makes

31:53.360 --> 31:58.960
sense, so to speak. So we talked about fund the person, not the project. That seems like a good

31:58.960 --> 32:04.960
idea. And we should use it sometimes. But I think if literally 100% of science funding was fund the

32:04.960 --> 32:08.880
person, not the project, there probably be some failure points there as well. There probably be

32:08.880 --> 32:14.080
some things that got missed. There are probably some examples where you should fund an organization,

32:14.080 --> 32:19.120
like fund a team, not the person. So there are lots of different approaches one could use.

32:19.200 --> 32:23.920
And in fact, in some areas of science, the Large Shader and Collider or big astrophysics

32:23.920 --> 32:28.640
efforts, you're not funding one person, you're funding like a team of 1000 people. You know what

32:28.640 --> 32:33.200
I mean? Yeah, if you want to approach this to science and to science funding, I think would

32:33.200 --> 32:39.760
probably be suboptimal. But I do think that hopefully going forward, I think one thing that

32:39.760 --> 32:46.560
could help improve the pace of innovation is having a more deliberately diverse approach

32:46.560 --> 32:51.440
in like how we fund science and the source of people to get funded, and so forth. And

32:51.440 --> 32:55.680
when I say the source of people to get funded, that's also an interesting point to emphasize.

32:56.320 --> 33:00.720
There are lots and lots of examples from history where great scientific advances come from places

33:00.720 --> 33:05.040
that sometimes you wouldn't necessarily have expected or they come from people that were

33:05.600 --> 33:10.960
heretics at their time, Semmelweis and the germ theory of disease, like people despise them at

33:10.960 --> 33:15.680
the time. There are tons of examples like that. It doesn't mean we should, again, we don't want

33:15.680 --> 33:19.840
a science funding system that only funds people that are outcasts and heretics. That probably would

33:19.840 --> 33:24.080
be in the wrong direction too. But I do think there should be some space within science,

33:24.080 --> 33:29.440
like a National Institute for Oddball. We should have a deliberate approach to fund some things

33:29.440 --> 33:34.800
that are outside the box. And now some of them will be crazy and won't work. We might end up

33:34.800 --> 33:38.720
funding some of the greatest breakthroughs ever if we've made more space within the scientific

33:38.720 --> 33:43.040
funding system or people with truly outside the box ideas and approaches that don't get funded

33:43.280 --> 33:50.720
correctly. Yeah, I remember I was talking to an economist, I think, Johan Nurebe,

33:51.280 --> 33:57.360
about he was talking about how technology often progresses. It comes from quite dirty areas or

33:57.360 --> 34:02.880
not necessarily the most appreciated ones. I think his example was the technology of online

34:02.880 --> 34:08.000
payment solutions coming from porn, like people wanting to watch porn online and that was like

34:08.000 --> 34:13.360
what are online payment solutions? And now that's a very useful and established thing.

34:13.360 --> 34:17.920
And I'm sure there are more exciting scientific innovations that came from the not the most

34:17.920 --> 34:25.040
appreciated areas maybe. Yeah, but it sounds like you're positive and you're optimistic.

34:25.040 --> 34:27.360
Would you say that you're optimistic about the future?

34:28.480 --> 34:33.920
That is a big question. In general, yes, I think that there's lots of possibilities. There's

34:33.920 --> 34:38.240
dangers as well. We've both kind of, I think I've met you in an effective algorithm conference.

34:38.240 --> 34:45.360
There are certainly areas like nuclear proliferation or biosecurity or artificial

34:45.360 --> 34:52.480
general intelligence. There are some areas of potential R&D advancement that do possibly have

34:52.480 --> 34:57.600
some risk and some would say existential risk. But I think the theme of your podcast existential

34:57.920 --> 35:04.240
right is that hopefully with the broad sweep of innovation and improvement that we can address

35:04.240 --> 35:09.280
those existential risks and that we can hopefully still keep progressing and making life better

35:09.280 --> 35:14.400
for everyone. And so I think that's where I guess my hopes and efforts would lie is like trying to

35:14.400 --> 35:20.320
figure out what we're doing wrong, all the ways in which we're holding back scientists and science

35:20.320 --> 35:27.040
itself and figuring out ways to hopefully speed up and accelerate the pace of innovation. I think

35:27.040 --> 35:34.000
that does offer more hope for the future. Yeah. I'd be interested to hear in relation to the

35:34.000 --> 35:39.280
like increasing pace of progress on like in relation to maybe AI in specific,

35:39.280 --> 35:42.640
do you see the science landscape shifting due to that?

35:44.720 --> 35:53.600
Due to AI in general, I haven't looked at it that much in depth. There are some really amazing

35:53.600 --> 35:57.440
advances that have been made, for example, AlphaFold and protein folding. There are other

35:57.440 --> 36:03.520
similar tools that are like that that offer the potential to speed up at least some components

36:03.520 --> 36:10.640
of science. I'm less certain myself with what I've seen out of large language models so far. It

36:10.640 --> 36:15.840
seems like they have, they sometimes show science a great sophistication, but then sometimes they

36:16.480 --> 36:21.680
like just completely hallucinate, at least the ones to date. And so I'm a little nervous about

36:21.760 --> 36:25.840
that. You could end up with kind of pollution of the scientific literature with people using

36:25.840 --> 36:30.720
AI models to write papers thinking this will help them publish more and then it'll end up on

36:30.720 --> 36:36.960
live somewhere and might be largely fake or largely just made up or hallucinated. Another

36:36.960 --> 36:41.840
thing that I worry about, and this is born out of the work that I did while I was at the Arnold

36:41.840 --> 36:48.080
Foundation, a lot of the published literature just isn't that good. Some of it's outright fraudulent

36:48.880 --> 36:53.120
and there are more discoveries about academic broad that come out, it seems, every week.

36:53.120 --> 36:57.760
A lot of it isn't that reproducible. And even the stuff that is reproducible, it often isn't

36:57.760 --> 37:02.960
described that well in print. So one thing that I funded, for example, was called the

37:02.960 --> 37:08.320
Reproducibility Project in Cancer Biology. And their original idea was to replicate

37:08.320 --> 37:14.240
the experiments from 50 top-sided cancer biology papers. And ultimately, they could only complete

37:14.320 --> 37:20.080
fewer than half of their intended experiments. And the reason was that in every single case,

37:20.080 --> 37:24.320
you couldn't just go off the publish paper. You had to go back to the original lab and ask them

37:24.320 --> 37:28.560
to fill in all the gaps and fill in all the details about what they had actually done.

37:28.560 --> 37:33.040
And some of the original labs were not cooperative at all. In some cases, just were

37:33.040 --> 37:39.440
hostile. Some cases just said, we're not sure. And when they worked for operative,

37:39.440 --> 37:44.800
the answer was always that you need twice as much materials as you expected. And so it's

37:44.800 --> 37:49.040
going to cost more and take longer. And they're like, worry about AI models that might be

37:49.680 --> 37:56.960
trained on scientific literature as if what's written down on paper is the complete entry.

37:56.960 --> 38:02.240
And that's often not the case. And you just worry that might spiral into even more

38:02.240 --> 38:07.920
irreproducible work. So again, cautiously optimistic about some of the specialized tools

38:07.920 --> 38:14.720
that are out there that are based on like really rigorous systematic databases. But then

38:14.720 --> 38:18.560
there's a whole wealth or a whole broad millions and millions of scientific articles

38:19.200 --> 38:25.200
that I would say probably aren't worth trying to use in an AI model in the first place or at

38:25.200 --> 38:29.120
least with great skepticism and a lot less of corrections needed before you just

38:29.920 --> 38:33.760
train an AI model and expect to get useful information out of it. So it's all over the

38:33.760 --> 38:38.400
place. But yes, that's my answer for now. Yeah, that's very interesting. I hadn't really thought

38:38.400 --> 38:44.720
about that in relation to that it would get access to like maybe incorrect data technically.

38:44.720 --> 38:48.880
But yeah, I guess that I heard about the Center for Open Science and that's like

38:49.440 --> 38:54.640
where they try to pre-register the studies that they're doing so that you can actually check if

38:54.640 --> 39:00.800
they are correct in that they're reproducible or that that oftentimes you don't really publish

39:01.760 --> 39:05.520
what's maybe not like an exciting result or something like that. But here you can see what

39:05.520 --> 39:10.880
people have published or have been doing research on even if the results aren't like that exciting.

39:10.880 --> 39:16.960
Any other like projects like that that you think are promising or seem like they could

39:16.960 --> 39:21.920
actually make a difference in this field? Yeah, there's a lot of directions I could take this. So

39:22.960 --> 39:27.440
the idea of pre-registration really came out of medicine from some recommendations that were

39:27.440 --> 39:32.080
made. And I think it was early the late 1980s or definitely by the early 90s, there were some

39:32.080 --> 39:36.640
folks writing about it, the idea in medicine. These folks in medicine, they were trying to do

39:36.640 --> 39:41.760
meta research in medicine to try to summarize the whole body of literature. And as of the 90s,

39:42.800 --> 39:46.880
probably still true somewhat today. They were very frustrated. And I remember an article

39:46.880 --> 39:51.440
by a couple of folks at the time where they said that it's just really strange to them that you

39:51.440 --> 39:57.040
can find much more information on baseball statistics and up to the minute information

39:57.040 --> 40:01.120
about every baseball team, every baseball player, everything they've ever done. But yes,

40:01.120 --> 40:05.200
it's impossible to find that information about clinical trials, that much wealth of information

40:05.200 --> 40:10.960
about clinical trials in medicine, which is to them more important than baseball. So pre-registration

40:10.960 --> 40:16.080
was in part a way to get access to information about the trials that are being conducted

40:16.960 --> 40:23.280
on human beings and involving drugs or other types of treatments that might be used in medicine.

40:23.280 --> 40:28.640
That was one motivation for me to still be able to see the kind of see the whole denominator,

40:28.640 --> 40:32.560
so to speak. It's easy to see the published successes and the press releases of announcing

40:32.560 --> 40:38.400
that a drug will cure in the US, the commercial that say try this drug. But it's harder to find

40:38.400 --> 40:43.280
the failure since the idea of pre-registration in part was intended to address that. And then

40:43.280 --> 40:48.720
like subsequently, I guess you're able to like what there was one famous article by kind of

40:48.720 --> 40:54.960
Eric Turner and some colleagues where they reviewed something like 70 or 80 clinical trials

40:54.960 --> 41:00.320
that have been done on antidepressants. And I'm going off a memory here, so I might get a number

41:00.320 --> 41:04.880
slightly wrong, but roughly half of the trials showed that the antidepressants work and roughly

41:04.880 --> 41:09.920
half of the trials showed no results. The antidepressant wasn't any better than placebo.

41:09.920 --> 41:15.120
And they had access to all this because of both pre-registration and because they went to the FDA

41:15.120 --> 41:19.440
and these were FDA-free drugs and the FDA demands to see all the evidence and not just

41:19.440 --> 41:23.360
what got in the top journal. So you have the whole denominator there to look at.

41:23.360 --> 41:28.000
And so what they found was that basically all of the positive trials, I think except one,

41:28.000 --> 41:34.240
got published in a top journal. And the negative trials or the null trials mostly went unpublished,

41:34.240 --> 41:40.000
but I think a few of them were published and then with a kind of spin or misrepresentation

41:40.000 --> 41:44.480
as if they've been positive studies. And so yeah, if you look at the medical literature,

41:44.480 --> 41:49.040
and this is also back to what I was saying about AI, if you looked at just the medical literature

41:49.040 --> 41:52.880
on those antidepressants, you would say, wow, that'll work. Everything's amazing. But if you

41:52.880 --> 41:56.480
look at the whole body of evidence that the FDA could look at, you would say sometimes they work,

41:56.480 --> 42:00.320
sometimes they don't own or sometimes the one medicine is better than others. It's a lot more

42:00.320 --> 42:04.480
complicated and messy when you have all the evidence sitting before you. Yeah, there have been

42:04.480 --> 42:09.360
efforts like that in medicine. Pre-registration has been growing in other disciplines, psychology and

42:09.360 --> 42:15.120
economics in particular over the past 10 years or so. The American Economics Association, like

42:15.120 --> 42:20.560
the Center for International Science, started demanding pre-registration about 10 years ago,

42:21.360 --> 42:26.960
and the rate at which that happened on a yearly basis that's gone up within economics alone.

42:26.960 --> 42:31.680
Yeah, I think that's all kind of hopeful signs of progress in different fields, just being better

42:31.680 --> 42:37.120
practices about being public about what kinds of studies you're doing. And then ultimately,

42:37.680 --> 42:43.440
it's kind of all for not unless you publicize the failures and the nor results as well. Because

42:43.440 --> 42:47.600
again, if you only publish the positive results and don't say anything publicly about the negative

42:47.600 --> 42:52.000
results, it's very skewed. It'd be like if you flip a coin and then you only announce when you flip

42:52.000 --> 42:57.520
the heads. Yeah, you would look like you'd flip 100% heads, but that wouldn't be true. So be very

42:57.520 --> 43:06.240
misleading. Yeah, I'm going to make a bit of a turn with the next question now, which is it's a

43:06.240 --> 43:11.440
question that we always ask in this podcast, which is in relation to the like AU catastrophe. So

43:11.440 --> 43:16.640
it's a term that means basically the opposite of a catastrophe. So once it's happened, the value of

43:16.640 --> 43:23.200
the world would be much higher. And feel free to relate this question to like your area of expertise

43:23.200 --> 43:29.600
within science. And I think also think ambitiously when I ask you this question, which is if you

43:29.600 --> 43:36.160
could envision like a specific you could have for the progress of science, what would that be?

43:36.160 --> 43:41.680
What would be an existential hope scenario of science? If you like, if all the work that you're

43:41.680 --> 43:48.560
doing now came true, what would happen? That's great. Yeah, I first came across that word,

43:48.560 --> 43:53.360
you catastrophe and the writings of JR Volkian. Did he invent the word? I can't remember. Yeah,

43:53.360 --> 43:59.760
I believe he did. Yeah, it's a long time. Yeah, that's that is a super interesting question.

43:59.760 --> 44:05.120
The kind of revolutionary side of me says that in terms of meta science, what would be really cool

44:05.120 --> 44:11.920
is if you could duplicate all federal funding of science, but with an entirely new set of

44:11.920 --> 44:18.080
institutions. Imagine we spend 50 billion or so on NIH, what if we add in an extra 50 billion on

44:18.080 --> 44:22.560
biomedical research? Or with the condition that it has to be run completely differently

44:22.640 --> 44:27.200
from NIH, and it has to be in the hands of different people. And again, touching on these

44:27.200 --> 44:34.160
ideas of exploiting the and proliferating the diversity of the approaches and the scientists

44:34.160 --> 44:38.400
that get funded and the ways in which funding is handed out, because then you have two different

44:38.400 --> 44:43.440
systems operating. And so thinking very meta here, you have two different systems operating

44:43.440 --> 44:48.000
with equal amounts of funding. And now you can really see at a grand scale, hopefully,

44:48.000 --> 44:52.800
what happens? What are the results? It would be a chance to test out lots of different meta

44:52.800 --> 44:58.560
science ideas that people have discussed for years or for decades, but you just really need

44:58.560 --> 45:04.880
a kind of the grand landscape in which to experiment with that. So again, that's very meta,

45:04.880 --> 45:11.360
but my hope would be that we learn a lot about how to fund science and how to organize scientists

45:11.360 --> 45:16.720
into organizations, into labs and universities. We need entirely different institutions that

45:16.720 --> 45:21.040
are not don't look anything like universities, for example, maybe you should maybe you should

45:21.040 --> 45:24.960
set up a whole national institute where the rule is you can only fund scientists who are

45:24.960 --> 45:29.200
working out of their garage. I don't know, it just you need some kind of like wild ideas out

45:29.200 --> 45:34.240
there to try out different approaches, different scientists, different ideas. And my hope would

45:34.240 --> 45:39.360
be that at a minimum, we'd learn something from that. And but in terms of existential hope, I think

45:39.360 --> 45:45.120
we we might end up creating a number of great breakthroughs that wouldn't have happened otherwise.

45:45.120 --> 45:52.400
And today is hot, heavy, bureaucratic system that is so conformist and so focused on doing

45:52.400 --> 45:55.920
whatever gets you approval from the kind of the existing bureaucracy.

45:57.920 --> 46:07.520
Yeah, I really, really like that. It's if you like were to introduce someone who is entirely

46:07.520 --> 46:12.640
new to this field, is there anything you'd recommend that they like read or watch? Maybe it's

46:12.640 --> 46:16.640
just your own sub stack? Or is there anything else that you would recommend for an intro to the

46:16.640 --> 46:22.640
field? Sure, the writings that Good Science Project has produced are good points to look at.

46:22.640 --> 46:26.880
You mentioned the Center for Open Science, they've had a number of publications and projects that

46:26.880 --> 46:31.520
are related to meta science. I would say that there's more stuff coming out from the Institute

46:31.520 --> 46:35.600
for Progress and the Federation of American Scientists, they've had a series of papers on

46:35.600 --> 46:40.800
open science, for example. Yeah, that might be that gives you plenty of reading to start with.

46:41.360 --> 46:48.000
That sounds like a great place to start. And how can listeners best stay updated with your work

46:48.000 --> 46:52.400
and the work of the Good Science Project? Sure, you mentioned sub stack, it's just

46:52.400 --> 46:59.520
goodscience.substack.com. Also, the website is just goodscienceproject.org. And yeah,

47:00.560 --> 47:05.440
we'll have to hear from folks who have ideas or enjoy the writings and want to learn more.

47:05.600 --> 47:12.080
Great. Thank you so much, Stuart, for coming on this podcast. We really appreciate it and

47:12.080 --> 47:15.840
we'll definitely keep an eye on all the work that you're doing with the Good Science Project

47:15.840 --> 47:18.080
in the future. So thank you so much.

